<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2018-01-29T03:29:21Z</responseDate>
<request verb="ListRecords" resumptionToken="2369777|121001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02424</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Parameter Estimation Techniques for Induction Motors using
  Hybrid Algorithms</dc:title>
 <dc:creator>Susanto, Julius</dc:creator>
 <dc:creator>Islam, Syed</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The performance of Newton-Raphson, Levenberg-Marquardt, Damped Newton-Raphson
and genetic algorithms are investigated for the estimation of induction motor
equivalent circuit parameters from commonly available manufacturer data. A new
hybrid algorithm is then proposed that combines the advantages of both descent
and natural optimisation algorithms. Through computer simulation, the hybrid
algorithm is shown to significantly outperform the conventional algorithms in
terms of convergence and squared error rates. All of the algorithms are tested
on a large data set of 6,380 IEC (50Hz) and NEMA (60Hz) motors.
</dc:description>
 <dc:date>2017-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02424</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02426</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Attack-Tolerant Networks: Concurrent Multipath Routing and the
  Butterfly Network</dc:title>
 <dc:creator>Platt, Edward L.</dc:creator>
 <dc:creator>Romero, Daniel M.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Targeted attacks against network infrastructure are notoriously difficult to
guard against. In the case of communication networks, such attacks can leave
users vulnerable to censorship and surveillance, even when cryptography is
used. Much of the existing work on network fault-tolerance focuses on random
faults and does not apply to adversarial faults (attacks). Centralized networks
have single points of failure by definition, leading to a growing popularity in
decentralized architectures and protocols for greater fault-tolerance. However,
centralized network structure can arise even when protocols are decentralized.
Despite their decentralized protocols, the Internet and World-Wide Web have
been shown both theoretically and historically to be highly susceptible to
attack, in part due to emergent structural centralization. When single points
of failure exist, they are potentially vulnerable to non-technological (i.e.,
coercive) attacks, suggesting the importance of a structural approach to
attack-tolerance. We show how the assumption of partial trust transitivity,
while more realistic than the assumption underlying webs of trust, can be used
to quantify the effective redundancy of a network as a function of trust
transitivity. We also prove that the effective redundancy of the wrap-around
butterfly topology increases exponentially with trust transitivity and describe
a novel concurrent multipath routing algorithm for constructing paths to
utilize that redundancy. When portions of network structure can be dictated our
results can be used to create scalable, attack-tolerant infrastructures. More
generally, our results provide a theoretical formalism for evaluating the
effects of network structure on adversarial fault-tolerance.
</dc:description>
 <dc:date>2017-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02426</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02427</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gathering in Dynamic Rings</dc:title>
 <dc:creator>Di Luna, Giuseppe Antonio</dc:creator>
 <dc:creator>Flocchini, Paola</dc:creator>
 <dc:creator>Pagli, Linda</dc:creator>
 <dc:creator>Prencipe, Giuseppe</dc:creator>
 <dc:creator>Santoro, Nicola</dc:creator>
 <dc:creator>Viglietta, Giovanni</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The gathering problem requires a set of mobile agents, arbitrarily positioned
at different nodes of a network to group within finite time at the same
location, not fixed in advanced.
  The extensive existing literature on this problem shares the same fundamental
assumption: the topological structure does not change during the rendezvous or
the gathering; this is true also for those investigations that consider faulty
nodes. In other words, they only consider static graphs. In this paper we start
the investigation of gathering in dynamic graphs, that is networks where the
topology changes continuously and at unpredictable locations.
  We study the feasibility of gathering mobile agents, identical and without
explicit communication capabilities, in a dynamic ring of anonymous nodes; the
class of dynamics we consider is the classic 1-interval-connectivity.
  We focus on the impact that factors such as chirality (i.e., a common sense
of orientation) and cross detection (i.e., the ability to detect, when
traversing an edge, whether some agent is traversing it in the other
direction), have on the solvability of the problem. We provide a complete
characterization of the classes of initial configurations from which the
gathering problem is solvable in presence and in absence of cross detection and
of chirality. The feasibility results of the characterization are all
constructive: we provide distributed algorithms that allow the agents to
gather. In particular, the protocols for gathering with cross detection are
time optimal. We also show that cross detection is a powerful computational
element.
  We prove that, without chirality, knowledge of the ring size is strictly more
powerful than knowledge of the number of agents; on the other hand, with
chirality, knowledge of n can be substituted by knowledge of k, yielding the
same classes of feasible initial configurations.
</dc:description>
 <dc:date>2017-04-07</dc:date>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02427</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02431</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Cross-Modal Deep Representations for Robust Pedestrian
  Detection</dc:title>
 <dc:creator>Xu, Dan</dc:creator>
 <dc:creator>Ouyang, Wanli</dc:creator>
 <dc:creator>Ricci, Elisa</dc:creator>
 <dc:creator>Wang, Xiaogang</dc:creator>
 <dc:creator>Sebe, Nicu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a novel method for detecting pedestrians under adverse
illumination conditions. Our approach relies on a novel cross-modality learning
framework and it is based on two main phases. First, given a multimodal
dataset, a deep convolutional network is employed to learn a non-linear
mapping, modeling the relations between RGB and thermal data. Then, the learned
feature representations are transferred to a second deep network, which
receives as input an RGB image and outputs the detection results. In this way,
features which are both discriminative and robust to bad illumination
conditions are learned. Importantly, at test time, only the second pipeline is
considered and no thermal data are required. Our extensive evaluation
demonstrates that the proposed approach outperforms the state-of- the-art on
the challenging KAIST multispectral pedestrian dataset and it is competitive
with previous methods on the popular Caltech dataset.
</dc:description>
 <dc:description>Comment: Accepted at CVPR 2017</dc:description>
 <dc:date>2017-04-07</dc:date>
 <dc:date>2018-01-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02431</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02432</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Race Prediction in Linear Time</dc:title>
 <dc:creator>Kini, Dileep</dc:creator>
 <dc:creator>Mathur, Umang</dc:creator>
 <dc:creator>Viswanathan, Mahesh</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:description>  Writing reliable concurrent software remains a huge challenge for today's
programmers. Programmers rarely reason about their code by explicitly
considering different possible inter-leavings of its execution. We consider the
problem of detecting data races from individual executions in a sound manner.
The classical approach to solving this problem has been to use Lamport's
happens-before (HB) relation. Until now HB remains the only approach that runs
in linear time. Previous efforts in improving over HB such as causally-precedes
(CP) and maximal causal models fall short due to the fact that they are not
implementable efficiently and hence have to compromise on their race detecting
ability by limiting their techniques to bounded sized fragments of the
execution. We present a new relation weak-causally-precedes (WCP) that is
provably better than CP in terms of being able to detect more races, while
still remaining sound. Moreover it admits a linear time algorithm which works
on the entire execution without having to fragment it.
</dc:description>
 <dc:description>Comment: 22 pages, 8 figures, 1 algorithm, 1 table</dc:description>
 <dc:date>2017-04-07</dc:date>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02432</dc:identifier>
 <dc:identifier>doi:10.1145/3140587.3062374</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02436</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximation Algorithms for Barrier Sweep Coverage</dc:title>
 <dc:creator>Gorain, Barun</dc:creator>
 <dc:creator>Mandal, Partha Sarathi</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Time-varying coverage, namely sweep coverage is a recent development in the
area of wireless sensor networks, where a small number of mobile sensors sweep
or monitor comparatively large number of locations periodically. In this
article we study barrier sweep coverage with mobile sensors where the barrier
is considered as a finite length continuous curve on a plane. The coverage at
every point on the curve is time-variant. We propose an optimal solution for
sweep coverage of a finite length continuous curve. Usually energy source of a
mobile sensor is battery with limited power, so energy restricted sweep
coverage is a challenging problem for long running applications. We propose an
energy restricted sweep coverage problem where every mobile sensors must visit
an energy source frequently to recharge or replace its battery. We propose a
$\frac{13}{3}$-approximation algorithm for this problem. The proposed algorithm
for multiple curves achieves the best possible approximation factor 2 for a
special case. We propose a 5-approximation algorithm for the general problem.
As an application of the barrier sweep coverage problem for a set of line
segments, we formulate a data gathering problem. In this problem a set of
mobile sensors is arbitrarily monitoring the line segments one for each. A set
of data mules periodically collects the monitoring data from the set of mobile
sensors. We prove that finding the minimum number of data mules to collect data
periodically from every mobile sensor is NP-hard and propose a 3-approximation
algorithm to solve it.
</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02438</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coordination game in bidirectional flow</dc:title>
 <dc:creator>Yanagisawa, Daichi</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We have introduced evolutionary game dynamics to a one-dimensional
cellular-automaton to investigate evolution and maintenance of cooperative
avoiding behavior of self-driven particles in bidirectional flow. In our model,
there are two kinds of particles, which are right-going particles and
left-going particles. They often face opponent particles, so that they swerve
to the right or left stochastically in order to avoid conflicts. The particles
reinforce their preferences of the swerving direction after their successful
avoidance. The preference is also weakened by memory-loss effect.
  Result of our simulation indicates that cooperative avoiding behavior is
achieved, i.e., swerving directions of the particles are unified, when the
density of particles is close to 1/2 and the memory-loss rate is small.
Furthermore, when the right-going particles occupy the majority of the system,
we observe that their flow increases when the number of left-going particles,
which prevent the smooth movement of right-going particles, becomes large. It
is also investigated that the critical memory-loss rate of the cooperative
avoiding behavior strongly depends on the size of the system. Small system can
prolong the cooperative avoiding behavior in wider range of memory-loss rate
than large system.
</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02438</dc:identifier>
 <dc:identifier>Collective Dynamics, 1, A8:1-14, 2016</dc:identifier>
 <dc:identifier>doi:10.17815/CD.2016.8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02440</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Audit Analysis Models, Security Frameworks and Their Relevance for VoIP</dc:title>
 <dc:creator>Gavilanez, Oscar</dc:creator>
 <dc:creator>Gavilanez, Franklin</dc:creator>
 <dc:creator>Rodriguez, Glen</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>K.6.5</dc:subject>
 <dc:description>  Voice over IP (VoIP) is the transmission of voice and multimedia content over
Internet Protocol (IP) networks, this paper reviews models, frameworks and
auditing standards proposed to this date to manage VoIP security through a
literature review, with descriptions of both the historical and philosophical
evolution reflecting an adequate knowledge of related research. Three research
questions are raised here: RQ1. What are the requirements to be met by a model
of security audit in VoIP systems to achieve their goals? RQ2. Today, are there
additional attacks that previous works have not considered? RQ3. Which security
requirements in the VoIP systems are covered (and which are not covered) by
security frameworks? After some discussion about VoIP Protocols, Attacks on
VoIP, Information Technology (IT) audit, IT security audits, Frameworks and
auditing standards, we present a unified view of VoIP Security Requirements; as
well as considering the contributions and disadvantages of frameworks and
auditing standards toward achieving those requirements through a comparative
evaluation. It was determined that there is no security framework which
considers social engineering attacks in spite of being an important aspect to
consider in security management VoIP; also there is no specific framework that
covers all categories of security requirements for VoIP system, therefore, a
more extensive model is needed.
</dc:description>
 <dc:description>Comment: 12th International Conference on Cyber Warfare and Security - ICCWS
  2017, At Dayton, USA</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02440</dc:identifier>
 <dc:identifier>Proceedings of the 12th International Conference on Cyber Warfare
  and Security - ICCWS 2017, pp.143-151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02441</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ontologies for Network Security and Future Challenges</dc:title>
 <dc:creator>Velasco, Danny</dc:creator>
 <dc:creator>Rodriguez, Glen</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>K.6.5</dc:subject>
 <dc:description>  Efforts have been recently made to construct ontologies for network security.
The proposed ontologies are related to specific aspects of network security.
Therefore, it is necessary to identify the specific aspects covered by existing
ontologies for network security. A review and analysis of the principal issues,
challenges, and the extent of progress related to distinct ontologies was
performed. Each example was classified according to the typology of the
ontologies for network security. Some aspects include identifying threats,
intrusion detection systems (IDS), alerts, attacks, countermeasures, security
policies, and network management tools. The research performed here proposes
the use of three stages: 1. Inputs; 2. Processing; and 3. Outputs. The analysis
resulted in the introduction of new challenges and aspects that may be used as
the basis for future research. One major issue that was discovered identifies
the need to develop new ontologies that relate to distinct aspects of network
security, thereby facilitating management tasks.
</dc:description>
 <dc:description>Comment: 12th International Conference on Cyber Warfare and Security - ICCWS
  2017, At Dayton, USA</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02441</dc:identifier>
 <dc:identifier>Proceedings of the 12th International Conference on Cyber Warfare
  and Security - ICCWS 2017, pp.541-547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02445</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exact 3D seismic data reconstruction using Tubal-Alt-Min algorithm</dc:title>
 <dc:creator>Qian, Feng</dc:creator>
 <dc:creator>Chen, Quan</dc:creator>
 <dc:creator>Su, Ming-Jun</dc:creator>
 <dc:creator>Hu, Guang-Min</dc:creator>
 <dc:creator>Liu, Xiao-Yang</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Data missing is an common issue in seismic data, and many methods have been
proposed to solve it. In this paper, we present the low-tubal-rank tensor model
and a novel tensor completion algorithm to recover 3D seismic data. This is a
fast iterative algorithm, called Tubal-Alt-Min which completes our 3D seismic
data by exploiting the low-tubal-rank property expressed as the product of two
much smaller tensors. TubalAlt-Min alternates between estimating those two
tensor using least squares minimization. We evaluate its reconstruction
performance both on synthetic seismic data and land data survey. The
experimental results show that compared with the tensor nuclear norm
minimization algorithm, Tubal-Alt-Min improves the reconstruction error by
orders of magnitude.
</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02445</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02446</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Seismic facies recognition based on prestack data using deep
  convolutional autoencoder</dc:title>
 <dc:creator>Qian, Feng</dc:creator>
 <dc:creator>Yin, Miao</dc:creator>
 <dc:creator>Su, Ming-Jun</dc:creator>
 <dc:creator>Wang, Yaojun</dc:creator>
 <dc:creator>Hu, Guangmin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Prestack seismic data carries much useful information that can help us find
more complex atypical reservoirs. Therefore, we are increasingly inclined to
use prestack seismic data for seis- mic facies recognition. However, due to the
inclusion of ex- cessive redundancy, effective feature extraction from prestack
seismic data becomes critical. In this paper, we consider seis- mic facies
recognition based on prestack data as an image clus- tering problem in computer
vision (CV) by thinking of each prestack seismic gather as a picture. We
propose a convo- lutional autoencoder (CAE) network for deep feature learn- ing
from prestack seismic data, which is more effective than principal component
analysis (PCA) in redundancy removing and valid information extraction. Then,
using conventional classification or clustering techniques (e.g. K-means or
self- organizing maps) on the extracted features, we can achieve seismic facies
recognition. We applied our method to the prestack data from physical model and
LZB region. The re- sult shows that our approach is superior to the
conventionals.
</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02446</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02447</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards 3D Human Pose Estimation in the Wild: a Weakly-supervised
  Approach</dc:title>
 <dc:creator>Zhou, Xingyi</dc:creator>
 <dc:creator>Huang, Qixing</dc:creator>
 <dc:creator>Sun, Xiao</dc:creator>
 <dc:creator>Xue, Xiangyang</dc:creator>
 <dc:creator>Wei, Yichen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we study the task of 3D human pose estimation in the wild.
This task is challenging due to lack of training data, as existing datasets are
either in the wild images with 2D pose or in the lab images with 3D pose.
  We propose a weakly-supervised transfer learning method that uses mixed 2D
and 3D labels in a unified deep neutral network that presents two-stage
cascaded structure. Our network augments a state-of-the-art 2D pose estimation
sub-network with a 3D depth regression sub-network. Unlike previous two stage
approaches that train the two sub-networks sequentially and separately, our
training is end-to-end and fully exploits the correlation between the 2D pose
and depth estimation sub-tasks. The deep features are better learnt through
shared representations. In doing so, the 3D pose labels in controlled lab
environments are transferred to in the wild images. In addition, we introduce a
3D geometric constraint to regularize the 3D pose prediction, which is
effective in the absence of ground truth depth labels. Our method achieves
competitive results on both 2D and 3D benchmarks.
</dc:description>
 <dc:description>Comment: Accepted to ICCV 2017</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02447</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02450</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coupled Deep Learning for Heterogeneous Face Recognition</dc:title>
 <dc:creator>Wu, Xiang</dc:creator>
 <dc:creator>Song, Lingxiao</dc:creator>
 <dc:creator>He, Ran</dc:creator>
 <dc:creator>Tan, Tieniu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Heterogeneous face matching is a challenge issue in face recognition due to
large domain difference as well as insufficient pairwise images in different
modalities during training. This paper proposes a coupled deep learning (CDL)
approach for the heterogeneous face matching. CDL seeks a shared feature space
in which the heterogeneous face matching problem can be approximately treated
as a homogeneous face matching problem. The objective function of CDL mainly
includes two parts. The first part contains a trace norm and a block-diagonal
prior as relevance constraints, which not only make unpaired images from
multiple modalities be clustered and correlated, but also regularize the
parameters to alleviate overfitting. An approximate variational formulation is
introduced to deal with the difficulties of optimizing low-rank constraint
directly. The second part contains a cross modal ranking among triplet domain
specific images to maximize the margin for different identities and increase
data for a small amount of training samples. Besides, an alternating
minimization method is employed to iteratively update the parameters of CDL.
Experimental results show that CDL achieves better performance on the
challenging CASIA NIR-VIS 2.0 face recognition database, the IIIT-D Sketch
database, the CUHK Face Sketch (CUFS), and the CUHK Face Sketch FERET (CUFSF),
which significantly outperforms state-of-the-art heterogeneous face recognition
methods.
</dc:description>
 <dc:description>Comment: AAAI 2018</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02450</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02453</identifier>
 <datestamp>2017-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consistent Approval-Based Multi-Winner Rules</dc:title>
 <dc:creator>Lackner, Martin</dc:creator>
 <dc:creator>Skowron, Piotr</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  This paper is an axiomatic study of consistent approval-based multi-winner
rules, i.e., voting rules that select a fixed-size group of candidates based on
approval ballots. We introduce the class of counting rules, provide an
axiomatic characterization of this class and, in particular, show that counting
rules are consistent. Building upon this result, we axiomatically characterize
three important consistent multi-winner rules: Proportional Approval Voting,
Multi-Winner Approval Voting and the Approval Chamberlin--Courant rule. Our
results demonstrate the variety of multi-winner rules and illustrate three
different, orthogonal principles that multi-winner voting rules may represent:
excellence, diversity, and proportionality.
</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:date>2017-07-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02453</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02455</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Pseudo-color Technique Based on Intensity Information Protection
  for Passive Sensor Imagery</dc:title>
 <dc:creator>Khosravi, Mohammad Reza</dc:creator>
 <dc:creator>Rostami, Habib</dc:creator>
 <dc:creator>Ahmadi, Gholam Reza</dc:creator>
 <dc:creator>Mansouri, Suleiman</dc:creator>
 <dc:creator>Keshavarz, Ahmad</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Remote sensing image processing is so important in geo-sciences. Images which
are obtained by different types of sensors might initially be unrecognizable.
To make an acceptable visual perception in the images, some pre-processing
steps (for removing noises and etc) are preformed which they affect the
analysis of images. There are different types of processing according to the
types of remote sensing images. The method that we are going to introduce in
this paper is to use virtual colors to colorize the gray-scale images of
satellite sensors. This approach helps us to have a better analysis on a sample
single-band image which has been taken by Landsat-8 (OLI) sensor (as a
multi-band sensor with natural color bands, its images' natural color can be
compared to synthetic color by our approach). A good feature of this method is
the original image reversibility in order to keep the suitable resolution of
output images.
</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02455</dc:identifier>
 <dc:identifier>International Journal of Electronics Communication and Computer
  Engineering, vol. 6, no. 3, pp. 324-329 (2015)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02457</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BLASFEO: basic linear algebra subroutines for embedded optimization</dc:title>
 <dc:creator>Frison, Gianluca</dc:creator>
 <dc:creator>Kouzoupis, Dimitris</dc:creator>
 <dc:creator>Sartor, Tommaso</dc:creator>
 <dc:creator>Zanelli, Andrea</dc:creator>
 <dc:creator>Diehl, Moritz</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  BLASFEO is a dense linear algebra library providing high-performance
implementations of BLAS- and LAPACK-like routines for use in embedded
optimization. A key difference with respect to existing high-performance
implementations of BLAS is that the computational performance is optimized for
small to medium scale matrices, i.e., for sizes up to a few hundred. BLASFEO
comes with three different implementations: a high-performance implementation
aiming at providing the highest performance for matrices fitting in cache, a
reference implementation providing portability and embeddability and optimized
for very small matrices, and a wrapper to standard BLAS and LAPACK providing
high-performance on large matrices. The three implementations of BLASFEO
together provide high-performance dense linear algebra routines for matrices
ranging from very small to large. Compared to both open-source and proprietary
highly-tuned BLAS libraries, for matrices of size up to about one hundred the
high-performance implementation of BLASFEO is about 20-30% faster than the
corresponding level 3 BLAS routines and 2-3 times faster than the corresponding
LAPACK routines.
</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:date>2018-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02457</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02463</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>First-Person Hand Action Benchmark with RGB-D Videos and 3D Hand Pose
  Annotations</dc:title>
 <dc:creator>Garcia-Hernando, Guillermo</dc:creator>
 <dc:creator>Yuan, Shanxin</dc:creator>
 <dc:creator>Baek, Seungryul</dc:creator>
 <dc:creator>Kim, Tae-Kyun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work we study the use of 3D hand poses to recognize first-person hand
actions interacting with 3D objects. Towards this goal, we collected RGB-D
video sequences of more than 100K frames of 45 daily hand action categories,
involving 25 different objects in several hand grasp configurations. To obtain
high quality hand pose annotations from real sequences, we used our own mo-cap
system that automatically infers the location of each of the 21 joints of the
hand via 6 magnetic sensors on the finger tips and the inverse-kinematics of a
hand model. To the best of our knowledge, this is the first benchmark for RGB-D
hand action sequences with 3D hand poses. Additionally, we recorded the 6D
(i.e. 3D rotations and locations) object poses and provide 3D object models for
a subset of hand-object interaction sequences. We present extensive
experimental evaluations of RGB-D and pose-based action recognition by 18
baselines/state-of-the-art. The impact of using appearance features, poses and
their combinations are measured, and the different training/testing protocols
including cross-persons are evaluated. Finally, we assess how ready the current
hand pose estimation is when hands are severely occluded by objects in
egocentric views and its influence on action recognition. From the results, we
see clear benefits of using hand pose as a cue for action recognition compared
to other data modalities. Our dataset and experiments can be of interest to
communities of 6D object pose, robotics, and 3D hand pose estimation as well as
action recognition.
</dc:description>
 <dc:description>Comment: Dataset can be visualized here: https://youtu.be/U5gleNWjz44</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02463</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02468</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Basic Formal Properties of A Relational Model of The Mathematical Theory
  of Evidence</dc:title>
 <dc:creator>K&#x142;opotek, Mieczys&#x142;aw A.</dc:creator>
 <dc:creator>Wierzcho&#x144;, S&#x142;awomir T.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The paper presents a novel view of the Dempster-Shafer belief function as a
measure of diversity in relational data bases. It is demonstrated that under
the interpretation The Dempster rule of evidence combination corresponds to the
join operator of the relational database theory. This rough-set based
interpretation is qualitative in nature and can represent a number of belief
function operators.
  The interpretation has the property that Given a definition of the belief
measure of objects in the interpretation domain we can perform operations in
this domain and the measure of the resulting object is derivable from measures
of component objects via belief operator. We demonstrated this property for
Dempster rule of combination, marginalization, Shafer's conditioning,
independent variables, Shenoy's notion of conditional independence of
variables.
  The interpretation is based on rough sets (in connection with decision
tables), but differs from previous interpretations of this type in that it
counts the diversity rather than frequencies in a decision table.
</dc:description>
 <dc:description>Comment: 23 pages</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02468</dc:identifier>
 <dc:identifier>This is the preliminary version of the paper published in
  Demonstratio Mathematica. Vol XXXI No 3,1998, pp. 669-688</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02470</identifier>
 <datestamp>2017-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DSLR-Quality Photos on Mobile Devices with Deep Convolutional Networks</dc:title>
 <dc:creator>Ignatov, Andrey</dc:creator>
 <dc:creator>Kobyshev, Nikolay</dc:creator>
 <dc:creator>Timofte, Radu</dc:creator>
 <dc:creator>Vanhoey, Kenneth</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Despite a rapid rise in the quality of built-in smartphone cameras, their
physical limitations - small sensor size, compact lenses and the lack of
specific hardware, - impede them to achieve the quality results of DSLR
cameras. In this work we present an end-to-end deep learning approach that
bridges this gap by translating ordinary photos into DSLR-quality images. We
propose learning the translation function using a residual convolutional neural
network that improves both color rendition and image sharpness. Since the
standard mean squared loss is not well suited for measuring perceptual image
quality, we introduce a composite perceptual error function that combines
content, color and texture losses. The first two losses are defined
analytically, while the texture loss is learned in an adversarial fashion. We
also present DPED, a large-scale dataset that consists of real photos captured
from three different phones and one high-end reflex camera. Our quantitative
and qualitative assessments reveal that the enhanced image quality is
comparable to that of DSLR-taken photos, while the methodology is generalized
to any type of digital camera.
</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:date>2017-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02470</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02484</identifier>
 <datestamp>2017-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase limitations of Zames-Falb multipliers</dc:title>
 <dc:creator>Wang, Shuai</dc:creator>
 <dc:creator>Carrasco, Joaquin</dc:creator>
 <dc:creator>Heath, William P.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Phase limitations of both continuous-time and discrete-time Zames-Falb
multipliers and their relation with the Kalman conjecture are analysed. A phase
limitation for continuous-time multipliers given by Megretski is generalised
and its applicability is clarified; its relation to the Kalman conjecture is
illustrated with a classical example from the literature. It is demonstrated
that there exist fourth-order plants where the existence of a suitable
Zames-Falb multiplier can be discarded and for which simulations show unstable
behavior. A novel phase-limitation for discrete-time Zames-Falb multipliers is
developed. Its application is demonstrated with a second-order counterexample
to the Kalman conjecture. Finally, the discrete-time limitation is used to show
that there can be no direct counterpart of the off-axis circle criterion in the
discrete-time domain.
</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:date>2017-07-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02484</dc:identifier>
 <dc:identifier>doi:10.1109/TAC.2017.2729162</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02489</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analyzing Social Interaction Networks from Twitter for Planned Special
  Events</dc:title>
 <dc:creator>Sadri, Arif Mohaimin</dc:creator>
 <dc:creator>Hasan, Samiul</dc:creator>
 <dc:creator>Ukkusuri, Satish V.</dc:creator>
 <dc:creator>Lopez, Juan Esteban Suarez</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The complex topology of real networks allows its actors to change their
functional behavior. Network models provide better understanding of the
evolutionary mechanisms being accountable for the growth of such networks by
capturing the dynamics in the ways network agents interact and change their
behavior. Considerable amount of research efforts is required for developing
novel network modeling techniques to understand the structural properties such
networks, reproducing similar properties based on empirical evidence, and
designing such networks efficiently. First, we demonstrate how to construct
social interaction networks using social media data and then present the key
findings obtained from the network analytics. We analyze the characteristics
and growth of such interaction networks, examine the network properties and
derive important insights based on the theories of network science literature.
We also discuss the application of such networks as a useful tool to
effectively disseminate targeted information during planned special events. We
observed that the degree-distributions of such networks follow power-law that
is indicative of the existence of fewer nodes in the network with higher levels
of interactions, and many other nodes with less interactions. While the network
elements and average user degree grow linearly each day, densities of such
networks tend to become zero. Largest connected components exhibit higher
connectivity (density) when compared with the whole graph. Network radius and
diameter become stable over time evidencing the small-world property. We also
observe increased transitivity and higher stability of the power-law exponents
as the networks grow. Data is specific to the Purdue University community and
two large events, namely Purdue Day of Giving and Senator Bernie Sanders' visit
to Purdue University as part of Indiana Primary Election 2016.
</dc:description>
 <dc:description>Comment: 20 pages, 6 figures, 1 table. arXiv admin note: text overlap with
  arXiv:1704.01706</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02489</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02492</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Metric Learning in Codebook Generation of Bag-of-Words for Person
  Re-identification</dc:title>
 <dc:creator>Tian, Lu</dc:creator>
 <dc:creator>Wang, Shengjin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Person re-identification is generally divided into two part: first how to
represent a pedestrian by discriminative visual descriptors and second how to
compare them by suitable distance metrics. Conventional methods isolate these
two parts, the first part usually unsupervised and the second part supervised.
The Bag-of-Words (BoW) model is a widely used image representing descriptor in
part one. Its codebook is simply generated by clustering visual features in
Euclidian space. In this paper, we propose to use part two metric learning
techniques in the codebook generation phase of BoW. In particular, the proposed
codebook is clustered under Mahalanobis distance which is learned supervised.
Extensive experiments prove that our proposed method is effective. With several
low level features extracted on superpixel and fused together, our method
outperforms state-of-the-art on person re-identification benchmarks including
VIPeR, PRID450S, and Market1501.
</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02492</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02497</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Linearity of Semantic Change: Investigating Meaning Variation via
  Dynamic Graph Models</dc:title>
 <dc:creator>Eger, Steffen</dc:creator>
 <dc:creator>Mehler, Alexander</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We consider two graph models of semantic change. The first is a time-series
model that relates embedding vectors from one time period to embedding vectors
of previous time periods. In the second, we construct one graph for each word:
nodes in this graph correspond to time points and edge weights to the
similarity of the word's meaning across two time points. We apply our two
models to corpora across three different languages. We find that semantic
change is linear in two senses. Firstly, today's embedding vectors (= meaning)
of words can be derived as linear combinations of embedding vectors of their
neighbors in previous time periods. Secondly, self-similarity of words decays
linearly in time. We consider both findings as new laws/hypotheses of semantic
change.
</dc:description>
 <dc:description>Comment: Published at ACL 2016, Berlin (short papers)</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02497</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02510</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DualGAN: Unsupervised Dual Learning for Image-to-Image Translation</dc:title>
 <dc:creator>Yi, Zili</dc:creator>
 <dc:creator>Zhang, Hao</dc:creator>
 <dc:creator>Tan, Ping</dc:creator>
 <dc:creator>Gong, Minglun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Conditional Generative Adversarial Networks (GANs) for cross-domain
image-to-image translation have made much progress recently. Depending on the
task complexity, thousands to millions of labeled image pairs are needed to
train a conditional GAN. However, human labeling is expensive, even
impractical, and large quantities of data may not always be available. Inspired
by dual learning from natural language translation, we develop a novel dual-GAN
mechanism, which enables image translators to be trained from two sets of
unlabeled images from two domains. In our architecture, the primal GAN learns
to translate images from domain U to those in domain V, while the dual GAN
learns to invert the task. The closed loop made by the primal and dual tasks
allows images from either domain to be translated and then reconstructed. Hence
a loss function that accounts for the reconstruction error of images can be
used to train the translators. Experiments on multiple image translation tasks
with unlabeled data show considerable performance gain of DualGAN over a single
GAN. For some tasks, DualGAN can even achieve comparable or slightly better
results than conditional GAN trained on fully labeled data.
</dc:description>
 <dc:description>Comment: Accepted by ICCV 2017</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02510</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02515</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Balanced $k$-Center Clustering When $k$ Is A Constant</dc:title>
 <dc:creator>Ding, Hu</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  The problem of constrained $k$-center clustering has attracted significant
attention in the past decades. In this paper, we study balanced $k$-center
cluster where the size of each cluster is constrained by the given lower and
upper bounds. The problem is motivated by the applications in processing and
analyzing large-scale data in high dimension. We provide a simple nearly linear
time $4$-approximation algorithm when the number of clusters $k$ is assumed to
be a constant. Comparing with existing method, our algorithm improves the
approximation ratio and significantly reduces the time complexity. Moreover,
our result can be easily extended to any metric space.
</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02515</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02516</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Empirical Evaluation of Visual Question Answering for Novel Objects</dc:title>
 <dc:creator>Ramakrishnan, Santhosh K.</dc:creator>
 <dc:creator>Pal, Ambar</dc:creator>
 <dc:creator>Sharma, Gaurav</dc:creator>
 <dc:creator>Mittal, Anurag</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We study the problem of answering questions about images in the harder
setting, where the test questions and corresponding images contain novel
objects, which were not queried about in the training data. Such setting is
inevitable in real world-owing to the heavy tailed distribution of the visual
categories, there would be some objects which would not be annotated in the
train set. We show that the performance of two popular existing methods drop
significantly (up to 28%) when evaluated on novel objects cf. known objects. We
propose methods which use large existing external corpora of (i) unlabeled
text, i.e. books, and (ii) images tagged with classes, to achieve novel object
based visual question answering. We do systematic empirical studies, for both
an oracle case where the novel objects are known textually, as well as a fully
automatic case without any explicit knowledge of the novel objects, but with
the minimal assumption that the novel objects are semantically related to the
existing objects in training. The proposed methods for novel object based
visual question answering are modular and can potentially be used with many
visual question answering architectures. We show consistent improvements with
the two popular architectures and give qualitative analysis of the cases where
the model does well and of those where it fails to bring improvements.
</dc:description>
 <dc:description>Comment: 11 pages, 4 figures, accepted in CVPR 2017 (poster)</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02516</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02518</identifier>
 <datestamp>2017-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Generative Adversarial Compression Artifact Removal</dc:title>
 <dc:creator>Galteri, Leonardo</dc:creator>
 <dc:creator>Seidenari, Lorenzo</dc:creator>
 <dc:creator>Bertini, Marco</dc:creator>
 <dc:creator>Del Bimbo, Alberto</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Compression artifacts arise in images whenever a lossy compression algorithm
is applied. These artifacts eliminate details present in the original image, or
add noise and small structures; because of these effects they make images less
pleasant for the human eye, and may also lead to decreased performance of
computer vision algorithms such as object detectors. To eliminate such
artifacts, when decompressing an image, it is required to recover the original
image from a disturbed version. To this end, we present a feed-forward fully
convolutional residual network model trained using a generative adversarial
framework. To provide a baseline, we show that our model can be also trained
optimizing the Structural Similarity (SSIM), which is a better loss with
respect to the simpler Mean Squared Error (MSE). Our GAN is able to produce
images with more photorealistic details than MSE or SSIM based networks.
Moreover we show that our approach can be used as a pre-processing step for
object detection in case images are degraded by compression to a point that
state-of-the art detectors fail. In this task, our GAN method obtains better
performance than MSE or SSIM trained networks.
</dc:description>
 <dc:description>Comment: ICCV 2017 Camera Ready + Acknowledgements</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:date>2017-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02518</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02525</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Density-equalizing maps for simply-connected open surfaces</dc:title>
 <dc:creator>Choi, Gary P. T.</dc:creator>
 <dc:creator>Rycroft, Chris H.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Mathematics - Differential Geometry</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  In this paper, we are concerned with the problem of creating flattening maps
of simply-connected open surfaces in $\mathbb{R}^3$. Using a natural principle
of density diffusion in physics, we propose an effective algorithm for
computing density-equalizing flattening maps with any prescribed density
distribution. By varying the initial density distribution, a large variety of
mappings with different properties can be achieved. For instance,
area-preserving parameterizations of simply-connected open surfaces can be
easily computed. Experimental results are presented to demonstrate the
effectiveness of our proposed method. Applications to data visualization and
surface remeshing are explored.
</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02525</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02532</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Reinforcement Learning framework for Autonomous Driving</dc:title>
 <dc:creator>Sallab, Ahmad El</dc:creator>
 <dc:creator>Abdou, Mohammed</dc:creator>
 <dc:creator>Perot, Etienne</dc:creator>
 <dc:creator>Yogamani, Senthil</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Reinforcement learning is considered to be a strong AI paradigm which can be
used to teach machines through interaction with the environment and learning
from their mistakes. Despite its perceived utility, it has not yet been
successfully applied in automotive applications. Motivated by the successful
demonstrations of learning of Atari games and Go by Google DeepMind, we propose
a framework for autonomous driving using deep reinforcement learning. This is
of particular relevance as it is difficult to pose autonomous driving as a
supervised learning problem due to strong interactions with the environment
including other vehicles, pedestrians and roadworks. As it is a relatively new
area of research for autonomous driving, we provide a short overview of deep
reinforcement learning and then describe our proposed framework. It
incorporates Recurrent Neural Networks for information integration, enabling
the car to handle partially observable scenarios. It also integrates the recent
work on attention models to focus on relevant information, thereby reducing the
computational complexity for deployment on embedded hardware. The framework was
tested in an open source 3D car racing simulator called TORCS. Our simulation
results demonstrate learning of autonomous maneuvering in a scenario of complex
road curvatures and simple interaction of other vehicles.
</dc:description>
 <dc:description>Comment: Reprinted with permission of IS&amp;T: The Society for Imaging Science
  and Technology, sole copyright owners of Electronic Imaging, Autonomous
  Vehicles and Machines 2017</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02532</dc:identifier>
 <dc:identifier>IS&amp;T Electronic Imaging, Autonomous Vehicles and Machines 2017,
  AVM-023, pg. 70-76 (2017)</dc:identifier>
 <dc:identifier>doi:10.2352/ISSN.2470-1173.2017.19.AVM-023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02536</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wireless Information and Power Transfer in Full-Duplex Systems with
  Massive Antenna Arrays</dc:title>
 <dc:creator>Mohammadi, Mohammadali</dc:creator>
 <dc:creator>Chalise, Batu K.</dc:creator>
 <dc:creator>Suraweera, Himal A.</dc:creator>
 <dc:creator>Ding, Zhiguo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We consider a multiuser wireless system with a full-duplex hybrid access
point (HAP) that transmits to a set of users in the downlink channel, while
receiving data from a set of energy-constrained sensors in the uplink channel.
We assume that the HAP is equipped with a massive antenna array, while all
users and sensor nodes have a single antenna. We adopt a time-switching
protocol where in the first phase, sensors are powered through wireless energy
transfer from HAP and HAP estimates the downlink channel of the users. In the
second phase, sensors use the harvested energy to transmit to the HAP. The
downlink-uplink sum-rate region is obtained by solving downlink sum-rate
maximization problem under a constraint on uplink sum-rate. Moreover, assuming
perfect and imperfect channel state information, we derive expressions for the
achievable uplink and downlink rates in the large-antenna limit and approximate
results that hold for any finite number of antennas. Based on these analytical
results, we obtain the power-scaling law and analyze the effect of the number
of antennas on the cancellation of intra-user interference and the
self-interference.
</dc:description>
 <dc:description>Comment: Accepted for the IEEE International Conference on Communications (ICC
  2017)</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02536</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02537</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dual polynomials and communication complexity of $\textsf{XOR}$
  functions</dc:title>
 <dc:creator>Chattopadhyay, Arkadev</dc:creator>
 <dc:creator>Mande, Nikhil S.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We show a new duality between the polynomial margin complexity of $f$ and the
discrepancy of the function $f \circ \textsf{XOR}$, called an $\textsf{XOR}$
function. Using this duality, we develop polynomial based techniques for
understanding the bounded error ($\textsf{BPP}$) and the weakly-unbounded error
($\textsf{PP}$) communication complexities of $\textsf{XOR}$ functions. We show
the following.
  A weak form of an interesting conjecture of Zhang and Shi (Quantum
Information and Computation, 2009) (The full conjecture has just been reported
to be independently settled by Hatami and Qian (Arxiv, 2017). However, their
techniques are quite different and are not known to yield many of the results
we obtain here). Zhang and Shi assert that for symmetric functions $f : \{0,
1\}^n \rightarrow \{-1, 1\}$, the weakly unbounded-error complexity of $f \circ
\textsf{XOR}$ is essentially characterized by the number of points $i$ in the
set $\{0,1, \dots,n-2\}$ for which $D_f(i) \neq D_f(i+2)$, where $D_f$ is the
predicate corresponding to $f$. The number of such points is called the
odd-even degree of $f$. We show that the $\textsf{PP}$ complexity of $f \circ
\textsf{XOR}$ is $\Omega(k/ \log(n/k))$.
  We resolve a conjecture of a different Zhang characterizing the Threshold of
Parity circuit size of symmetric functions in terms of their odd-even degree.
  We obtain a new proof of the exponential separation between
$\textsf{PP}^{cc}$ and $\textsf{UPP}^{cc}$ via an $\textsf{XOR}$ function.
  We provide a characterization of the approximate spectral norm of symmetric
functions, affirming a conjecture of Ada et al. (APPROX-RANDOM, 2012) which has
several consequences.
  Additionally, we prove strong $\textsf{UPP}$ lower bounds for $f \circ
\textsf{XOR}$, when $f$ is symmetric and periodic with period
$O(n^{1/2-\epsilon})$, for any constant $\epsilon &gt; 0$.
</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02537</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02540</identifier>
 <datestamp>2017-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>5G Cellular User Equipment: From Theory to Practical Hardware Design</dc:title>
 <dc:creator>Huo, Yiming</dc:creator>
 <dc:creator>Dong, Xiaodai</dc:creator>
 <dc:creator>Xu, Wei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Research and development on the next generation wireless systems, namely 5G,
has experienced explosive growth in recent years. In the physical layer (PHY),
the massive multiple-input-multiple-output (MIMO) technique and the use of high
GHz frequency bands are two promising trends for adoption. Millimeter-wave
(mmWave) bands such as 28 GHz, 38 GHz, 64 GHz, and 71 GHz, which were
previously considered not suitable for commercial cellular networks, will play
an important role in 5G. Currently, most 5G research deals with the algorithms
and implementations of modulation and coding schemes, new spatial signal
processing technologies, new spectrum opportunities, channel modeling, 5G proof
of concept (PoC) systems, and other system-level enabling technologies. In this
paper, we first investigate the contemporary wireless user equipment (UE)
hardware design, and unveil the critical 5G UE hardware design constraints on
circuits and systems. On top of the said investigation and design trade-off
analysis, a new, highly reconfigurable system architecture for 5G cellular user
equipment, namely distributed phased arrays based MIMO (DPA-MIMO) is proposed.
Finally, the link budget calculation and data throughput numerical results are
presented for the evaluation of the proposed architecture.
</dc:description>
 <dc:description>Comment: Submitted to IEEE ACCESS. It has 18 pages, 17 figures, and 5 tables</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:date>2017-07-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02540</dc:identifier>
 <dc:identifier>doi:10.1109/ACCESS.2017.2727550</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02544</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Linearly Relaxed Approximate Linear Program for Markov Decision
  Processes</dc:title>
 <dc:creator>Lakshminarayanan, Chandrashekar</dc:creator>
 <dc:creator>Bhatnagar, Shalabh</dc:creator>
 <dc:creator>Szepesvari, Csaba</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Approximate linear programming (ALP) and its variants have been widely
applied to Markov Decision Processes (MDPs) with a large number of states. A
serious limitation of ALP is that it has an intractable number of constraints,
as a result of which constraint approximations are of interest. In this paper,
we define a linearly relaxed approximation linear program (LRALP) that has a
tractable number of constraints, obtained as positive linear combinations of
the original constraints of the ALP. The main contribution is a novel
performance bound for LRALP.
</dc:description>
 <dc:description>Comment: 23 pages, 2 figures, submitted to IEEE TAC</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02544</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02546</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LSH on the Hypercube Revisited</dc:title>
 <dc:creator>Har-Peled, Sariel</dc:creator>
 <dc:creator>Mahabadi, Sepideh</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  LSH (locality sensitive hashing) had emerged as a powerful technique in
nearest-neighbor search in high dimensions [IM98, HIM12]. Given a point set $P$
in a metric space, and given parameters $r$ and $\varepsilon &gt; 0$, the task is
to preprocess the point set, such that given a query point $q$, one can quickly
decide if $q$ is in distance at most $\leq r$ or $\geq (1+\varepsilon)r$ from
the point set $P$. Once such a near-neighbor data-structure is available, one
can reduce the general nearest-neighbor search to logarithmic number of queries
in such structures [IM98, Har01, HIM12].
  In this note, we revisit the most basic settings, where $P$ is a set of
points in the binary hypercube $\{0,1\}^d$, under the $L_1$/Hamming metric, and
present a short description of the LSH scheme in this case. We emphasize that
there is no new contribution in this note, except (maybe) the presentation
itself, which is inspired by the authors recent work [HM17].
</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02546</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02549</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving Parameter Estimation Problems with Discrete Adjoint Exponential
  Integrators</dc:title>
 <dc:creator>Roemer, Ulrich</dc:creator>
 <dc:creator>Narayanamurthi, Mahesh</dc:creator>
 <dc:creator>Sandu, Adrian</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>34H05, 34K29, 34K35</dc:subject>
 <dc:description>  The solution of inverse problems in a variational setting finds best
estimates of the model parameters by minimizing a cost function that penalizes
the mismatch between model outputs and observations. The gradients required by
the numerical optimization process are computed using adjoint models.
Exponential integrators are a promising family of time discretizations for
evolutionary partial differential equations. In order to allow the use of these
discretizations in the context of inverse problems adjoints of exponential
integrators are required. This work derives the discrete adjoint formulae for a
W-type exponential propagation iterative methods of Runge-Kutta type (EPIRK-W).
These methods allow arbitrary approximations of the Jacobian while maintaining
the overall accuracy of the forward integration. The use of Jacobian
approximation matrices that do not depend on the model state avoids the complex
calculation of Hessians in the discrete adjoint formulae, and allows efficient
adjoint code generation via algorithmic differentiation. We use the discrete
EPIRK-W adjoints to solve inverse problems with the Lorenz-96 model and a
computational magnetics benchmark test. Numerical results validate our
theoretical derivations.
</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02549</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02552</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Embedded Collaborative Filtering for &quot;Cold Start&quot; Prediction</dc:title>
 <dc:creator>Zhou, Yubo</dc:creator>
 <dc:creator>Nadaf, Ali</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Using only implicit data, many recommender systems fail in general to provide
a precise set of recommendations to users with limited interaction history.
This issue is regarded as the &quot;Cold Start&quot; problem and is typically resolved by
switching to content-based approaches where extra costly information is
required. In this paper, we use a dimensionality reduction algorithm, Word2Vec
(W2V), originally applied in Natural Language Processing problems under the
framework of Collaborative Filtering (CF) to tackle the &quot;Cold Start&quot; problem
using only implicit data. This combined method is named Embedded Collaborative
Filtering (ECF). An experiment is conducted to determine the performance of ECF
on two different implicit data sets. We show that the ECF approach outperforms
other popular and state-of-the-art approaches in &quot;Cold Start&quot; scenarios.
</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02552</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02553</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Securing Vehicle to Vehicle Communications using Blockchain through
  Visible Light and Acoustic Side-Channels</dc:title>
 <dc:creator>Rowan, Sean</dc:creator>
 <dc:creator>Clear, Michael</dc:creator>
 <dc:creator>Gerla, Mario</dc:creator>
 <dc:creator>Huggard, Meriel</dc:creator>
 <dc:creator>Goldrick, Ciar&#xe1;n Mc</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Autonomous and self-driving vehicles are appearing on the public highways.
These vehicles commonly use wireless communication techniques for both
vehicle-to-vehicle and vehicle-to-infrastructure communications. Manufacturers,
regulators and the public are understandably concerned about large-scale
systems failure or malicious attack via these wireless vehicular networks. This
paper explores the use of sensing and signalling devices that are commonly
integrated into modern vehicles for side-channel communication purposes.
Visible light (using a CMOS camera) and acoustic (ultrasonic audio)
side-channel encoding techniques are proposed, developed and evaluated in this
context. The side-channels are examined both theoretically and experimentally
and an upper bound on the line code modulation rate that is achievable with
these side channel schemes in the vehicular networking context is established.
A novel inter-vehicle session key establishment protocol, leveraging both
side-channels and a blockchain public key infrastructure, is then presented. In
light of the limited channel capacity and the interoperability/security
requirements for vehicular communications, techniques for constraining the
throughput requirement, providing device independence and validating the
location of the intended recipient vehicle, are presented. These reduce the
necessary device handshake throughput to 176 bits for creating symmetric
encryption and message authentication keys and in verifying a vehicle's
certificate with a recognised certification authority.
</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02553</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02556</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Management of Cascading Outage Risk Based on Risk Gradient and Markovian
  Tree Search</dc:title>
 <dc:creator>Yao, Rui</dc:creator>
 <dc:creator>Sun, Kai</dc:creator>
 <dc:creator>Liu, Feng</dc:creator>
 <dc:creator>Mei, Shengwei</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Since cascading outages are major threats to power systems, it is important
to reduce the risk of potential cascading outages. In this paper, a risk
management method of cascading outages based on Markovian tree search is
proposed. With the tree expansion on the cascading outage risk, risk gradient
is computed efficiently by a forward-backward tree search scheme with good
convergence, and it is then employed in an optimization model to minimize
control cost while effectively reducing the cascading outage risk. To overcome
the limitation with linearization in computing risk gradient, an iterative risk
management (IRM) approach is further developed. Tests on the RTS-96 3-area
system verify the accuracy of the computed risk gradient and its effectiveness
for risk reduction. Time performance of the proposed IRM approach is tested on
the RTS-96 system, a 410-bus US-Canada northeast system and a 1354-bus
Mid-European system, and demonstrates its potentials for decision support on
practical power systems online or on hourly basis.
</dc:description>
 <dc:description>Comment: 10 pages. Accepted by IEEE Transactions on Power Systems</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02556</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02565</identifier>
 <datestamp>2017-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prosody: The Rhythms and Melodies of Speech</dc:title>
 <dc:creator>Gibbon, Dafydd</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The present contribution is a tutorial on selected aspects of prosody, the
rhythms and melodies of speech, based on a course of the same name at the
Summer School on Contemporary Phonetics and Phonology at Tongji University,
Shanghai, China in July 2016. The tutorial is not intended as an introduction
to experimental methodology or as an overview of the literature on the topic,
but as an outline of observationally accessible aspects of fundamental
frequency and timing patterns with the aid of computational visualisation,
situated in a semiotic framework of sign ranks and interpretations. After an
informal introduction to the basic concepts of prosody in the introduction and
a discussion of the place of prosody in the architecture of language, a
selection of acoustic phonetic topics in phonemic tone and accent prosody, word
prosody, phrasal prosody and discourse prosody are discussed, and a stylisation
method for visualising aspects of prosody is introduced. Examples are taken
from a number of typologically different languages: Anyi/Agni (Niger-Congo&gt;Kwa,
Ivory Coast), English, Kuki-Thadou (Sino-Tibetan, North-East India and
Myanmar), Mandarin Chinese, Tem (Niger-Congo&gt;Gur, Togo) and Farsi. The main
focus is on fundamental frequency patterns, but issues of timing and rhythm are
also discussed. In the final section, further reading and possible future
research directions are outlined.
</dc:description>
 <dc:description>Comment: 35 pages, 22 figures (2nd version at arxiv.org)</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:date>2017-04-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02565</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02567</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Motion Saliency Based Automatic Delineation of Glottis Contour in
  High-speed Digital Images</dc:title>
 <dc:creator>Chen, Xin</dc:creator>
 <dc:creator>Marriott, Emma</dc:creator>
 <dc:creator>Yan, Yuling</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In recent years, high-speed videoendoscopy (HSV) has significantly aided the
diagnosis of voice pathologies and furthered the understanding the voice
production in recent years. As the first step of these studies, automatic
segmentation of glottal images till presents a major challenge for this
technique. In this paper, we propose an improved Saliency Network that
automatically delineates the contour of the glottis from HSV image sequences.
Our proposed additional saliency measure, Motion Saliency (MS), improves upon
the original Saliency Network by using the velocities of defined edges. In our
results and analysis, we demonstrate the effectiveness of our approach and
discuss its potential applications for computer-aided assessment of voice
pathologies and understanding voice production.
</dc:description>
 <dc:description>Comment: 4 pages 2 figures</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02567</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02569</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Continuous-Time Gaussian Channels</dc:title>
 <dc:creator>Liu, Xianming</dc:creator>
 <dc:creator>Han, Guangyue</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A continuous-time white Gaussian channel can be formulated using a white
Gaussian noise, and a conventional way for examining such a channel is the
sampling approach based on the Shannon-Nyquist sampling theorem, where the
original continuous-time channel is converted to an equivalent discrete-time
channel, to which a great variety of established tools and methodology can be
applied. However, one of the key issues of this scheme is that continuous-time
feedback and memory cannot be incorporated into the channel model. It turns out
that this issue can be circumvented by considering the Brownian motion
formulation of a continuous-time white Gaussian channel. Nevertheless, as
opposed to the white Gaussian noise formulation, a link that establishes the
information-theoretic connection between a continuous-time channel under the
Brownian motion formulation and its discrete-time counterparts has long been
missing. This paper is to fill this gap by establishing causality-preserving
connections between continuous-time Gaussian feedback/memory channels and their
associated discrete-time versions in the forms of sampling and approximation
theorems, which we believe will play important roles in the long run for
further developing continuous-time information theory.
  As an immediate application of the approximation theorem, we propose the
so-called approximation approach to examine continuous-time white Gaussian
channels in the point-to-point or multi-user setting. It turns out that the
approximation approach, complemented by relevant tools from stochastic
calculus, can enhance our understanding of continuous-time Gaussian channels in
terms of giving alternative and strengthened interpretation to some long-held
folklore, recovering &quot;long known&quot; results from new perspectives, and rigorously
establishing new results predicted by the intuition that the approximation
approach carries.
</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:date>2017-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02569</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02581</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling Temporal Dynamics and Spatial Configurations of Actions Using
  Two-Stream Recurrent Neural Networks</dc:title>
 <dc:creator>Wang, Hongsong</dc:creator>
 <dc:creator>Wang, Liang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, skeleton based action recognition gains more popularity due to
cost-effective depth sensors coupled with real-time skeleton estimation
algorithms. Traditional approaches based on handcrafted features are limited to
represent the complexity of motion patterns. Recent methods that use Recurrent
Neural Networks (RNN) to handle raw skeletons only focus on the contextual
dependency in the temporal domain and neglect the spatial configurations of
articulated skeletons. In this paper, we propose a novel two-stream RNN
architecture to model both temporal dynamics and spatial configurations for
skeleton based action recognition. We explore two different structures for the
temporal stream: stacked RNN and hierarchical RNN. Hierarchical RNN is designed
according to human body kinematics. We also propose two effective methods to
model the spatial structure by converting the spatial graph into a sequence of
joints. To improve generalization of our model, we further exploit 3D
transformation based data augmentation techniques including rotation and
scaling transformation to transform the 3D coordinates of skeletons during
training. Experiments on 3D action recognition benchmark datasets show that our
method brings a considerable improvement for a variety of actions, i.e.,
generic actions, interaction activities and gestures.
</dc:description>
 <dc:description>Comment: Accepted to IEEE International Conference on Computer Vision and
  Pattern Recognition (CVPR) 2017</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02581</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02592</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MLC Toolbox: A MATLAB/OCTAVE Library for Multi-Label Classification</dc:title>
 <dc:creator>Kimura, Keigo</dc:creator>
 <dc:creator>Sun, Lu</dc:creator>
 <dc:creator>Kudo, Mineichi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Multi-Label Classification toolbox is a MATLAB/OCTAVE library for Multi-Label
Classification (MLC). There exists a few Java libraries for MLC, but no
MATLAB/OCTAVE library that covers various methods. This toolbox offers an
environment for evaluation, comparison and visualization of the MLC results.
One attraction of this toolbox is that it enables us to try many combinations
of feature space dimension reduction, sample clustering, label space dimension
reduction and ensemble, etc.
</dc:description>
 <dc:description>Comment: Instruction pages are now under construction</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02592</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02596</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Achievable Rates of Buffer-Aided Full-Duplex Gaussian Relay Channels</dc:title>
 <dc:creator>Shafie, Ahmed El</dc:creator>
 <dc:creator>Sultan, Ahmed</dc:creator>
 <dc:creator>Krikidis, Ioannis</dc:creator>
 <dc:creator>Al-Dhahir, Naofal</dc:creator>
 <dc:creator>Hamila, Ridha</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We derive closed-form expressions for the achievable rates of a buffer-aided
full-duplex (FD) multiple-input multiple-output (MIMO) Gaussian relay channel.
The FD relay still suffers from residual self-interference (RSI) after the
application of self-interference mitigation techniques. We investigate both
cases of a slow-RSI channel where the RSI is fixed over the entire codeword,
and a fast-RSI channel where the RSI changes from one symbol duration to
another within the codeword. We show that the RSI can be completely eliminated
in the slow-RSI case when the FD relay is equipped with a buffer while the fast
RSI cannot be eliminated. For the fixed-rate data transmission scenario, we
derive the optimal transmission strategy that should be adopted by the source
node and relay node to maximize the system throughput. We verify our analytical
findings through simulations.
</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02596</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02598</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Sample Complexity Measure with Applications to Learning Optimal
  Auctions</dc:title>
 <dc:creator>Syrgkanis, Vasilis</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We introduce a new sample complexity measure, which we refer to as
split-sample growth rate. For any hypothesis $H$ and for any sample $S$ of size
$m$, the split-sample growth rate $\hat{\tau}_H(m)$ counts how many different
hypotheses can empirical risk minimization output on any sub-sample of $S$ of
size $m/2$. We show that the expected generalization error is upper bounded by
$O\left(\sqrt{\frac{\log(\hat{\tau}_H(2m))}{m}}\right)$. Our result is enabled
by a strengthening of the Rademacher complexity analysis of the expected
generalization error. We show that this sample complexity measure, greatly
simplifies the analysis of the sample complexity of optimal auction design, for
many auction classes studied in the literature. Their sample complexity can be
derived solely by noticing that in these auction classes, ERM on any sample or
sub-sample will pick parameters that are equal to one of the points in the
sample.
</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02598</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02602</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Image Filtering on Social Networks Using Deep Learning and
  Perceptual Hashing During Crises</dc:title>
 <dc:creator>Nguyen, Dat Tien</dc:creator>
 <dc:creator>Alam, Firoj</dc:creator>
 <dc:creator>Ofli, Ferda</dc:creator>
 <dc:creator>Imran, Muhammad</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The extensive use of social media platforms, especially during disasters,
creates unique opportunities for humanitarian organizations to gain situational
awareness and launch relief operations accordingly. In addition to the textual
content, people post overwhelming amounts of imagery data on social networks
within minutes of a disaster hit. Studies point to the importance of this
online imagery content for emergency response. Despite recent advances in the
computer vision field, automatic processing of the crisis-related social media
imagery data remains a challenging task. It is because a majority of which
consists of redundant and irrelevant content. In this paper, we present an
image processing pipeline that comprises de-duplication and relevancy filtering
mechanisms to collect and filter social media image content in real-time during
a crisis event. Results obtained from extensive experiments on real-world
crisis datasets demonstrate the significance of the proposed pipeline for
optimal utilization of both human and machine computing resources.
</dc:description>
 <dc:description>Comment: Accepted for publication in the 14th International Conference on
  Information Systems For Crisis Response and Management (ISCRAM), 2017</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02602</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02603</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating Tactile Data for Adaptive Grasping of Novel Objects</dc:title>
 <dc:creator>Hyttinen, Emil</dc:creator>
 <dc:creator>Kragic, Danica</dc:creator>
 <dc:creator>Detry, Renaud</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We present an adaptive grasping method that finds stable grasps on novel
objects. The main contributions of this paper is in the computation of the
probability of success of grasps in the vicinity of an already applied grasp.
Our method performs grasp adaptions by simulating tactile data for grasps in
the vicinity of the current grasp. The simulated data is used to evaluate
hypothetical grasps and thereby guide us toward better grasps. We demonstrate
the applicability of our method by constructing a system that can plan, apply
and adapt grasps on novel objects. Experiments are conducted on objects from
the YCB object set and the success rate of our method is 88%. Our experiments
show that the application of our grasp adaption method improves grasp stability
significantly.
</dc:description>
 <dc:description>Comment: This paper has been withdrawn by the author due to an incomplete
  related work section</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02603</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02608</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Framework for the Secretary Problem on the Intersection of Matroids</dc:title>
 <dc:creator>Feldman, Moran</dc:creator>
 <dc:creator>Svensson, Ola</dc:creator>
 <dc:creator>Zenklusen, Rico</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>68W27 (Primary) 68R05, 68W40 (Secondary)</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  The secretary problem became one of the most prominent online selection
problems due to its numerous applications in online mechanism design. The task
is to select a maximum weight subset of elements subject to given constraints,
where elements arrive one-by-one in random order, revealing a weight upon
arrival. The decision whether to select an element has to be taken immediately
after its arrival. The different applications that map to the secretary problem
ask for different constraint families to be handled. The most prominent ones
are matroid constraints, which both capture many relevant settings and admit
strongly competitive secretary algorithms. However, dealing with more involved
constraints proved to be much more difficult, and strong algorithms are known
only for a few specific settings. In this paper, we present a general framework
for dealing with the secretary problem over the intersection of several
matroids. This framework allows us to combine and exploit the large set of
matroid secretary algorithms known in the literature. As one consequence, we
get constant-competitive secretary algorithms over the intersection of any
constant number of matroids whose corresponding (single-)matroid secretary
problems are currently known to have a constant-competitive algorithm.
Moreover, we show that our results extend to submodular objectives.
</dc:description>
 <dc:description>Comment: 45 pages</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02608</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02612</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BigHand2.2M Benchmark: Hand Pose Dataset and State of the Art Analysis</dc:title>
 <dc:creator>Yuan, Shanxin</dc:creator>
 <dc:creator>Ye, Qi</dc:creator>
 <dc:creator>Stenger, Bjorn</dc:creator>
 <dc:creator>Jain, Siddhant</dc:creator>
 <dc:creator>Kim, Tae-Kyun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we introduce a large-scale hand pose dataset, collected using a
novel capture method. Existing datasets are either generated synthetically or
captured using depth sensors: synthetic datasets exhibit a certain level of
appearance difference from real depth images, and real datasets are limited in
quantity and coverage, mainly due to the difficulty to annotate them. We
propose a tracking system with six 6D magnetic sensors and inverse kinematics
to automatically obtain 21-joints hand pose annotations of depth maps captured
with minimal restriction on the range of motion. The capture protocol aims to
fully cover the natural hand pose space. As shown in embedding plots, the new
dataset exhibits a significantly wider and denser range of hand poses compared
to existing benchmarks. Current state-of-the-art methods are evaluated on the
dataset, and we demonstrate significant improvements in cross-benchmark
performance. We also show significant improvements in egocentric hand pose
estimation with a CNN trained on the new dataset.
</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:date>2017-12-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02612</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02613</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Multi-User Reinforcement Learning for Distributed Dynamic Spectrum
  Access</dc:title>
 <dc:creator>Naparstek, Oshri</dc:creator>
 <dc:creator>Cohen, Kobi</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We consider the problem of dynamic spectrum access for network utility
maximization in multichannel wireless networks. The shared bandwidth is divided
into K orthogonal channels. In the beginning of each time slot, each user
selects a channel and transmits a packet with a certain attempt probability.
After each time slot, each user that has transmitted a packet receives a local
observation indicating whether its packet was successfully delivered or not
(i.e., ACK signal). The objective is a multi-user strategy for accessing the
spectrum that maximizes a certain network utility in a distributed manner
without online coordination or message exchanges between users. Obtaining an
optimal solution for the spectrum access problem is computationally expensive
in general due to the large state space and partial observability of the
states. To tackle this problem, we develop a novel distributed dynamic spectrum
access algorithm based on deep multi-user reinforcement leaning. Specifically,
at each time slot, each user maps its current state to spectrum access actions
based on a trained deep-Q network used to maximize the objective function. Game
theoretic analysis of the system dynamic is developed for establishing design
principles for the implementation of the algorithm. Experimental results
demonstrate strong performance of the algorithm.
</dc:description>
 <dc:description>Comment: This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:date>2017-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02613</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02621</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mixed Graphical Models for Causal Analysis of Multi-modal Variables</dc:title>
 <dc:creator>Sedgewick, Andrew J</dc:creator>
 <dc:creator>Ramsey, Joseph D.</dc:creator>
 <dc:creator>Spirtes, Peter</dc:creator>
 <dc:creator>Glymour, Clark</dc:creator>
 <dc:creator>Benos, Panayiotis V.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Graphical causal models are an important tool for knowledge discovery because
they can represent both the causal relations between variables and the
multivariate probability distributions over the data. Once learned, causal
graphs can be used for classification, feature selection and hypothesis
generation, while revealing the underlying causal network structure and thus
allowing for arbitrary likelihood queries over the data. However, current
algorithms for learning sparse directed graphs are generally designed to handle
only one type of data (continuous-only or discrete-only), which limits their
applicability to a large class of multi-modal biological datasets that include
mixed type variables. To address this issue, we developed new methods that
modify and combine existing methods for finding undirected graphs with methods
for finding directed graphs. These hybrid methods are not only faster, but also
perform better than the directed graph estimation methods alone for a variety
of parameter settings and data set sizes. Here, we describe a new conditional
independence test for learning directed graphs over mixed data types and we
compare performances of different graph learning strategies on synthetic data.
</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02621</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02627</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On non-full-rank perfect codes over finite fields</dc:title>
 <dc:creator>Romanov, Alexander M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94B25</dc:subject>
 <dc:description>  The paper deals with the perfect 1-error correcting codes over a finite field
with $q$ elements (briefly $q$-ary 1-perfect codes). We show that the
orthogonal code to the $q$-ary non-full-rank 1-perfect code of length $n =
(q^{m}-1)/(q-1)$ is a $q$-ary constant-weight code with Hamming weight equals
to $q^{m - 1}$ where $m$ is any natural number not less than two. We derive
necessary and sufficient conditions for $q$-ary 1-perfect codes of non-full
rank. We suggest a generalization of the concatenation construction to the
$q$-ary case and construct the ternary 1-perfect codes of length 13 and rank
12.
</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02627</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02630</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Distributed Control Framework for a Team of Unmanned Aerial Vehicles
  for Dynamic Wildfire Tracking</dc:title>
 <dc:creator>Pham, Huy X.</dc:creator>
 <dc:creator>La, Hung M.</dc:creator>
 <dc:creator>Feil-Seifer, David</dc:creator>
 <dc:creator>Deans, Matthew</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Wildland fire fighting is a very dangerous job, and the lack of information
of the fire front is one of main reasons that causes many accidents. Using
unmanned aerial vehicle (UAV) to cover wildfire is promising because it can
replace human in hazardous fire tracking and save operation costs
significantly. In this paper we propose a distributed control framework
designed for a team of UAVs that can closely monitor a wildfire in open space,
and precisely track its development. The UAV team, designed for flexible
deployment, can effectively avoid in-flight collision as well as cooperate well
with other neighbors. Experimental results are conducted to demonstrate the
capabilites of the UAV team in covering a spreading wildfire.
</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02630</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02631</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectral and Energy Efficiency in Cognitive Radio Systems with Unslotted
  Primary Users and Sensing Uncertainty</dc:title>
 <dc:creator>Ozcan, Gozde</dc:creator>
 <dc:creator>Gursoy, M. Cenk</dc:creator>
 <dc:creator>Tang, Jian</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies energy efficiency (EE) and average throughput maximization
for cognitive radio systems in the presence of unslotted primary users. It is
assumed that primary user activity follows an ON-OFF alternating renewal
process. Secondary users first sense the channel possibly with errors in the
form of miss detections and false alarms, and then start the data transmission
only if no primary user activity is detected. The secondary user transmission
is subject to constraints on collision duration ratio, which is defined as the
ratio of average collision duration to transmission duration. In this setting,
the optimal power control policy which maximizes the EE of the secondary users
or maximizes the average throughput while satisfying a minimum required EE
under average/peak transmit power and average interference power constraints
are derived. Subsequently, low-complexity algorithms for jointly determining
the optimal power level and frame duration are proposed. The impact of
probabilities of detection and false alarm, transmit and interference power
constraints on the EE, average throughput of the secondary users, optimal
transmission power, and the collisions with primary user transmissions are
evaluated. In addition, some important properties of the collision duration
ratio are investigated. The tradeoff between the EE and average throughput
under imperfect sensing decisions and different primary user traffic are
further analyzed.
</dc:description>
 <dc:description>Comment: This paper is accepted for publication in IEEE Transactions on
  Communications</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02631</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02632</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MapReduce Scheduler: A 360-degree view</dc:title>
 <dc:creator>Das, Rajdeep</dc:creator>
 <dc:creator>Singh, Rohit Pratap</dc:creator>
 <dc:creator>Patgiri, Ripon</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Undoubtedly, the MapReduce is the most powerful programming paradigm in
distributed computing. The enhancement of the MapReduce is essential and it can
lead the computing faster. Therefore, here are many scheduling algorithms to
discuss based on their characteristics. Moreover, there are many shortcoming to
discover in this field. In this article, we present the state-of-the-art
scheduling algorithm to enhance the understanding of the algorithms. The
algorithms are presented systematically such that there can be many future
possibilities in scheduling algorithm through this article. In this paper, we
provide in-depth insight on the MapReduce scheduling algorithm. In addition, we
discuss various issues of MapReduce scheduler developed for large-scale
computing as well as heterogeneous environment.
</dc:description>
 <dc:description>Comment: Journal Article</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02632</dc:identifier>
 <dc:identifier>International Journal of Current Engineering and Scientific
  Research, volume 3(11), pages 88-100, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02634</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>R\'enyi entropy power inequality and a reverse</dc:title>
 <dc:creator>Li, Jiange</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:description>  This paper is twofold. In the first part, we present a refinement of the
R\'enyi Entropy Power Inequality (EPI) recently obtained in \cite{BM16}. The
proof largely follows the approach in \cite{DCT91} of employing Young's
convolution inequalities with sharp constants. In the second part, we study the
reversibility of the R\'enyi EPI, and confirm a conjecture in \cite{BNT15,
MMX16} in two cases. Connections with various $p$-th mean bodies in convex
geometry are also explored.
</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02634</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02635</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Subspace Identification with Multiple Data Records: unlocking the
  archive</dc:title>
 <dc:creator>Holcomb, Chad M.</dc:creator>
 <dc:creator>Bitmead, Robert R.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>93B30</dc:subject>
 <dc:subject>I.1.5</dc:subject>
 <dc:subject>H.1.1</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:description>  We develop an approach to subspace system identification using multiple data
records and present a simple rank-based test for the adequacy of these data for
fitting the unique linear, noise-free, dynamic model of prescribed
state-vector, input-vector and output-vector dimensions. The approach is
motivated by the prospect of sorting through archives of operational data and
extracting a sequence of not-necessarily-contiguous data records individually
insufficient for providing identifiability but collectively making this
possible. The test of identifiability then becomes the sorting criterion for
accepting or rejecting new data records. En passant, the familiar Hankel
structure of the data matrices of subspace system identification is
reinterpreted and revised.
</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02635</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02641</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantized Innovations Bayesian Filtering</dc:title>
 <dc:creator>Huang, Chun-Chia</dc:creator>
 <dc:creator>Bitmead, Robert R.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>93E11, 60G35</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>E.4</dc:subject>
 <dc:description>  The paper provides simple formulas of Bayesian filtering for the exact
recursive computation of state conditional probability density functions given
quantized innovations signal measurements of a linear stochastic system. This
is a topic of current interest because the innovations signal should be white
and therefore efficient in its use of channel capacity and in the design and
optimization of the quantizer. Earlier approaches, which we reexamine and
characterize here, have relied on assumptions concerning densities or
approximations to yield recursive solutions, which include the
sign-of-innovations Kalman filter and a Particle filtering technique. Our
approach uses the Kalman filter innovations at the transmitter side and
provides a point of comparison for the other methods, since it is based on the
Bayesian filter. Computational examples are provided.
</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02654</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhancing Robustness of Machine Learning Systems via Data
  Transformations</dc:title>
 <dc:creator>Bhagoji, Arjun Nitin</dc:creator>
 <dc:creator>Cullina, Daniel</dc:creator>
 <dc:creator>Sitawarin, Chawin</dc:creator>
 <dc:creator>Mittal, Prateek</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose the use of data transformations as a defense against evasion
attacks on ML classifiers. We present and investigate strategies for
incorporating a variety of data transformations including dimensionality
reduction via Principal Component Analysis and data `anti-whitening' to enhance
the resilience of machine learning, targeting both the classification and the
training phase. We empirically evaluate and demonstrate the feasibility of
linear transformations of data as a defense mechanism against evasion attacks
using multiple real-world datasets. Our key findings are that the defense is
(i) effective against the best known evasion attacks from the literature,
resulting in a two-fold increase in the resources required by a white-box
adversary with knowledge of the defense for a successful attack, (ii)
applicable across a range of ML classifiers, including Support Vector Machines
and Deep Neural Networks, and (iii) generalizable to multiple application
domains, including image classification and human activity classification.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:date>2017-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02654</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02657</identifier>
 <datestamp>2017-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Algorithmic Approach to Search Games: Finding Solutions Using Best
  Response Oracles</dc:title>
 <dc:creator>Hellerstein, Lisa</dc:creator>
 <dc:creator>Lidbetter, Thomas</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We present efficient algorithms for computing optimal or approximately
optimal strategies in a zero-sum game for which Player I has n pure strategies
and Player II has an arbitrary number of pure strategies. We assume that for
any given mixed strategy of Player I, a best response or &quot;approximate&quot; best
response of Player II can be found by an oracle in time polynomial in n. We
then show how our algorithms may be applied to several search games with
applications to security and counter-terrorism.
</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:date>2017-05-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02657</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02658</identifier>
 <datestamp>2017-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Statistical Estimation and Rates of Convergence in Normal
  Approximation</dc:title>
 <dc:creator>Minsker, Stanislav</dc:creator>
 <dc:creator>Strawn, Nate</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>68W15, 62G35</dc:subject>
 <dc:description>  This paper presents new algorithms for distributed statistical estimation
that can take advantage of the divide-and-conquer approach. We show that one of
the key benefits attained by an appropriate divide-and-conquer strategy is
robustness, an important characteristic of large distributed systems. We
introduce a class of algorithms that are based on the properties of the
geometric median, establish connections between performance of these
distributed algorithms and rates of convergence in normal approximation, and
provide tight deviations guarantees for resulting estimators in the form of
exponential concentration inequalities. Our techniques are illustrated through
several examples; in particular, we obtain new results for the median-of-means
estimator, as well as provide performance guarantees for robust distributed
maximum likelihood estimation.
</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02658</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02659</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Backup Strategies Against Cyber Attacks</dc:title>
 <dc:creator>Bar-On, Achiya</dc:creator>
 <dc:creator>Dinur, Itai</dc:creator>
 <dc:creator>Dunkelman, Orr</dc:creator>
 <dc:creator>Hod, Rani</dc:creator>
 <dc:creator>Keller, Nathan</dc:creator>
 <dc:creator>Ronen, Eyal</dc:creator>
 <dc:creator>Shamir, Adi</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We introduce a new problem of finding the best way to protect a computer
system against cyber and ransomware attacks by choosing an optimal backup
scheme using k storage devices. While in standard backup schemes it is
beneficial to backup as frequently as possible, in the case of sophisticated
cyber attacks any attempt to connect a backup device to an already infected
computer is likely to stealthily corrupt its data and thus make it unusable
when the actual attack happens. Our formalization of the problem casts it as a
special case of an online/offline optimization problem, in which the defender
tries to minimize the maximal extra cost caused by his lack of knowledge about
the time of the infection.
  Any backup scheme can be viewed as a very simple pebbling game where in each
step any one of the k backup pebbles can be moved to any point to the right of
all the pebbles along the time axis, and the goal of the game is to keep the
pebbles as evenly spread as possible at all times. However, its optimal
solution is surprisingly complicated and leads to interesting combinatorial
questions which are reminiscent of questions in discrepancy theory. For small
k's, we find provably optimal backup strategies for all k&lt;10, and each case
seems to be somewhat different: For k=3 the best schedule uses backup times
which form a simple geometric progression based on the golden ratio, but
already for k=4 there is no geometric progression can be optimal and the
efficiency of the best online scheme is worse than the efficiency of the best
offline scheme by a strange factor of 2/(1+cos(2pi/7)). For k=8 the optimal
order of device updates is highly complicated:
1,2,4,7,5,3,1,7,5,3,7,1,4,2,4,5,... while for k=9 it is much simpler. We
consider the case of arbitrarily large values of k, and prove a matching upper
and lower bound of ln(4) on the asymptotic of optimal backup schemes when k
goes to infinity.
</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02659</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02665</identifier>
 <datestamp>2017-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Supervised Infinite Feature Selection</dc:title>
 <dc:creator>Eskandari, Sadegh</dc:creator>
 <dc:creator>Akbas, Emre</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we present a new feature selection method that is suitable for
both unsupervised and supervised problems. We build upon the recently proposed
Infinite Feature Selection (IFS) method where feature subsets of all sizes
(including infinity) are considered. We extend IFS in two ways. First, we
propose a supervised version of it. Second, we propose new ways of forming the
feature adjacency matrix that perform better for unsupervised problems. We
extensively evaluate our methods on many benchmark datasets, including large
image-classification datasets (PASCAL VOC), and show that our methods
outperform both the IFS and the widely used &quot;minimum-redundancy
maximum-relevancy (mRMR)&quot; feature selection algorithm.
</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:date>2017-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02665</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02672</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quaternion Based Camera Pose Estimation From Matched Feature Points</dc:title>
 <dc:creator>Fathian, Kaveh</dc:creator>
 <dc:creator>Ramirez-Paredes, J. Pablo</dc:creator>
 <dc:creator>Doucette, Emily A.</dc:creator>
 <dc:creator>Curtis, J. Willard</dc:creator>
 <dc:creator>Gans, Nicholas R.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We present a novel solution to the camera pose estimation problem, where
rotation and translation of a camera between two views are estimated from
matched feature points in the images. The camera pose estimation problem is
traditionally solved via algorithms that are based on the essential matrix or
the Euclidean homography. With six or more feature points in general positions
in the space, essential matrix based algorithms can recover a unique solution.
However, such algorithms fail when points are on critical surfaces (e.g.,
coplanar points) and homography should be used instead. By formulating the
problem in quaternions and decoupling the rotation and translation estimation,
our proposed algorithm works for all point configurations. Using both simulated
and real world images, we compare the estimation accuracy of our algorithm with
some of the most commonly used algorithms. Our method is shown to be more
robust to noise and outliers. For the benefit of community, we have made the
implementation of our algorithm available online and free.
</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02672</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02673</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lattice Gaussian Sampling by Markov Chain Monte Carlo: Convergence Rate
  and Decoding Complexity</dc:title>
 <dc:creator>Wang, Zheng</dc:creator>
 <dc:creator>Ling, Cong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Sampling from the lattice Gaussian distribution is an efficient way for
solving the closest vector problem (CVP) in lattice decoding. In this paper,
decoding by MCMC-based lattice Gaussian sampling is investigated in full
details. First of all, the spectral gap of the transition matrix of the Markov
chain induced by the independent Metropolis-Hastings-Klein (MHK) algorithm is
derived, dictating an exponential convergence rate to the target lattice
Gaussian distribution. Then, the decoding complexity of CVP is derived as
$O(e^{d^2(\Lambda, \mathbf{c})/\min_i^2\|\widehat{\mathbf{b}}_i\|})$, where
$d(\Lambda, \mathbf{c})$ represents the Euclidean distance between the query
point $\mathbf{c}$ and the lattice $\Lambda$, and $\mathbf{\widehat{b}}_i$ is
the $i$th Gram-Schmidt vector of the lattice basis $\mathbf{B}$. Furthermore,
the decoding radius from the perspective of bounded distance decoding (BDD)
given a fixed number of Markov moves $t$ is also derived, revealing a flexible
trade-off between the decoding performance and complexity. Finally, by taking
advantages of $k$ trial samples from the proposal distribution, the independent
multiple-try Metropolis-Klein (MTMK) algorithm is proposed to further enhance
the exponential convergence rate. By adjusting $k$, the independent MTMK
sampler enjoys a flexible decoding performance, where the independent MHK
algorithm is just a case with $k=1$. Additionally, the proposed decoding allows
a fully parallel implementation, which is beneficial for the practical
interest.
</dc:description>
 <dc:description>Comment: submitted to Transaction on Information Theory</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02673</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02676</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Existence of Separable Contraction Metrics for Monotone Nonlinear
  Systems</dc:title>
 <dc:creator>Manchester, Ian R.</dc:creator>
 <dc:creator>Slotine, Jean-Jacques E.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  Finding separable certificates of stability is important for tractability of
analysis methods for large-scale networked systems. In this paper we consider
the question of when a nonlinear system which is contracting, i.e. all
solutions are exponentially stable, can have that property verified by a
separable metric. Making use of recent results in the theory of positive linear
systems and separable Lyapunov functions, we prove several new results showing
when this is possible, and discuss the application of to nonlinear distributed
control design via convex optimization.
</dc:description>
 <dc:description>Comment: Accepted to IFAC World Congress 2017</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02676</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02677</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Banshee: Bandwidth-Efficient DRAM Caching Via Software/Hardware
  Cooperation</dc:title>
 <dc:creator>Yu, Xiangyao</dc:creator>
 <dc:creator>Hughes, Christopher J.</dc:creator>
 <dc:creator>Satish, Nadathur</dc:creator>
 <dc:creator>Mutlu, Onur</dc:creator>
 <dc:creator>Devadas, Srinivas</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Putting the DRAM on the same package with a processor enables several times
higher memory bandwidth than conventional off-package DRAM. Yet, the latency of
in-package DRAM is not appreciably lower than that of off-package DRAM. A
promising use of in-package DRAM is as a large cache. Unfortunately, most
previous DRAM cache designs mainly optimize for hit latency and do not consider
off-chip bandwidth efficiency as a first-class design constraint. Hence, as we
show in this paper, these designs are suboptimal for use with in-package DRAM.
  We propose a new DRAM cache design, Banshee, that optimizes for both in- and
off-package DRAM bandwidth efficiency without degrading access latency. The key
ideas are to eliminate the in-package DRAM bandwidth overheads due to costly
tag accesses through virtual memory mechanism and to incorporate a
bandwidth-aware frequency-based replacement policy that is biased to reduce
unnecessary traffic to off-package DRAM. Our extensive evaluation shows that
Banshee provides significant performance improvement and traffic reduction over
state-of-the-art latency-optimized DRAM cache designs.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02677</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02681</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pyramid Vector Quantization for Deep Learning</dc:title>
 <dc:creator>Liguori, Vincenzo</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  This paper explores the use of Pyramid Vector Quantization (PVQ) to reduce
the computational cost for a variety of neural networks (NNs) while, at the
same time, compressing the weights that describe them. This is based on the
fact that the dot product between an N dimensional vector of real numbers and
an N dimensional PVQ vector can be calculated with only additions and
subtractions and one multiplication. This is advantageous since tensor
products, commonly used in NNs, can be re-conduced to a dot product or a set of
dot products. Finally, it is stressed that any NN architecture that is based on
an operation that can be re-conduced to a dot product can benefit from the
techniques described here.
</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02681</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02683</identifier>
 <datestamp>2017-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Secure Key Agreement Protocol for Dynamic Group</dc:title>
 <dc:creator>Bilal, Muhammad</dc:creator>
 <dc:creator>Kang, Shin-Gak</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>94A62, 94A62, 94A60, 68P25, 68M12, 68M14, 94A62</dc:subject>
 <dc:subject>K.6.5</dc:subject>
 <dc:subject>K.6.m</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:subject>B.2.4</dc:subject>
 <dc:description>  To accomplish secure group communication, it is essential to share a unique
cryptographic key among group members. The underlying challenges to group key
agreement are scalability, efficiency, and security. In a dynamic group
environment, the rekeying process is more frequent; therefore, it is more
crucial to design an efficient group key agreement protocol. Moreover, with the
emergence of various group-based services, it is becoming common for several
multicast groups to coexist in the same network. These multicast groups may
have several shared users; a join or leave request by a single user can trigger
regeneration of multiple group keys. Under the given circumstances the rekeying
process becomes a challenging task. In this work, we propose a novel
methodology for group key agreement which exploits the state vectors of group
members. The state vector is a set of randomly generated nonce instances which
determine the logical link between group members and which empowers the group
member to generate multiple cryptographic keys independently. Using local
knowledge of a secret nonce, each member can generate and share a large number
of secure keys, indicating that SGRS inherently provides a considerable amount
of secure subgroup multicast communication using subgroup multicasting keys
derived from local state vectors. The resulting protocol is secure and
efficient in terms of both communication and computation.
</dc:description>
 <dc:description>Comment: This article is accepted for the publication in Cluster Computing-The
  Journal of Networks, Software Tools and Applications. Print ISSN 1386-7857,
  Online ISSN 1573-7543</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02683</dc:identifier>
 <dc:identifier>Cluster Comput (2017) 20: 2779</dc:identifier>
 <dc:identifier>doi:10.1007/s10586-017-0853-0</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02685</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Important Features Through Propagating Activation Differences</dc:title>
 <dc:creator>Shrikumar, Avanti</dc:creator>
 <dc:creator>Greenside, Peyton</dc:creator>
 <dc:creator>Kundaje, Anshul</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The purported &quot;black box&quot;' nature of neural networks is a barrier to adoption
in applications where interpretability is essential. Here we present DeepLIFT
(Deep Learning Important FeaTures), a method for decomposing the output
prediction of a neural network on a specific input by backpropagating the
contributions of all neurons in the network to every feature of the input.
DeepLIFT compares the activation of each neuron to its 'reference activation'
and assigns contribution scores according to the difference. By optionally
giving separate consideration to positive and negative contributions, DeepLIFT
can also reveal dependencies which are missed by other approaches. Scores can
be computed efficiently in a single backward pass. We apply DeepLIFT to models
trained on MNIST and simulated genomic data, and show significant advantages
over gradient-based methods. A detailed video tutorial on the method is at
http://goo.gl/qKb7pL and code is at http://goo.gl/RM8jvH.
</dc:description>
 <dc:description>Comment: 9 pages, 6 figures</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02685</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02686</identifier>
 <datestamp>2017-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Word Embeddings via Tensor Factorization</dc:title>
 <dc:creator>Bailey, Eric</dc:creator>
 <dc:creator>Aeron, Shuchin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Most popular word embedding techniques involve implicit or explicit
factorization of a word co-occurrence based matrix into low rank factors. In
this paper, we aim to generalize this trend by using numerical methods to
factor higher-order word co-occurrence based arrays, or \textit{tensors}. We
present four word embeddings using tensor factorization and analyze their
advantages and disadvantages. One of our main contributions is a novel joint
symmetric tensor factorization technique related to the idea of coupled tensor
factorization. We show that embeddings based on tensor factorization can be
used to discern the various meanings of polysemous words without being
explicitly trained to do so, and motivate the intuition behind why this works
in a way that doesn't with existing methods. We also modify an existing word
embedding evaluation metric known as Outlier Detection [Camacho-Collados and
Navigli, 2016] to evaluate the quality of the order-$N$ relations that a word
embedding captures, and show that tensor-based methods outperform existing
matrix-based methods at this task. Experimentally, we show that all of our word
embeddings either outperform or are competitive with state-of-the-art baselines
commonly used today on a variety of recent datasets. Suggested applications of
tensor factorization-based word embeddings are given, and all source code and
pre-trained vectors are publicly available online.
</dc:description>
 <dc:description>Comment: More simulation results added</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:date>2017-09-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02686</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02694</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ClusterNet: Detecting Small Objects in Large Scenes by Exploiting
  Spatio-Temporal Information</dc:title>
 <dc:creator>LaLonde, Rodney</dc:creator>
 <dc:creator>Zhang, Dong</dc:creator>
 <dc:creator>Shah, Mubarak</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Object detection in wide area motion imagery (WAMI) has drawn the attention
of the computer vision research community for a number of years. WAMI proposes
a number of unique challenges including extremely small object sizes, both
sparse and densely-packed objects, and extremely large search spaces (large
video frames). Nearly all state-of-the-art methods in WAMI object detection
report that appearance-based classifiers fail in this challenging data and
instead rely almost entirely on motion information in the form of background
subtraction or frame-differencing. In this work, we experimentally verify the
failure of appearance-based classifiers in WAMI, such as Faster R-CNN and a
heatmap-based fully convolutional neural network (CNN), and propose a novel
two-stage spatio-temporal CNN which effectively and efficiently combines both
appearance and motion information to significantly surpass the state-of-the-art
in WAMI object detection. To reduce the large search space, the first stage
(ClusterNet) takes in a set of extremely large video frames, combines the
motion and appearance information within the convolutional architecture, and
proposes regions of objects of interest (ROOBI). These ROOBI can contain from
one to clusters of several hundred objects due to the large video frame size
and varying object density in WAMI. The second stage (FoveaNet) then estimates
the centroid location of all objects in that given ROOBI simultaneously via
heatmap estimation. The proposed method exceeds state-of-the-art results on the
WPAFB 2009 dataset by 5-16% for moving objects and nearly 50% for stopped
objects, as well as being the first proposed method in wide area motion imagery
to detect completely stationary objects.
</dc:description>
 <dc:description>Comment: Main paper is 8 pages. Supplemental section contains a walk-through
  of our method (using a qualitative example) and qualitative results for WPAFB
  2009 dataset</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:date>2017-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02694</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02696</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Implementing a Cloud Platform for Autonomous Driving</dc:title>
 <dc:creator>Liu, Shaoshan</dc:creator>
 <dc:creator>Tang, Jie</dc:creator>
 <dc:creator>Wang, Chao</dc:creator>
 <dc:creator>Wang, Quan</dc:creator>
 <dc:creator>Gaudiot, Jean-Luc</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Autonomous driving clouds provide essential services to support autonomous
vehicles. Today these services include but not limited to distributed
simulation tests for new algorithm deployment, offline deep learning model
training, and High-Definition (HD) map generation. These services require
infrastructure support including distributed computing, distributed storage, as
well as heterogeneous computing. In this paper, we present the details of how
we implement a unified autonomous driving cloud infrastructure, and how we
support these services on top of this infrastructure.
</dc:description>
 <dc:description>Comment: 8 pages, 12 figures</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02696</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02698</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Steganographic Technique Matching the Secret Message and Cover
  image Binary Value</dc:title>
 <dc:creator>Umamaheswari, G.</dc:creator>
 <dc:creator>Sumathi, Dr. C. P.</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Steganography involves hiding a secret message or image inside another cover
image. Changes are made in the cover image without affecting visual quality of
the image. In contrast to cryptography, Steganography provides complete secrecy
of the communication. Security of very sensitive data can be enhanced by
combining cryptography and steganography. A new technique that uses the concept
of Steganography to obtain the position values from an image is suggested. This
paper proposes a new method where no change is made to the cover image, only
the pixel position LSB (Least Significant Bit) values that match with the
secret message bit values are noted in a separate position file. At the sending
end the position file along with the cover image is sent. At the receiving end
the position file is opened only with a secret key. The bit positions are taken
from the position file and the LSB values from the positions are combined to
get ASCII values and then form characters of the secret message
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02698</dc:identifier>
 <dc:identifier>International Journal of Computer Science and Information
  Security, January 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02700</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>0/1/all CSPs, Half-Integral $A$-path Packing, and Linear-Time FPT
  Algorithms</dc:title>
 <dc:creator>Iwata, Yoichi</dc:creator>
 <dc:creator>Yamaguchi, Yutaro</dc:creator>
 <dc:creator>Yoshida, Yuichi</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A recent trend in the design of FPT algorithms is exploiting the
half-integrality of LP relaxations. In other words, starting with a
half-integral optimal solution to an LP relaxation, we assign integral values
to variables one-by-one by branch and bound. This technique is general and the
resulting time complexity has a low dependency on the parameter. However, the
time complexity often becomes a large polynomial in the input size because we
need to compute half-integral optimal LP solutions.
  In this paper, we address this issue by providing an $O(km)$-time algorithm
for solving the LPs arising from various FPT problems, where $k$ is the optimal
value and $m$ is the number of edges/constraints. Our algorithm is based on
interesting connections among 0/1/all constraints, which has been studied in
the field of constraints satisfaction, $A$-path packing, which has been studied
in the field of combinatorial optimization, and the LPs used in FPT algorithms.
With the aid of this algorithm, we obtain improved FPT algorithms for various
problems, including Group Feedback Vertex Set, Subset Feedback Vertex Set, Node
Multiway Cut, Node Unique Label Cover, and Non-monochromatic Cycle Transversal.
The obtained running time for each of these problems is linear in the input
size and has the current smallest dependency on the parameter. In particular,
these algorithms are the first linear-time FPT algorithms for problems
including Group Feedback Vertex Set and Non-monochromatic Cycle Transversal.
</dc:description>
 <dc:description>Comment: Added new results on two-fan constraints</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02700</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02703</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Liver Lesion Detection using Cascaded Deep Residual Networks</dc:title>
 <dc:creator>Bi, Lei</dc:creator>
 <dc:creator>Kim, Jinman</dc:creator>
 <dc:creator>Kumar, Ashnil</dc:creator>
 <dc:creator>Feng, Dagan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automatic segmentation of liver lesions is a fundamental requirement towards
the creation of computer aided diagnosis (CAD) and decision support systems
(CDS). Traditional segmentation approaches depend heavily upon hand-crafted
features and a priori knowledge of the user. As such, these methods are
difficult to adopt within a clinical environment. Recently, deep learning
methods based on fully convolutional networks (FCNs) have been successful in
many segmentation problems primarily because they leverage a large labelled
dataset to hierarchically learn the features that best correspond to the
shallow visual appearance as well as the deep semantics of the areas to be
segmented. However, FCNs based on a 16 layer VGGNet architecture have limited
capacity to add additional layers. Therefore, it is challenging to learn more
discriminative features among different classes for FCNs. In this study, we
overcome these limitations using deep residual networks (ResNet) to segment
liver lesions. ResNet contain skip connections between convolutional layers,
which solved the problem of the training degradation of training accuracy in
very deep networks and thereby enables the use of additional layers for
learning more discriminative features. In addition, we achieve more precise
boundary definitions through a novel cascaded ResNet architecture with
multi-scale fusion to gradually learn and infer the boundaries of both the
liver and the liver lesions. Our proposed method achieved 4th place in the ISBI
2017 Liver Tumor Segmentation Challenge by the submission deadline.
</dc:description>
 <dc:description>Comment: Submission for 2017 ISBI LiTS Challenge</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02708</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evolving a Vector Space with any Generating Set</dc:title>
 <dc:creator>Nock, Richard</dc:creator>
 <dc:creator>Nielsen, Frank</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  In Valiant's model of evolution, a class of representations is evolvable iff
a polynomial-time process of random mutations guided by selection converges
with high probability to a representation as $\epsilon$-close as desired from
the optimal one, for any required $\epsilon&gt;0$. Several previous positive
results exist that can be related to evolving a vector space, but each former
result imposes disproportionate representations or restrictions on
(re)initialisations, distributions, performance functions and/or the mutator.
In this paper, we show that all it takes to evolve a normed vector space is
merely a set that generates the space. Furthermore, it takes only
$\tilde{O}(1/\epsilon^2)$ steps and it is essentially stable, agnostic and
handles target drifts that rival some proven in fairly restricted settings. Our
algorithm can be viewed as a close relative to a popular fifty-years old
gradient-free optimization method for which little is still known from the
convergence standpoint: Nelder-Mead simplex method.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-12-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02708</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02709</identifier>
 <datestamp>2017-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Implicit Semantic Role Labeling by Predicting Semantic Frame
  Arguments</dc:title>
 <dc:creator>Do, Quynh Ngoc Thi</dc:creator>
 <dc:creator>Bethard, Steven</dc:creator>
 <dc:creator>Moens, Marie-Francine</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Implicit semantic role labeling (iSRL) is the task of predicting the semantic
roles of a predicate that do not appear as explicit arguments, but rather
regard common sense knowledge or are mentioned earlier in the discourse. We
introduce an approach to iSRL based on a predictive recurrent neural semantic
frame model (PRNSFM) that uses a large unannotated corpus to learn the
probability of a sequence of semantic arguments given a predicate. We leverage
the sequence probabilities predicted by the PRNSFM to estimate selectional
preferences for predicates and their arguments. On the NomBank iSRL test set,
our approach improves state-of-the-art performance on implicit semantic role
labeling with less reliance than prior work on manually constructed language
resources.
</dc:description>
 <dc:description>Comment: IJCNLP 2017</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-10-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02711</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A MALL Geometry of Interaction Based on Indexed Linear Logic</dc:title>
 <dc:creator>Hamano, Masahiro</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We construct a geometry of interaction (GoI; dynamic modeling of Gentzen
style cut elimination) for multiplicative additive linear logic (MALL) by
employing the Bucciarelli-Ehrhard MALL(I) of indexed linear logic to handle the
additives. Our construction is an extension to the additives of the
Haghverdi-Scott categorical formulation (a multiplicative GoI situation in a
traced monoidal category) for Girard's original GoI I. The indexes are shown to
serve not only in their original denotational level, but also at a finer
grained dynamic level so that the peculiarities of additive cut elimination
such as superposition, erasure of subproofs, and additive (co-) contraction can
be handled with the explicit use of indexes. Proofs are interpreted as indexed
subsets in the category Rel, but without the explicit relational composition;
instead, execution formulas are run pointwise on the interpretation at each
index, w.r.t symmetries of cuts, in a traced monoidal category with a reflexive
object and a zero morphism. The indexes diminish overall when an execution
formula is run, corresponding to the additive cut-elimination procedure
(erasure), and allowing recovery of the relational composition. The main
theorem is the invariance of cut elimination via convergence of the execution
formulas on the denotations of (cut-free) proofs.
</dc:description>
 <dc:description>Comment: 22 pages</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02711</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02712</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Relaxed ADMM: Convergence Theory and Practical Implementation</dc:title>
 <dc:creator>Xu, Zheng</dc:creator>
 <dc:creator>Figueiredo, Mario A. T.</dc:creator>
 <dc:creator>Yuan, Xiaoming</dc:creator>
 <dc:creator>Studer, Christoph</dc:creator>
 <dc:creator>Goldstein, Tom</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Many modern computer vision and machine learning applications rely on solving
difficult optimization problems that involve non-differentiable objective
functions and constraints. The alternating direction method of multipliers
(ADMM) is a widely used approach to solve such problems. Relaxed ADMM is a
generalization of ADMM that often achieves better performance, but its
efficiency depends strongly on algorithm parameters that must be chosen by an
expert user. We propose an adaptive method that automatically tunes the key
algorithm parameters to achieve optimal performance without user oversight.
Inspired by recent work on adaptivity, the proposed adaptive relaxed ADMM
(ARADMM) is derived by assuming a Barzilai-Borwein style linear gradient. A
detailed convergence analysis of ARADMM is provided, and numerical results on
several applications demonstrate fast practical convergence.
</dc:description>
 <dc:description>Comment: CVPR 2017</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02712</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02716</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formal approaches to a definition of agents</dc:title>
 <dc:creator>Biehl, Martin</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>92B20</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>H.1.1</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:subject>I.5.m</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:description>  This thesis contributes to the formalisation of the notion of an agent within
the class of finite multivariate Markov chains. Agents are seen as entities
that act, perceive, and are goal-directed.
  We present a new measure that can be used to identify entities (called
$\iota$-entities), some general requirements for entities in multivariate
Markov chains, as well as formal definitions of actions and perceptions
suitable for such entities.
  The intuition behind $\iota$-entities is that entities are spatiotemporal
patterns for which every part makes every other part more probable. The
measure, complete local integration (CLI), is formally investigated in general
Bayesian networks. It is based on the specific local integration (SLI) which is
measured with respect to a partition. CLI is the minimum value of SLI over all
partitions. We prove that $\iota$-entities are blocks in specific partitions of
the global trajectory. These partitions are the finest partitions that achieve
a given SLI value. We also establish the transformation behaviour of SLI under
permutations of nodes in the network.
  We go on to present three conditions on general definitions of entities.
These are not fulfilled by sets of random variables i.e.\ the perception-action
loop, which is often used to model agents, is too restrictive. We propose that
any general entity definition should in effect specify a subset (called an an
entity-set) of the set of all spatiotemporal patterns of a given multivariate
Markov chain. The set of $\iota$-entities is such a set. Importantly the
perception-action loop also induces an entity-set.
  We then propose formal definitions of actions and perceptions for arbitrary
entity-sets. These specialise to standard notions in case of the
perception-action loop entity-set.
  Finally we look at some very simple examples.
</dc:description>
 <dc:description>Comment: PhD thesis, 198 pages</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02716</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02718</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Learning for Cooperative Inference</dc:title>
 <dc:creator>Nedi&#x107;, Angelia</dc:creator>
 <dc:creator>Olshevsky, Alex</dc:creator>
 <dc:creator>Uribe, C&#xe9;sar A.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the problem of cooperative inference where a group of agents
interact over a network and seek to estimate a joint parameter that best
explains a set of observations. Agents do not know the network topology or the
observations of other agents. We explore a variational interpretation of the
Bayesian posterior density, and its relation to the stochastic mirror descent
algorithm, to propose a new distributed learning algorithm. We show that, under
appropriate assumptions, the beliefs generated by the proposed algorithm
concentrate around the true parameter exponentially fast. We provide explicit
non-asymptotic bounds for the convergence rate. Moreover, we develop explicit
and computationally efficient algorithms for observation models belonging to
exponential families.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02724</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CanvoX: High-resolution VR Painting in Large Volumetric Canvas</dc:title>
 <dc:creator>Kim, Yeojin</dc:creator>
 <dc:creator>Kim, Byungmoon</dc:creator>
 <dc:creator>Kim, Jiyang</dc:creator>
 <dc:creator>Kim, Young J.</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  With virtual reality, digital painting on 2D canvases is now being extended
to 3D spaces. Tilt Brush and Oculus Quill are widely accepted among artists as
tools that pave the way to a new form of art - 3D emmersive painting. Current
3D painting systems are only a start, emitting textured triangular geometries.
In this paper, we advance this new art of 3D painting to 3D volumetric painting
that enables an artist to draw a huge scene with full control of spatial color
fields. Inspired by the fact that 2D paintings often use vast space to paint
background and small but detailed space for foreground, we claim that
supporting a large canvas in varying detail is essential for 3D painting. In
order to help artists focus and audiences to navigate the large canvas space,
we provide small artist-defined areas, called rooms, that serve as beacons for
artist-suggested scales, spaces, locations for intended appreciation view of
the painting. Artists and audiences can easily transport themselves between
different rooms. Technically, our canvas is represented as an array of deep
octrees of depth 24 or higher, built on CPU for volume painting and on GPU for
volume rendering using accurate ray casting. In CPU side, we design an
efficient iterative algorithm to refine or coarsen octree, as a result of
volumetric painting strokes, at highly interactive rates, and update the
corresponding GPU textures. Then we use GPU-based ray casting algorithms to
render the volumetric painting result. We explore precision issues stemming
from ray-casting the octree of high depth, and provide a new analysis and
verification. From our experimental results as well as the positive feedback
from the participating artists, we strongly believe that our new 3D volume
painting system can open up a new possibility for VR-driven digital art medium
to professional artists as well as to novice users.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02724</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02729</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepPermNet: Visual Permutation Learning</dc:title>
 <dc:creator>Cruz, Rodrigo Santa</dc:creator>
 <dc:creator>Fernando, Basura</dc:creator>
 <dc:creator>Cherian, Anoop</dc:creator>
 <dc:creator>Gould, Stephen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a principled approach to uncover the structure of visual data by
solving a novel deep learning task coined visual permutation learning. The goal
of this task is to find the permutation that recovers the structure of data
from shuffled versions of it. In the case of natural images, this task boils
down to recovering the original image from patches shuffled by an unknown
permutation matrix. Unfortunately, permutation matrices are discrete, thereby
posing difficulties for gradient-based methods. To this end, we resort to a
continuous approximation of these matrices using doubly-stochastic matrices
which we generate from standard CNN predictions using Sinkhorn iterations.
Unrolling these iterations in a Sinkhorn network layer, we propose DeepPermNet,
an end-to-end CNN model for this task. The utility of DeepPermNet is
demonstrated on two challenging computer vision problems, namely, (i) relative
attributes learning and (ii) self-supervised representation learning. Our
results show state-of-the-art performance on the Public Figures and OSR
benchmarks for (i) and on the classification and segmentation tasks on the
PASCAL VOC dataset for (ii).
</dc:description>
 <dc:description>Comment: Accepted in IEEE International Conference on Computer Vision and
  Pattern Recognition CVPR 2017</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02729</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02732</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Degrees of Freedom and Achievable Rate of Wide-Band Multi-cell Multiple
  Access Channels With No CSIT</dc:title>
 <dc:creator>Jeon, Yo-Seb</dc:creator>
 <dc:creator>Lee, Namyoon</dc:creator>
 <dc:creator>Tandon, Ravi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers a $K$-cell multiple access channel with inter-symbol
interference. The primary finding of this paper is that, without instantaneous
channel state information at the transmitters (CSIT), the sum
degrees-of-freedom (DoF) of the considered channel is $\frac{\beta -1}{\beta}K$
with $\beta \geq 2$ when the number of users per cell is sufficiently large,
where $\beta$ is the ratio of the maximum channel-impulse-response (CIR) length
of desired links to that of interfering links in each cell. Our finding implies
that even without instantaneous CSIT, \textit{interference-free DoF per cell}
is achievable as $\beta$ approaches infinity with a sufficiently large number
of users per cell. This achievability is shown by a blind interference
management method that exploits the relativity in delay spreads between desired
and interfering links. In this method, all inter-cell-interference signals are
aligned to the same direction by using a discrete-Fourier-transform-based
precoding with cyclic prefix that only depends on the number of CIR taps. Using
this method, we also characterize the achievable sum rate of the considered
channel, in a closed-form expression.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Communications</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02732</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02737</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Mode Distinguishability for Switching Systems Subject to Sparse
  Attacks</dc:title>
 <dc:creator>Fiore, Gabriella</dc:creator>
 <dc:creator>De Santis, Elena</dc:creator>
 <dc:creator>Di Benedetto, Maria Domenica</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Switching systems are an important mathematical formalism when dealing with
Cyber-Physical Systems (CPSs). In this paper we provide conditions for the
exact reconstruction of the initial discrete state of a switching system, when
only the continuous output is measurable, and the discrete output signal is not
available. In particular, assuming that the continuous input and output signals
may be corrupted by additive malicious attacks, we provide conditions for the
secure mode distinguishability for linear switching systems. As illustrative
example, we consider the hybrid model of a DC/DC boost converter.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02737</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02738</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detail-revealing Deep Video Super-resolution</dc:title>
 <dc:creator>Tao, Xin</dc:creator>
 <dc:creator>Gao, Hongyun</dc:creator>
 <dc:creator>Liao, Renjie</dc:creator>
 <dc:creator>Wang, Jue</dc:creator>
 <dc:creator>Jia, Jiaya</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Previous CNN-based video super-resolution approaches need to align multiple
frames to the reference. In this paper, we show that proper frame alignment and
motion compensation is crucial for achieving high quality results. We
accordingly propose a `sub-pixel motion compensation' (SPMC) layer in a CNN
framework. Analysis and experiments show the suitability of this layer in video
SR. The final end-to-end, scalable CNN framework effectively incorporates the
SPMC layer and fuses multiple frames to reveal image details. Our
implementation can generate visually and quantitatively high-quality results,
superior to current state-of-the-arts, without the need of parameter tuning.
</dc:description>
 <dc:description>Comment: 9 pages, submitted to conference</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02738</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02748</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Connectivity with Multiple Nonisotropic Antennas for Vehicular
  Communications</dc:title>
 <dc:creator>Nagalapur, Keerthi Kumar</dc:creator>
 <dc:creator>Str&#xf6;m, Erik G.</dc:creator>
 <dc:creator>Br&#xe4;nnstr&#xf6;m, Fredrik</dc:creator>
 <dc:creator>Carlsson, Jan</dc:creator>
 <dc:creator>Karlsson, Kristian</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  For critical services, such as traffic safety and traffic efficiency, it is
advisable to design systems with robustness as the main criteria, possibly at
the price of reduced peak performance and efficiency. Ensuring robust
communications in case of embedded or hidden antennas is a challenging task due
to nonisotropic radiation patterns of these antennas. The challenges due to the
nonisotropic radiation patterns can be overcome with the use of multiple
antennas. In this paper, we describe a simple, low-cost method for combining
the output of multiple nonisotropic antennas to guarantee robustness, i.e.,
support reliable communications in worst-case scenarios. The combining method
is designed to minimize the burst error probability, i.e., the probability of
consecutive decoding errors of status messages arriving periodically at a
receiver from an arbitrary angle of arrival. The proposed method does not
require the knowledge of instantaneous signal-to-noise ratios or the
complex-valued channel gains at the antenna outputs. The proposed method is
applied to measured and theoretical antenna radiation patterns, and it is shown
that the method supports robust communications from an arbitrary angle of
arrival.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02748</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02754</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Synchronization Algorithm Based on Moving Average for Robust Audio
  Watermarking Scheme</dc:title>
 <dc:creator>Jin-quan, Zhang</dc:creator>
 <dc:creator>Bin, Han</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  A synchronization code scheme based on moving average is proposed for robust
audio watermarking in the paper. Two proper positive integers are chosen to
compute the moving average sequence by sliding one sample every time. The
synchronization bits are embedded at crosses of the two moving average
sequences with the quantization index modulation. The experimental results show
that the proposed watermarking scheme maintains high audio quality and is
robust to common attacks such as additive white Gaussian noise, re-sampling,
low-pass filtering, random cropping, MP3 compression, jitter attack and time
scale modification. Simultaneously, the algorithm has high search efficiency
and low false alarm rate.
</dc:description>
 <dc:description>Comment: 23 pages, 7 tables,5 figures</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02754</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02755</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Audio Watermarking Algorithm Based on Moving Average and DCT</dc:title>
 <dc:creator>Zhang, Jinquan</dc:creator>
 <dc:creator>Han, Bin</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Noise is often brought to host audio by common signal processing operation,
and it usually changes the high-frequency component of an audio signal. So
embedding watermark by adjusting low-frequency coefficient can improve the
robustness of a watermark scheme. Moving Average sequence is a low-frequency
feature of an audio signal. This work proposed a method which embedding
watermark into the maximal coefficient in discrete cosine transform domain of a
moving average sequence. Subjective and objective tests reveal that the
proposed watermarking scheme maintains highly audio quality, and
simultaneously, the algorithm is highly robust to common digital signal
processing operations, including additive noise, sampling rate change, bit
resolution transformation, MP3 compression, and random cropping, especially
low-pass filtering.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02755</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02767</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deterministic Distributed Edge-Coloring via Hypergraph Maximal Matching</dc:title>
 <dc:creator>Fischer, Manuela</dc:creator>
 <dc:creator>Ghaffari, Mohsen</dc:creator>
 <dc:creator>Kuhn, Fabian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present a deterministic distributed algorithm that computes a
$(2\Delta-1)$-edge-coloring, or even list-edge-coloring, in any $n$-node graph
with maximum degree $\Delta$, in $O(\log^7 \Delta \log n)$ rounds. This answers
one of the long-standing open questions of \emph{distributed graph algorithms}
from the late 1980s, which asked for a polylogarithmic-time algorithm. See,
e.g., Open Problem 4 in the Distributed Graph Coloring book of Barenboim and
Elkin. The previous best round complexities were $2^{O(\sqrt{\log n})}$ by
Panconesi and Srinivasan [STOC'92] and $\tilde{O}(\sqrt{\Delta}) + O(\log^* n)$
by Fraigniaud, Heinrich, and Kosowski [FOCS'16]. A corollary of our
deterministic list-edge-coloring also improves the randomized complexity of
$(2\Delta-1)$-edge-coloring to poly$(\log\log n)$ rounds.
  The key technical ingredient is a deterministic distributed algorithm for
\emph{hypergraph maximal matching}, which we believe will be of interest beyond
this result. In any hypergraph of rank $r$ --- where each hyperedge has at most
$r$ vertices --- with $n$ nodes and maximum degree $\Delta$, this algorithm
computes a maximal matching in $O(r^5 \log^{6+\log r } \Delta \log n)$ rounds.
  This hypergraph matching algorithm and its extensions lead to a number of
other results. In particular, a polylogarithmic-time deterministic distributed
maximal independent set algorithm for graphs with bounded neighborhood
independence, hence answering Open Problem 5 of Barenboim and Elkin's book, a
$((\log \Delta/\varepsilon)^{O(\log (1/\varepsilon))})$-round deterministic
algorithm for $(1+\varepsilon)$-approximation of maximum matching, and a
quasi-polylogarithmic-time deterministic distributed algorithm for orienting
$\lambda$-arboricity graphs with out-degree at most $(1+\varepsilon)\lambda$,
for any constant $\varepsilon&gt;0$, hence partially answering Open Problem 10 of
Barenboim and Elkin's book.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02767</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02768</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prover efficient public verification of dense or sparse/structured
  matrix-vector multiplication</dc:title>
 <dc:creator>Dumas, Jean-Guillaume</dc:creator>
 <dc:creator>Zucca, Vincent</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  With the emergence of cloud computing services, computationally weak devices
(Clients) can delegate expensive tasks to more powerful entities (Servers).
This raises the question of verifying a result at a lower cost than that of
recomputing it. This verification can be private, between the Client and the
Server, or public, when the result can be verified by any third party. We here
present protocols for the verification of matrix-vector multiplications, that
are secure against malicious Servers. The obtained algorithms are essentially
optimal in the amortized model: the overhead for the Server is limited to a
very small constant factor, even in the sparse or structured matrix case; and
the computational time for the public Verifier is linear in the dimension. Our
protocols combine probabilistic checks and cryptographic operations, but
minimize the latter to preserve practical efficiency. Therefore our protocols
are overall more than two orders of magnitude faster than existing ones.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02768</dc:identifier>
 <dc:identifier>ACISP 2017, 22nd Australasian Conference on Information Security
  and Privacy, Jul 2017, Auckland, New Zealand. Lecture Notes in Computer
  Science, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02770</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Massively parallel implementation and approaches to simulate quantum
  dynamics using Krylov subspace techniques</dc:title>
 <dc:creator>Brenes, Marlon</dc:creator>
 <dc:creator>Varma, Vipin Kerala</dc:creator>
 <dc:creator>Scardicchio, Antonello</dc:creator>
 <dc:creator>Girotto, Ivan</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Strongly Correlated Electrons</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We have developed an application and implemented parallel algorithms in order
to provide a computational framework suitable for massively parallel
supercomputers to study the unitary dynamics of quantum systems. We use
renowned parallel libraries such as PETSc/SLEPc combined with high-performance
computing approaches in order to overcome the large memory requirements to be
able to study systems whose Hilbert space dimension comprises over 9 billion
independent quantum states. Moreover, we provide descriptions on the parallel
approach used for the three most important stages of the simulation: handling
the Hilbert subspace basis, constructing a matrix representation for a generic
Hamiltonian operator and the time evolution of the system by means of the
Krylov subspace methods. We employ our setup to study the evolution of
quasidisordered and clean many-body systems, focussing on the return
probability and related dynamical exponents: the large system sizes accessible
provide novel insights into their thermalization properties.
</dc:description>
 <dc:description>Comment: 16 pages, 6 figures, 3 tables</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02770</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02771</identifier>
 <datestamp>2017-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Group Importance Sampling for Particle Filtering and MCMC</dc:title>
 <dc:creator>Martino, L.</dc:creator>
 <dc:creator>Elvira, V.</dc:creator>
 <dc:creator>Camps-Valls, G.</dc:creator>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Importance Sampling (IS) is a well-known Monte Carlo technique that
approximates integrals involving a posterior distribution by means of weighted
samples. In this work, we study the assignation of a single weighted sample
which compresses the information contained in a population of weighted samples.
Part of the theory that we present as Group Importance Sampling (GIS) has been
employed implicitly in different works in the literature. The provided analysis
yields several theoretical and practical consequences. For instance, we discuss
the application of GIS into the Sequential Importance Resampling framework and
show that Independent Multiple Try Metropolis schemes can be interpreted as a
standard Metropolis-Hastings algorithm, following the GIS approach. We also
introduce two novel Markov Chain Monte Carlo (MCMC) techniques based on GIS.
The first one, named Group Metropolis Sampling method, produces a Markov chain
of sets of weighted samples. All these sets are then employed for obtaining a
unique global estimator. The second one is the Distributed Particle
Metropolis-Hastings technique, where different parallel particle filters are
jointly used to drive an MCMC algorithm. Different resampled trajectories are
compared and then tested with a proper acceptance probability. The novel
schemes are tested in different numerical experiments such as learning the
hyperparameters of Gaussian Processes, the localization problem in a wireless
sensor network and the tracking of vegetation parameters given satellite
observations, where they are compared with several benchmark Monte Carlo
techniques. Three illustrative Matlab demos are also provided.
</dc:description>
 <dc:description>Comment: Related Matlab demos are provided at
  https://github.com/lukafree/GIS.git</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-04-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02771</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02774</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Professional Hackers Understand Protected Code while Performing
  Attack Tasks</dc:title>
 <dc:creator>Ceccato, Mariano</dc:creator>
 <dc:creator>Tonella, Paolo</dc:creator>
 <dc:creator>Basile, Cataldo</dc:creator>
 <dc:creator>Coppens, Bart</dc:creator>
 <dc:creator>De Sutter, Bjorn</dc:creator>
 <dc:creator>Falcarin, Paolo</dc:creator>
 <dc:creator>Torchiano, Marco</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Code protections aim at blocking (or at least delaying) reverse engineering
and tampering attacks to critical assets within programs. Knowing the way
hackers understand protected code and perform attacks is important to achieve a
stronger protection of the software assets, based on realistic assumptions
about the hackers' behaviour. However, building such knowledge is difficult
because hackers can hardly be involved in controlled experiments and empirical
studies. The FP7 European project Aspire has given the authors of this paper
the unique opportunity to have access to the professional penetration testers
employed by the three industrial partners. In particular, we have been able to
perform a qualitative analysis of three reports of professional penetration
test performed on protected industrial code. Our qualitative analysis of the
reports consists of open coding, carried out by 7 annotators and resulting in
459 annotations, followed by concept extraction and model inference. We
identified the main activities: understanding, building attack, choosing and
customizing tools, and working around or defeating protections. We built a
model of how such activities take place. We used such models to identify a set
of research directions for the creation of stronger code protections.
</dc:description>
 <dc:description>Comment: Post-print for ICPC 2017 conference</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-05-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02774</dc:identifier>
 <dc:identifier>doi:10.1109/ICPC.2017.2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02781</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracking the Trackers: An Analysis of the State of the Art in Multiple
  Object Tracking</dc:title>
 <dc:creator>Leal-Taix&#xe9;, Laura</dc:creator>
 <dc:creator>Milan, Anton</dc:creator>
 <dc:creator>Schindler, Konrad</dc:creator>
 <dc:creator>Cremers, Daniel</dc:creator>
 <dc:creator>Reid, Ian</dc:creator>
 <dc:creator>Roth, Stefan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Standardized benchmarks are crucial for the majority of computer vision
applications. Although leaderboards and ranking tables should not be
over-claimed, benchmarks often provide the most objective measure of
performance and are therefore important guides for research. We present a
benchmark for Multiple Object Tracking launched in the late 2014, with the goal
of creating a framework for the standardized evaluation of multiple object
tracking methods. This paper collects the two releases of the benchmark made so
far, and provides an in-depth analysis of almost 50 state-of-the-art trackers
that were tested on over 11000 frames. We show the current trends and
weaknesses of multiple people tracking methods, and provide pointers of what
researchers should be focusing on to push the field forward.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02781</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02782</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Kth Traveling Salesman Problem is Pseudopolynomial when TSP is
  polynomial</dc:title>
 <dc:creator>Chaourar, Brahim</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>90C27 (Primary), 90C57 (Secondary)</dc:subject>
 <dc:description>  Given an undirected graph $G=(V, E)$ with a weight function $c\in R^E$, and a
positive integer $K$, the Kth Traveling Salesman Problem (KthTSP) is to find
$K$ Hamilton cycles $H_1, H_2, , ..., H_K$ such that, for any Hamilton cycle
$H\not \in \{H_1, H_2, , ..., H_K \}$, we have $c(H)\geq c(H_i), i=1, 2, ...,
K$. This problem is NP-hard even for $K$ fixed. We prove that KthTSP is
pseudopolynomial when TSP is polynomial.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02782</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02786</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Flawed Tutorials for Seeding Large-Scale Web Vulnerability
  Discovery</dc:title>
 <dc:creator>Unruh, Tommi</dc:creator>
 <dc:creator>Shastry, Bhargava</dc:creator>
 <dc:creator>Skoruppa, Malte</dc:creator>
 <dc:creator>Maggi, Federico</dc:creator>
 <dc:creator>Rieck, Konrad</dc:creator>
 <dc:creator>Seifert, Jean-Pierre</dc:creator>
 <dc:creator>Yamaguchi, Fabian</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The Web is replete with tutorial-style content on how to accomplish
programming tasks. Unfortunately, even top-ranked tutorials suffer from severe
security vulnerabilities, such as cross-site scripting (XSS), and SQL injection
(SQLi). Assuming that these tutorials influence real-world software
development, we hypothesize that code snippets from popular tutorials can be
used to bootstrap vulnerability discovery at scale. To validate our hypothesis,
we propose a semi-automated approach to find recurring vulnerabilities starting
from a handful of top-ranked tutorials that contain vulnerable code snippets.
We evaluate our approach by performing an analysis of tens of thousands of
open-source web applications to check if vulnerabilities originating in the
selected tutorials recur. Our analysis framework has been running on a standard
PC, analyzed 64,415 PHP codebases hosted on GitHub thus far, and found a total
of 117 vulnerabilities that have a strong syntactic similarity to vulnerable
code snippets present in popular tutorials. In addition to shedding light on
the anecdotal belief that programmers reuse web tutorial code in an ad hoc
manner, our study finds disconcerting evidence of insufficiently reviewed
tutorials compromising the security of open-source projects. Moreover, our
findings testify to the feasibility of large-scale vulnerability discovery
using poorly written tutorials as a starting point.
</dc:description>
 <dc:description>Comment: 17+3 pages</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02786</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02787</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Affordance-grounded Sensorimotor Object Recognition</dc:title>
 <dc:creator>Thermos, Spyridon</dc:creator>
 <dc:creator>Papadopoulos, Georgios Th.</dc:creator>
 <dc:creator>Daras, Petros</dc:creator>
 <dc:creator>Potamianos, Gerasimos</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  It is well-established by cognitive neuroscience that human perception of
objects constitutes a complex process, where object appearance information is
combined with evidence about the so-called object &quot;affordances&quot;, namely the
types of actions that humans typically perform when interacting with them. This
fact has recently motivated the &quot;sensorimotor&quot; approach to the challenging task
of automatic object recognition, where both information sources are fused to
improve robustness. In this work, the aforementioned paradigm is adopted,
surpassing current limitations of sensorimotor object recognition research.
Specifically, the deep learning paradigm is introduced to the problem for the
first time, developing a number of novel neuro-biologically and
neuro-physiologically inspired architectures that utilize state-of-the-art
neural networks for fusing the available information sources in multiple ways.
The proposed methods are evaluated using a large RGB-D corpus, which is
specifically collected for the task of sensorimotor object recognition and is
made publicly available. Experimental results demonstrate the utility of
affordance information to object recognition, achieving an up to 29% relative
error reduction by its inclusion.
</dc:description>
 <dc:description>Comment: 9 pages, 7 figures, dataset link included, accepted to CVPR 2017</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02788</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entity Linking for Queries by Searching Wikipedia Sentences</dc:title>
 <dc:creator>Tan, Chuanqi</dc:creator>
 <dc:creator>Wei, Furu</dc:creator>
 <dc:creator>Ren, Pengjie</dc:creator>
 <dc:creator>Lv, Weifeng</dc:creator>
 <dc:creator>Zhou, Ming</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a simple yet effective approach for linking entities in queries.
The key idea is to search sentences similar to a query from Wikipedia articles
and directly use the human-annotated entities in the similar sentences as
candidate entities for the query. Then, we employ a rich set of features, such
as link-probability, context-matching, word embeddings, and relatedness among
candidate entities as well as their related entities, to rank the candidates
under a regression based framework. The advantages of our approach lie in two
aspects, which contribute to the ranking process and final linking result.
First, it can greatly reduce the number of candidate entities by filtering out
irrelevant entities with the words in the query. Second, we can obtain the
query sensitive prior probability in addition to the static link-probability
derived from all Wikipedia articles. We conduct experiments on two benchmark
datasets on entity linking for queries, namely the ERD14 dataset and the GERDAQ
dataset. Experimental results show that our method outperforms state-of-the-art
systems and yields 75.0% in F1 on the ERD14 dataset and 56.9% on the GERDAQ
dataset.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02788</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02789</identifier>
 <datestamp>2017-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parsimonious Random Vector Functional Link Network for Data Streams</dc:title>
 <dc:creator>Pratama, Mahardhika</dc:creator>
 <dc:creator>Angelov, Plamen P.</dc:creator>
 <dc:creator>Lughofer, Edwin</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The theory of random vector functional link network (RVFLN) has provided a
breakthrough in the design of neural networks (NNs) since it conveys solid
theoretical justification of randomized learning. Existing works in RVFLN are
hardly scalable for data stream analytics because they are inherent to the
issue of complexity as a result of the absence of structural learning
scenarios. A novel class of RVLFN, namely parsimonious random vector functional
link network (pRVFLN), is proposed in this paper. pRVFLN features an open
structure paradigm where its network structure can be built from scratch and
can be automatically generated in accordance with degree of nonlinearity and
time-varying property of system being modelled. pRVFLN is equipped with
complexity reduction scenarios where inconsequential hidden nodes can be pruned
and input features can be dynamically selected. pRVFLN puts into perspective an
online active learning mechanism which expedites the training process and
relieves operator labelling efforts. In addition, pRVFLN introduces a
non-parametric type of hidden node, developed using an interval-valued data
cloud. The hidden node completely reflects the real data distribution and is
not constrained by a specific shape of the cluster. All learning procedures of
pRVFLN follow a strictly single-pass learning mode, which is applicable for an
online real-time deployment. The efficacy of pRVFLN was rigorously validated
through numerous simulations and comparisons with state-of-the art algorithms
where it produced the most encouraging numerical results. Furthermore, the
robustness of pRVFLN was investigated and a new conclusion is made to the scope
of random parameters where it plays vital role to the success of randomized
learning.
</dc:description>
 <dc:description>Comment: this paper is submitted for publication in Information Sciences</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-05-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02789</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02790</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Analysis of Reliable Video Streaming with Strict Playout
  Deadline in Multi-Hop Wireless Networks</dc:title>
 <dc:creator>Al-Zubaidy, Hussein</dc:creator>
 <dc:creator>Fodor, Viktoria</dc:creator>
 <dc:creator>D&#xe1;n, Gy&#xf6;rgy</dc:creator>
 <dc:creator>Flierl, Markus</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Motivated by emerging vision-based intelligent services, we consider the
problem of rate adaptation for high quality and low delay visual information
delivery over wireless networks using scalable video coding. Rate adaptation in
this setting is inherently challenging due to the interplay between the
variability of the wireless channels, the queuing at the network nodes and the
frame-based decoding and playback of the video content at the receiver at very
short time scales. To address the problem, we propose a low-complexity,
model-based rate adaptation algorithm for scalable video streaming systems,
building on a novel performance model based on stochastic network calculus. We
validate the model using extensive simulations. We show that it allows fast,
near optimal rate adaptation for fixed transmission paths, as well as
cross-layer optimized routing and video rate adaptation in mesh networks, with
less than $10$\% quality degradation compared to the best achievable
performance.
</dc:description>
 <dc:description>Comment: 33 single column pages, 10 figures</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02790</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02792</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fine-graind Image Classification via Combining Vision and Language</dc:title>
 <dc:creator>He, Xiangteng</dc:creator>
 <dc:creator>Peng, Yuxin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Fine-grained image classification is a challenging task due to the large
intra-class variance and small inter-class variance, aiming at recognizing
hundreds of sub-categories belonging to the same basic-level category. Most
existing fine-grained image classification methods generally learn part
detection models to obtain the semantic parts for better classification
accuracy. Despite achieving promising results, these methods mainly have two
limitations: (1) not all the parts which obtained through the part detection
models are beneficial and indispensable for classification, and (2)
fine-grained image classification requires more detailed visual descriptions
which could not be provided by the part locations or attribute annotations. For
addressing the above two limitations, this paper proposes the two-stream model
combining vision and language (CVL) for learning latent semantic
representations. The vision stream learns deep representations from the
original visual information via deep convolutional neural network. The language
stream utilizes the natural language descriptions which could point out the
discriminative parts or characteristics for each image, and provides a flexible
and compact way of encoding the salient visual aspects for distinguishing
sub-categories. Since the two streams are complementary, combining the two
streams can further achieves better classification accuracy. Comparing with 12
state-of-the-art methods on the widely used CUB-200-2011 dataset for
fine-grained image classification, the experimental results demonstrate our CVL
approach achieves the best performance.
</dc:description>
 <dc:description>Comment: 9 pages, to appear in CVPR 2017</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-05-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02792</dc:identifier>
 <dc:identifier>doi:10.1109/CVPR.2017.775</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02793</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Voronoi diagrams on planar graphs, and computing the diameter in
  deterministic $\tilde{O}(n^{5/3})$ time</dc:title>
 <dc:creator>Gawrychowski, Pawe&#x142;</dc:creator>
 <dc:creator>Kaplan, Haim</dc:creator>
 <dc:creator>Mozes, Shay</dc:creator>
 <dc:creator>Sharir, Micha</dc:creator>
 <dc:creator>Weimann, Oren</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We present a deterministic algorithm that computes the diameter of a directed
planar graph with real arc lengths in $\tilde{O}(n^{5/3})$ time. This improves
the recent breakthrough result of Cabello (SODA'17), both by improving the
running time (from $\tilde{O}(n^{11/6})$), and by using a deterministic
algorithm. It is in fact the first truly subquadratic deterministic algorithm
for this problem.
  Our algorithm follows the general high-level approach of Cabello, but differs
in the way it is implemented. Our main technical contribution is an explicit
and efficient construction of additively weighted Voronoi diagrams on planar
graphs (under the assumption that all Voronoi sites lie on a constant number of
faces). The idea of using Voronoi diagrams is also borrowed from Cabello,
except that he uses abstract Voronoi diagrams (as a black box), which makes the
implementation more involved, more expensive, and randomized. Our explicit
construction avoids these issues, and leads to the improved (and deterministic)
running time.
  As in Cabello's work, our algorithm can also compute the Wiener index of (sum
of all pairwise distances in) a planar graph, within the same bounds.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02793</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02794</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient, Single Hop Time Synchronization Protocol For Randomly
  Connected WSNs</dc:title>
 <dc:creator>Al-Shaikhi, Ali</dc:creator>
 <dc:creator>Masoud, Ahmad</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper develops a fast, accurate and energy-efficient time
synchronization protocol in wireless sensor networks that operate in harsh
environments. The suggested protocol concept is based on an electrical physical
metaphor. The protocol treats the nodes times as the states of an
unconditionally stable discrete dynamical system that uses only single hop
communication. The system can terminate at a low number of message exchanges
while still in the transient phase. It can yield high quality time estimates
with accuracies that are fractions of the clock at which node communication
takes place. The synchronizer is developed and its capabilities are
demonstrated by simulation and physical experiments on the MICA-Z wireless
sensor network
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02794</dc:identifier>
 <dc:identifier>IEEE WIRELESS COMMUNICATIONS LETTERS, VOL. 6, NO. 2, APRIL 2017,
  Pp. 170-173</dc:identifier>
 <dc:identifier>doi:10.1109/LWC.2017.2650223</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02796</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Backtracking and Commutative Algorithms for the LLL</dc:title>
 <dc:creator>Iliopoulos, Fotis</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  Following the groundbreaking works of Moser and Tardos~\cite{M,MT} that made
the Lov\'asz Local Lemma (LLL) constructive, a series of works have exploited
key ideas of their analysis to come up with a plethora of results.
  A first line of works employs the entropy compression method to analyze
stochastic search algorithm similar to the Moser-Tardos algorithm but without
explicitly referring to a specific version of the LLL. Such an example is a
class of backtracking algorithms for Constraint Satisfaction Problems (CSPs)
introduced by Grytczuk, Kozik and Micek~\cite{djm}, and later approached more
systematically by the work of Esperet and Parraeu~\cite{ac}, which have found
applications in a wide variety of problems.
  A different series of works exploit a key ingredient of the original analysis
of Moser and Tardos, the witness tree lemma, in order to: derive deterministic
and parallel algorithms for the LLL, to estimate the entropy of the output
distribution, to partially avoid bad events and to deal with super-polynomially
many bad events. Unfortunately, these results do not extend to the most general
algorithmic LLL frameworks~\cite{AI,HV}. Mainly, this is because the witness
tree lemma, provably, no longer holds.
  Our first contribution is to extend the framework of Achlioptas and
Iliopoulos~\cite{AI} and provide a Local Lemma criterion that can capture every
application of backtracking algorithms we are aware of and more. Our second
contribution is to show that for commutative algorithms, a class recently
introduced by Kolmogorov, the witness tree lemma holds. Armed with this fact,
we extend the main result of Haeupler, Saha, and Srinivasan~\cite{HSS} to
commutative algorithms, establishing that the output of such algorithms
well-approximates the LLL-distribution. Moreover, we define a class of
commutative backtracking algorithms and show that we can get similar results.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02796</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02797</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Spatial Multiplexing and Transmit Diversity in MIMO Ad Hoc
  Networks</dc:title>
 <dc:creator>Firyaguna, Fadhil</dc:creator>
 <dc:creator>Christ&#xf3;faro, Ana C. O.</dc:creator>
 <dc:creator>Andrade, &#xc9;verton A. L.</dc:creator>
 <dc:creator>Bonfim, Tiago</dc:creator>
 <dc:creator>Carvalho, Marcelo M.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper investigates the performance of MIMO ad hoc networks that employ
transmit diversity, as delivered by the Alamouti scheme, and/or spatial
multiplexing, according to the Vertical Bell Labs Layered Space-Time system
(V-BLAST). Both techniques are implemented in a discrete-event network
simulator by focusing on their overall effect on the resulting
signal-to-interference-plus-noise ratio (SINR) at the intended receiver. Unlike
previous works that have studied fully-connected scenarios or have assumed
simple abstractions to represent MIMO behavior, this paper evaluates MIMO ad
hoc networks that are not fully connected by taking into account the effects of
multiple antennas on the clear channel assessment (CCA) mechanism of CSMA-like
medium access control (MAC) protocols. In addition to presenting a performance
evaluation of ad hoc networks operating according to each individual MIMO
scheme, this paper proposes simple modifications to the IEEE 802.11 DCF MAC to
allow the joint operation of both MIMO techniques. Hence, each pair of nodes is
allowed to select the best MIMO configuration for the impending data transfer.
The joint operation is based on three operation modes that are selected based
on the estimated SINR at the intended receiver and its comparision with a set
of threshold values. The performance of ad hoc networks operating with the
joint MIMO scheme is compared with their operation using each individual MIMO
scheme and the standard SISO IEEE 802.11. Performance results are presented
based on MAC-level throughput per node, delay, and fairness under saturated
traffic conditions.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02797</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02798</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Recurrent Neural Networks</dc:title>
 <dc:creator>Fortunato, Meire</dc:creator>
 <dc:creator>Blundell, Charles</dc:creator>
 <dc:creator>Vinyals, Oriol</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this work we explore a straightforward variational Bayes scheme for
Recurrent Neural Networks. Firstly, we show that a simple adaptation of
truncated backpropagation through time can yield good quality uncertainty
estimates and superior regularisation at only a small extra computational cost
during training. Secondly, we demonstrate how a novel kind of posterior
approximation yields further improvements to the performance of Bayesian RNNs.
We incorporate local gradient information into the approximate posterior to
sharpen it around the current batch statistics. This technique is not exclusive
to recurrent neural networks and can be applied more widely to train Bayesian
neural networks. We also empirically demonstrate how Bayesian RNNs are superior
to traditional RNNs on a language modelling benchmark and an image captioning
task, as well as showing how each of these methods improve our model over a
variety of other schemes for training them. We also introduce a new benchmark
for studying uncertainty for language models so future methods can be easily
compared.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02799</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comparative Study for Predicting Heart Diseases Using Data Mining
  Classification Methods</dc:title>
 <dc:creator>Zriqat, Israa Ahmed</dc:creator>
 <dc:creator>Altamimi, Ahmad Mousa</dc:creator>
 <dc:creator>Azzeh, Mohammad</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Improving the precision of heart diseases detection has been investigated by
many researchers in the literature. Such improvement induced by the
overwhelming health care expenditures and erroneous diagnosis. As a result,
various methodologies have been proposed to analyze the disease factors aiming
to decrease the physicians practice variation and reduce medical costs and
errors. In this paper, our main motivation is to develop an effective
intelligent medical decision support system based on data mining techniques. In
this context, five data mining classifying algorithms, with large datasets,
have been utilized to assess and analyze the risk factors statistically related
to heart diseases in order to compare the performance of the implemented
classifiers (e.g., Na\&quot;ive Bayes, Decision Tree, Discriminant, Random Forest,
and Support Vector Machine). To underscore the practical viability of our
approach, the selected classifiers have been implemented using MATLAB tool with
two datasets. Results of the conducted experiments showed that all
classification algorithms are predictive and can give relatively correct
answer. However, the decision tree outperforms other classifiers with an
accuracy rate of 99.0% followed by Random forest. That is the case because both
of them have relatively same mechanism but the Random forest can build ensemble
of decision tree. Although ensemble learning has been proved to produce
superior results, but in our case the decision tree has outperformed its
ensemble version.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02799</dc:identifier>
 <dc:identifier>ISSN 1947-5500</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02801</identifier>
 <datestamp>2017-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Inference of Individualized Treatment Effects using Multi-task
  Gaussian Processes</dc:title>
 <dc:creator>Alaa, Ahmed M.</dc:creator>
 <dc:creator>van der Schaar, Mihaela</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Predicated on the increasing abundance of electronic health records, we
investi- gate the problem of inferring individualized treatment effects using
observational data. Stemming from the potential outcomes model, we propose a
novel multi- task learning framework in which factual and counterfactual
outcomes are mod- eled as the outputs of a function in a vector-valued
reproducing kernel Hilbert space (vvRKHS). We develop a nonparametric Bayesian
method for learning the treatment effects using a multi-task Gaussian process
(GP) with a linear coregion- alization kernel as a prior over the vvRKHS. The
Bayesian approach allows us to compute individualized measures of confidence in
our estimates via pointwise credible intervals, which are crucial for realizing
the full potential of precision medicine. The impact of selection bias is
alleviated via a risk-based empirical Bayes method for adapting the multi-task
GP prior, which jointly minimizes the empirical error in factual outcomes and
the uncertainty in (unobserved) counter- factual outcomes. We conduct
experiments on observational datasets for an inter- ventional social program
applied to premature infants, and a left ventricular assist device applied to
cardiac patients wait-listed for a heart transplant. In both experi- ments, we
show that our method significantly outperforms the state-of-the-art.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-05-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02801</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02803</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Making Defeating CAPTCHAs Harder for Bots</dc:title>
 <dc:creator>Al-Fannah, Nasser Mohammed</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  For a number of years, many websites have used CAPTCHAs to filter out
interactions by bots. However, attackers have found ways to circumvent CAPTCHAs
by programming bots to solve or bypass them, or even relay them for humans to
solve. In order to reduce the chances of success of such attacks, CAPTCHAs can
be strengthened by the addition of certain safeguards. In this paper, we
discuss seven existing safeguards as well as five novel safeguards designed to
make circumventing CAPTCHAs harder. These safeguards are not mutually exclusive
and can add multiple layers of protection to a CAPTCHA. We further provide a
high-level comparison of their effectiveness in addressing the threat posed by
CAPTCHA-defeating techniques. In order to focus on safeguards that are usable,
we restrict our attention to those which have minimal adverse effect on the
user experience.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02803</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02806</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Serving Distance and Coverage in a Closed Access PHP-Based Heterogeneous
  Cellular Network</dc:title>
 <dc:creator>Yazdanshenasan, Zeinab</dc:creator>
 <dc:creator>Dhillon, Harpreet S.</dc:creator>
 <dc:creator>Chong, Peter Han Joo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Heterogeneous cellular networks (HCNs) usually exhibit spatial separation
amongst base stations (BSs) of different types (termed tiers in this paper).
For instance, operators will usually not deploy a picocell in close proximity
to a macrocell, thus inducing separation amongst the locations of pico and
macrocells. This separation has recently been captured by modeling the small
cell locations by a Poisson Hole Process (PHP) with the hole centers being the
locations of the macrocells. Due to the presence of exclusion zones, the
analysis of the resulting model is significantly more complex compared to the
more popular Poisson Point Process (PPP) based models. In this paper, we derive
a tight bound on the distribution of the distance of a typical user to the
closest point of a PHP. Since the exact distribution of this distance is not
known, it is often approximated in the literature. For this model, we then
provide tight characterization of the downlink coverage probability for a
typical user in a two-tier closed-access HCN under two cases: (i) typical user
is served by the closest macrocell, and (ii) typical user is served by its
closest small cell. The proposed approach can be extended to analyze other
relevant cases of interest, e.g., coverage in a PHP-based open access HCN.
</dc:description>
 <dc:description>Comment: Proc., Biennial Symposium on Communications (BSC), 2016</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02806</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02809</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>R-Clustering for Egocentric Video Segmentation</dc:title>
 <dc:creator>Talavera, Estefania</dc:creator>
 <dc:creator>Dimiccoli, Mariella</dc:creator>
 <dc:creator>Bola&#xf1;os, Marc</dc:creator>
 <dc:creator>Aghaei, Maedeh</dc:creator>
 <dc:creator>Radeva, Petia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we present a new method for egocentric video temporal
segmentation based on integrating a statistical mean change detector and
agglomerative clustering(AC) within an energy-minimization framework. Given the
tendency of most AC methods to oversegment video sequences when clustering
their frames, we combine the clustering with a concept drift detection
technique (ADWIN) that has rigorous guarantee of performances. ADWIN serves as
a statistical upper bound for the clustering-based video segmentation. We
integrate both techniques in an energy-minimization framework that serves to
disambiguate the decision of both techniques and to complete the segmentation
taking into account the temporal continuity of video frames descriptors. We
present experiments over egocentric sets of more than 13.000 images acquired
with different wearable cameras, showing that our method outperforms
state-of-the-art clustering methods.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02809</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02813</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Character-Word LSTM Language Models</dc:title>
 <dc:creator>Verwimp, Lyan</dc:creator>
 <dc:creator>Pelemans, Joris</dc:creator>
 <dc:creator>Van hamme, Hugo</dc:creator>
 <dc:creator>Wambacq, Patrick</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a Character-Word Long Short-Term Memory Language Model which both
reduces the perplexity with respect to a baseline word-level language model and
reduces the number of parameters of the model. Character information can reveal
structural (dis)similarities between words and can even be used when a word is
out-of-vocabulary, thus improving the modeling of infrequent and unknown words.
By concatenating word and character embeddings, we achieve up to 2.77% relative
improvement on English compared to a baseline model with a similar amount of
parameters and 4.57% on Dutch. Moreover, we also outperform baseline word-level
models with a larger number of parameters.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02813</dc:identifier>
 <dc:identifier>European Chapter of the Association for Computational Linguistics
  (EACL) 2017, Valencia, Spain, pp. 417-427</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02819</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flags of almost affine codes</dc:title>
 <dc:creator>Johnsen, Trygve</dc:creator>
 <dc:creator>Verdure, Hugues</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We describe a two-party wire-tap channel of type II in the framework of
almost affine codes. Its cryptological performance is related to some relative
profiles of a pair of almost affine codes. These profiles are analogues of
relative generalized Hamming weights in the linear case.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02824</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Industry 4.0: Gap Analysis between Current Automotive MES and
  Industry Standards using Model-Based Requirement Engineering</dc:title>
 <dc:creator>Soundarapandian, Manoj Kannan</dc:creator>
 <dc:creator>Suri, Kunal</dc:creator>
 <dc:creator>Cadavid, Juan</dc:creator>
 <dc:creator>Barosan, Ion</dc:creator>
 <dc:creator>Brand, Mark Van Den</dc:creator>
 <dc:creator>Alferez, Mauricio</dc:creator>
 <dc:creator>Gerard, Sebastien</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The dawn of the fourth industrial revolution, Industry 4.0 has created great
enthusiasm among companies and researchers by giving them an opportunity to
pave the path towards the vision of a connected smart factory ecosystem.
However, in context of automotive industry there is an evident gap between the
requirements supported by the current automotive manufacturing execution
systems (MES) and the requirements proposed by industrial standards from the
International Society of Automation (ISA) such as, ISA-95, ISA-88 over which
the Industry 4.0 is being built on. In this paper, we bridge this gap by
following a model-based requirements engineering approach along with a gap
analysis process. Our work is mainly divided into three phases, (i) automotive
MES tool selection phase, (ii) requirements modeling phase, (iii) and gap
analysis phase based on the modeled requirements. During the MES tool selection
phase, we used known reliable sources such as, MES product survey reports,
white papers that provide in-depth and comprehensive information about various
comparison criteria and tool vendors list for the current MES landscape. During
the requirement modeling phase, we specified requirements derived from the
needs of ISA-95 and ISA-88 industrial standards using the general purpose
Systems Modeling Language (SysML). During the gap analysis phase, we find the
misalignment between standard requirements and the compliance of the existing
software tools to those standards.
</dc:description>
 <dc:description>Comment: 7 Pages, Accepted Paper (Preprint) at Third International Workshop on
  Automotive Software Architectures (WASA 2017), 03 April 2017 to 07 April
  2017, Gothenburg, Sweden</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02824</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02827</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Human Motion Models for Long-term Predictions</dc:title>
 <dc:creator>Ghosh, Partha</dc:creator>
 <dc:creator>Song, Jie</dc:creator>
 <dc:creator>Aksan, Emre</dc:creator>
 <dc:creator>Hilliges, Otmar</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a new architecture for the learning of predictive spatio-temporal
motion models from data alone. Our approach, dubbed the Dropout Autoencoder
LSTM, is capable of synthesizing natural looking motion sequences over long
time horizons without catastrophic drift or motion degradation. The model
consists of two components, a 3-layer recurrent neural network to model
temporal aspects and a novel auto-encoder that is trained to implicitly recover
the spatial structure of the human skeleton via randomly removing information
about joints during training time. This Dropout Autoencoder (D-AE) is then used
to filter each predicted pose of the LSTM, reducing accumulation of error and
hence drift over time. Furthermore, we propose new evaluation protocols to
assess the quality of synthetic motion sequences even for which no ground truth
data exists. The proposed protocols can be used to assess generated sequences
of arbitrary length. Finally, we evaluate our proposed method on two of the
largest motion-capture datasets available to date and show that our model
outperforms the state-of-the-art on a variety of actions, including cyclic and
acyclic motion, and that it can produce natural looking sequences over longer
time horizons than previous methods.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02827</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02837</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Throughput Optimal Random Medium Access Control for Relay Networks with
  Time-Varying Channels</dc:title>
 <dc:creator>Abad, Mehdi Salehi Heydar</dc:creator>
 <dc:creator>Ercetin, Ozgur</dc:creator>
 <dc:creator>Ekici, Eylem</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The use of existing network devices as relays has a potential to improve the
overall network performance. In this work, we consider a two-hop wireless relay
setting, where the channels between the source and relay nodes to the
destination node are time varying. The relay nodes are able to overhear the
transmissions of the source node which may have a weak connection to the
destination, and they help the source node by forwarding its messages to the
destination on its behalf, whenever this is needed. We develop a distributed
scheme for relay selection and channel access that is suitable for time-varying
channels, and prove that this scheme is throughput optimal. We obtain the
achievable rate region of our proposed scheme analytically for a relay network
with a single source and a single relay node. Meanwhile, for a more general
network with more than one relay nodes, we perform Monte-Carlo simulations to
obtain the achievable rate region. In both cases, we demonstrate that the
achievable rate region attained with our distributed scheme is the same as the
one attained with centralized optimal scheme.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02837</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02839</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Application of the Waveform Relaxation Technique to the Co-Simulation of
  Power Converter Controller and Electrical Circuit Models</dc:title>
 <dc:creator>Maciejewski, Micha&#x142;</dc:creator>
 <dc:creator>Garcia, Idoia Cortes</dc:creator>
 <dc:creator>Sch&#xf6;ps, Sebastian</dc:creator>
 <dc:creator>Auchmann, Bernhard</dc:creator>
 <dc:creator>Bortot, Lorenzo</dc:creator>
 <dc:creator>Prioli, Marco</dc:creator>
 <dc:creator>Verweij, Arjan</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Physics - Accelerator Physics</dc:subject>
 <dc:subject>94C99, 65L80, 49J15</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>I.6.3</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:description>  In this paper we present the co-simulation of a PID class power converter
controller and an electrical circuit by means of the waveform relaxation
technique. The simulation of the controller model is characterized by a
fixed-time stepping scheme reflecting its digital implementation, whereas a
circuit simulation usually employs an adaptive time stepping scheme in order to
account for a wide range of time constants within the circuit model. In order
to maintain the characteristic of both models as well as to facilitate model
replacement, we treat them separately by means of input/output relations and
propose an application of a waveform relaxation algorithm. Furthermore, the
maximum and minimum number of iterations of the proposed algorithm are
mathematically analyzed. The concept of controller/circuit coupling is
illustrated by an example of the co-simulation of a PI power converter
controller and a model of the main dipole circuit of the Large Hadron Collider.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02839</dc:identifier>
 <dc:identifier>2017 22nd International Conference on Methods and Models in
  Automation and Robotics (MMAR), Miedzyzdroje, Poland, 2017, pp. 837-842</dc:identifier>
 <dc:identifier>doi:10.1109/MMAR.2017.8046937</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02841</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Modal to Multimodal Ambiguities: a Classification Approach</dc:title>
 <dc:creator>Caschera, Maria Chiara</dc:creator>
 <dc:creator>Ferri, Fernando</dc:creator>
 <dc:creator>Grifoni, Patrizia</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.1</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper deals with classifying ambiguities for Multimodal Languages. It
evolves the classifications and the methods of the literature on ambiguities
for Natural Language and Visual Language, empirically defining an original
classification of ambiguities for multimodal interaction using a linguistic
perspective. This classification distinguishes between Semantic and Syntactic
multimodal ambiguities and their subclasses, which are intercepted using a
rule-based method implemented in a software module. The experimental results
have achieved an accuracy of the obtained classification compared to the
expected one, which are defined by the human judgment, of 94.6% for the
semantic ambiguities classes, and 92.1% for the syntactic ambiguities classes.
</dc:description>
 <dc:description>Comment: 23 pages</dc:description>
 <dc:date>2017-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02841</dc:identifier>
 <dc:identifier>JNIT (Journal of Next Generation Information Technology), Volume 4
  Issue 5, July, 2013,Pages 87-109, ISSN 2092-8637. GlobalCIS (Convergence
  Information Society, Republic of Korea)</dc:identifier>
 <dc:identifier>doi:10.4156/jnit.vol4.issue5.10</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02844</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fully Dynamic Approximate Maximum Matching and Minimum Vertex Cover in
  $O(\log^3 n)$ Worst Case Update Time</dc:title>
 <dc:creator>Bhattacharya, Sayan</dc:creator>
 <dc:creator>Henzinger, Monika</dc:creator>
 <dc:creator>Nanongkai, Danupon</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the problem of maintaining an approximately maximum (fractional)
matching and an approximately minimum vertex cover in a dynamic graph. Starting
with the seminal paper by Onak and Rubinfeld [STOC 2010], this problem has
received significant attention in recent years. There remains, however, a
polynomial gap between the best known worst case update time and the best known
amortised update time for this problem, even after allowing for randomisation.
Specifically, Bernstein and Stein [ICALP 2015, SODA 2016] have the best known
worst case update time. They present a deterministic data structure with
approximation ratio $(3/2+\epsilon)$ and worst case update time
$O(m^{1/4}/\epsilon^2)$, where $m$ is the number of edges in the graph. In
recent past, Gupta and Peng [FOCS 2013] gave a deterministic data structure
with approximation ratio $(1+\epsilon)$ and worst case update time
$O(\sqrt{m}/\epsilon^2)$. No known randomised data structure beats the worst
case update times of these two results. In contrast, the paper by Onak and
Rubinfeld [STOC 2010] gave a randomised data structure with approximation ratio
$O(1)$ and amortised update time $O(\log^2 n)$, where $n$ is the number of
nodes in the graph. This was later improved by Baswana, Gupta and Sen [FOCS
2011] and Solomon [FOCS 2016], leading to a randomised date structure with
approximation ratio $2$ and amortised update time $O(1)$.
  We bridge the polynomial gap between the worst case and amortised update
times for this problem, without using any randomisation. We present a
deterministic data structure with approximation ratio $(2+\epsilon)$ and worst
case update time $O(\log^3 n)$, for all sufficiently small constants
$\epsilon$.
</dc:description>
 <dc:description>Comment: An extended abstract of this paper appeared in SODA 2017</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02844</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02848</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised prototype learning in an associative-memory network</dc:title>
 <dc:creator>Zhen, Huiling</dc:creator>
 <dc:creator>Wang, Shang-Nan</dc:creator>
 <dc:creator>Zhou, Hai-Jun</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Unsupervised learning in a generalized Hopfield associative-memory network is
investigated in this work. First, we prove that the (generalized) Hopfield
model is equivalent to a semi-restricted Boltzmann machine with a layer of
visible neurons and another layer of hidden binary neurons, so it could serve
as the building block for a multilayered deep-learning system. We then
demonstrate that the Hopfield network can learn to form a faithful internal
representation of the observed samples, with the learned memory patterns being
prototypes of the input data. Furthermore, we propose a spectral method to
extract a small set of concepts (idealized prototypes) as the most concise
summary or abstraction of the empirical data.
</dc:description>
 <dc:description>Comment: We found serious inconsistence between the numerical protocol
  described in the text and the actual numerical code used by the first author
  to produce the data. Because of this inconsistence, we decide to withdraw the
  preprint. The corresponding author (Hai-Jun Zhou) deeply apologizes for not
  being able to detect this inconsistence earlier</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02848</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02852</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modular Techniques For Noncommutative Gr\&quot;obner Bases</dc:title>
 <dc:creator>Decker, Wolfram</dc:creator>
 <dc:creator>Eder, Christian</dc:creator>
 <dc:creator>Levandovskyy, Viktor</dc:creator>
 <dc:creator>Tiwari, Sharwan K.</dc:creator>
 <dc:subject>Mathematics - Rings and Algebras</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  In this note, we extend modular techniques for computing Gr\&quot;obner bases from
the commutative setting to the vast class of noncommutative $G$-algebras. As in
the commutative case, an effective verification test is only known to us in the
graded case. In the general case, our algorithm is probabilistic in the sense
that the resulting Gr\&quot;obner basis can only be expected to generate the given
ideal, with high probability. We have implemented our algorithm in the computer
algebra system {\sc{Singular}} and give timings to compare its performance with
that of other instances of Buchberger's algorithm, testing examples from
$D$-module theory as well as classical benchmark examples. A particular feature
of the modular algorithm is that it allows parallel runs.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02852</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02853</identifier>
 <datestamp>2017-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SemEval 2017 Task 10: ScienceIE - Extracting Keyphrases and Relations
  from Scientific Publications</dc:title>
 <dc:creator>Augenstein, Isabelle</dc:creator>
 <dc:creator>Das, Mrinal</dc:creator>
 <dc:creator>Riedel, Sebastian</dc:creator>
 <dc:creator>Vikraman, Lakshmi</dc:creator>
 <dc:creator>McCallum, Andrew</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We describe the SemEval task of extracting keyphrases and relations between
them from scientific documents, which is crucial for understanding which
publications describe which processes, tasks and materials. Although this was a
new task, we had a total of 26 submissions across 3 evaluation scenarios. We
expect the task and the findings reported in this paper to be relevant for
researchers working on understanding scientific content, as well as the broader
knowledge base population and information extraction communities.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-05-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02853</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02854</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Memetic Algorithm for the Minimum Conductance Graph Partitioning
  Problem</dc:title>
 <dc:creator>Chalupa, David</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The minimum conductance problem is an NP-hard graph partitioning problem.
Apart from the search for bottlenecks in complex networks, the problem is very
closely related to the popular area of network community detection. In this
paper, we tackle the minimum conductance problem as a pseudo-Boolean
optimisation problem and propose a memetic algorithm to solve it. An efficient
local search strategy is established. Our memetic algorithm starts by using
this local search strategy with different random strings to sample a set of
diverse initial solutions. This is followed by an evolutionary phase based on a
steady-state framework and two intensification subroutines. We compare the
algorithm to a wide range of multi-start local search approaches and classical
genetic algorithms with different crossover operators. The experimental results
are presented for a diverse set of real-world networks. These results indicate
that the memetic algorithm outperforms the alternative stochastic approaches.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02854</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02855</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Decision Tree Based Approach Towards Adaptive Profiling of Distributed
  Applications</dc:title>
 <dc:creator>Giannakopoulos, Ioannis</dc:creator>
 <dc:creator>Tsoumakos, Dimitrios</dc:creator>
 <dc:creator>Koziris, Nectarios</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  The adoption of the distributed paradigm has allowed applications to increase
their scalability, robustness and fault tolerance, but it has also complicated
their structure, leading to an exponential growth of the applications'
configuration space and increased difficulty in predicting their performance.
In this work, we describe a novel, automated profiling methodology that makes
no assumptions on application structure. Our approach utilizes oblique Decision
Trees in order to recursively partition an application's configuration space in
disjoint regions, choose a set of representative samples from each subregion
according to a defined policy and return a model for the entire space as a
composition of linear models over each subregion. An extensive evaluation over
real-life applications and synthetic performance functions showcases that our
scheme outperforms other state-of-the-art profiling methodologies. It
particularly excels at reflecting abnormalities and discontinuities of the
performance function, allowing the user to influence the sampling policy based
on the modeling accuracy and the space coverage.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02855</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02882</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Safe Interruptibility for Decentralized Multi-Agent
  Reinforcement Learning</dc:title>
 <dc:creator>Mhamdi, El Mahdi El</dc:creator>
 <dc:creator>Guerraoui, Rachid</dc:creator>
 <dc:creator>Hendrikx, Hadrien</dc:creator>
 <dc:creator>Maurer, Alexandre</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In reinforcement learning, agents learn by performing actions and observing
their outcomes. Sometimes, it is desirable for a human operator to
\textit{interrupt} an agent in order to prevent dangerous situations from
happening. Yet, as part of their learning process, agents may link these
interruptions, that impact their reward, to specific states and deliberately
avoid them. The situation is particularly challenging in a multi-agent context
because agents might not only learn from their own past interruptions, but also
from those of other agents. Orseau and Armstrong defined \emph{safe
interruptibility} for one learner, but their work does not naturally extend to
multi-agent systems. This paper introduces \textit{dynamic safe
interruptibility}, an alternative definition more suited to decentralized
learning problems, and studies this notion in two learning frameworks:
\textit{joint action learners} and \textit{independent learners}. We give
realistic sufficient conditions on the learning algorithm to enable dynamic
safe interruptibility in the case of joint action learners, yet show that these
conditions are not sufficient for independent learners. We show however that if
agents can detect interruptions, it is possible to prune the observations to
ensure dynamic safe interruptibility even for independent learners.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02882</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02883</identifier>
 <datestamp>2017-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Update-tolerant and Revocable Password Backup (Extended Version)</dc:title>
 <dc:creator>Horsch, Moritz</dc:creator>
 <dc:creator>Braun, Johannes</dc:creator>
 <dc:creator>Metz, Dominique</dc:creator>
 <dc:creator>Buchmann, Johannes</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  It is practically impossible for users to memorize a large portfolio of
strong and individual passwords for their online accounts. A solution is to
generate passwords randomly and store them. Yet, storing passwords instead of
memorizing them bears the risk of loss, e.g., in situations where the device on
which the passwords are stored is damaged, lost, or stolen. This makes the
creation of backups of the passwords indispensable. However, placing such
backups at secure locations to protect them as well from loss and unauthorized
access and keeping them up-to-date at the same time is an unsolved problem in
practice.
  We present PASCO, a backup solution for passwords that solves this challenge.
PASCO backups need not to be updated, even when the user's password portfolio
is changed. PASCO backups can be revoked without having physical access to
them. This prevents password leakage, even when a user loses control over a
backup. Additionally, we show how to extend PASCO to enable a fully
controllable emergency access. It allows a user to give someone else access to
his passwords in urgent situations. We also present a security evaluation and
an implementation of PASCO.
</dc:description>
 <dc:description>Comment: Extended version of the paper appeared in the proceedings of the
  ACISP 2017</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-04-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02883</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02890</identifier>
 <datestamp>2017-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Opinion Polarization by Learning from Social Feedback</dc:title>
 <dc:creator>Banisch, Sven</dc:creator>
 <dc:creator>Olbrich, Eckehard</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:description>  We explore a new mechanism to explain polarization phenomena in opinion
dynamics. The model is based on the idea that agents evaluate alternative views
on the basis of the social feedback obtained on expressing them. A high support
of the favored and therefore expressed opinion in the social environment, is
treated as a positive social feedback which reinforces the value associated to
this opinion. In this paper we concentrate on the model with dyadic
communication and encounter probabilities defined by an unweighted,
time-homogeneous network. The model captures polarization dynamics more
plausibly compared to bounded confidence opinion models and avoids extensive
opinion flipping usually present in binary opinion dynamics. We perform
systematic simulation experiments to understand the role of network
connectivity for the emergence of polarization and analytically characterize
the conditions for stable polarization in a two-community setting. While
previous models have emphasized the polarization effects of deliberative
argument-based communication, our model highlights an affective
experience-based route to polarization.
</dc:description>
 <dc:description>Comment: Presented at the Social Simulation Conference (Dublin 2017)</dc:description>
 <dc:date>2017-04-07</dc:date>
 <dc:date>2017-10-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02890</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02894</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Hidden Markov Restless Multi-armed Bandit Model for Playout
  Recommendation Systems</dc:title>
 <dc:creator>Meshram, Rahul</dc:creator>
 <dc:creator>Gopalan, Aditya</dc:creator>
 <dc:creator>Manjunath, D.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We consider a restless multi-armed bandit (RMAB) in which there are two types
of arms, say A and B. Each arm can be in one of two states, say $0$ or $1.$
Playing a type A arm brings it to state $0$ with probability one and not
playing it induces state transitions with arm-dependent probabilities. Whereas
playing a type B arm leads it to state $1$ with probability $1$ and not playing
it gets state that dependent on transition probabilities of arm. Further, play
of an arm generates a unit reward with a probability that depends on the state
of the arm. The belief about the state of the arm can be calculated using a
Bayesian update after every play. This RMAB has been designed for use in
recommendation systems where the user's preferences depend on the history of
recommendations. This RMAB can also be used in applications like creating of
playlists or placement of advertisements. In this paper we formulate the long
term reward maximization problem as infinite horizon discounted reward and
average reward problem. We analyse the RMAB by first studying discounted reward
scenario. We show that it is Whittle-indexable and then obtain a closed form
expression for the Whittle index for each arm calculated from the belief about
its state and the parameters that describe the arm. We next analyse the average
reward problem using vanishing discounted approach and derive the closed form
expression for Whittle index. For a RMAB to be useful in practice, we need to
be able to learn the parameters of the arms. We present an algorithm derived
from Thompson sampling scheme, that learns the parameters of the arms and also
illustrate its performance numerically.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02894</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02895</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ActionVLAD: Learning spatio-temporal aggregation for action
  classification</dc:title>
 <dc:creator>Girdhar, Rohit</dc:creator>
 <dc:creator>Ramanan, Deva</dc:creator>
 <dc:creator>Gupta, Abhinav</dc:creator>
 <dc:creator>Sivic, Josef</dc:creator>
 <dc:creator>Russell, Bryan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we introduce a new video representation for action
classification that aggregates local convolutional features across the entire
spatio-temporal extent of the video. We do so by integrating state-of-the-art
two-stream networks with learnable spatio-temporal feature aggregation. The
resulting architecture is end-to-end trainable for whole-video classification.
We investigate different strategies for pooling across space and time and
combining signals from the different streams. We find that: (i) it is important
to pool jointly across space and time, but (ii) appearance and motion streams
are best aggregated into their own separate representations. Finally, we show
that our representation outperforms the two-stream base architecture by a large
margin (13% relative) as well as out-performs other baselines with comparable
base architectures on HMDB51, UCF101, and Charades video classification
benchmarks.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2017. Project page:
  https://rohitgirdhar.github.io/ActionVLAD/</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02895</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02897</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Projection Mapping Technologies for AR</dc:title>
 <dc:creator>Iwai, Daisuke</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>H.5.1</dc:subject>
 <dc:description>  This invited talk will present recent projection mapping technologies for
augmented reality. First, fundamental technologies are briefly explained, which
have been proposed to overcome the technical limitations of ordinary
projectors. Second, augmented reality (AR) applications using projection
mapping technologies are introduced.
</dc:description>
 <dc:description>Comment: 3 pages, 1 figure, 23rd International Display Workshops in
  conjunction with Asia Display 2016. arXiv admin note: substantial text
  overlap with arXiv:1510.02710</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02897</dc:identifier>
 <dc:identifier>Proceedings of International Display Workshops (IDW), pp.
  1076-1078, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02899</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continuously heterogeneous hyper-objects in cryo-EM and 3-D movies of
  many temporal dimensions</dc:title>
 <dc:creator>Lederman, Roy R.</dc:creator>
 <dc:creator>Singer, Amit</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Single particle cryo-electron microscopy (EM) is an increasingly popular
method for determining the 3-D structure of macromolecules from noisy 2-D
images of single macromolecules whose orientations and positions are random and
unknown. One of the great opportunities in cryo-EM is to recover the structure
of macromolecules in heterogeneous samples, where multiple types or multiple
conformations are mixed together. Indeed, in recent years, many tools have been
introduced for the analysis of multiple discrete classes of molecules mixed
together in a cryo-EM experiment. However, many interesting structures have a
continuum of conformations which do not fit discrete models nicely; the
analysis of such continuously heterogeneous models has remained a more elusive
goal. In this manuscript, we propose to represent heterogeneous molecules and
similar structures as higher dimensional objects. We generalize the basic
operations used in many existing reconstruction algorithms, making our approach
generic in the sense that, in principle, existing algorithms can be adapted to
reconstruct those higher dimensional objects. As proof of concept, we present a
prototype of a new algorithm which we use to solve simulated reconstruction
problems.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02899</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02901</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on
  Graphs</dc:title>
 <dc:creator>Simonovsky, Martin</dc:creator>
 <dc:creator>Komodakis, Nikos</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  A number of problems can be formulated as prediction on graph-structured
data. In this work, we generalize the convolution operator from regular grids
to arbitrary graphs while avoiding the spectral domain, which allows us to
handle graphs of varying size and connectivity. To move beyond a simple
diffusion, filter weights are conditioned on the specific edge labels in the
neighborhood of a vertex. Together with the proper choice of graph coarsening,
we explore constructing deep neural networks for graph classification. In
particular, we demonstrate the generality of our formulation in point cloud
classification, where we set the new state of the art, and on a graph
classification dataset, where we outperform other deep learning approaches. The
source code is available at https://github.com/mys007/ecc
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2017; extended version</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02901</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02902</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stable Throughput and Delay Analysis of a Random Access Network With
  Queue-Aware Transmission</dc:title>
 <dc:creator>Dimitriou, Ioannis</dc:creator>
 <dc:creator>Pappas, Nikolaos</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this work we consider a two-user and a three-user slotted ALOHA network
with multi-packet reception (MPR) capabilities. The nodes can adapt their
transmission probabilities and their transmission parameters based on the
status of the other nodes. Each user has external bursty arrivals that are
stored in their infinite capacity queues. For the two- and the three-user cases
we obtain the stability region of the system. For the two-user case we provide
the conditions where the stability region is a convex set. We perform a
detailed mathematical analysis in order to study the queueing delay by
formulating two boundary value problems (a Dirichlet and a Riemann-Hilbert
boundary value problem), the solution of which provides the generating function
of the joint stationary probability distribution of the queue size at user
nodes. Furthermore, for the two-user symmetric case with MPR we obtain a lower
and an upper bound for the average delay without explicitly computing the
generating function for the stationary joint queue length distribution. The
bounds as it is seen in the numerical results appear to be tight. Explicit
expressions for the average delay are obtained for the symmetrical model with
capture effect which is a subclass of MPR models. We also provide the optimal
transmission probability in closed form expression that minimizes the average
delay in the symmetric capture case. Finally, we evaluate numerically the
presented theoretical results.
</dc:description>
 <dc:description>Comment: Submitted for journal publication</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02902</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02906</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Agent Diverse Generative Adversarial Networks</dc:title>
 <dc:creator>Ghosh, Arnab</dc:creator>
 <dc:creator>Kulharia, Viveka</dc:creator>
 <dc:creator>Namboodiri, Vinay</dc:creator>
 <dc:creator>Torr, Philip H. S.</dc:creator>
 <dc:creator>Dokania, Puneet K.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper describes an intuitive generalization to the Generative
Adversarial Networks (GANs) to generate samples while capturing diverse modes
of the true data distribution. Firstly, we propose a very simple and intuitive
multi-agent GAN architecture that incorporates multiple generators capable of
generating samples from high probability modes. Secondly, in order to enforce
different generators to generate samples from diverse modes, we propose two
extensions to the standard GAN objective function. (1) We augment the generator
specific GAN objective function with a diversity enforcing term that encourage
different generators to generate diverse samples using a user-defined
similarity based function. (2) We modify the discriminator objective function
where along with finding the real and fake samples, the discriminator has to
predict the generator which generated the given fake sample. Intuitively, in
order to succeed in this task, the discriminator must learn to push different
generators towards different identifiable modes. Our framework is generalizable
in the sense that it can be easily combined with other existing variants of
GANs to produce diverse samples. Experimentally we show that our framework is
able to produce high quality diverse samples for the challenging tasks such as
image/face generation and image-to-image translation. We also show that it is
capable of learning a better feature representation in an unsupervised setting.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02906</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02907</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy Harvesting Enabled MIMO Relaying through Time Switching</dc:title>
 <dc:creator>Liao, Jialing</dc:creator>
 <dc:creator>Khandaker, Muhammad R. A.</dc:creator>
 <dc:creator>Wong, Kai-Kit</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This letter considers simultaneous wireless information and power transfer
(SWIPT) for a multiple-input multiple-output (MIMO) relay system. The relay is
powered by harvesting energy from the source via time switching (TS) and
utilizes the harvested energy to forward the information signal. Our aim is to
maximize the rate of the system subject to the power constraints at both the
source and relay nodes. In the first scenario in which the source covariance
matrix is an identity matrix, we present the joint-optimal solution for
relaying and the TS ratio in closed form. An iterative scheme is then proposed
for jointly optimizing the source and relaying matrices and the TS ratio.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02907</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02908</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When mmWave Communications Meet Network Densification: A Scalable
  Interference Coordination Perspective</dc:title>
 <dc:creator>Feng, Wei</dc:creator>
 <dc:creator>Wang, Yanmin</dc:creator>
 <dc:creator>Lin, Dengsheng</dc:creator>
 <dc:creator>Ge, Ning</dc:creator>
 <dc:creator>Lu, Jianhua</dc:creator>
 <dc:creator>Li, Shaoqian</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The millimeter-wave (mmWave) communication is envisioned to provide orders of
magnitude capacity improvement. However, it is challenging to realize a
sufficient link margin due to high path loss and blockages. To address this
difficulty, in this paper, we explore the potential gain of ultra-densification
for enhancing mmWave communications from a network-level perspective. By
deploying the mmWave base stations (BSs) in an extremely dense and amorphous
fashion, the access distance is reduced and the choice of serving BSs is
enriched for each user, which are intuitively effective for mitigating the
propagation loss and blockages. Nevertheless, co-channel interference under
this model will become a performance-limiting factor. To solve this problem, we
propose a large-scale channel state information (CSI) based interference
coordination approach. Note that the large-scale CSI is highly
location-dependent, and can be obtained with a quite low cost. Thus, the
scalability of the proposed coordination framework can be guaranteed.
Particularly, using only the large-scale CSI of interference links, a
coordinated frequency resource block allocation problem is formulated for
maximizing the minimum achievable rate of the users, which is uncovered to be a
NP-hard integer programming problem. To circumvent this difficulty, a greedy
scheme with polynomial-time complexity is proposed by adopting the bisection
method and linear integer programming tools. Simulation results demonstrate
that the proposed coordination scheme based on large-scale CSI only can still
offer substantial gains over the existing methods. Moreover, although the
proposed scheme is only guaranteed to converge to a local optimum, it performs
well in terms of both user fairness and system efficiency.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures, accepted by IEEE JSAC</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02908</dc:identifier>
 <dc:identifier>IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02914</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kinematic analysis of geared robotic mechanism using matroid and T-T
  graph methods</dc:title>
 <dc:creator>Vahid, Amirinezhad S.</dc:creator>
 <dc:creator>Mustafa, Uyguro&#x11f;lu</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this paper, the kinematic structure of the geared robotic mechanism (GRM)
is investigated with the aid of two different methods which are based on
directed graphs and the methods are compared. One of the methods is Matroid
Method developed by Talpasanu and the other method is Tsai-Tokad (T-T) Graph
method developed by Uyguroglu and Demirel. It is shown that the kinematic
structure of the geared robotic mechanism can be represented by directed graphs
and angular velocity equations of the mechanisms can be systematically obtained
from the graphs. The advantages and disadvantages of both methods are
demonstrated relative to each other.
</dc:description>
 <dc:date>2017-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02914</dc:identifier>
 <dc:identifier>22nd Mediterranean Conference on Control and Automation, 2014,
  Mechanism and Machine Theory, 88, pp.1458 - 1463</dc:identifier>
 <dc:identifier>doi:10.1109/MED.2014.6961581</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02923</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pay Attention to Those Sets! Learning Quantification from Images</dc:title>
 <dc:creator>Sorodoc, Ionut</dc:creator>
 <dc:creator>Pezzelle, Sandro</dc:creator>
 <dc:creator>Herbelot, Aur&#xe9;lie</dc:creator>
 <dc:creator>Dimiccoli, Mariella</dc:creator>
 <dc:creator>Bernardi, Raffaella</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Major advances have recently been made in merging language and vision
representations. But most tasks considered so far have confined themselves to
the processing of objects and lexicalised relations amongst objects (content
words). We know, however, that humans (even pre-school children) can abstract
over raw data to perform certain types of higher-level reasoning, expressed in
natural language by function words. A case in point is given by their ability
to learn quantifiers, i.e. expressions like 'few', 'some' and 'all'. From
formal semantics and cognitive linguistics, we know that quantifiers are
relations over sets which, as a simplification, we can see as proportions. For
instance, in 'most fish are red', most encodes the proportion of fish which are
red fish. In this paper, we study how well current language and vision
strategies model such relations. We show that state-of-the-art attention
mechanisms coupled with a traditional linguistic formalisation of quantifiers
gives best performance on the task. Additionally, we provide insights on the
role of 'gist' representations in quantification. A 'logical' strategy to
tackle the task would be to first obtain a numerosity estimation for the two
involved sets and then compare their cardinalities. We however argue that
precisely identifying the composition of the sets is not only beyond current
state-of-the-art models but perhaps even detrimental to a task that is most
efficiently performed by refining the approximate numerosity estimator of the
system.
</dc:description>
 <dc:description>Comment: Submitted to Journal Paper, 28 pages, 12 figures, 5 tables</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02923</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02930</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Learning and Prediction for Object Detection using Whitened CNN
  Features</dc:title>
 <dc:creator>Barz, Bj&#xf6;rn</dc:creator>
 <dc:creator>Rodner, Erik</dc:creator>
 <dc:creator>K&#xe4;ding, Christoph</dc:creator>
 <dc:creator>Denzler, Joachim</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We combine features extracted from pre-trained convolutional neural networks
(CNNs) with the fast, linear Exemplar-LDA classifier to get the advantages of
both: the high detection performance of CNNs, automatic feature engineering,
fast model learning from few training samples and efficient sliding-window
detection. The Adaptive Real-Time Object Detection System (ARTOS) has been
refactored broadly to be used in combination with Caffe for the experimental
studies reported in this work.
</dc:description>
 <dc:description>Comment: Technical Report about the possibilities introduced with ARTOS v2,
  originally created March 2016</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02930</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02935</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Cooperative Enterprise Agent Based Control Architecture</dc:title>
 <dc:creator>Caramihai, Simona</dc:creator>
 <dc:creator>Dumitrache, Ioan</dc:creator>
 <dc:creator>Stanescu, Aurelian</dc:creator>
 <dc:creator>Culita, Janetta</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  The paper proposes a hierarchical, agent-based, DES supported, distributed
architecture for networked organization control. Taking into account enterprise
integration engineering frameworks and business process management techniques,
the paper intends to apply control engineering approaches for solving some
problems of coordinating networked organizations, such as performance
evaluation and optimization of workflows.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures. 5th IFAC International Workshop DECOM-TT 2007,
  Cesme-Izmir, Turkey</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02935</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02939</identifier>
 <datestamp>2017-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minor-matching hypertree width</dc:title>
 <dc:creator>Yolov, Nikola</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper we present a new width measure for a tree decomposition,
minor-matching hypertree width, $\mu\text{-}tw$, for graphs and hypergraphs,
such that bounding the width guarantees that set of maximal independent sets
has a polynomially-sized restriction to each decomposition bag. The relaxed
conditions of the decomposition allow a much wider class of graphs and
hypergraphs of bounded width compared to other tree decompositions. We show
that, for fixed $k$, there are $2^{(1 - \frac1k + o(1)){n \choose 2}}$
$n$-vertex graphs of minor-matching hypertree width at most $k$. A number of
problems including Maximum Independence Set, $k$-Colouring, and Homomorphism of
uniform hypergraphs permit polynomial-time solutions for hypergraphs with
bounded minor-matching hypertree width and bounded rank. We show that for any
given $k$ and any graph $G$, it is possible to construct a decomposition of
minor-matching hypertree width at most $O(k^3)$, or to prove that
$\mu\text{-}tw(G) &gt; k$ in time $n^{O(k^3)}$. This is done by presenting a
general algorithm for approximating the hypertree width of well-behaved
measures, and reducing $\mu\text{-}tw$ to such measure. The result relating the
restriction of the maximal independent sets to a set $S$ with the set of
induced matchings intersecting $S$ in graphs, and minor matchings intersecting
$S$ in hypergraphs, might be of independent interest.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02939</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02942</identifier>
 <datestamp>2017-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Boolean SATisfiability Problem in Clifford algebra</dc:title>
 <dc:creator>Budinich, Marco</dc:creator>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We present a formulation of the Boolean Satisfiability Problem in spinor
language that allows to give a necessary and sufficient condition for
unsatisfiability. With this result we outline an algorithm to test for
unsatisfiability with possibly interesting theoretical properties.
</dc:description>
 <dc:description>Comment: 18 pages, better notation and simpler proofs, algorithmic part moved
  to appendix</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-05-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02942</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02948</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incentive-rewarding mechanisms to stimulate participation in
  heterogeneous DTNs</dc:title>
 <dc:creator>El-Azouzi, Rachid</dc:creator>
 <dc:creator>Ouadrhiri, Ahmed El</dc:creator>
 <dc:creator>Prabhu, Balakrishna</dc:creator>
 <dc:creator>Menasch, Daniel</dc:creator>
 <dc:creator>Brun, Olivier</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Delay Tolerant Networks (DTNs) rely on the cooperation of nodes in a network
to forward a message from its source to its destination. Most of previous
studies on DTNs have focused on the design of routing schemes under the
hypothesis that each relay node is willing to participate in the forwarding
process. However, the delivery of a message incurs energy and memory costs. In
this paper we handle the problem of how to incentivize mobile nodes to
participate in relaying messages using a reward mechanism. We consider
heterogeneous relay nodes where the cost for taking part in the forwarding
process varies as a function of the mobility patterns of the relays. We show
that under fairly weak assumptions on the mobility pattern, the expected reward
the source pays remains the same irrespective of the information it conveys to
the relays, provided that the type of information does not vary dynamically
over time. We also characterize the effect of time to live (TTL) counters on
the delivery probability and memory usage. Using simulations based on a
synthetic mobility model and real mobility traces, we perform a few tests that
show a good accordance among theoretical and simulation results.
</dc:description>
 <dc:description>Comment: 15 pages, 10 figures</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02948</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02955</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised record matching with noisy and incomplete data</dc:title>
 <dc:creator>van Gennip, Yves</dc:creator>
 <dc:creator>Hunter, Blake</dc:creator>
 <dc:creator>Ma, Anna</dc:creator>
 <dc:creator>Moyer, Daniel</dc:creator>
 <dc:creator>de Vera, Ryan</dc:creator>
 <dc:creator>Bertozzi, Andrea L.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  We consider the problem of duplicate detection: given a large data set in
which each entry has multiple attributes, detect which distinct entries refer
to the same real world entity. Our method consists of three main steps:
creating a similarity score between entries, grouping entries together into
`unique entities', and refining the groups. We compare various methods for
creating similarity scores, considering different combinations of string
matching, term frequency-inverse document frequency methods, and n-gram
techniques. In particular, we introduce a vectorized soft term
frequency-inverse document frequency method, with an optional refinement step.
  We test our method on the Los Angeles Police Department Field Interview Card
data set, the Cora Citation Matching data set, and two sets of restaurant
review data. The results show that in certain parameter ranges soft term
frequency-inverse document frequency methods can outperform the standard term
frequency-inverse document frequency method; they also confirm that our method
for automatically determining the number of groups typically works well in many
cases and allows for accurate results in the absence of a priori knowledge of
the number of unique entities in the data set.
</dc:description>
 <dc:description>Comment: 19 pages, 15 figures</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02955</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02956</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Surface Normals in the Wild</dc:title>
 <dc:creator>Chen, Weifeng</dc:creator>
 <dc:creator>Xiang, Donglai</dc:creator>
 <dc:creator>Deng, Jia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We study the problem of single-image depth estimation for images in the wild.
We collect human annotated surface normals and use them to train a neural
network that directly predicts pixel-wise depth. We propose two novel loss
functions for training with surface normal annotations. Experiments on NYU
Depth and our own dataset demonstrate that our approach can significantly
improve the quality of depth estimation in the wild.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02956</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02958</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Fine-Grained Complexity of Empirical Risk Minimization: Kernel
  Methods and Neural Networks</dc:title>
 <dc:creator>Backurs, Arturs</dc:creator>
 <dc:creator>Indyk, Piotr</dc:creator>
 <dc:creator>Schmidt, Ludwig</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Empirical risk minimization (ERM) is ubiquitous in machine learning and
underlies most supervised learning methods. While there has been a large body
of work on algorithms for various ERM problems, the exact computational
complexity of ERM is still not understood. We address this issue for multiple
popular ERM problems including kernel SVMs, kernel ridge regression, and
training the final layer of a neural network. In particular, we give
conditional hardness results for these problems based on complexity-theoretic
assumptions such as the Strong Exponential Time Hypothesis. Under these
assumptions, we show that there are no algorithms that solve the aforementioned
ERM problems to high accuracy in sub-quadratic time. We also give similar
hardness results for computing the gradient of the empirical loss, which is the
main computational burden in many non-convex learning tasks.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02958</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02963</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring Word Embeddings for Unsupervised Textual User-Generated
  Content Normalization</dc:title>
 <dc:creator>Bertaglia, Thales Felipe Costa</dc:creator>
 <dc:creator>Nunes, Maria das Gra&#xe7;as Volpe</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Text normalization techniques based on rules, lexicons or supervised training
requiring large corpora are not scalable nor domain interchangeable, and this
makes them unsuitable for normalizing user-generated content (UGC). Current
tools available for Brazilian Portuguese make use of such techniques. In this
work we propose a technique based on distributed representation of words (or
word embeddings). It generates continuous numeric vectors of
high-dimensionality to represent words. The vectors explicitly encode many
linguistic regularities and patterns, as well as syntactic and semantic word
relationships. Words that share semantic similarity are represented by similar
vectors. Based on these features, we present a totally unsupervised, expandable
and language and domain independent method for learning normalization lexicons
from word embeddings. Our approach obtains high correction rate of orthographic
errors and internet slang in product reviews, outperforming the current
available tools for Brazilian Portuguese.
</dc:description>
 <dc:description>Comment: Published in Proceedings of the 2nd Workshop on Noisy User-generated
  Text, 9 pages</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02963</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02965</identifier>
 <datestamp>2017-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using convolutional networks and satellite imagery to identify patterns
  in urban environments at a large scale</dc:title>
 <dc:creator>Albert, Adrian</dc:creator>
 <dc:creator>Kaur, Jasleen</dc:creator>
 <dc:creator>Gonzalez, Marta</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Urban planning applications (energy audits, investment, etc.) require an
understanding of built infrastructure and its environment, i.e., both
low-level, physical features (amount of vegetation, building area and geometry
etc.), as well as higher-level concepts such as land use classes (which encode
expert understanding of socio-economic end uses). This kind of data is
expensive and labor-intensive to obtain, which limits its availability
(particularly in developing countries). We analyze patterns in land use in
urban neighborhoods using large-scale satellite imagery data (which is
available worldwide from third-party providers) and state-of-the-art computer
vision techniques based on deep convolutional neural networks. For supervision,
given the limited availability of standard benchmarks for remote-sensing data,
we obtain ground truth land use class labels carefully sampled from open-source
surveys, in particular the Urban Atlas land classification dataset of $20$ land
use classes across $~300$ European cities. We use this data to train and
compare deep architectures which have recently shown good performance on
standard computer vision tasks (image classification and segmentation),
including on geospatial data. Furthermore, we show that the deep
representations extracted from satellite imagery of urban environments can be
used to compare neighborhoods across several cities. We make our dataset
available for other machine learning researchers to use for remote-sensing
applications.
</dc:description>
 <dc:description>Comment: 10 pages, 11 figures</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02965</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02966</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Loss Max-Pooling for Semantic Image Segmentation</dc:title>
 <dc:creator>Bul&#xf2;, Samuel Rota</dc:creator>
 <dc:creator>Neuhold, Gerhard</dc:creator>
 <dc:creator>Kontschieder, Peter</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We introduce a novel loss max-pooling concept for handling imbalanced
training data distributions, applicable as alternative loss layer in the
context of deep neural networks for semantic image segmentation. Most
real-world semantic segmentation datasets exhibit long tail distributions with
few object categories comprising the majority of data and consequently biasing
the classifiers towards them. Our method adaptively re-weights the
contributions of each pixel based on their observed losses, targeting
under-performing classification results as often encountered for
under-represented object classes. Our approach goes beyond conventional
cost-sensitive learning attempts through adaptive considerations that allow us
to indirectly address both, inter- and intra-class imbalances. We provide a
theoretical justification of our approach, complementary to experimental
analyses on benchmark datasets. In our experiments on the Cityscapes and Pascal
VOC 2012 segmentation datasets we find consistently improved results,
demonstrating the efficacy of our approach.
</dc:description>
 <dc:description>Comment: accepted at CVPR 2017</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02966</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02971</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Dual-Stage Attention-Based Recurrent Neural Network for Time Series
  Prediction</dc:title>
 <dc:creator>Qin, Yao</dc:creator>
 <dc:creator>Song, Dongjin</dc:creator>
 <dc:creator>Chen, Haifeng</dc:creator>
 <dc:creator>Cheng, Wei</dc:creator>
 <dc:creator>Jiang, Guofei</dc:creator>
 <dc:creator>Cottrell, Garrison</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The Nonlinear autoregressive exogenous (NARX) model, which predicts the
current value of a time series based upon its previous values as well as the
current and past values of multiple driving (exogenous) series, has been
studied for decades. Despite the fact that various NARX models have been
developed, few of them can capture the long-term temporal dependencies
appropriately and select the relevant driving series to make predictions. In
this paper, we propose a dual-stage attention-based recurrent neural network
(DA-RNN) to address these two issues. In the first stage, we introduce an input
attention mechanism to adaptively extract relevant driving series (a.k.a.,
input features) at each time step by referring to the previous encoder hidden
state. In the second stage, we use a temporal attention mechanism to select
relevant encoder hidden states across all time steps. With this dual-stage
attention scheme, our model can not only make predictions effectively, but can
also be easily interpreted. Thorough empirical studies based upon the SML 2010
dataset and the NASDAQ 100 Stock dataset demonstrate that the DA-RNN can
outperform state-of-the-art methods for time series prediction.
</dc:description>
 <dc:description>Comment: International Joint Conference on Artificial Intelligence (IJCAI),
  2017</dc:description>
 <dc:date>2017-04-07</dc:date>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02971</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02972</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Aesthetic Judgements to Distinguish between Humans and Computers</dc:title>
 <dc:creator>Al-Fannah, Nasser Mohammed</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  As a result of continuing advances in computer capabilities, it is becoming
increasingly difficult to distinguish between humans and computers in the
digital world. We propose using the fundamental human ability to distinguish
between things that are aesthetically pleasing and those that are not as the
basis of a method to verify that a communicating party is human. We discuss one
possible implementation of this notion to develop a new CAPTCHA, the Aesthetic
CAPTCHA, which we compare with widely used CAPTCHAs. Our initial analysis shows
that, at least in theory, Aesthetic CAPTCHAs offer advantages over other
schemes in terms of satisfying the full range of CAPTCHA requirements. More
generally, using human aesthetic judgement adds a possible new dimension to the
future design of Turing tests.
</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02972</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02973</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Business Process Modeling: Blueprinting</dc:title>
 <dc:creator>Al-Fedaghi, Sabah</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  This paper presents a flow-based methodology for capturing processes
specified in business process modeling. The proposed methodology is
demonstrated through re-modeling of an IBM Blueworks case study. While the
Blueworks approach offers a well-proven tool in the field, this should not
discourage workers from exploring other ways of thinking about effectively
capturing processes. The diagrammatic representation presented here
demonstrates a viable methodology in this context. It is hoped this explicit
analysis of diverse fundamental approaches will benefit the research in the
field and also advance current practices.
</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02973</dc:identifier>
 <dc:identifier>International Journal of Computer Science and Information
  Security, Vol. 15, No. 3, MAR 2017, 286-291</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02978</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Field of Groves: An Energy-Efficient Random Forest</dc:title>
 <dc:creator>Takhirov, Zafar</dc:creator>
 <dc:creator>Wang, Joseph</dc:creator>
 <dc:creator>Louis, Marcia S.</dc:creator>
 <dc:creator>Saligrama, Venkatesh</dc:creator>
 <dc:creator>Joshi, Ajay</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Machine Learning (ML) algorithms, like Convolutional Neural Networks (CNN),
Support Vector Machines (SVM), etc. have become widespread and can achieve high
statistical performance. However their accuracy decreases significantly in
energy-constrained mobile and embedded systems space, where all computations
need to be completed under a tight energy budget. In this work, we present a
field of groves (FoG) implementation of random forests (RF) that achieves an
accuracy comparable to CNNs and SVMs under tight energy budgets. Evaluation of
the FoG shows that at comparable accuracy it consumes ~1.48x, ~24x, ~2.5x, and
~34.7x lower energy per classification compared to conventional RF, SVM_RBF ,
MLP, and CNN, respectively. FoG is ~6.5x less energy efficient than SVM_LR, but
achieves 18% higher accuracy on average across all considered datasets.
</dc:description>
 <dc:description>Comment: Submitted as Work in Progress to DAC'17</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02978</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02993</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterizing Product Lifecycle in Online Marketing: Sales, Trust,
  Revenue, and Competition Modeling</dc:title>
 <dc:creator>C, Santosh K</dc:creator>
 <dc:creator>Mukherjee, Arjun</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Recent researches have seen an upsurge in the analysis of consumer reviews.
Although, several dimensions have been explored, less is known on the temporal
dynamics of events that happen over the lifecycle of online products. What are
the dominant sales patterns? How are they affected by review count, rating,
helpfulness and sentiment? How is trust characterized and what are its effects
on sales and revenue? What happens during a market competition? When does a
takeover/recovery happen and by what percentage do sales increase on a
takeover? This work aims to answer these fundamental research questions based
on a sales time-series analysis of reviews of over 1 million products from
Amazon.com. We discover novel temporal patterns of sales and interesting
correlations of sales with the ratings. We find that trust and helpfulness are
important for higher revenue. Based on the analyses, we propose a model to
forecast sales that significantly outperforms other baselines. We then explore
the phenomena of market competition. Particularly, we characterize different
factors that govern survival/death of a product under competition and a model
for competition forecast. Experimental results on large-scale reviews
demonstrate the effectiveness of the proposed approaches.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02993</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02996</identifier>
 <datestamp>2017-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ROSA: R Optimizations with Static Analysis</dc:title>
 <dc:creator>Sen, Rathijit</dc:creator>
 <dc:creator>Zhu, Jianqiao</dc:creator>
 <dc:creator>Patel, Jignesh M.</dc:creator>
 <dc:creator>Jha, Somesh</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  R is a popular language and programming environment for data scientists. It
is increasingly co-packaged with both relational and Hadoop-based data
platforms and can often be the most dominant computational component in data
analytics pipelines. Recent work has highlighted inefficiencies in executing R
programs, both in terms of execution time and memory requirements, which in
practice limit the size of data that can be analyzed by R. This paper presents
ROSA, a static analysis framework to improve the performance and space
efficiency of R programs. ROSA analyzes input programs to determine program
properties such as reaching definitions, live variables, aliased variables, and
types of variables. These inferred properties enable program transformations
such as C++ code translation, strength reduction, vectorization, code motion,
in addition to interpretive optimizations such as avoiding redundant object
copies and performing in-place evaluations. An empirical evaluation shows
substantial reductions by ROSA in execution time and memory consumption over
both CRAN R and Microsoft R Open.
</dc:description>
 <dc:description>Comment: A talk on this work will be presented at RIOT 2017 (3rd Workshop on R
  Implementation, Optimization and Tooling)</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02996</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.02998</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weakly-Supervised Spatial Context Networks</dc:title>
 <dc:creator>Wu, Zuxuan</dc:creator>
 <dc:creator>Davis, Larry S.</dc:creator>
 <dc:creator>Sigal, Leonid</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We explore the power of spatial context as a self-supervisory signal for
learning visual representations. In particular, we propose spatial context
networks that learn to predict a representation of one image patch from another
image patch, within the same image, conditioned on their real-valued relative
spatial offset. Unlike auto-encoders, that aim to encode and reconstruct
original image patches, our network aims to encode and reconstruct intermediate
representations of the spatially offset patches. As such, the network learns a
spatially conditioned contextual representation. By testing performance with
various patch selection mechanisms we show that focusing on object-centric
patches is important, and that using object proposal as a patch selection
mechanism leads to the highest improvement in performance. Further, unlike
auto-encoders, context encoders [21], or other forms of unsupervised feature
learning, we illustrate that contextual supervision (with pre-trained model
initialization) can improve on existing pre-trained model performance. We build
our spatial context networks on top of standard VGG_19 and CNN_M architectures
and, among other things, show that we can achieve improvements (with no
additional explicit supervision) over the original ImageNet pre-trained VGG_19
and CNN_M models in object categorization and detection on VOC2007.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.02998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03003</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Curriculum Learning for Neural Networks</dc:title>
 <dc:creator>Graves, Alex</dc:creator>
 <dc:creator>Bellemare, Marc G.</dc:creator>
 <dc:creator>Menick, Jacob</dc:creator>
 <dc:creator>Munos, Remi</dc:creator>
 <dc:creator>Kavukcuoglu, Koray</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We introduce a method for automatically selecting the path, or syllabus, that
a neural network follows through a curriculum so as to maximise learning
efficiency. A measure of the amount that the network learns from each data
sample is provided as a reward signal to a nonstationary multi-armed bandit
algorithm, which then determines a stochastic syllabus. We consider a range of
signals derived from two distinct indicators of learning progress: rate of
increase in prediction accuracy, and rate of increase in network complexity.
Experimental results for LSTM networks on three curricula demonstrate that our
approach can significantly accelerate learning, in some cases halving the time
required to attain a satisfactory performance level.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03004</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constant Modulus Beamforming via Convex Optimization</dc:title>
 <dc:creator>Adler, Amir</dc:creator>
 <dc:creator>Wax, Mati</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We present novel convex-optimization-based solutions to the problem of blind
beamforming of constant modulus signals, and to the related problem of linearly
constrained blind beamforming of constant modulus signals. These solutions
ensure global optimality and are parameter free, namely, do not contain any
tuneable parameters and do not require any a-priori parameter settings. The
performance of these solutions, as demonstrated by simulated data, is superior
to existing methods.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03012</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Neural Networks for Hierarchical Reinforcement Learning</dc:title>
 <dc:creator>Florensa, Carlos</dc:creator>
 <dc:creator>Duan, Yan</dc:creator>
 <dc:creator>Abbeel, Pieter</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Deep reinforcement learning has achieved many impressive results in recent
years. However, tasks with sparse rewards or long horizons continue to pose
significant challenges. To tackle these important problems, we propose a
general framework that first learns useful skills in a pre-training
environment, and then leverages the acquired skills for learning faster in
downstream tasks. Our approach brings together some of the strengths of
intrinsic motivation and hierarchical methods: the learning of useful skill is
guided by a single proxy reward, the design of which requires very minimal
domain knowledge about the downstream tasks. Then a high-level policy is
trained on top of these skills, providing a significant improvement of the
exploration and allowing to tackle sparse rewards in the downstream tasks. To
efficiently pre-train a large span of skills, we use Stochastic Neural Networks
combined with an information-theoretic regularizer. Our experiments show that
this combination is effective in learning a wide span of interpretable skills
in a sample-efficient way, and can significantly boost the learning performance
uniformly across a wide range of downstream tasks.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2017</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03012</dc:identifier>
 <dc:identifier>International Conference on Learning Representations 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03013</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Classification of the Complexity of Nonfiction Texts in
  Portuguese for Early School Years</dc:title>
 <dc:creator>Hartmann, Nathan Siegle</dc:creator>
 <dc:creator>Cucatto, Livia</dc:creator>
 <dc:creator>Brants, Danielle</dc:creator>
 <dc:creator>Alu&#xed;sio, Sandra</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recent research shows that most Brazilian students have serious problems
regarding their reading skills. The full development of this skill is key for
the academic and professional future of every citizen. Tools for classifying
the complexity of reading materials for children aim to improve the quality of
the model of teaching reading and text comprehension. For English, Fengs work
[11] is considered the state-of-art in grade level prediction and achieved 74%
of accuracy in automatically classifying 4 levels of textual complexity for
close school grades. There are no classifiers for nonfiction texts for close
grades in Portuguese. In this article, we propose a scheme for manual
annotation of texts in 5 grade levels, which will be used for customized
reading to avoid the lack of interest by students who are more advanced in
reading and the blocking of those that still need to make further progress. We
obtained 52% of accuracy in classifying texts into 5 levels and 74% in 3
levels. The results prove to be promising when compared to the state-of-art
work.9
</dc:description>
 <dc:description>Comment: PROPOR International Conference on the Computational Processing of
  Portuguese, 2016, 9 pages</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03013</dc:identifier>
 <dc:identifier>Hartmann N., Cucatto L., Brants D., Alu\'isio S. (2016) Automatic
  Classification of the Complexity of Nonfiction Texts in Portuguese for Early
  School Years. In: Computational Processing of the Portuguese Language. PROPOR
  2016. Springer</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-41552-9_2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03016</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic semantic role labeling on non-revised syntactic trees of
  journalistic texts</dc:title>
 <dc:creator>Hartmann, Nathan Siegle</dc:creator>
 <dc:creator>Duran, Magali Sanches</dc:creator>
 <dc:creator>Alu&#xed;sio, Sandra Maria</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Semantic Role Labeling (SRL) is a Natural Language Processing task that
enables the detection of events described in sentences and the participants of
these events. For Brazilian Portuguese (BP), there are two studies recently
concluded that perform SRL in journalistic texts. [1] obtained F1-measure
scores of 79.6, using the PropBank.Br corpus, which has syntactic trees
manually revised, [8], without using a treebank for training, obtained
F1-measure scores of 68.0 for the same corpus. However, the use of manually
revised syntactic trees for this task does not represent a real scenario of
application. The goal of this paper is to evaluate the performance of SRL on
revised and non-revised syntactic trees using a larger and balanced corpus of
BP journalistic texts. First, we have shown that [1]'s system also performs
better than [8]'s system on the larger corpus. Second, the SRL system trained
on non-revised syntactic trees performs better over non-revised trees than a
system trained on gold-standard data.
</dc:description>
 <dc:description>Comment: PROPOR International Conference on the Computational Processing of
  Portuguese, 2016, 8 pages</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03016</dc:identifier>
 <dc:identifier>PROPOR 2016. Springer. Lecture Notes in Computer Science volume
  9727 (2016) pgs. 202-212</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-41552-9_20</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03022</identifier>
 <datestamp>2017-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Precision Interfaces</dc:title>
 <dc:creator>Zhang, Haoci</dc:creator>
 <dc:creator>Sellam, Thibault</dc:creator>
 <dc:creator>Wu, Eugene</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Building interactive tools to support data analysis is hard because it is not
always clear what to build and how to build it. To address this problem, we
present Precision Interfaces, a semi-automatic system to generate task-specific
data analytics interfaces. Precision Interface can turn a log of executed
programs into an interface, by identifying micro-variations between the
programs and mapping them to interface components. This paper focuses on SQL
query logs, but we can generalize the approach to other languages. Our system
operates in two steps: it first build an interaction graph, which describes how
the queries can be transformed into each other. Then, it finds a set of UI
components that covers a maximal number of transformations. To restrict the
domain of changes to be detected, our system uses a domain-specific language,
PILang. We give a full description of Precision Interface's components,
showcase an early prototype on real program logs and discuss future research
opportunities.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03022</dc:identifier>
 <dc:identifier>Proceedings of the 2nd Workshop on Human-In-the-Loop Data
  Analytics HILDA'17; 10:1--10:6 (2017)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03024</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tight Lower Bounds for Differentially Private Selection</dc:title>
 <dc:creator>Steinke, Thomas</dc:creator>
 <dc:creator>Ullman, Jonathan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  A pervasive task in the differential privacy literature is to select the $k$
items of &quot;highest quality&quot; out of a set of $d$ items, where the quality of each
item depends on a sensitive dataset that must be protected. Variants of this
task arise naturally in fundamental problems like feature selection and
hypothesis testing, and also as subroutines for many sophisticated
differentially private algorithms.
  The standard approaches to these tasks---repeated use of the exponential
mechanism or the sparse vector technique---approximately solve this problem
given a dataset of $n = O(\sqrt{k}\log d)$ samples. We provide a tight lower
bound for some very simple variants of the private selection problem. Our lower
bound shows that a sample of size $n = \Omega(\sqrt{k} \log d)$ is required
even to achieve a very minimal accuracy guarantee.
  Our results are based on an extension of the fingerprinting method to sparse
selection problems. Previously, the fingerprinting method has been used to
provide tight lower bounds for answering an entire set of $d$ queries, but
often only some much smaller set of $k$ queries are relevant. Our extension
allows us to prove lower bounds that depend on both the number of relevant
queries and the total number of queries.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03033</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A probabilistic data-driven model for planar pushing</dc:title>
 <dc:creator>Bauza, Maria</dc:creator>
 <dc:creator>Rodriguez, Alberto</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper presents a data-driven approach to model planar pushing
interaction to predict both the most likely outcome of a push and its expected
variability. The learned models rely on a variation of Gaussian processes with
input-dependent noise called Variational Heteroscedastic Gaussian processes
(VHGP) that capture the mean and variance of a stochastic function. We show
that we can learn accurate models that outperform analytical models after less
than 100 samples and saturate in performance with less than 1000 samples. We
validate the results against a collected dataset of repeated trajectories, and
use the learned models to study questions such as the nature of the variability
in pushing, and the validity of the quasi-static assumption.
</dc:description>
 <dc:description>Comment: 8 pages, 11 figures, ICRA 2017</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-09-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03037</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning from Multi-View Structural Data via Structural Factorization
  Machines</dc:title>
 <dc:creator>Lu, Chun-Ta</dc:creator>
 <dc:creator>He, Lifang</dc:creator>
 <dc:creator>Ding, Hao</dc:creator>
 <dc:creator>Yu, Philip S.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Real-world relations among entities can often be observed and determined by
different perspectives/views. For example, the decision made by a user on
whether to adopt an item relies on multiple aspects such as the contextual
information of the decision, the item's attributes, the user's profile and the
reviews given by other users. Different views may exhibit multi-way
interactions among entities and provide complementary information. In this
paper, we introduce a multi-tensor-based approach that can preserve the
underlying structure of multi-view data in a generic predictive model.
Specifically, we propose structural factorization machines (SFMs) that learn
the common latent spaces shared by multi-view tensors and automatically adjust
the importance of each view in the predictive model. Furthermore, the
complexity of SFMs is linear in the number of parameters, which make SFMs
suitable to large-scale problems. Extensive experiments on real-world datasets
demonstrate that the proposed SFMs outperform several state-of-the-art methods
in terms of prediction accuracy and computational cost.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03039</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantically Consistent Regularization for Zero-Shot Recognition</dc:title>
 <dc:creator>Morgado, Pedro</dc:creator>
 <dc:creator>Vasconcelos, Nuno</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The role of semantics in zero-shot learning is considered. The effectiveness
of previous approaches is analyzed according to the form of supervision
provided. While some learn semantics independently, others only supervise the
semantic subspace explained by training classes. Thus, the former is able to
constrain the whole space but lacks the ability to model semantic correlations.
The latter addresses this issue but leaves part of the semantic space
unsupervised. This complementarity is exploited in a new convolutional neural
network (CNN) framework, which proposes the use of semantics as constraints for
recognition.Although a CNN trained for classification has no transfer ability,
this can be encouraged by learning an hidden semantic layer together with a
semantic code for classification. Two forms of semantic constraints are then
introduced. The first is a loss-based regularizer that introduces a
generalization constraint on each semantic predictor. The second is a codeword
regularizer that favors semantic-to-class mappings consistent with prior
semantic knowledge while allowing these to be learned from data. Significant
improvements over the state-of-the-art are achieved on several datasets.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2017</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03039</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03048</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Matching Media Contents with User Profiles by means of the
  Dempster-Shafer Theory</dc:title>
 <dc:creator>Troiano, Luigi</dc:creator>
 <dc:creator>D&#xed;az, Irene</dc:creator>
 <dc:creator>Gaglione, Ciro</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The media industry is increasingly personalizing the offering of contents in
attempt to better target the audience. This requires to analyze the
relationships that goes established between users and content they enjoy,
looking at one side to the content characteristics and on the other to the user
profile, in order to find the best match between the two. In this paper we
suggest to build that relationship using the Dempster-Shafer's Theory of
Evidence, proposing a reference model and illustrating its properties by means
of a toy example. Finally we suggest possible applications of the model for
tasks that are common in the modern media industry.
</dc:description>
 <dc:description>Comment: FUZZ-IEEE 2017. 6 pages, 3 figures, 4 tables</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03048</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03049</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Security Analytics of Network Flow Data of IoT and Mobile Devices
  (Work-in-progress)</dc:title>
 <dc:creator>Kundu, Ashish</dc:creator>
 <dc:creator>Kundu, Chinmay</dc:creator>
 <dc:creator>Budhraja, Karan K.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Given that security threats and privacy breaches are com- monplace today, it
is an important problem for one to know whether their device(s) are in a &quot;good
state of security&quot;, or is there a set of high- risk vulnerabilities that need
to be addressed. In this paper, we address this simple yet challenging problem.
Instead of gaining white-box access to the device, which offers privacy and
other system issues, we rely on network logs and events collected offine as
well as in realtime. Our approach is to apply analytics and machine learning
for network security analysis as well as analysis of the security of the
overall device - apps, the OS and the data on the device. We propose techniques
based on analytics in order to determine sensitivity of the device,
vulnerability rank of apps and of the device, degree of compromise of apps and
of the device, as well as how to define the state of security of the device
based on these metrics. Such metrics can be used further in machine learning
models in order to predict the users of the device of high risk states, and how
to avoid such risks.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03057</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DRAW: Deep networks for Recognizing styles of Artists Who illustrate
  children's books</dc:title>
 <dc:creator>Hicsonmez, Samet</dc:creator>
 <dc:creator>Samet, Nermin</dc:creator>
 <dc:creator>Sener, Fadime</dc:creator>
 <dc:creator>Duygulu, Pinar</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper is motivated from a young boy's capability to recognize an
illustrator's style in a totally different context. In the book &quot;We are All
Born Free&quot; [1], composed of selected rights from the Universal Declaration of
Human Rights interpreted by different illustrators, the boy was surprised to
see a picture similar to the ones in the &quot;Winnie the Witch&quot; series drawn by
Korky Paul (Figure 1). The style was noticeable in other characters of the same
illustrator in different books as well. The capability of a child to easily
spot the style was shown to be valid for other illustrators such as Axel
Scheffler and Debi Gliori. The boy's enthusiasm let us to start the journey to
explore the capabilities of machines to recognize the style of illustrators.
  We collected pages from children's books to construct a new illustrations
dataset consisting of about 6500 pages from 24 artists. We exploited deep
networks for categorizing illustrators and with around 94% classification
performance our method over-performed the traditional methods by more than 10%.
Going beyond categorization we explored transferring style. The classification
performance on the transferred images has shown the ability of our system to
capture the style. Furthermore, we discovered representative illustrations and
discriminative stylistic elements.
</dc:description>
 <dc:description>Comment: ACM ICMR 2017</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03057</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03058</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CERN: Confidence-Energy Recurrent Network for Group Activity Recognition</dc:title>
 <dc:creator>Shu, Tianmin</dc:creator>
 <dc:creator>Todorovic, Sinisa</dc:creator>
 <dc:creator>Zhu, Song-Chun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This work is about recognizing human activities occurring in videos at
distinct semantic levels, including individual actions, interactions, and group
activities. The recognition is realized using a two-level hierarchy of Long
Short-Term Memory (LSTM) networks, forming a feed-forward deep architecture,
which can be trained end-to-end. In comparison with existing architectures of
LSTMs, we make two key contributions giving the name to our approach as
Confidence-Energy Recurrent Network -- CERN. First, instead of using the common
softmax layer for prediction, we specify a novel energy layer (EL) for
estimating the energy of our predictions. Second, rather than finding the
common minimum-energy class assignment, which may be numerically unstable under
uncertainty, we specify that the EL additionally computes the p-values of the
solutions, and in this way estimates the most confident energy minimum. The
evaluation on the Collective Activity and Volleyball datasets demonstrates: (i)
advantages of our two contributions relative to the common softmax and
energy-minimization formulations and (ii) a superior performance relative to
the state-of-the-art approaches.
</dc:description>
 <dc:description>Comment: Accepted to IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR), 2017</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03058</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03062</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Controlling Lipschitz functions</dc:title>
 <dc:creator>Kupavskii, Andrey</dc:creator>
 <dc:creator>Pach, Janos</dc:creator>
 <dc:creator>Tardos, Gabor</dc:creator>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:description>  Given any positive integers $m$ and $d$, we say the a sequence of points
$(x_i)_{i\in I}$ in $\mathbb R^m$ is {\em Lipschitz-$d$-controlling} if one can
select suitable values $y_i\; (i\in I)$ such that for every Lipschitz function
$f:\mathbb R^m\rightarrow \mathbb R^d$ there exists $i$ with $|f(x_i)-y_i|&lt;1$.
We conjecture that for every $m\le d$, a sequence $(x_i)_{i\in I}\subset\mathbb
R^m$ is $d$-controlling if and only if $$\sup_{n\in\mathbb N}\frac{|\{i\in I\,
:\, |x_i|\le n\}|}{n^d}=\infty.$$ We prove that this condition is necessary and
a slightly stronger one is already sufficient for the sequence to be
$d$-controlling. We also prove the conjecture for $m=1$.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03065</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MoMo: a group mobility model for future generation mobile wireless
  networks</dc:title>
 <dc:creator>De Nardis, Luca</dc:creator>
 <dc:creator>Di Benedetto, Maria-Gabriella</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Existing group mobility models were not designed to meet the requirements
typical of current and future short distance wireless networks scenarios, that
need, in particular, accurate, up-to-date information on the position of each
node in the network, combined with a simple and flexible approach to mobility
modeling. A new model for group mobility in wireless networks, named MoMo, is
proposed in this paper, based on the combination of a memory-based individual
mobility model with a flexible group behavior model. MoMo is capable of
accurately describing all mobility scenarios, from individual mobility, in
which nodes move independently one from the other, to tight group mobility,
where mobility patterns of different nodes are strictly correlated. A new set
of intrinsic properties of a mobility model is proposed and adopted in the
analysis and comparison of MoMo with existing models. Results show that MoMo
leads to accurate, robust and flexible modeling of mobility of groups of nodes,
making it suitable for the wide range of network scenarios expected to
characterize the deployment of 5G networks.
</dc:description>
 <dc:description>Comment: 14 pages, 20 figures</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03067</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Action Unit Detection with Region Adaptation, Multi-labeling Learning
  and Optimal Temporal Fusing</dc:title>
 <dc:creator>Li, Wei</dc:creator>
 <dc:creator>Abitahi, Farnaz</dc:creator>
 <dc:creator>Zhu, Zhigang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Action Unit (AU) detection becomes essential for facial analysis. Many
proposed approaches face challenging problems in dealing with the alignments of
different face regions, in the effective fusion of temporal information, and in
training a model for multiple AU labels. To better address these problems, we
propose a deep learning framework for AU detection with region of interest
(ROI) adaptation, integrated multi-label learning, and optimal LSTM-based
temporal fusing. First, ROI cropping nets (ROI Nets) are designed to make sure
specifically interested regions of faces are learned independently; each
sub-region has a local convolutional neural network (CNN) - an ROI Net, whose
convolutional filters will only be trained for the corresponding region.
Second, multi-label learning is employed to integrate the outputs of those
individual ROI cropping nets, which learns the inter-relationships of various
AUs and acquires global features across sub-regions for AU detection. Finally,
the optimal selection of multiple LSTM layers to form the best LSTM Net is
carried out to best fuse temporal features, in order to make the AU prediction
the most accurate. The proposed approach is evaluated on two popular AU
detection datasets, BP4D and DISFA, outperforming the state of the art
significantly, with an average improvement of around 13% on BP4D and 25% on
DISFA, respectively.
</dc:description>
 <dc:description>Comment: The paper is accepted to CVPR 2017</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03067</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03069</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A semidiscrete version of the Citti-Petitot-Sarti model as a plausible
  model for anthropomorphic image reconstruction and pattern recognition</dc:title>
 <dc:creator>Prandi, Dario</dc:creator>
 <dc:creator>Gauthier, Jean-Paul</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:subject>Mathematics - Representation Theory</dc:subject>
 <dc:description>  In his beautiful book [66], Jean Petitot proposes a sub-Riemannian model for
the primary visual cortex of mammals. This model is neurophysiologically
justified. Further developments of this theory lead to efficient algorithms for
image reconstruction, based upon the consideration of an associated
hypoelliptic diffusion. The sub-Riemannian model of Petitot and Citti-Sarti (or
certain of its improvements) is a left-invariant structure over the group
$SE(2)$ of rototranslations of the plane. Here, we propose a semi-discrete
version of this theory, leading to a left-invariant structure over the group
$SE(2,N)$, restricting to a finite number of rotations. This apparently very
simple group is in fact quite atypical: it is maximally almost periodic, which
leads to much simpler harmonic analysis compared to $SE(2).$ Based upon this
semi-discrete model, we improve on previous image-reconstruction algorithms and
we develop a pattern-recognition theory that leads also to very efficient
algorithms in practice.
</dc:description>
 <dc:description>Comment: 123 pages, revised version</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2018-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03069</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03073</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data-efficient Deep Reinforcement Learning for Dexterous Manipulation</dc:title>
 <dc:creator>Popov, Ivaylo</dc:creator>
 <dc:creator>Heess, Nicolas</dc:creator>
 <dc:creator>Lillicrap, Timothy</dc:creator>
 <dc:creator>Hafner, Roland</dc:creator>
 <dc:creator>Barth-Maron, Gabriel</dc:creator>
 <dc:creator>Vecerik, Matej</dc:creator>
 <dc:creator>Lampe, Thomas</dc:creator>
 <dc:creator>Tassa, Yuval</dc:creator>
 <dc:creator>Erez, Tom</dc:creator>
 <dc:creator>Riedmiller, Martin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Deep learning and reinforcement learning methods have recently been used to
solve a variety of problems in continuous control domains. An obvious
application of these techniques is dexterous manipulation tasks in robotics
which are difficult to solve using traditional control theory or
hand-engineered approaches. One example of such a task is to grasp an object
and precisely stack it on another. Solving this difficult and practically
relevant problem in the real world is an important long-term goal for the field
of robotics. Here we take a step towards this goal by examining the problem in
simulation and providing models and techniques aimed at solving it. We
introduce two extensions to the Deep Deterministic Policy Gradient algorithm
(DDPG), a model-free Q-learning based method, which make it significantly more
data-efficient and scalable. Our results show that by making extensive use of
off-policy data and replay, it is possible to find control policies that
robustly grasp objects and stack them. Further, our results hint that it may
soon be feasible to train successful stacking policies by collecting
interactions on real robots.
</dc:description>
 <dc:description>Comment: 12 pages, 5 Figures</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03073</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03079</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>WRPN: Training and Inference using Wide Reduced-Precision Networks</dc:title>
 <dc:creator>Mishra, Asit</dc:creator>
 <dc:creator>Cook, Jeffrey J</dc:creator>
 <dc:creator>Nurvitadhi, Eriko</dc:creator>
 <dc:creator>Marr, Debbie</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  For computer vision applications, prior works have shown the efficacy of
reducing the numeric precision of model parameters (network weights) in deep
neural networks but also that reducing the precision of activations hurts model
accuracy much more than reducing the precision of model parameters. We study
schemes to train networks from scratch using reduced-precision activations
without hurting the model accuracy. We reduce the precision of activation maps
(along with model parameters) using a novel quantization scheme and increase
the number of filter maps in a layer, and find that this scheme compensates or
surpasses the accuracy of the baseline full-precision network. As a result, one
can significantly reduce the dynamic memory footprint, memory bandwidth,
computational energy and speed up the training and inference process with
appropriate hardware support. We call our scheme WRPN - wide reduced-precision
networks. We report results using our proposed schemes and show that our
results are better than previously reported accuracies on ILSVRC-12 dataset
while being computationally less expensive compared to previously reported
reduced-precision networks.
</dc:description>
 <dc:description>Comment: Under submission to CVPR Workshop</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03079</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03080</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Representing operational semantics with enriched Lawvere theories</dc:title>
 <dc:creator>Stay, Michael</dc:creator>
 <dc:creator>Meredith, L. G.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:subject>F.4</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:description>  Many term calculi, like lambda calculus or pi calculus, involve binders for
names, and the mathematics of bound variable names is subtle. Schoenfinkel
introduced the SKI combinator calculus in 1924 to clarify the role of
quantified variables in intuitionistic logic by eliminating them. Yoshida
demonstrated how to eliminate the bound names coming from the input prefix in
the asynchronous pi calculus, but her combinators still depend on the new
operator to bind names. Recently, Meredith and Stay showed how to modify
Yoshida's combinators by replacing new and replication with reflective
operators to provide the first combinator calculus with no bound names into
which the asynchronous pi calculus has a faithful embedding. Here we provide an
alternative set of combinators built from SKI plus reflection that also
eliminates all nominal phenomena, yet provides a faithful embedding of a
reflective higher-order pi calculus. We show that with the nominal features
effectively eliminated as syntactic sugar, multisorted Lawvere theories
enriched over graphs suffice to capture the operational semantics of the
calculus.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1703.07054</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03080</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03084</identifier>
 <datestamp>2017-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Composite Task-Completion Dialogue Policy Learning via Hierarchical Deep
  Reinforcement Learning</dc:title>
 <dc:creator>Peng, Baolin</dc:creator>
 <dc:creator>Li, Xiujun</dc:creator>
 <dc:creator>Li, Lihong</dc:creator>
 <dc:creator>Gao, Jianfeng</dc:creator>
 <dc:creator>Celikyilmaz, Asli</dc:creator>
 <dc:creator>Lee, Sungjin</dc:creator>
 <dc:creator>Wong, Kam-Fai</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Building a dialogue agent to fulfill complex tasks, such as travel planning,
is challenging because the agent has to learn to collectively complete multiple
subtasks. For example, the agent needs to reserve a hotel and book a flight so
that there leaves enough time for commute between arrival and hotel check-in.
This paper addresses this challenge by formulating the task in the mathematical
framework of options over Markov Decision Processes (MDPs), and proposing a
hierarchical deep reinforcement learning approach to learning a dialogue
manager that operates at different temporal scales. The dialogue manager
consists of: (1) a top-level dialogue policy that selects among subtasks or
options, (2) a low-level dialogue policy that selects primitive actions to
complete the subtask given by the top-level policy, and (3) a global state
tracker that helps ensure all cross-subtask constraints be satisfied.
Experiments on a travel planning task with simulated and real users show that
our approach leads to significant improvements over three baselines, two based
on handcrafted rules and the other based on flat deep reinforcement learning.
</dc:description>
 <dc:description>Comment: 12 pages, 8 figures</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-07-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03091</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Connecting Network Science and Information Theory</dc:title>
 <dc:creator>de Arruda, Henrique F.</dc:creator>
 <dc:creator>Silva, Filipi N.</dc:creator>
 <dc:creator>Comin, Cesar H.</dc:creator>
 <dc:creator>Amancio, Diego R.</dc:creator>
 <dc:creator>Costa, Luciano da F.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  A framework integrating information theory and network science is proposed,
giving rise to a potentially new area. By incorporating and integrating
concepts such as complexity, coding, topological projections and network
dynamics, the proposed network-based framework paves the way not only to
extending traditional information science, but also to modeling, characterizing
and analyzing a broad class of real-world problems, from language communication
to DNA coding. Basically, an original network is supposed to be transmitted,
with or without compaction, through a sequence of symbols or time-series
obtained by sampling its topology by some network dynamics, such as random
walks. We show that the degree of compression is ultimately related to the
ability to predict the frequency of symbols based on the topology of the
original network and the adopted dynamics. The potential of the proposed
approach is illustrated with respect to the efficiency of transmitting several
types of topologies by using a variety of random walks. Several interesting
results are obtained, including the behavior of the Barab\'asi-Albert model
oscillating between high and low performance depending on the considered
dynamics, and the distinct performances obtained for two geographical models.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03092</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strassen's Algorithm for Tensor Contraction</dc:title>
 <dc:creator>Huang, Jianyu</dc:creator>
 <dc:creator>Matthews, Devin A.</dc:creator>
 <dc:creator>van de Geijn, Robert A.</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  Tensor contraction (TC) is an important computational kernel widely used in
numerous applications. It is a multi-dimensional generalization of matrix
multiplication (GEMM). While Strassen's algorithm for GEMM is well studied in
theory and practice, extending it to accelerate TC has not been previously
pursued. Thus, we believe this to be the first paper to demonstrate how one can
in practice speed up tensor contraction with Strassen's algorithm. By adopting
a Block-Scatter-Matrix format, a novel matrix-centric tensor layout, we can
conceptually view TC as GEMM for a general stride storage, with an implicit
tensor-to-matrix transformation. This insight enables us to tailor a recent
state-of-the-art implementation of Strassen's algorithm to TC, avoiding
explicit transpositions (permutations) and extra workspace, and reducing the
overhead of memory movement that is incurred. Performance benefits are
demonstrated with a performance model as well as in practice on modern single
core, multicore, and distributed memory parallel architectures, achieving up to
1.3x speedup. The resulting implementations can serve as a drop-in replacement
for various applications with significant speedup.
</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03092</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03093</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards an Empirical Study of Affine Types for Isolated Actors in Scala</dc:title>
 <dc:creator>Haller, Philipp</dc:creator>
 <dc:creator>Sommar, Fredrik</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:description>  LaCasa is a type system and programming model to enforce the object
capability discipline in Scala, and to provide affine types. One important
application of LaCasa's type system is software isolation of concurrent
processes. Isolation is important for several reasons including security and
data-race freedom. Moreover, LaCasa's affine references enable efficient,
by-reference message passing while guaranteeing a &quot;deep-copy&quot; semantics. This
deep-copy semantics enables programmers to seamlessly port concurrent programs
running on a single machine to distributed programs running on large-scale
clusters of machines.
  This paper presents an integration of LaCasa with actors in Scala,
specifically, the Akka actor-based middleware, one of the most widely-used
actor systems in industry. The goal of this integration is to statically ensure
the isolation of Akka actors. Importantly, we present the results of an
empirical study investigating the effort required to use LaCasa's type system
in existing open-source Akka-based systems and applications.
</dc:description>
 <dc:description>Comment: In Proceedings PLACES 2017, arXiv:1704.02418</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03093</dc:identifier>
 <dc:identifier>EPTCS 246, 2017, pp. 3-9</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.246.3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03094</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Actors without Borders: Amnesty for Imprisoned State</dc:title>
 <dc:creator>Castegren, Elias</dc:creator>
 <dc:creator>Wrigstad, Tobias</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:description>  In concurrent systems, some form of synchronisation is typically needed to
achieve data-race freedom, which is important for correctness and safety. In
actor-based systems, messages are exchanged concurrently but executed
sequentially by the receiving actor. By relying on isolation and non-sharing,
an actor can access its own state without fear of data-races, and the internal
behavior of an actor can be reasoned about sequentially.
  However, actor isolation is sometimes too strong to express useful patterns.
For example, letting the iterator of a data-collection alias the internal
structure of the collection allows a more efficient implementation than if each
access requires going through the interface of the collection. With full
isolation, in order to maintain sequential reasoning the iterator must be made
part of the collection, which bloats the interface of the collection and means
that a client must have access to the whole data-collection in order to use the
iterator.
  In this paper, we propose a programming language construct that enables a
relaxation of isolation but without sacrificing sequential reasoning. We
formalise the mechanism in a simple lambda calculus with actors and passive
objects, and show how an actor may leak parts of its internal state while
ensuring that any interaction with this data is still synchronised.
</dc:description>
 <dc:description>Comment: In Proceedings PLACES 2017, arXiv:1704.02418</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03094</dc:identifier>
 <dc:identifier>EPTCS 246, 2017, pp. 10-20</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.246.4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03095</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantifying and Explaining Immutability in Scala</dc:title>
 <dc:creator>Haller, Philipp</dc:creator>
 <dc:creator>Axelsson, Ludvig</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.1.1</dc:subject>
 <dc:subject>D.2.8</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:description>  Functional programming typically emphasizes programming with first-class
functions and immutable data. Immutable data types enable fault tolerance in
distributed systems, and ensure process isolation in message-passing
concurrency, among other applications. However, beyond the distinction between
reassignable and non-reassignable fields, Scala's type system does not have a
built-in notion of immutability for type definitions. As a result, immutability
is &quot;by-convention&quot; in Scala, and statistics about the use of immutability in
real-world Scala code are non-existent.
  This paper reports on the results of an empirical study on the use of
immutability in several medium-to-large Scala open-source code bases, including
Scala's standard library and the Akka actor framework. The study investigates
both shallow and deep immutability, two widely-used forms of immutability in
Scala. Perhaps most interestingly, for type definitions determined to be
mutable, explanations are provided for why neither the shallow nor the deep
immutability property holds; in turn, these explanations are aggregated into
statistics in order to determine the most common reasons for why type
definitions are mutable rather than immutable.
</dc:description>
 <dc:description>Comment: In Proceedings PLACES 2017, arXiv:1704.02418</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03095</dc:identifier>
 <dc:identifier>EPTCS 246, 2017, pp. 21-27</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.246.5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03096</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inferring Types for Parallel Programs</dc:title>
 <dc:creator>Martins, Francisco</dc:creator>
 <dc:creator>Vasconcelos, Vasco Thudichum</dc:creator>
 <dc:creator>H&#xfc;ttel, Hans</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The Message Passing Interface (MPI) framework is widely used in implementing
imperative pro- grams that exhibit a high degree of parallelism. The PARTYPES
approach proposes a behavioural type discipline for MPI-like programs in which
a type describes the communication protocol followed by the entire program.
Well-typed programs are guaranteed to be exempt from deadlocks. In this paper
we describe a type inference algorithm for a subset of the original system; the
algorithm allows to statically extract a type for an MPI program from its
source code.
</dc:description>
 <dc:description>Comment: In Proceedings PLACES 2017, arXiv:1704.02418</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03096</dc:identifier>
 <dc:identifier>EPTCS 246, 2017, pp. 28-36</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.246.6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03097</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiparty Session Types, Beyond Duality (Abstract)</dc:title>
 <dc:creator>Scalas, Alceste</dc:creator>
 <dc:creator>Yoshida, Nobuko</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  Multiparty Session Types (MPST) are a well-established typing discipline for
message-passing processes interacting on sessions involving two or more
participants. Session typing can ensure desirable properties: absence of
communication errors and deadlocks, and protocol conformance. However, existing
MPST works provide a subject reduction result that is arguably (and sometimes,
surprisingly) restrictive: it only holds for typing contexts with strong
duality constraints on the interactions between pairs of participants.
Consequently, many &quot;intuitively correct&quot; examples cannot be typed and/or cannot
be proved type-safe. We illustrate some of these examples, and discuss the
reason for these limitations. Then, we outline a novel MPST typing system that
removes these restrictions.
</dc:description>
 <dc:description>Comment: In Proceedings PLACES 2017, arXiv:1704.02418</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03097</dc:identifier>
 <dc:identifier>EPTCS 246, 2017, pp. 37-38</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.246.7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03098</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generating Representative Executions [Extended Abstract]</dc:title>
 <dc:creator>Maarand, Hendrik</dc:creator>
 <dc:creator>Uustalu, Tarmo</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:description>  Analyzing the behaviour of a concurrent program is made difficult by the
number of possible executions. This problem can be alleviated by applying the
theory of Mazurkiewicz traces to focus only on the canonical representatives of
the equivalence classes of the possible executions of the program. This paper
presents a generic framework that allows to specify the possible behaviours of
the execution environment, and generate all Foata-normal executions of a
program, for that environment, by discarding abnormal executions during the
generation phase. The key ingredient of Mazurkiewicz trace theory, the
dependency relation, is used in the framework in two roles: first, as part of
the specification of which executions are allowed at all, and then as part of
the normality checking algorithm, which is used to discard the abnormal
executions. The framework is instantiated to the relaxed memory models of the
SPARC hierarchy.
</dc:description>
 <dc:description>Comment: In Proceedings PLACES 2017, arXiv:1704.02418</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03098</dc:identifier>
 <dc:identifier>EPTCS 246, 2017, pp. 39-48</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.246.8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03099</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Categorical Representation of Reversible Event Structures</dc:title>
 <dc:creator>Graversen, Eva</dc:creator>
 <dc:creator>Phillips, Iain</dc:creator>
 <dc:creator>Yoshida, Nobuko</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We study categories for reversible computing, focussing on reversible forms
of event structures. Event structures are a well-established model of true
concurrency. There exist a number of forms of event structures, including prime
event structures, asymmetric event structures, and general event structures.
More recently, reversible forms of these types of event structures have been
defined. We formulate corresponding categories and functors between them. We
show that products and co-products exist in many cases. In most work on
reversible computing, including reversible process calculi, a cause-respecting
condition is posited, meaning that the cause of an event may not be reversed
before the event itself. Since reversible event structures are not assumed to
be cause-respecting in general, we also define cause-respecting subcategories
of these event structures. Our longer-term aim is to formulate event structure
semantics for reversible process calculi.
</dc:description>
 <dc:description>Comment: In Proceedings PLACES 2017, arXiv:1704.02418</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03099</dc:identifier>
 <dc:identifier>EPTCS 246, 2017, pp. 49-60</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.246.9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03100</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Best-by-Simulations: A Framework for Comparing Efficiency of
  Reconfigurable Multicore Architectures on Workloads with Deadlines</dc:title>
 <dc:creator>Prasad, Sanjiva</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>C.1.3</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  Energy consumption is a major concern in multicore systems. Perhaps the
simplest strategy for reducing energy costs is to use only as many cores as
necessary while still being able to deliver a desired quality of service.
Motivated by earlier work on a dynamic (heterogeneous) core allocation scheme
for H.264 video decoding that reduces energy costs while delivering desired
frame rates, we formulate operationally the general problem of executing a
sequence of actions on a reconfigurable machine while meeting a corresponding
sequence of absolute deadlines, with the objective of reducing cost. Using a
transition system framework that associates costs (e.g., time, energy) with
executing an action on a particular resource configuration, we use the notion
of amortised cost to formulate in terms of simulation relations appropriate
notions for comparing deadline-conformant executions. We believe these notions
can provide the basis for an operational theory of optimal cost executions and
performance guarantees for approximate solutions, in particular relating the
notion of simulation from transition systems to that of competitive analysis
used for, e.g., online algorithms.
</dc:description>
 <dc:description>Comment: In Proceedings PLACES 2017, arXiv:1704.02418</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03100</dc:identifier>
 <dc:identifier>EPTCS 246, 2017, pp. 61-71</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.246.10</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03102</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Control Synthesis of Nonlinear Sampled Switched Systems using Euler's
  Method</dc:title>
 <dc:creator>Co&#xeb;nt, Adrien Le</dc:creator>
 <dc:creator>De Vuyst, Florian</dc:creator>
 <dc:creator>Chamoin, Ludovic</dc:creator>
 <dc:creator>Fribourg, Laurent</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  In this paper, we propose a symbolic control synthesis method for nonlinear
sampled switched systems whose vector fields are one-sided Lipschitz. The main
idea is to use an approximate model obtained from the forward Euler method to
build a guaranteed control. The benefit of this method is that the error
introduced by symbolic modeling is bounded by choosing suitable time and space
discretizations. The method is implemented in the interpreted language Octave.
Several examples of the literature are performed and the results are compared
with results obtained with a previous method based on the Runge-Kutta
integration method.
</dc:description>
 <dc:description>Comment: In Proceedings SNR 2017, arXiv:1704.02421</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03102</dc:identifier>
 <dc:identifier>EPTCS 247, 2017, pp. 18-33</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.247.2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03103</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minkowski Operations of Sets with Application to Robot Localization</dc:title>
 <dc:creator>Desrochers, Benoit</dc:creator>
 <dc:creator>Jaulin, Luc</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>interval analysis</dc:subject>
 <dc:description>  This papers shows that using separators, which is a pair of two complementary
contractors, we can easily and efficiently solve the localization problem of a
robot with sonar measurements in an unstructured environment. We introduce
separators associated with the Minkowski sum and the Minkowski difference in
order to facilitate the resolution. A test-case is given in order to illustrate
the principle of the approach.
</dc:description>
 <dc:description>Comment: In Proceedings SNR 2017, arXiv:1704.02421</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03103</dc:identifier>
 <dc:identifier>EPTCS 247, 2017, pp. 34-45</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.247.3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03104</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Underapproximation of Reach Sets of Abstract Continuous-Time
  Systems</dc:title>
 <dc:creator>Ivanov, Ievgen</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We consider the problem of proving that each point in a given set of states
(&quot;target set&quot;) can indeed be reached by a given nondeterministic
continuous-time dynamical system from some initial state. We consider this
problem for abstract continuous-time models that can be concretized as various
kinds of continuous and hybrid dynamical systems.
  The approach to this problem proposed in this paper is based on finding a
suitable superset S of the target set which has the property that each partial
trajectory of the system which lies entirely in S either is defined as the
initial time moment, or can be locally extended backward in time, or can be
locally modified in such a way that the resulting trajectory can be locally
extended back in time.
  This reformulation of the problem has a relatively simple logical expression
and is convenient for applying various local existence theorems and local
dynamics analysis methods to proving reachability which makes it suitable for
reasoning about the behavior of continuous and hybrid dynamical systems in
proof assistants such as Mizar, Isabelle, etc.
</dc:description>
 <dc:description>Comment: In Proceedings SNR 2017, arXiv:1704.02421</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03104</dc:identifier>
 <dc:identifier>EPTCS 247, 2017, pp. 46-51</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.247.4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03105</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compile-Time Extensions to Hybrid ODEs</dc:title>
 <dc:creator>Zeng, Yingfu</dc:creator>
 <dc:creator>Bartha, Ferenc</dc:creator>
 <dc:creator>Taha, Walid</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Reachability analysis for hybrid systems is an active area of development and
has resulted in many promising prototype tools. Most of these tools allow users
to express hybrid system as automata with a set of ordinary differential
equations (ODEs) associated with each state, as well as rules for transitions
between states. Significant effort goes into developing and verifying and
correctly implementing those tools. As such, it is desirable to expand the
scope of applicability tools of such as far as possible. With this goal, we
show how compile-time transformations can be used to extend the basic hybrid
ODE formalism traditionally supported in hybrid reachability tools such as
SpaceEx or Flow*. The extension supports certain types of partial derivatives
and equational constraints. These extensions allow users to express, among
other things, the Euler-Lagrangian equation, and to capture practically
relevant constraints that arise naturally in mechanical systems. Achieving this
level of expressiveness requires using a binding time-analysis (BTA), program
differentiation, symbolic Gaussian elimination, and abstract interpretation
using interval analysis. Except for BTA, the other components are either
readily available or can be easily added to most reachability tools. The paper
therefore focuses on presenting both the declarative and algorithmic
specifications for the BTA phase, and establishes the soundness of the
algorithmic specifications with respect to the declarative one.
</dc:description>
 <dc:description>Comment: In Proceedings SNR 2017, arXiv:1704.02421</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03105</dc:identifier>
 <dc:identifier>EPTCS 247, 2017, pp. 52-70</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.247.5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03114</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Visual Relationships with Deep Relational Networks</dc:title>
 <dc:creator>Dai, Bo</dc:creator>
 <dc:creator>Zhang, Yuqi</dc:creator>
 <dc:creator>Lin, Dahua</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Relationships among objects play a crucial role in image understanding.
Despite the great success of deep learning techniques in recognizing individual
objects, reasoning about the relationships among objects remains a challenging
task. Previous methods often treat this as a classification problem,
considering each type of relationship (e.g. &quot;ride&quot;) or each distinct visual
phrase (e.g. &quot;person-ride-horse&quot;) as a category. Such approaches are faced with
significant difficulties caused by the high diversity of visual appearance for
each kind of relationships or the large number of distinct visual phrases. We
propose an integrated framework to tackle this problem. At the heart of this
framework is the Deep Relational Network, a novel formulation designed
specifically for exploiting the statistical dependencies between objects and
their relationships. On two large datasets, the proposed method achieves
substantial improvement over state-of-the-art.
</dc:description>
 <dc:description>Comment: To be appeared in CVPR 2017 as an oral paper</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03116</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DOPE: Distributed Optimization for Pairwise Energies</dc:title>
 <dc:creator>Dolz, Jose</dc:creator>
 <dc:creator>Ayed, Ismail Ben</dc:creator>
 <dc:creator>Desrosiers, Christian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We formulate an Alternating Direction Method of Mul-tipliers (ADMM) that
systematically distributes the computations of any technique for optimizing
pairwise functions, including non-submodular potentials. Such discrete
functions are very useful in segmentation and a breadth of other vision
problems. Our method decomposes the problem into a large set of small
sub-problems, each involving a sub-region of the image domain, which can be
solved in parallel. We achieve consistency between the sub-problems through a
novel constraint that can be used for a large class of pair-wise functions. We
give an iterative numerical solution that alternates between solving the
sub-problems and updating consistency variables, until convergence. We report
comprehensive experiments, which demonstrate the benefit of our general
distributed solution in the case of the popular serial algorithm of Boykov and
Kolmogorov (BK algorithm) and, also, in the context of non-submodular
functions.
</dc:description>
 <dc:description>Comment: Accepted at CVPR 2017</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03116</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03118</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PIANO: Proximity-based User Authentication on Voice-Powered
  Internet-of-Things Devices</dc:title>
 <dc:creator>Gong, Neil Zhenqiang</dc:creator>
 <dc:creator>Ozen, Altay</dc:creator>
 <dc:creator>Wu, Yu</dc:creator>
 <dc:creator>Cao, Xiaoyu</dc:creator>
 <dc:creator>Shin, Richard</dc:creator>
 <dc:creator>Song, Dawn</dc:creator>
 <dc:creator>Jin, Hongxia</dc:creator>
 <dc:creator>Bao, Xuan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Voice is envisioned to be a popular way for humans to interact with
Internet-of-Things (IoT) devices. We propose a proximity-based user
authentication method (called PIANO) for access control on such voice-powered
IoT devices. PIANO leverages the built-in speaker, microphone, and Bluetooth
that voice-powered IoT devices often already have. Specifically, we assume that
a user carries a personal voice-powered device (e.g., smartphone, smartwatch,
or smartglass), which serves as the user's identity. When another voice-powered
IoT device of the user requires authentication, PIANO estimates the distance
between the two devices by playing and detecting certain acoustic signals;
PIANO grants access if the estimated distance is no larger than a user-selected
threshold. We implemented a proof-of-concept prototype of PIANO. Through
theoretical and empirical evaluations, we find that PIANO is secure, reliable,
personalizable, and efficient.
</dc:description>
 <dc:description>Comment: To appear in ICDCS'17</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03118</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03132</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Odd Yao-Yao Graphs may Not be Spanners</dc:title>
 <dc:creator>Jin, Yifei</dc:creator>
 <dc:creator>Li, Jian</dc:creator>
 <dc:creator>Zhan, Wei</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  It is a long standing open problem whether Yao-Yao graphs $\mathsf{YY}_{k}$
are all spanners. Bauer and Damian \cite{bauer2013infinite} showed that all
$\mathsf{YY}_{6k}$ for $k \geq 6$ are spanners. Li and Zhan \cite{li2016almost}
generalized their result and proved that all even Yao-Yao graphs
$\mathsf{YY}_{2k}$ are spanners (for $k\geq 42$). However, their technique
cannot be extended to odd Yao-Yao graphs, and whether they are spanners are
still elusive. In this paper, we show that, surprisingly, for any integer $k
\geq 1$, there exist odd Yao-Yao graph $\mathsf{YY}_{2k+1}$ instances, which
are not spanners.
</dc:description>
 <dc:description>Comment: 29 pages, 26 figures</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03132</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03135</identifier>
 <datestamp>2017-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Pairwise Ranking for Multi-label Image Classification</dc:title>
 <dc:creator>Li, Yuncheng</dc:creator>
 <dc:creator>Song, Yale</dc:creator>
 <dc:creator>Luo, Jiebo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Learning to rank has recently emerged as an attractive technique to train
deep convolutional neural networks for various computer vision tasks. Pairwise
ranking, in particular, has been successful in multi-label image
classification, achieving state-of-the-art results on various benchmarks.
However, most existing approaches use the hinge loss to train their models,
which is non-smooth and thus is difficult to optimize especially with deep
networks. Furthermore, they employ simple heuristics, such as top-k or
thresholding, to determine which labels to include in the output from a ranked
list of labels, which limits their use in the real-world setting. In this work,
we propose two techniques to improve pairwise ranking based multi-label image
classification: (1) we propose a novel loss function for pairwise ranking,
which is smooth everywhere and thus is easier to optimize; and (2) we
incorporate a label decision module into the model, estimating the optimal
confidence thresholds for each visual concept. We provide theoretical analyses
of our loss function in the Bayes consistency and risk minimization framework,
and show its benefit over existing pairwise ranking formulations. We
demonstrate the effectiveness of our approach on three large-scale datasets,
VOC2007, NUS-WIDE and MS-COCO, achieving the best reported results in the
literature.
</dc:description>
 <dc:description>Comment: cvpr 2017</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03135</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03137</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resolution-Adaptive Hybrid MIMO Architectures for Millimeter Wave
  Communications</dc:title>
 <dc:creator>Choi, Jinseok</dc:creator>
 <dc:creator>Evans, Brian L.</dc:creator>
 <dc:creator>Gatherer, Alan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose a hybrid analog-digital beamforming architecture
with resolution-adaptive ADCs for millimeter wave (mmWave) receivers with large
antenna arrays. We adopt array response vectors for the analog combiners and
derive ADC bit-allocation (BA) solutions in closed form. The BA solutions
reveal that the optimal number of ADC bits is logarithmically proportional to
the RF chain's signal-to-noise ratio raised to the 1/3 power. Using the
solutions, two proposed BA algorithms minimize the mean square quantization
error of received analog signals under a total ADC power constraint.
Contributions of this paper include 1) ADC bit-allocation algorithms to improve
communication performance of a hybrid MIMO receiver, 2) approximation of the
capacity with the BA algorithm as a function of channels, and 3) a worst-case
analysis of the ergodic rate of the proposed MIMO receiver that quantifies
system tradeoffs and serves as the lower bound. Simulation results demonstrate
that the BA algorithms outperform a fixed-ADC approach in both spectral and
energy efficiency, and validate the capacity and ergodic rate formula. For a
power constraint equivalent to that of fixed 4-bit ADCs, the revised BA
algorithm makes the quantization error negligible while achieving 22% better
energy efficiency. Having negligible quantization error allows existing
state-of-the-art digital beamformers to be readily applied to the proposed
system.
</dc:description>
 <dc:description>Comment: Accepted to IEEE Transactions on Signal Processing</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03137</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2745440</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03138</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Identification of Web Browsing Sessions</dc:title>
 <dc:creator>Guha, Neel</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We introduce a semantic identification attack, in which an adversary uses
semantic signals about the pages visited in one browsing session to identify
other browsing sessions launched by the same user. Current user fingerprinting
methods fail when a single machine is used by multiple users (e.g., in
cybercafes or spaces with public computers) as these methods fingerprint
devices, not individuals. We demonstrate how an adversary can employ a SIA to
successfully fingerprint users on public or shared machines and identify them
across browsing sessions. We additionally describe and evaluate possible
countermeasures to prevent identification.
</dc:description>
 <dc:description>Comment: 10 pages and Appendix. arXiv admin note: substantial text overlap
  with arXiv:1610.09417</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03138</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03140</identifier>
 <datestamp>2017-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Restoration of Atmospheric Turbulence-distorted Images via RPCA and
  Quasiconformal Maps</dc:title>
 <dc:creator>Lau, Chun Pong</dc:creator>
 <dc:creator>Lai, Yu Hin</dc:creator>
 <dc:creator>Lui, Lok Ming</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  We address the problem of restoring a high-quality image from an observed
image sequence strongly distorted by atmospheric turbulence. A novel algorithm
is proposed in this paper to reduce geometric distortion as well as
space-and-time-varying blur due to strong turbulence. By considering a suitable
energy functional, our algorithm first obtains a sharp reference image and a
subsampled image sequence containing sharp and mildly distorted image frames
with respect to the reference image. The subsampled image sequence is then
stabilized by applying the Robust Principal Component Analysis (RPCA) on the
deformation fields between image frames and warping the image frames by a
quasiconformal map associated with the low-rank part of the deformation matrix.
After image frames are registered to the reference image, the low-rank part of
them are deblurred via a blind deconvolution, and the deblurred frames are then
fused with the enhanced sparse part. Experiments have been carried out on both
synthetic and real turbulence-distorted video. Results demonstrate that our
method is effective in alleviating distortions and blur, restoring image
details and enhancing visual quality.
</dc:description>
 <dc:description>Comment: 21 pages, 24 figures</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-09-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03140</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03141</identifier>
 <datestamp>2017-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Federated Tensor Factorization for Computational Phenotyping</dc:title>
 <dc:creator>Kim, Yejin</dc:creator>
 <dc:creator>Sun, Jimeng</dc:creator>
 <dc:creator>Yu, Hwanjo</dc:creator>
 <dc:creator>Jiang, Xiaoqian</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Tensor factorization models offer an effective approach to convert massive
electronic health records into meaningful clinical concepts (phenotypes) for
data analysis. These models need a large amount of diverse samples to avoid
population bias. An open challenge is how to derive phenotypes jointly across
multiple hospitals, in which direct patient-level data sharing is not possible
(e.g., due to institutional policies). In this paper, we developed a novel
solution to enable federated tensor factorization for computational phenotyping
without sharing patient-level data. We developed secure data harmonization and
federated computation procedures based on alternating direction method of
multipliers (ADMM). Using this method, the multiple hospitals iteratively
update tensors and transfer secure summarized information to a central server,
and the server aggregates the information to generate phenotypes. We
demonstrated with real medical datasets that our method resembles the
centralized training model (based on combined datasets) in terms of accuracy
and phenotypes discovery while respecting privacy.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03141</dc:identifier>
 <dc:identifier>doi:10.1145/3097983.3098118</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03144</identifier>
 <datestamp>2017-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parametric Gaussian Process Regression for Big Data</dc:title>
 <dc:creator>Raissi, Maziar</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This work introduces the concept of parametric Gaussian processes (PGPs),
which is built upon the seemingly self-contradictory idea of making Gaussian
processes parametric. Parametric Gaussian processes, by construction, are
designed to operate in &quot;big data&quot; regimes where one is interested in
quantifying the uncertainty associated with noisy data. The proposed
methodology circumvents the well-established need for stochastic variational
inference, a scalable algorithm for approximating posterior distributions. The
effectiveness of the proposed approach is demonstrated using an illustrative
example with simulated data and a benchmark dataset in the airline industry
with approximately 6 million records.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-05-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03144</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03152</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Multimodal Representation Learning from Temporal Data</dc:title>
 <dc:creator>Yang, Xitong</dc:creator>
 <dc:creator>Ramesh, Palghat</dc:creator>
 <dc:creator>Chitta, Radha</dc:creator>
 <dc:creator>Madhvanath, Sriganesh</dc:creator>
 <dc:creator>Bernal, Edgar A.</dc:creator>
 <dc:creator>Luo, Jiebo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In recent years, Deep Learning has been successfully applied to multimodal
learning problems, with the aim of learning useful joint representations in
data fusion applications. When the available modalities consist of time series
data such as video, audio and sensor signals, it becomes imperative to consider
their temporal structure during the fusion process. In this paper, we propose
the Correlational Recurrent Neural Network (CorrRNN), a novel temporal fusion
model for fusing multiple input modalities that are inherently temporal in
nature. Key features of our proposed model include: (i) simultaneous learning
of the joint representation and temporal dependencies between modalities, (ii)
use of multiple loss terms in the objective function, including a maximum
correlation loss term to enhance learning of cross-modal information, and (iii)
the use of an attention model to dynamically adjust the contribution of
different input modalities to the joint representation. We validate our model
via experimentation on two different tasks: video- and sensor-based activity
classification, and audio-visual speech recognition. We empirically analyze the
contributions of different components of the proposed CorrRNN model, and
demonstrate its robustness, effectiveness and state-of-the-art performance on
multiple datasets.
</dc:description>
 <dc:description>Comment: To appear in CVPR 2017</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03152</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03155</identifier>
 <datestamp>2017-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EAST: An Efficient and Accurate Scene Text Detector</dc:title>
 <dc:creator>Zhou, Xinyu</dc:creator>
 <dc:creator>Yao, Cong</dc:creator>
 <dc:creator>Wen, He</dc:creator>
 <dc:creator>Wang, Yuzhi</dc:creator>
 <dc:creator>Zhou, Shuchang</dc:creator>
 <dc:creator>He, Weiran</dc:creator>
 <dc:creator>Liang, Jiajun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Previous approaches for scene text detection have already achieved promising
performances across various benchmarks. However, they usually fall short when
dealing with challenging scenarios, even when equipped with deep neural network
models, because the overall performance is determined by the interplay of
multiple stages and components in the pipelines. In this work, we propose a
simple yet powerful pipeline that yields fast and accurate text detection in
natural scenes. The pipeline directly predicts words or text lines of arbitrary
orientations and quadrilateral shapes in full images, eliminating unnecessary
intermediate steps (e.g., candidate aggregation and word partitioning), with a
single neural network. The simplicity of our pipeline allows concentrating
efforts on designing loss functions and neural network architecture.
Experiments on standard datasets including ICDAR 2015, COCO-Text and MSRA-TD500
demonstrate that the proposed algorithm significantly outperforms
state-of-the-art methods in terms of both accuracy and efficiency. On the ICDAR
2015 dataset, the proposed algorithm achieves an F-score of 0.7820 at 13.2fps
at 720p resolution.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2017, fix equation (3)</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03155</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03160</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lean and Full Congruence Formats for Recursion</dc:title>
 <dc:creator>van Glabbeek, Rob</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  In this paper I distinguish two (pre)congruence requirements for semantic
equivalences and preorders on processes given as closed terms in a system
description language with a recursion construct. A lean congruence preserves
equivalence when replacing closed subexpressions of a process by equivalent
alternatives. A full congruence moreover allows replacement within a recursive
specification of subexpressions that may contain recursion variables bound
outside of these subexpressions.
  I establish that bisimilarity is a lean (pre)congruence for recursion for all
languages with a structural operational semantics in the ntyft/ntyxt format.
Additionally, it is a full congruence for the tyft/tyxt format.
</dc:description>
 <dc:description>Comment: To appear in: Proc. LICS'17, Reykjavik, Iceland, IEEE</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03160</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03162</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Show, Ask, Attend, and Answer: A Strong Baseline For Visual Question
  Answering</dc:title>
 <dc:creator>Kazemi, Vahid</dc:creator>
 <dc:creator>Elqursh, Ali</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a new baseline for visual question answering task. Given
an image and a question in natural language, our model produces accurate
answers according to the content of the image. Our model, while being
architecturally simple and relatively small in terms of trainable parameters,
sets a new state of the art on both unbalanced and balanced VQA benchmark. On
VQA 1.0 open ended challenge, our model achieves 64.6% accuracy on the
test-standard set without using additional data, an improvement of 0.4% over
state of the art, and on newly released VQA 2.0, our model scores 59.7% on
validation set outperforming best previously reported results by 0.5%. The
results presented in this paper are especially interesting because very similar
models have been tried before but significantly lower performance were
reported. In light of the new results we hope to see more meaningful research
on visual question answering in the future.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03162</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03165</identifier>
 <datestamp>2017-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>struc2vec: Learning Node Representations from Structural Identity</dc:title>
 <dc:creator>Ribeiro, Leonardo F. R.</dc:creator>
 <dc:creator>Saverese, Pedro H. P.</dc:creator>
 <dc:creator>Figueiredo, Daniel R.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Structural identity is a concept of symmetry in which network nodes are
identified according to the network structure and their relationship to other
nodes. Structural identity has been studied in theory and practice over the
past decades, but only recently has it been addressed with representational
learning techniques. This work presents struc2vec, a novel and flexible
framework for learning latent representations for the structural identity of
nodes. struc2vec uses a hierarchy to measure node similarity at different
scales, and constructs a multilayer graph to encode structural similarities and
generate structural context for nodes. Numerical experiments indicate that
state-of-the-art techniques for learning node representations fail in capturing
stronger notions of structural identity, while struc2vec exhibits much superior
performance in this task, as it overcomes limitations of prior approaches. As a
consequence, numerical experiments indicate that struc2vec improves performance
on classification tasks that depend more on structural identity.
</dc:description>
 <dc:description>Comment: 10 pages, KDD2017, Research Track</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03165</dc:identifier>
 <dc:identifier>doi:10.1145/3097983.3098061</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03167</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Slicewise definability in first-order logic with bounded quantifier rank</dc:title>
 <dc:creator>Chen, Yijia</dc:creator>
 <dc:creator>Flum, Joerg</dc:creator>
 <dc:creator>Huang, Xuangui</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  For every $q\in \mathbb N$ let $\textrm{FO}_q$ denote the class of sentences
of first-order logic FO of quantifier rank at most $q$. If a graph property can
be defined in $\textrm{FO}_q$, then it can be decided in time $O(n^q)$. Thus,
minimizing $q$ has favorable algorithmic consequences. Many graph properties
amount to the existence of a certain set of vertices of size $k$. Usually this
can only be expressed by a sentence of quantifier rank at least $k$. We use the
color-coding method to demonstrate that some (hyper)graph problems can be
defined in $\textrm{FO}_q$ where $q$ is independent of $k$. This property of a
graph problem is equivalent to the question of whether the corresponding
parameterized problem is in the class $\textrm{para-AC}^0$.
  It is crucial for our results that the FO-sentences have access to built-in
addition and multiplication. It is known that then FO corresponds to the
circuit complexity class uniform $\textrm{AC}^0$. We explore the connection
between the quantifier rank of FO-sentences and the depth of
$\textrm{AC}^0$-circuits, and prove that $\textrm{FO}_q \subsetneq
\textrm{FO}_{q+1}$ for structures with built-in addition and multiplication.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03167</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03168</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FMMU: A Hardware-Automated Flash Map Management Unit for Scalable
  Performance of NAND Flash-Based SSDs</dc:title>
 <dc:creator>Woo, Yeong-Jae</dc:creator>
 <dc:creator>Min, Sang Lyul</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  NAND flash-based Solid State Drives (SSDs), which are widely used from
embedded systems to enterprise servers, are enhancing performance by exploiting
the parallelism of NAND flash memories. To cope with the performance
improvement of SSDs, storage systems have rapidly adopted the host interface
for SSDs from Serial-ATA, which is used for existing hard disk drives, to
high-speed PCI express. Since NAND flash memory does not allow in-place
updates, it requires special software called Flash Translation Layer (FTL), and
SSDs are equipped with embedded processors to run FTL. Existing SSDs increase
the clock frequency of embedded processors or increase the number of embedded
processors in order to prevent FTL from acting as bottleneck of SSD
performance, but these approaches are not scalable. This paper proposes a
hardware-automated Flash Map Management Unit, called FMMU, that handles the
address translation process dominating the execution time of the FTL by
hardware automation. FMMU provides methods for exploiting the parallelism of
flash memory by processing outstanding requests in a non-blocking manner while
reducing the number of flash operations. The experimental results show that the
FMMU reduces the FTL execution time in the map cache hit case and the miss case
by 44% and 37%, respectively, compared with the existing software-based
approach operating in 4-core. FMMU also prevents FTL from acting as a
performance bottleneck for up to 32-channel, 8-way SSD using PCIe 3.0 x32 host
interface.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03169</identifier>
 <datestamp>2017-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Later-stage Minimum Bayes-Risk Decoding for Neural Machine Translation</dc:title>
 <dc:creator>Shu, Raphael</dc:creator>
 <dc:creator>Nakayama, Hideki</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  For extended periods of time, sequence generation models rely on beam search
algorithm to generate output sequence. However, the correctness of beam search
degrades when the a model is over-confident about a suboptimal prediction. In
this paper, we propose to perform minimum Bayes-risk (MBR) decoding for some
extra steps at a later stage. In order to speed up MBR decoding, we compute the
Bayes risks on GPU in batch mode. In our experiments, we found that MBR
reranking works with a large beam size. Later-stage MBR decoding is shown to
outperform simple MBR reranking in machine translation tasks.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03173</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mining Object Parts from CNNs via Active Question-Answering</dc:title>
 <dc:creator>Zhang, Quanshi</dc:creator>
 <dc:creator>Cao, Ruiming</dc:creator>
 <dc:creator>Wu, Ying Nian</dc:creator>
 <dc:creator>Zhu, Song-Chun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Given a convolutional neural network (CNN) that is pre-trained for object
classification, this paper proposes to use active question-answering to
semanticize neural patterns in conv-layers of the CNN and mine part concepts.
For each part concept, we mine neural patterns in the pre-trained CNN, which
are related to the target part, and use these patterns to construct an And-Or
graph (AOG) to represent a four-layer semantic hierarchy of the part. As an
interpretable model, the AOG associates different CNN units with different
explicit object parts. We use an active human-computer communication to
incrementally grow such an AOG on the pre-trained CNN as follows. We allow the
computer to actively identify objects, whose neural patterns cannot be
explained by the current AOG. Then, the computer asks human about the
unexplained objects, and uses the answers to automatically discover certain CNN
patterns corresponding to the missing knowledge. We incrementally grow the AOG
to encode new knowledge discovered during the active-learning process. In
experiments, our method exhibits high learning efficiency. Our method uses
about 1/6-1/3 of the part annotations for training, but achieves similar or
better part-localization performance than fast-RCNN methods.
</dc:description>
 <dc:description>Comment: Published in CVPR 2017</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03173</dc:identifier>
 <dc:identifier>Quanshi Zhang, Ruiming Cao, Ying Nian Wu, and Song-Chun Zhu,
  &quot;Mining Object Parts from CNNs via Active Question-Answering&quot; in CVPR 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03174</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bell states in a Penning trap as the quantum simulator of the integer
  factorization problem</dc:title>
 <dc:creator>Rosales, Jose Luis</dc:creator>
 <dc:creator>Martin, Vicente</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We recently introduced a formulation of the integer factorization problem for
$N=xy$ based on the physics of a quantum device. The energies of this system,
being related univocally with the factors of $N$ in number theory, are the
eigenvalues of a bounded Hamiltonian. Here we solve the quantum conditions to
obtain a discrete energy spectrum that allows to assign a relative probability
for a prime to be a factor candidate of $N$. This kind of quantum sieve can be
understood as a polynomial time probabilistic quantum factoring algorithm only
requiring $ O(\log \sqrt N)^3$ energy measurements. Finally the state of this
quantum simulator will be identified as that corresponding to two entangled
electrons in a Penning trap. We also consider the possibility to build the
simulator experimentally to obtain, from the measured magnetron trap
frequencies, a device performing a probabilistic quantum sieve for the possible
factors of $N$. % This approach is suited for large $N$ and $x=O(\sqrt{N})$.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03176</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Spectral Properties of Symmetric Functions</dc:title>
 <dc:creator>Ada, Anil</dc:creator>
 <dc:creator>Fawzi, Omar</dc:creator>
 <dc:creator>Kulkarni, Raghav</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:description>  We characterize the approximate monomial complexity, sign monomial complexity
, and the approximate L 1 norm of symmetric functions in terms of simple
combinatorial measures of the functions. Our characterization of the
approximate L 1 norm solves the main conjecture in [AFH12]. As an application
of the characterization of the sign monomial complexity, we prove a conjecture
in [ZS09] and provide a characterization for the unbounded-error communication
complexity of symmetric-xor functions.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03176</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03188</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simplified Stochastic Feedforward Neural Networks</dc:title>
 <dc:creator>Lee, Kimin</dc:creator>
 <dc:creator>Kim, Jaehyung</dc:creator>
 <dc:creator>Chong, Song</dc:creator>
 <dc:creator>Shin, Jinwoo</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  It has been believed that stochastic feedforward neural networks (SFNNs) have
several advantages beyond deterministic deep neural networks (DNNs): they have
more expressive power allowing multi-modal mappings and regularize better due
to their stochastic nature. However, training large-scale SFNN is notoriously
harder. In this paper, we aim at developing efficient training methods for
SFNN, in particular using known architectures and pre-trained parameters of
DNN. To this end, we propose a new intermediate stochastic model, called
Simplified-SFNN, which can be built upon any baseline DNNand approximates
certain SFNN by simplifying its upper latent units above stochastic ones. The
main novelty of our approach is in establishing the connection between three
models, i.e., DNN-&gt;Simplified-SFNN-&gt;SFNN, which naturally leads to an efficient
training procedure of the stochastic models utilizing pre-trained parameters of
DNN. Using several popular DNNs, we show how they can be effectively
transferred to the corresponding stochastic models for both multi-modal and
classification tasks on MNIST, TFD, CASIA, CIFAR-10, CIFAR-100 and SVHN
datasets. In particular, we train a stochastic model of 28 layers and 36
million parameters, where training such a large-scale stochastic network is
significantly challenging without using Simplified-SFNN
</dc:description>
 <dc:description>Comment: 22 pages, 6 figures</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03188</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03192</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the modeling of neural cognition for social network applications</dc:title>
 <dc:creator>Wei, Jieqiang</dc:creator>
 <dc:creator>Wu, Junfeng</dc:creator>
 <dc:creator>Molinari, Marco</dc:creator>
 <dc:creator>Cvetkovic, Vladimir</dc:creator>
 <dc:creator>Johansson, Karl H.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this paper, we study neural cognition in social network. A stochastic
model is introduced and shown to incorporate two well-known models in Pavlovian
conditioning and social networks as special case, namely Rescorla-Wagner model
and Friedkin-Johnsen model. The interpretation and comparison of these model
are discussed. We consider two cases when the disturbance is independent
identical distributed for all time and when the distribution of the random
variable evolves according to a markov chain. We show that the systems for both
cases are mean square stable and the expectation of the states converges to
consensus.
</dc:description>
 <dc:description>Comment: submitted to IEEE CCAT 2017</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03192</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03202</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Symbolic Computation and Automated Reasoning for Program Analysis</dc:title>
 <dc:creator>Kovacs, Laura</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  This talk describes how a combination of symbolic computation techniques with
first-order theorem proving can be used for solving some challenges of
automating program analysis, in particular for generating and proving
properties about the logically complex parts of software. The talk will first
present how computer algebra methods, such as Groebner basis computation,
quantifier elimination and algebraic recurrence solving, help us in inferring
properties of program loops with non-trivial arithmetic. Typical properties
inferred by our work are loop invariants and expressions bounding the number of
loop iterations. The talk will then describe our work to generate first-order
properties of programs with unbounded data structures, such as arrays. For
doing so, we use saturation-based first-order theorem proving and extend
first-order provers with support for program analysis. Since program analysis
requires reasoning in the combination of first-order theories of data
structures, the talk also discusses new features in firstorder theorem proving,
such as inductive reasoning and built-in boolean sort. These extensions allow
us to express program properties directly in first-order logic and hence use
further first-order theorem provers to reason about program properties.
</dc:description>
 <dc:description>Comment: Paper published at iFM 2016</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03202</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-33693-0_2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03205</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Feature Reduction using Deep Learning for Trend Prediction in Finance</dc:title>
 <dc:creator>Troiano, Luigi</dc:creator>
 <dc:creator>Mejuto, Elena</dc:creator>
 <dc:creator>Kriplani, Pravesh</dc:creator>
 <dc:subject>Quantitative Finance - Trading and Market Microstructure</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  One of the major advantages in using Deep Learning for Finance is to embed a
large collection of information into investment decisions. A way to do that is
by means of compression, that lead us to consider a smaller feature space.
Several studies are proving that non-linear feature reduction performed by Deep
Learning tools is effective in price trend prediction. The focus has been put
mainly on Restricted Boltzmann Machines (RBM) and on output obtained by them.
Few attention has been payed to Auto-Encoders (AE) as an alternative means to
perform a feature reduction. In this paper we investigate the application of
both RBM and AE in more general terms, attempting to outline how architectural
and input space characteristics can affect the quality of prediction.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures, 5 tables</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03217</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pyramidal Gradient Matching for Optical Flow Estimation</dc:title>
 <dc:creator>Li, Yuanwei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Initializing optical flow field by either sparse descriptor matching or dense
patch matches has been proved to be particularly useful for capturing large
displacements. In this paper, we present a pyramidal gradient matching approach
that can provide dense matches for highly accurate and efficient optical flow
estimation. A novel contribution of our method is that image gradient is used
to describe image patches and proved to be able to produce robust matching.
Therefore, our method is more efficient than methods that adopt special
features (like SIFT) or patch distance metric. Moreover, we find that image
gradient is scalable for optical flow estimation, which means we can use
different levels of gradient feature (for example, full gradients or only
direction information of gradients) to obtain different complexity without
dramatic changes in accuracy. Another contribution is that we uncover the
secrets of limited PatchMatch through a thorough analysis and design a
pyramidal matching framework based these secrets. Our pyramidal matching
framework is aimed at robust gradient matching and effective to grow inliers
and reject outliers. In this framework, we present some special enhancements
for outlier filtering in gradient matching. By initializing EpicFlow with our
matches, experimental results show that our method is efficient and robust
(ranking 1st on both clean pass and final pass of MPI Sintel dataset among
published methods).
</dc:description>
 <dc:description>Comment: This work was finished in August 2016 and then submitted to IEEE PAMI
  in August 17,2016 and submitted to IEEE TIP in April 9,2017 after revising</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03217</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03219</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Error Vector Magnitude Analysis in Generalized Fading with Co-Channel
  Interference</dc:title>
 <dc:creator>Parthasarathy, Sudharsan</dc:creator>
 <dc:creator>Kumar, Suman</dc:creator>
 <dc:creator>Ganti, Radha Krishna</dc:creator>
 <dc:creator>Kalyani, Sheetal</dc:creator>
 <dc:creator>Giridhar, K.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we derive the data-aided Error Vector Magnitude (EVM) in an
interference limited system when both the desired signal and interferers
experience independent and non identically distributed $\kappa$-$\mu$ shadowed
fading. Then it is analytically shown that the EVM is equal to the square root
of number of interferers when the desired signal and interferers do not
experience fading. Further, EVM is derived in the presence of interference and
noise, when the desired signal experiences $\kappa$-$\mu$ shadowed fading and
the interferers experience independent and identical Nakagami fading. Moreover,
using the properties of the special functions, the derived EVM expressions are
also simplified for various special cases.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03219</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03223</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Persian Wordnet Construction using Supervised Learning</dc:title>
 <dc:creator>Mousavi, Zahra</dc:creator>
 <dc:creator>Faili, Heshaam</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper presents an automated supervised method for Persian wordnet
construction. Using a Persian corpus and a bi-lingual dictionary, the initial
links between Persian words and Princeton WordNet synsets have been generated.
These links will be discriminated later as correct or incorrect by employing
seven features in a trained classification system. The whole method is just a
classification system, which has been trained on a train set containing FarsNet
as a set of correct instances. State of the art results on the automatically
derived Persian wordnet is achieved. The resulted wordnet with a precision of
91.18% includes more than 16,000 words and 22,000 synsets.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03223</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03225</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reconstruction of three-dimensional porous media using generative
  adversarial neural networks</dc:title>
 <dc:creator>Mosser, Lukas</dc:creator>
 <dc:creator>Dubrule, Olivier</dc:creator>
 <dc:creator>Blunt, Martin J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:subject>Physics - Geophysics</dc:subject>
 <dc:description>  To evaluate the variability of multi-phase flow properties of porous media at
the pore scale, it is necessary to acquire a number of representative samples
of the void-solid structure. While modern x-ray computer tomography has made it
possible to extract three-dimensional images of the pore space, assessment of
the variability in the inherent material properties is often experimentally not
feasible. We present a novel method to reconstruct the solid-void structure of
porous media by applying a generative neural network that allows an implicit
description of the probability distribution represented by three-dimensional
image datasets. We show, by using an adversarial learning approach for neural
networks, that this method of unsupervised learning is able to generate
representative samples of porous media that honor their statistics. We
successfully compare measures of pore morphology, such as the Euler
characteristic, two-point statistics and directional single-phase permeability
of synthetic realizations with the calculated properties of a bead pack, Berea
sandstone, and Ketton limestone. Results show that GANs can be used to
reconstruct high-resolution three-dimensional images of porous media at
different scales that are representative of the morphology of the images used
to train the neural network. The fully convolutional nature of the trained
neural network allows the generation of large samples while maintaining
computational efficiency. Compared to classical stochastic methods of image
reconstruction, the implicit representation of the learned data distribution
can be stored and reused to generate multiple realizations of the pore
structure very rapidly.
</dc:description>
 <dc:description>Comment: 21 pages, 20 figures</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03225</dc:identifier>
 <dc:identifier>Phys. Rev. E 96, 043309 (2017)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.96.043309</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03234</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Error Bounds for Uplink and Downlink 3D Localization in 5G mmWave
  Systems</dc:title>
 <dc:creator>Abu-Shaban, Zohair</dc:creator>
 <dc:creator>Zhou, Xiangyun</dc:creator>
 <dc:creator>Abhayapala, Thushara</dc:creator>
 <dc:creator>Seco-Granados, Gonzalo</dc:creator>
 <dc:creator>Wymeersch, Henk</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Location-aware communication systems are expected to play a pivotal part in
the next generation of mobile communication networks. Therefore, there is a
need to understand the localization limits in these networks, particularly,
using millimeter-wave technology (mmWave). Towards that, we address the uplink
and downlink localization limits in terms of 3D position and orientation error
bounds for mmWave multipath channels. We also carry out a detailed analysis of
the dependence of the bounds of different systems parameters. Our key findings
indicate that the uplink and downlink behave differently in two distinct ways.
First of all, the error bounds have different scaling factors with respect to
the number of antennas in the uplink and downlink. Secondly, uplink
localization is sensitive to the orientation angle of the user equipment (UE),
whereas downlink is not. Moreover, in the considered outdoor scenarios, the
non-line-of-sight paths generally improve localization when a line-of-sight
path exists. Finally, our numerical results show that mmWave systems are
capable of localizing a UE with sub-meter position error, and sub-degree
orientation error.
</dc:description>
 <dc:description>Comment: This work has been submitted to the IEEE Transactions on Wireless
  Communications</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03234</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03242</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Keyword Extraction for Text Summarization: A Survey</dc:title>
 <dc:creator>Bharti, Santosh Kumar</dc:creator>
 <dc:creator>Babu, Korra Sathya</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In recent times, data is growing rapidly in every domain such as news, social
media, banking, education, etc. Due to the excessiveness of data, there is a
need of automatic summarizer which will be capable to summarize the data
especially textual data in original document without losing any critical
purposes. Text summarization is emerged as an important research area in recent
past. In this regard, review of existing work on text summarization process is
useful for carrying out further research. In this paper, recent literature on
automatic keyword extraction and text summarization are presented since text
summarization process is highly depend on keyword extraction. This literature
includes the discussion about different methodology used for keyword extraction
and text summarization. It also discusses about different databases used for
text summarization in several domains along with evaluation matrices. Finally,
it discusses briefly about issues and research challenges faced by researchers
along with future direction.
</dc:description>
 <dc:description>Comment: 12 pages, 4 figures</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03242</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03247</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structured linear fractional parametric controller design with
  $\mathcal{H}_\infty$ performances</dc:title>
 <dc:creator>Poussot-Vassal, C.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  This paper proposes an simple but yet effective approach to structured
parametric controller design in a linear fractional form. The main contribution
consists in using structured $\mathcal{H}_\infty$ oriented optimization tools
in an original manner to either (i) construct a parametric controller or (ii) a
family of controllers with varying performances. Practical and numerical issues
are also discussed to provide readers and practitioners a simple way to deploy
the proposed process. The overall approach is illustrated through two numerical
academical (but still complex) examples illustrating two applications: first, a
parametric controller design adapted to a parameter dependent model of a
clamped beam and, second, a controller with parameter dependent performance
applied on a building model.
</dc:description>
 <dc:description>Comment: Submitted to IEEE CDC 2017</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03247</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03248</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Robust Blind Watermarking Using Convolutional Neural Network</dc:title>
 <dc:creator>Mun, Seung-Min</dc:creator>
 <dc:creator>Nam, Seung-Hun</dc:creator>
 <dc:creator>Jang, Han-Ul</dc:creator>
 <dc:creator>Kim, Dongkyu</dc:creator>
 <dc:creator>Lee, Heung-Kyu</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  This paper introduces a blind watermarking based on a convolutional neural
network (CNN). We propose an iterative learning framework to secure robustness
of watermarking. One loop of learning process consists of the following three
stages: Watermark embedding, attack simulation, and weight update. We have
learned a network that can detect a 1-bit message from a image sub-block.
Experimental results show that this learned network is an extension of the
frequency domain that is widely used in existing watermarking scheme. The
proposed scheme achieved robustness against geometric and signal processing
attacks with a learning time of one day.
</dc:description>
 <dc:description>Comment: 4 pages. We are modifying this paper to submit to SPL</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03248</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03255</identifier>
 <datestamp>2017-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Linear Least-Squares Optimization of Rational Filters for the
  Solution of Interior Eigenvalue Problems</dc:title>
 <dc:creator>Winkelmann, Jan</dc:creator>
 <dc:creator>Di Napoli, Edoardo</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>15A18, 65F10, 65F15, 65F50, 90C26</dc:subject>
 <dc:description>  Rational filter functions can be used to improve convergence of contour-based
eigensolvers, a popular family of algorithms for the solution of the interior
eigenvalue problem. We present a framework for the optimization of rational
filters based on a non-convex weighted Least-Squares scheme. When used in
combination with the FEAST library, our filters out-perform existing ones on a
large and representative set of benchmark problems. This work provides a
detailed description of: (1) a set up of the optimization process that exploits
symmetries of the filter function for Hermitian eigenproblems, (2) a
formulation of the gradient descent and Levenberg-Marquardt algorithms that
exploits the symmetries, (3) a method to select the starting position for the
optimization algorithms that reliably produces effective filters, (4) a
constrained optimization scheme that produces filter functions with specific
properties that may be beneficial to the performance of the eigensolver that
employs them.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-04-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03255</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03261</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling of Information Diffusion on Social Networks with Applications
  to WeChat</dc:title>
 <dc:creator>Liu, Liang</dc:creator>
 <dc:creator>Qu, Bo</dc:creator>
 <dc:creator>Chen, Bin</dc:creator>
 <dc:creator>Hanjalic, Alan</dc:creator>
 <dc:creator>Wang, Huijuan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Traces of user activities recorded in online social networks such as the
creation, viewing and forwarding/sharing of information over time open new
possibilities to quantitatively and systematically understand the information
diffusion process on social networks. From an online social network like
WeChat, we could collect a large number of information cascade trees, each of
which tells the spreading trajectory of a message/information such as which
user creates the information and which users view or forward the information
shared by which neighbors. In this work, we propose two heterogeneous
non-linear models. Both models are validated by the WeChat data in reproducing
and explaining key features of cascade trees. Specifically, we firstly apply
the Random Recursive Tree (RRT) to model the cascade tree topologies, capturing
key features, i.e. the average path length and degree variance of a cascade
tree in relation to the number of nodes (size) of the tree. The RRT model with
a single parameter $\theta$ describes the growth mechanism of a tree, where a
node in the existing tree has a probability $d_i^{\theta}$ of being connected
to a newly added node that depends on the degree $d_i$ of the existing node.
The identified parameter $\theta$ quantifies the relative depth or broadness of
the cascade trees, indicating that information propagates via a star-like
broadcasting or viral-like hop by hop spreading. The RRT model explains the
appearance of hubs, thus a possibly smaller average path length as the cascade
size increases, as observed in WeChat. We further propose the stochastic
Susceptible View Forward Removed (SVFR) model to depict the dynamic user
behaviors including creating, viewing, forwarding and ignoring a message on a
given social network.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03261</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03264</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Deep CNN Denoiser Prior for Image Restoration</dc:title>
 <dc:creator>Zhang, Kai</dc:creator>
 <dc:creator>Zuo, Wangmeng</dc:creator>
 <dc:creator>Gu, Shuhang</dc:creator>
 <dc:creator>Zhang, Lei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Model-based optimization methods and discriminative learning methods have
been the two dominant strategies for solving various inverse problems in
low-level vision. Typically, those two kinds of methods have their respective
merits and drawbacks, e.g., model-based optimization methods are flexible for
handling different inverse problems but are usually time-consuming with
sophisticated priors for the purpose of good performance; in the meanwhile,
discriminative learning methods have fast testing speed but their application
range is greatly restricted by the specialized task. Recent works have revealed
that, with the aid of variable splitting techniques, denoiser prior can be
plugged in as a modular part of model-based optimization methods to solve other
inverse problems (e.g., deblurring). Such an integration induces considerable
advantage when the denoiser is obtained via discriminative learning. However,
the study of integration with fast discriminative denoiser prior is still
lacking. To this end, this paper aims to train a set of fast and effective CNN
(convolutional neural network) denoisers and integrate them into model-based
optimization method to solve other inverse problems. Experimental results
demonstrate that the learned set of denoisers not only achieve promising
Gaussian denoising results but also can be used as prior to deliver good
performance for various low-level vision applications.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2017. Code: https://github.com/cszn/ircnn</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03264</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03273</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simultaneous Stereo Video Deblurring and Scene Flow Estimation</dc:title>
 <dc:creator>Pan, Liyuan</dc:creator>
 <dc:creator>Dai, Yuchao</dc:creator>
 <dc:creator>Liu, Miaomiao</dc:creator>
 <dc:creator>Porikli, Fatih</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Videos for outdoor scene often show unpleasant blur effects due to the large
relative motion between the camera and the dynamic objects and large depth
variations. Existing works typically focus monocular video deblurring. In this
paper, we propose a novel approach to deblurring from stereo videos. In
particular, we exploit the piece-wise planar assumption about the scene and
leverage the scene flow information to deblur the image. Unlike the existing
approach [31] which used a pre-computed scene flow, we propose a single
framework to jointly estimate the scene flow and deblur the image, where the
motion cues from scene flow estimation and blur information could reinforce
each other, and produce superior results than the conventional scene flow
estimation or stereo deblurring methods. We evaluate our method extensively on
two available datasets and achieve significant improvement in flow estimation
and removing the blur effect over the state-of-the-art methods.
</dc:description>
 <dc:description>Comment: Accepted to IEEE International Conference on Computer Vision and
  Pattern Recognition (CVPR) 2017</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03275</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scavenger 0.1: A Theorem Prover Based on Conflict Resolution</dc:title>
 <dc:creator>Itegulov, Daniyar</dc:creator>
 <dc:creator>Slaney, John</dc:creator>
 <dc:creator>Paleo, Bruno Woltzenlogel</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  This paper introduces Scavenger, the first theorem prover for pure
first-order logic without equality based on the new conflict resolution
calculus. Conflict resolution has a restricted resolution inference rule that
resembles (a first-order generalization of) unit propagation as well as a rule
for assuming decision literals and a rule for deriving new clauses by (a
first-order generalization of) conflict-driven clause learning.
</dc:description>
 <dc:description>Comment: Published at CADE 2017</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03275</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03279</identifier>
 <datestamp>2017-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unfolding and Shrinking Neural Machine Translation Ensembles</dc:title>
 <dc:creator>Stahlberg, Felix</dc:creator>
 <dc:creator>Byrne, Bill</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Ensembling is a well-known technique in neural machine translation (NMT) to
improve system performance. Instead of a single neural net, multiple neural
nets with the same topology are trained separately, and the decoder generates
predictions by averaging over the individual models. Ensembling often improves
the quality of the generated translations drastically. However, it is not
suitable for production systems because it is cumbersome and slow. This work
aims to reduce the runtime to be on par with a single system without
compromising the translation quality. First, we show that the ensemble can be
unfolded into a single large neural network which imitates the output of the
ensemble system. We show that unfolding can already improve the runtime in
practice since more work can be done on the GPU. We proceed by describing a set
of techniques to shrink the unfolded network by reducing the dimensionality of
layers. On Japanese-English we report that the resulting network has the size
and decoding speed of a single NMT network but performs on the level of a
3-ensemble system.
</dc:description>
 <dc:description>Comment: Accepted at EMNLP 2017</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-07-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03285</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Video Deblurring via Dynamic Temporal Blending Network</dc:title>
 <dc:creator>Kim, Tae Hyun</dc:creator>
 <dc:creator>Lee, Kyoung Mu</dc:creator>
 <dc:creator>Sch&#xf6;lkopf, Bernhard</dc:creator>
 <dc:creator>Hirsch, Michael</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  State-of-the-art video deblurring methods are capable of removing non-uniform
blur caused by unwanted camera shake and/or object motion in dynamic scenes.
However, most existing methods are based on batch processing and thus need
access to all recorded frames, rendering them computationally demanding and
time consuming and thus limiting their practical use. In contrast, we propose
an online (sequential) video deblurring method based on a spatio-temporal
recurrent network that allows for real-time performance. In particular, we
introduce a novel architecture which extends the receptive field while keeping
the overall size of the network small to enable fast execution. In doing so,
our network is able to remove even large blur caused by strong camera shake
and/or fast moving objects. Furthermore, we propose a novel network layer that
enforces temporal consistency between consecutive frames by dynamic temporal
blending which compares and adaptively (at test time) shares features obtained
at different time steps. We show the superiority of the proposed method in an
extensive experimental evaluation.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03285</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03286</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase Retrieval via Sparse Wirtinger Flow</dc:title>
 <dc:creator>Yuan, Ziyang</dc:creator>
 <dc:creator>Wang, Qi</dc:creator>
 <dc:creator>Wang, Hongxia</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Phase retrieval(PR) problem is a kind of ill-condition inverse problem which
can be found in various of applications. Utilizing the sparse priority, an
algorithm called SWF(Sparse Wirtinger Flow) is proposed in this paper to deal
with sparse PR problem based on the Wirtinger flow method. SWF firstly recovers
the support of the signal and then updates the evaluation by hard thresholding
method with an elaborate initialization. Theoretical analyses show that SWF has
a geometric convergence for any $k$ sparse $n$ length signal with the sampling
complexity $\mathcal{O}(k^2\mathrm{log}n)$. To get $\varepsilon$ accuracy, the
computational complexity of SWF is
$\mathcal{O}(k^3n\mathrm{log}n\mathrm{log}\frac{1}{\varepsilon})$.
  Numerical tests also demonstrate that SWF performs better than
state-of-the-art methods especially when we have no priori knowledge about
sparsity $k$. Moreover, SWF is also robust to the noise
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03286</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03287</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uplink Multiuser Massive MIMO Systems with Low-Resolution ADCs: A
  Coding-Theoretic Approach</dc:title>
 <dc:creator>Hong, Song-Nam</dc:creator>
 <dc:creator>Kim, Seonho</dc:creator>
 <dc:creator>Lee, Namyoon</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers an uplink multiuser massive
multiple-input-multiple-output (MIMO) system with low-resolution
analog-to-digital converters (ADCs), in which K users with a single-antenna
communicate with one base station (BS) with Nr antennas. In this system, we
present a novel multiuser MIMO detection framework that is inspired by coding
theory. The key idea of the proposed framework is to create a code C of length
2Nr over a spatial domain. This code is constructed by a so-called
auto-encoding function that is not designable but is completely described by a
channel transformation followed by a quantization function of the ADCs. From
this point of view, we convert a multiuser MIMO detection problem into an
equivalent channel coding problem, in which a codeword of C corresponding to
users' messages is sent over 2Nr parallel channels, each with different channel
reliability. To the resulting problem, we propose a novel weighted minimum
distance decoding (wMDD) that appropriately exploits the unequal channel
reliabilities. It is shown that the proposed wMDD yields a non-trivial gain
over the conventional minimum distance decoding (MDD). From coding-theoretic
viewpoint, we identify that bit-error-rate (BER) exponentially decreases with
the minimum distance of the code C, which plays a similar role with a condition
number in conventional MIMO systems. Furthermore, we develop the communication
method that uses the wMDD for practical scenarios where the BS has no knowledge
of channel state information. Finally, numerical results are provided to verify
the superiority of the proposed method.
</dc:description>
 <dc:description>Comment: Submitted to IEEE TWC</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03287</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03288</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy Efficiency in Cell-Free Massive MIMO with Zero-Forcing Precoding
  Design</dc:title>
 <dc:creator>Nguyen, L. D.</dc:creator>
 <dc:creator>Duong, T. Q.</dc:creator>
 <dc:creator>Ngo, H. Q.</dc:creator>
 <dc:creator>Tourki, K.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the downlink of a cell-free massive multiple-input
multiple-output (MIMO) network where numerous distributed access points (APs)
serve a smaller number of users under time division duplex operation. An
important issue in deploying cell-free networks is high power consumption,
which is proportional to the number of APs. This issue has raised the question
as to their suitability for green communications in terms of the total energy
efficiency (bits/Joule). To tackle this, we develop a novel low-complexity
power control technique with zero-forcing precoding design to maximize the
energy efficiency of cell-free massive MIMO taking into account the backhaul
power consumption and the imperfect channel state information.
</dc:description>
 <dc:description>Comment: Accepted for publication on IEEE Communications Letters</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03288</dc:identifier>
 <dc:identifier>IEEE Communications Letters, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03289</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impact Of Content Features For Automatic Online Abuse Detection</dc:title>
 <dc:creator>Papegnies, Etienne</dc:creator>
 <dc:creator>Labatut, Vincent</dc:creator>
 <dc:creator>Dufour, Richard</dc:creator>
 <dc:creator>Linares, Georges</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Online communities have gained considerable importance in recent years due to
the increasing number of people connected to the Internet. Moderating user
content in online communities is mainly performed manually, and reducing the
workload through automatic methods is of great financial interest for community
maintainers. Often, the industry uses basic approaches such as bad words
filtering and regular expression matching to assist the moderators. In this
article, we consider the task of automatically determining if a message is
abusive. This task is complex since messages are written in a non-standardized
way, including spelling errors, abbreviations, community-specific codes...
First, we evaluate the system that we propose using standard features of online
messages. Then, we evaluate the impact of the addition of pre-processing
strategies, as well as original specific features developed for the community
of an online in-browser strategy game. We finally propose to analyze the
usefulness of this wide range of features using feature selection. This work
can lead to two possible applications: 1) automatically flag potentially
abusive messages to draw the moderator's attention on a narrow subset of
messages ; and 2) fully automate the moderation process by deciding whether a
message is abusive without any human intervention.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03289</dc:identifier>
 <dc:identifier>International Conference on Computational Linguistics and
  Intelligent Text Processing, Apr 2017, Budapest, Hungary. International
  Conference on Computational Linguistics and Intelligent Text Processing, 18,
  International Conference on Computational Linguistics and Intelligent Text
  Processing</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03292</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enumeration Complexity of Poor Man's Propositional Dependence Logic</dc:title>
 <dc:creator>Meier, Arne</dc:creator>
 <dc:creator>Reinbold, Christian</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In this paper, we aim to initiate the study of enumeration complexity in the
field of dependence logics. Consequently, as a first step, we investigate the
problem of enumerating all satisfying teams of a given propositional dependence
logic formula without the split junction operator. We distinguish between
restricting the team size by arbitrary functions and the parametrised version
where the parameter is the team size. We show that a polynomial delay can be
reached for polynomials and otherwise, in the parametrised setting, we reach
FPT delay. However, the constructed enumeration algorithm with polynomial delay
requires exponential space. We show that an incremental polynomial delay
algorithm exists which uses polynomial space only. Negatively, we show that for
the general problem without restricting the team size, an enumeration algorithm
running in polynomial space cannot exist.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03292</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03295</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic segmentation of MR brain images with a convolutional neural
  network</dc:title>
 <dc:creator>Moeskops, Pim</dc:creator>
 <dc:creator>Viergever, Max A.</dc:creator>
 <dc:creator>Mendrik, Adri&#xeb;nne M.</dc:creator>
 <dc:creator>de Vries, Linda S.</dc:creator>
 <dc:creator>Benders, Manon J. N. L.</dc:creator>
 <dc:creator>I&#x161;gum, Ivana</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automatic segmentation in MR brain images is important for quantitative
analysis in large-scale studies with images acquired at all ages.
  This paper presents a method for the automatic segmentation of MR brain
images into a number of tissue classes using a convolutional neural network. To
ensure that the method obtains accurate segmentation details as well as spatial
consistency, the network uses multiple patch sizes and multiple convolution
kernel sizes to acquire multi-scale information about each voxel. The method is
not dependent on explicit features, but learns to recognise the information
that is important for the classification based on training data. The method
requires a single anatomical MR image only.
  The segmentation method is applied to five different data sets: coronal
T2-weighted images of preterm infants acquired at 30 weeks postmenstrual age
(PMA) and 40 weeks PMA, axial T2- weighted images of preterm infants acquired
at 40 weeks PMA, axial T1-weighted images of ageing adults acquired at an
average age of 70 years, and T1-weighted images of young adults acquired at an
average age of 23 years. The method obtained the following average Dice
coefficients over all segmented tissue classes for each data set, respectively:
0.87, 0.82, 0.84, 0.86 and 0.91.
  The results demonstrate that the method obtains accurate segmentations in all
five sets, and hence demonstrates its robustness to differences in age and
acquisition protocol.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03295</dc:identifier>
 <dc:identifier>IEEE Transactions on Medical Imaging, 35(5), 1252-1261 (2016)</dc:identifier>
 <dc:identifier>doi:10.1109/TMI.2016.2548501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03296</identifier>
 <datestamp>2018-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpretable Explanations of Black Boxes by Meaningful Perturbation</dc:title>
 <dc:creator>Fong, Ruth</dc:creator>
 <dc:creator>Vedaldi, Andrea</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  As machine learning algorithms are increasingly applied to high impact yet
high risk tasks, such as medical diagnosis or autonomous driving, it is
critical that researchers can explain how such algorithms arrived at their
predictions. In recent years, a number of image saliency methods have been
developed to summarize where highly complex neural networks &quot;look&quot; in an image
for evidence for their predictions. However, these techniques are limited by
their heuristic nature and architectural constraints. In this paper, we make
two main contributions: First, we propose a general framework for learning
different kinds of explanations for any black box algorithm. Second, we
specialise the framework to find the part of an image most responsible for a
classifier decision. Unlike previous works, our method is model-agnostic and
testable because it is grounded in explicit and interpretable image
perturbations.
</dc:description>
 <dc:description>Comment: Final camera-ready paper published at ICCV 2017 (Supplementary
  materials:
  http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Fong_Interpretable_Explanations_of_ICCV_2017_supplemental.pdf)</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2018-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03296</dc:identifier>
 <dc:identifier>Proceedings of the 2017 IEEE International Conference on Computer
  Vision (ICCV)</dc:identifier>
 <dc:identifier>doi:10.1109/ICCV.2017.371</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03298</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The MATLAB Toolbox SciXMiner: User's Manual and Programmer's Guide</dc:title>
 <dc:creator>Mikut, Ralf</dc:creator>
 <dc:creator>Bartschat, Andreas</dc:creator>
 <dc:creator>Doneit, Wolfgang</dc:creator>
 <dc:creator>Ordiano, Jorge &#xc1;ngel Gonz&#xe1;lez</dc:creator>
 <dc:creator>Schott, Benjamin</dc:creator>
 <dc:creator>Stegmaier, Johannes</dc:creator>
 <dc:creator>Waczowicz, Simon</dc:creator>
 <dc:creator>Reischl, Markus</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The Matlab toolbox SciXMiner is designed for the visualization and analysis
of time series and features with a special focus to classification problems. It
was developed at the Institute of Applied Computer Science of the Karlsruhe
Institute of Technology (KIT), a member of the Helmholtz Association of German
Research Centres in Germany. The aim was to provide an open platform for the
development and improvement of data mining methods and its applications to
various medical and technical problems. SciXMiner bases on Matlab (tested for
the version 2017a). Many functions do not require additional standard toolboxes
but some parts of Signal, Statistics and Wavelet toolboxes are used for special
cases. The decision to a Matlab-based solution was made to use the wide
mathematical functionality of this package provided by The Mathworks Inc.
SciXMiner is controlled by a graphical user interface (GUI) with menu items and
control elements like popup lists, checkboxes and edit elements. This makes it
easier to work with SciXMiner for inexperienced users. Furthermore, an
automatization and batch standardization of analyzes is possible using macros.
The standard Matlab style using the command line is also available. SciXMiner
is an open source software. The download page is
http://sourceforge.net/projects/SciXMiner. It is licensed under the conditions
of the GNU General Public License (GNU-GPL) of The Free Software Foundation.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03298</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03311</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>$b$-symbol distance distribution of repeated-root cyclic codes</dc:title>
 <dc:creator>Mostafanasab, Hojjat</dc:creator>
 <dc:creator>Sevim, Esra Sengelen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Symbol-pair codes, introduced by Cassuto and Blaum [1], have been raised for
symbol-pair read channels. This new idea is motivated by the limitation of the
reading process in high-density data storage technologies. Yaakobi et al. [8]
introduced codes for $b$-symbol read channels, where the read operation is
performed as a consecutive sequence of $b&gt;2$ symbols. In this paper, we come up
with a method to compute the $b$-symbol-pair distance of two $n$-tuples, where
$n$ is a positive integer. Also, we deal with the $b$-symbol-pair distances of
some kind of cyclic codes of length $p^e$ over $\mathbb{F}_{p^m}$.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03311</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03318</identifier>
 <datestamp>2017-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weighted k-Server Bounds via Combinatorial Dichotomies</dc:title>
 <dc:creator>Bansal, Nikhil</dc:creator>
 <dc:creator>Elias, Marek</dc:creator>
 <dc:creator>Koumoutsos, Grigorios</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The weighted $k$-server problem is a natural generalization of the $k$-server
problem where each server has a different weight. We consider the problem on
uniform metrics, which corresponds to a natural generalization of paging. Our
main result is a doubly exponential lower bound on the competitive ratio of any
deterministic online algorithm, that essentially matches the known upper bounds
for the problem and closes a large and long-standing gap.
  The lower bound is based on relating the weighted $k$-server problem to a
certain combinatorial problem and proving a Ramsey-theoretic lower bound for
it. This combinatorial connection also reveals several structural properties of
low cost feasible solutions to serve a sequence of requests. We use this to
show that the generalized Work Function Algorithm achieves an almost optimum
competitive ratio, and to obtain new refined upper bounds on the competitive
ratio for the case of $d$ different weight classes.
</dc:description>
 <dc:description>Comment: accepted to FOCS'17</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-09-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03318</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03319</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Speeding up Consensus by Chasing Fast Decisions</dc:title>
 <dc:creator>Arun, Balaji</dc:creator>
 <dc:creator>Peluso, Sebastiano</dc:creator>
 <dc:creator>Palmieri, Roberto</dc:creator>
 <dc:creator>Losa, Giuliano</dc:creator>
 <dc:creator>Ravindran, Binoy</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  This paper proposes CAESAR, a novel multi-leader Generalized Consensus
protocol for geographically replicated sites. The main goal of CAESAR is to
overcome one of the major limitations of existing approaches, which is the
significant performance degradation when application workload produces
conflicting requests. CAESAR does that by changing the way a fast decision is
taken: its ordering protocol does not reject a fast decision for a client
request if a quorum of nodes reply with different dependency sets for that
request. The effectiveness of CAESAR is demonstrated through an evaluation
study performed on Amazon's EC2 infrastructure using 5 geo-replicated sites.
CAESAR outperforms other multi-leader (e.g., EPaxos) competitors by as much as
1.7x in the presence of 30% conflicting requests, and single-leader (e.g.,
Multi-Paxos) by up to 3.5x.
</dc:description>
 <dc:description>Comment: To be published in the 47th IEEE/IFIP International Conference on
  Dependable Systems and Networks</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03319</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03324</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gang-GC: Locality-aware Parallel Data Placement Optimizations for
  Key-Value Storages</dc:title>
 <dc:creator>Patr&#xed;cio, Duarte</dc:creator>
 <dc:creator>Sim&#xe3;o, Jos&#xe9;</dc:creator>
 <dc:creator>Veiga, Lu&#xed;s</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Many cloud applications rely on fast and non-relational storage to aid in the
processing of large amounts of data. Managed runtimes are now widely used to
support the execution of several storage solutions of the NoSQL movement,
particularly when dealing with big data key-value store-driven applications.
The benefits of these runtimes can however be limited by modern parallel
throughput-oriented GC algorithms, where related objects have the potential to
be dispersed in memory, either in the same or different generations. In the
long run this causes more page faults and degradation of locality on
system-level memory caches.
  We propose, Gang-CG, an extension to modern heap layouts and to a parallel GC
algorithm to promote locality between groups of related objects. This is done
without extensive profiling of the applications and in a way that is
transparent to the programmer, without the need to use specialized data
structures. The heap layout and algorithmic extensions were implemented over
the Parallel Scavenge garbage collector of the HotSpot JVM\@.
  Using microbenchmarks that capture the architecture of several key-value
stores databases, we show negligible overhead in frequent operations such as
the allocation of new objects and improvements to the access speed of data,
supported by lower misses in system-level memory caches. Overall, we show a 6\%
improvement in the average time of read and update operations and an average
decrease of 12.4\% in page faults.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03324</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03329</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Domain Specific Language for Performance Portable Molecular Dynamics
  Algorithms</dc:title>
 <dc:creator>Saunders, William R.</dc:creator>
 <dc:creator>Grant, James</dc:creator>
 <dc:creator>M&#xfc;ller, Eike H.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>D.1.3, D.2.11, J.2, G.4</dc:subject>
 <dc:description>  Developers of Molecular Dynamics (MD) codes face significant challenges when
adapting existing simulation packages to new hardware. In a continuously
diversifying hardware landscape it becomes increasingly difficult for
scientists to be experts both in their own domain (physics/chemistry/biology)
and specialists in the low level parallelisation and optimisation of their
codes. To address this challenge, we describe a &quot;Separation of Concerns&quot;
approach for the development of parallel and optimised MD codes: the science
specialist writes code at a high abstraction level in a domain specific
language (DSL), which is then translated into efficient computer code by a
scientific programmer. In a related context, an abstraction for the solution of
partial differential equations with grid based methods has recently been
implemented in the (Py)OP2 library. Inspired by this approach, we develop a
Python code generation system for molecular dynamics simulations on different
parallel architectures, including massively parallel distributed memory systems
and GPUs. We demonstrate the efficiency of the auto-generated code by studying
its performance and scalability on different hardware and compare it to other
state-of-the-art simulation packages. With growing data volumes the extraction
of physically meaningful information from the simulation becomes increasingly
challenging and requires equally efficient implementations. A particular
advantage of our approach is the easy expression of such analysis algorithms.
We consider two popular methods for deducing the crystalline structure of a
material from the local environment of each atom, show how they can be
expressed in our abstraction and implement them in the code generation
framework.
</dc:description>
 <dc:description>Comment: 24 pages, 12 figures, 11 tables, accepted for publication in Computer
  Physics Communications on 12 Nov 2017</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03329</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03330</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Food-bridging: a new network construction to unveil the principles of
  cooking</dc:title>
 <dc:creator>Simas, Tiago</dc:creator>
 <dc:creator>Ficek, Michal</dc:creator>
 <dc:creator>Diaz-Guilera, Albert</dc:creator>
 <dc:creator>Obrador, Pere</dc:creator>
 <dc:creator>Rodriguez, Pablo R.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  In this manuscript we propose, analyse, and discuss a possible new principle
behind traditional cuisine: the Food-bridging hypothesis and its comparison
with the food-pairing hypothesis using the same dataset and graphical models
employed in the food-pairing study by Ahn et al. [Scientific Reports, 1:196
(2011)].
  The Food-bridging hypothesis assumes that if two ingredients do not share a
strong molecular or empirical affinity, they may become affine through a chain
of pairwise affinities. That is, in a graphical model as employed by Ahn et
al., a chain represents a path that joints the two ingredients, the shortest
path represents the strongest pairwise chain of affinities between the two
ingredients.
  Food-pairing and Food-bridging are different hypotheses that may describe
possible mechanisms behind the recipes of traditional cuisines. Food-pairing
intensifies flavour by mixing ingredients in a recipe with similar chemical
compounds, and food-bridging smoothes contrast between ingredients. Both
food-pairing and food-bridging are observed in traditional cuisines, as shown
in this work.
  We observed four classes of cuisines according to food-pairing and
food-bridging: (1) East Asian cuisines, at one extreme, tend to avoid
food-pairing as well as food-bridging; and (4) Latin American cuisines, at the
other extreme, follow both principles. For the two middle classes: (2)
Southeastern Asian cuisines, avoid food-pairing and follow food-bridging; and
(3) Western cuisines, follow food-pairing and avoid food-bridging.
</dc:description>
 <dc:date>2017-04-07</dc:date>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03330</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03342</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beliefs and Probability in Bacchus' l.p. Logic: A~3-Valued Logic
  Solution to Apparent Counter-intuition</dc:title>
 <dc:creator>K&#x142;opotek, Mieczys&#x142;aw A.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Fundamental discrepancy between first order logic and statistical inference
(global versus local properties of universe) is shown to be the obstacle for
integration of logic and probability in L.p. logic of Bacchus. To overcome the
counterintuitiveness of L.p. behaviour, a 3-valued logic is proposed.
</dc:description>
 <dc:description>Comment: Draft for the conference M.A. K{\l}opotek: Beliefs and Probability in
  Bacchus' l.p. Logic: A 3-Valued Logic Solution to Apparent Counter-intuition.
  [in:] R. Trappl Ed,: Cybernetics and Systems Research. Proc. 11 European
  Meeting on Cybernetics and System Research EMCSR'92, Wien, Osterreich, 20.
  April 1992. World Scientific Singapore, New Jersey, London, HongKong Vol. 1,
  pp. 519-526</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03342</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03345</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive channel selection for DOA estimation in MIMO radar</dc:title>
 <dc:creator>Mateos-N&#xfa;&#xf1;ez, David</dc:creator>
 <dc:creator>Gonz&#xe1;lez-Huici, Mar&#xed;a A.</dc:creator>
 <dc:creator>Simoni, Renato</dc:creator>
 <dc:creator>Br&#xfc;ggenwirth, Stefan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We present adaptive strategies for antenna selection for Direction of Arrival
(DoA) estimation of a far-field source using TDM MIMO radar with linear arrays.
Our treatment is formulated within a general adaptive sensing framework that
uses one-step ahead predictions of the Bayesian MSE using a parametric family
of Weiss-Weinstein bounds that depend on previous measurements. We compare in
simulations our strategy with adaptive policies that optimize the Bobrovsky-
Zaka{\i} bound and the Expected Cram\'er-Rao bound, and show the performance
for different levels of measurement noise.
</dc:description>
 <dc:description>Comment: Submitted to the 25th European Signal Processing Conference
  (EUSIPCO), 2017</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03354</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimized Data Pre-Processing for Discrimination Prevention</dc:title>
 <dc:creator>Calmon, Flavio P.</dc:creator>
 <dc:creator>Wei, Dennis</dc:creator>
 <dc:creator>Ramamurthy, Karthikeyan Natesan</dc:creator>
 <dc:creator>Varshney, Kush R.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Non-discrimination is a recognized objective in algorithmic decision making.
In this paper, we introduce a novel probabilistic formulation of data
pre-processing for reducing discrimination. We propose a convex optimization
for learning a data transformation with three goals: controlling
discrimination, limiting distortion in individual data samples, and preserving
utility. We characterize the impact of limited sample size in accomplishing
this objective, and apply two instances of the proposed optimization to
datasets, including one on real-world criminal recidivism. The results
demonstrate that all three criteria can be simultaneously achieved and also
reveal interesting patterns of bias in American society.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03354</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03356</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Empirical Study on Android-related Vulnerabilities</dc:title>
 <dc:creator>Linares-Vasquez, Mario</dc:creator>
 <dc:creator>Bavota, Gabriele</dc:creator>
 <dc:creator>Escobar-Velasquez, Camilo</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Mobile devices are used more and more in everyday life. They are our cameras,
wallets, and keys. Basically, they embed most of our private information in our
pocket. For this and other reasons, mobile devices, and in particular the
software that runs on them, are considered first-class citizens in the
software-vulnerabilities landscape. Several studies investigated the
software-vulnerabilities phenomenon in the context of mobile apps and, more in
general, mobile devices. Most of these studies focused on vulnerabilities that
could affect mobile apps, while just few investigated vulnerabilities affecting
the underlying platform on which mobile apps run: the Operating System (OS).
Also, these studies have been run on a very limited set of vulnerabilities.
  In this paper we present the largest study at date investigating
Android-related vulnerabilities, with a specific focus on the ones affecting
the Android OS. In particular, we (i) define a detailed taxonomy of the types
of Android-related vulnerability; (ii) investigate the layers and subsystems
from the Android OS affected by vulnerabilities; and (iii) study the
survivability of vulnerabilities (i.e., the number of days between the
vulnerability introduction and its fixing). Our findings could help OS and apps
developers in focusing their verification &amp; validation activities, and
researchers in building vulnerability detection tools tailored for the mobile
world.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03356</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03361</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Societal impacts of big data: challenges and opportunities in Europe</dc:title>
 <dc:creator>Cuquet, Mart&#xed;</dc:creator>
 <dc:creator>Vega-Gorgojo, Guillermo</dc:creator>
 <dc:creator>Lammerant, Hans</dc:creator>
 <dc:creator>Finn, Rachel</dc:creator>
 <dc:creator>Hassan, Umair ul</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  This paper presents the risks and opportunities of big data and the potential
social benefits it can bring. The research is based on an analysis of the
societal impacts observed in a set of six case studies across different
European sectors. These impacts are divided into economic, social and ethical,
legal and political impacts, and affect areas such as improved efficiency,
innovation and decision making, changing business models, dependency on public
funding, participation, equality, discrimination and trust, data protection and
intellectual property rights, private and public tensions and losing control to
actors abroad. A special focus is given to the risks and opportunities coming
from the legal framework and how to counter the negative impacts of big data.
Recommendations are presented for four specific legal frameworks: copyright and
database protection, protection of trade secrets, privacy and data protection
and anti-discrimination. In addition, the potential social benefits of big data
are exemplified in six domains: improved decision making and event detection;
data-driven innovations and new business models; direct social, environmental
and other citizen benefits; citizen participation, transparency and public
trust; privacy-aware data practices; and big data for identifying
discrimination. Several best practices are suggested to capture these benefits.
</dc:description>
 <dc:description>Comment: 17 pages, 2 figures, 1 table</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03361</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03371</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sublinear Time Low-Rank Approximation of Positive Semidefinite Matrices</dc:title>
 <dc:creator>Musco, Cameron</dc:creator>
 <dc:creator>Woodruff, David P.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We show how to compute a relative-error low-rank approximation to any
positive semidefinite (PSD) matrix in sublinear time, i.e., for any $n \times
n$ PSD matrix $A$, in $\tilde O(n \cdot poly(k/\epsilon))$ time we output a
rank-$k$ matrix $B$, in factored form, for which $\|A-B\|_F^2 \leq
(1+\epsilon)\|A-A_k\|_F^2$, where $A_k$ is the best rank-$k$ approximation to
$A$. When $k$ and $1/\epsilon$ are not too large compared to the sparsity of
$A$, our algorithm does not need to read all entries of the matrix. Hence, we
significantly improve upon previous $nnz(A)$ time algorithms based on oblivious
subspace embeddings, and bypass an $nnz(A)$ time lower bound for general
matrices (where $nnz(A)$ denotes the number of non-zero entries in the matrix).
We prove time lower bounds for low-rank approximation of PSD matrices, showing
that our algorithm is close to optimal. Finally, we extend our techniques to
give sublinear time algorithms for low-rank approximation of $A$ in the (often
stronger) spectral norm metric $\|A-B\|_2^2$ and for ridge regression on PSD
matrices.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03371</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03373</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quality Aware Network for Set to Set Recognition</dc:title>
 <dc:creator>Liu, Yu</dc:creator>
 <dc:creator>Yan, Junjie</dc:creator>
 <dc:creator>Ouyang, Wanli</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper targets on the problem of set to set recognition, which learns the
metric between two image sets. Images in each set belong to the same identity.
Since images in a set can be complementary, they hopefully lead to higher
accuracy in practical applications. However, the quality of each sample cannot
be guaranteed, and samples with poor quality will hurt the metric. In this
paper, the quality aware network (QAN) is proposed to confront this problem,
where the quality of each sample can be automatically learned although such
information is not explicitly provided in the training stage. The network has
two branches, where the first branch extracts appearance feature embedding for
each sample and the other branch predicts quality score for each sample.
Features and quality scores of all samples in a set are then aggregated to
generate the final feature embedding. We show that the two branches can be
trained in an end-to-end manner given only the set-level identity annotation.
Analysis on gradient spread of this mechanism indicates that the quality
learned by the network is beneficial to set-to-set recognition and simplifies
the distribution that the network needs to fit. Experiments on both face
verification and person re-identification show advantages of the proposed QAN.
The source code and network structure can be downloaded at
https://github.com/sciencefans/Quality-Aware-Network.
</dc:description>
 <dc:description>Comment: Accepted at CVPR 2017</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03373</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03375</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reconstruction of~3-D Rigid Smooth Curves Moving Free when Two Traceable
  Points Only are Available</dc:title>
 <dc:creator>K&#x142;opotek, Mieczys&#x142;aw A.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  This paper extends previous research in that sense that for orthogonal
projections of rigid smooth (true-3D) curves moving totally free it reduces the
number of required traceable points to two only (the best results known so far
to the author are 3 points from free motion and 2 for motion restricted to
rotation around a fixed direction and and 2 for motion restricted to influence
of a homogeneous force field). The method used is exploitation of information
on tangential projections. It discusses also possibility of simplification of
reconstruction of flat curves moving free for prospective projections.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03375</dc:identifier>
 <dc:identifier>Preliminaru version of the paper M.A. K{\l}opotek: Reconstruction
  of 3-D rigid smooth curves moving free when two traceable points only are
  available. Machine Graphics \&amp; Vision 1(1992)1-2, pp. 392-405</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03379</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning for Multi-Task Medical Image Segmentation in Multiple
  Modalities</dc:title>
 <dc:creator>Moeskops, Pim</dc:creator>
 <dc:creator>Wolterink, Jelmer M.</dc:creator>
 <dc:creator>van der Velden, Bas H. M.</dc:creator>
 <dc:creator>Gilhuijs, Kenneth G. A.</dc:creator>
 <dc:creator>Leiner, Tim</dc:creator>
 <dc:creator>Viergever, Max A.</dc:creator>
 <dc:creator>I&#x161;gum, Ivana</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automatic segmentation of medical images is an important task for many
clinical applications. In practice, a wide range of anatomical structures are
visualised using different imaging modalities. In this paper, we investigate
whether a single convolutional neural network (CNN) can be trained to perform
different segmentation tasks.
  A single CNN is trained to segment six tissues in MR brain images, the
pectoral muscle in MR breast images, and the coronary arteries in cardiac CTA.
The CNN therefore learns to identify the imaging modality, the visualised
anatomical structures, and the tissue classes.
  For each of the three tasks (brain MRI, breast MRI and cardiac CTA), this
combined training procedure resulted in a segmentation performance equivalent
to that of a CNN trained specifically for that task, demonstrating the high
capacity of CNN architectures. Hence, a single system could be used in clinical
practice to automatically perform diverse segmentation tasks without
task-specific training.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03379</dc:identifier>
 <dc:identifier>Moeskops, P., Wolterink, J.M., van der Velden, B.H.M., Gilhuijs,
  K.G.A., Leiner, T., Viergever, M.A., I\v{s}gum, I. Deep learning for
  multi-task medical image segmentation in multiple modalities. In: MICCAI
  2016, pp. 478-486</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-46723-8_55</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03383</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Portable, high-performance containers for HPC</dc:title>
 <dc:creator>Benedicic, Lucas</dc:creator>
 <dc:creator>Cruz, Felipe A.</dc:creator>
 <dc:creator>Madonna, Alberto</dc:creator>
 <dc:creator>Mariotti, Kean</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Building and deploying software on high-end computing systems is a
challenging task. High performance applications have to reliably run across
multiple platforms and environments, and make use of site-specific resources
while resolving complicated software-stack dependencies. Containers are a type
of lightweight virtualization technology that attempt to solve this problem by
packaging applications and their environments into standard units of software
that are: portable, easy to build and deploy, have a small footprint, and low
runtime overhead. In this work we present an extension to the container runtime
of Shifter that provides containerized applications with a mechanism to access
GPU accelerators and specialized networking from the host system, effectively
enabling performance portability of containers across HPC resources. The
presented extension makes possible to rapidly deploy high-performance software
on supercomputers from containerized applications that have been developed,
built, and tested in non-HPC commodity hardware, e.g. the laptop or workstation
of a researcher.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03387</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhancement of Physical Layer Security Using Destination Artificial
  Noise Based on Outage Probability</dc:title>
 <dc:creator>Rahmanpour, Ali</dc:creator>
 <dc:creator>Vakili, Vahid T.</dc:creator>
 <dc:creator>Razavizadeh, S. Mohammad</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this paper, we study using Destination Artificial Noise (DAN) besides
Source Artificial Noise (SAN) to enhance physical layer secrecy with an outage
probability based approach. It is assumed that all nodes in the network (i.e.
source, destination and eavesdropper) are equipped with multiple antennas. In
addition, the eavesdropper is passive and its channel state and location are
unknown at the source and destination. In our proposed scheme, by optimized
allocation of power to the SAN, DAN and data signal, a minimum value for the
outage probability is guaranteed at the eavesdropper, and at the same time a
certain level of signal to noise ratio (SNR) at the destination is ensured. Our
simulation results show that using DAN along with SAN brings a significant
enhancement in power consumption compared to methods that merely adopt SAN to
achieve the same outage probability at the eavesdropper.
</dc:description>
 <dc:description>Comment: Accepted for publication in Wireless Personal Communications
  (Springer)</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03387</dc:identifier>
 <dc:identifier>doi:10.1007/s11277-016-3865-9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03391</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Testing a Saturation-Based Theorem Prover: Experiences and Challenges
  (Extended Version)</dc:title>
 <dc:creator>Reger, Giles</dc:creator>
 <dc:creator>Suda, Martin</dc:creator>
 <dc:creator>Voronkov, Andrei</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  This paper attempts to address the question of how best to assure the
correctness of saturation-based automated theorem provers using our experience
developing the theorem prover Vampire. We describe the techniques we currently
employ to ensure that Vampire is correct and use this to motivate future
challenges that need to be addressed to make this process more straightforward
and to achieve better correctness guarantees.
</dc:description>
 <dc:description>Comment: 13 pages, 1 figure</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03391</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03394</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Achieving High Coverage for Floating-point Code via Unconstrained
  Programming (Extended Version)</dc:title>
 <dc:creator>Fu, Zhoulai</dc:creator>
 <dc:creator>Su, Zhendong</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Achieving high code coverage is essential in testing, which gives us
confidence in code quality. Testing floating-point code usually requires
painstaking efforts in handling floating-point constraints, e.g., in symbolic
execution. This paper turns the challenge of testing floating-point code into
the opportunity of applying unconstrained programming --- the mathematical
solution for calculating function minimum points over the entire search space.
Our core insight is to derive a representing function from the floating-point
program, any of whose minimum points is a test input guaranteed to exercise a
new branch of the tested program. This guarantee allows us to achieve high
coverage of the floating-point program by repeatedly minimizing the
representing function.
  We have realized this approach in a tool called CoverMe and conducted an
extensive evaluation of it on Sun's C math library. Our evaluation results show
that CoverMe achieves, on average, 90.8% branch coverage in 6.9 seconds,
drastically outperforming our compared tools: (1) Random testing, (2) AFL, a
highly optimized, robust fuzzer released by Google, and (3) Austin, a
state-of-the-art coverage-based testing tool designed to support floating-point
code.
</dc:description>
 <dc:description>Comment: Extended version of Fu and Su's PLDI'17 paper. arXiv admin note: text
  overlap with arXiv:1610.01133</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03394</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03396</identifier>
 <datestamp>2017-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Source-Sensitive Belief Change</dc:title>
 <dc:creator>Ebrahimi, Shahab</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The AGM model is the most remarkable framework for modeling belief revision.
However, it is not perfect in all aspects. Paraconsistent belief revision,
multi-agent belief revision and non-prioritized belief revision are three
different extensions to AGM to address three important criticisms applied to
it. In this article, we propose a framework based on AGM that takes a position
in each of these categories. Also, we discuss some features of our framework
and study the satisfiability of AGM postulates in this new context.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-05-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03396</dc:identifier>
 <dc:identifier>International Journal of Artificial Intelligence and Applications
  (IJAIA), Vol.8, No.2, March 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03397</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Debugging Behaviour of Embedded-Software Developers: An Exploratory
  Study</dc:title>
 <dc:creator>Arafa, Pansy</dc:creator>
 <dc:creator>Solomon, Daniel</dc:creator>
 <dc:creator>Navabpour, Samaneh</dc:creator>
 <dc:creator>Fischmeister, Sebastian</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Many researchers have studied the behaviour of successful developers while
debugging desktop software. In this paper, we investigate the embedded-software
debugging by intermediate programmers through an exploratory study. The bugs
are semantic low-level errors, and the participants are students who completed
a real-time operating systems course in addition to five other programming
courses. We compare between the behaviour involved in successful debugging
attempts versus unsuccessful ones. We describe some characteristics of smooth
and successful debugging behaviour.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03397</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03402</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Next Generation Business Intelligence and Analytics: A Survey</dc:title>
 <dc:creator>Vo, Quoc Duy</dc:creator>
 <dc:creator>Thomas, Jaya</dc:creator>
 <dc:creator>Cho, Shinyoung</dc:creator>
 <dc:creator>De, Pradipta</dc:creator>
 <dc:creator>Choi, Bong Jun</dc:creator>
 <dc:creator>Sael, Lee</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Business Intelligence and Analytics (BI&amp;A) is the process of extracting and
predicting business-critical insights from data. Traditional BI focused on data
collection, extraction, and organization to enable efficient query processing
for deriving insights from historical data. With the rise of big data and cloud
computing, there are many challenges and opportunities for the BI. Especially
with the growing number of data sources, traditional BI\&amp;A are evolving to
provide intelligence at different scales and perspectives - operational BI,
situational BI, self-service BI. In this survey, we review the evolution of
business intelligence systems in full scale from back-end architecture to and
front-end applications. We focus on the changes in the back-end architecture
that deals with the collection and organization of the data. We also review the
changes in the front-end applications, where analytic services and
visualization are the core components. Using a uses case from BI in Healthcare,
which is one of the most complex enterprises, we show how BI\&amp;A will play an
important role beyond the traditional usage. The survey provides a holistic
view of Business Intelligence and Analytics for anyone interested in getting a
complete picture of the different pieces in the emerging next generation BI\&amp;A
solutions.
</dc:description>
 <dc:description>Comment: 11 pages, 4 figures</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03402</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03404</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ENWalk: Learning Network Features for Spam Detection in Twitter</dc:title>
 <dc:creator>Santosh, K C</dc:creator>
 <dc:creator>Maity, Suman Kalyan</dc:creator>
 <dc:creator>Mukherjee, Arjun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Social medias are increasing their influence with the vast public information
leading to their active use for marketing by the companies and organizations.
Such marketing promotions are difficult to identify unlike the traditional
medias like TV and newspaper. So, it is very much important to identify the
promoters in the social media. Although, there are active ongoing researches,
existing approaches are far from solving the problem. To identify such
imposters, it is very much important to understand their strategies of social
circle creation and dynamics of content posting. Are there any specific spammer
types? How successful are each types? We analyze these questions in the light
of social relationships in Twitter. Our analyses discover two types of spammers
and their relationships with the dynamics of content posts. Our results
discover novel dynamics of spamming which are intuitive and arguable. We
propose ENWalk, a framework to detect the spammers by learning the feature
representations of the users in the social media. We learn the feature
representations using the random walks biased on the spam dynamics.
Experimental results on large-scale twitter network and the corresponding
tweets show the effectiveness of our approach that outperforms the existing
approaches
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03404</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03407</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What we really want to find by Sentiment Analysis: The Relationship
  between Computational Models and Psychological State</dc:title>
 <dc:creator>Jo, Hwiyeol</dc:creator>
 <dc:creator>Kim, Soo-Min</dc:creator>
 <dc:creator>Ryu, Jeong</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  As the first step to model emotional state of a person, we build sentiment
analysis models with existing deep neural network algorithms and compare the
models with psychological measurements to enlighten the relationship. In the
experiments, we first examined psychological state of 64 participants and asked
them to summarize the story of a book, Chronicle of a Death Foretold (Marquez,
1981). Secondly, we trained models using crawled 365,802 movie review data;
then we evaluated participants' summaries using the pretrained model as a
concept of transfer learning. With the background that emotion affects on
memories, we investigated the relationship between the evaluation score of the
summaries from computational models and the examined psychological
measurements. The result shows that although CNN performed the best among other
deep neural network algorithms (LSTM, GRU), its results are not related to the
psychological state. Rather, GRU shows more explainable results depending on
the psychological state. The contribution of this paper can be summarized as
follows: (1) we enlighten the relationship between computational models and
psychological measurements. (2) we suggest this framework as objective methods
to evaluate the emotion; the real sentiment analysis of a person.
</dc:description>
 <dc:description>Comment: Rejected Paper in CogSci2017. I'm sure there is no place for
  integrated research. arXiv admin note: text overlap with arXiv:1607.03707</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03407</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03414</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A-Fast-RCNN: Hard Positive Generation via Adversary for Object Detection</dc:title>
 <dc:creator>Wang, Xiaolong</dc:creator>
 <dc:creator>Shrivastava, Abhinav</dc:creator>
 <dc:creator>Gupta, Abhinav</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  How do we learn an object detector that is invariant to occlusions and
deformations? Our current solution is to use a data-driven strategy -- collect
large-scale datasets which have object instances under different conditions.
The hope is that the final classifier can use these examples to learn
invariances. But is it really possible to see all the occlusions in a dataset?
We argue that like categories, occlusions and object deformations also follow a
long-tail. Some occlusions and deformations are so rare that they hardly
happen; yet we want to learn a model invariant to such occurrences. In this
paper, we propose an alternative solution. We propose to learn an adversarial
network that generates examples with occlusions and deformations. The goal of
the adversary is to generate examples that are difficult for the object
detector to classify. In our framework both the original detector and adversary
are learned in a joint manner. Our experimental results indicate a 2.3% mAP
boost on VOC07 and a 2.6% mAP boost on VOC2012 object detection challenge
compared to the Fast-RCNN pipeline. We also release the code for this paper.
</dc:description>
 <dc:description>Comment: CVPR 2017 Camera Ready</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03414</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03421</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Large Scale Clustering based on data partitioning</dc:title>
 <dc:creator>Bendechache, Malika</dc:creator>
 <dc:creator>Le-Khac, Nhien-An</dc:creator>
 <dc:creator>Kechadi, M-Tahar</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Clustering techniques are very attractive for extracting and identifying
patterns in datasets. However, their application to very large spatial datasets
presents numerous challenges such as high-dimensionality data, heterogeneity,
and high complexity of some algorithms. For instance, some algorithms may have
linear complexity but they require the domain knowledge in order to determine
their input parameters. Distributed clustering techniques constitute a very
good alternative to the big data challenges (e.g.,Volume, Variety, Veracity,
and Velocity). Usually these techniques consist of two phases. The first phase
generates local models or patterns and the second one tends to aggregate the
local results to obtain global models. While the first phase can be executed in
parallel on each site and, therefore, efficient, the aggregation phase is
complex, time consuming and may produce incorrect and ambiguous global clusters
and therefore incorrect models. In this paper we propose a new distributed
clustering approach to deal efficiently with both phases; generation of local
results and generation of global models by aggregation. For the first phase,
our approach is capable of analysing the datasets located in each site using
different clustering techniques. The aggregation phase is designed in such a
way that the final clusters are compact and accurate while the overall process
is efficient in time and memory allocation. For the evaluation, we use two
well-known clustering algorithms; K-Means and DBSCAN. One of the key outputs of
this distributed clustering technique is that the number of global clusters is
dynamic; no need to be fixed in advance. Experimental results show that the
approach is scalable and produces high quality results.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03421</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03432</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Forecasting Human Dynamics from Static Images</dc:title>
 <dc:creator>Chao, Yu-Wei</dc:creator>
 <dc:creator>Yang, Jimei</dc:creator>
 <dc:creator>Price, Brian</dc:creator>
 <dc:creator>Cohen, Scott</dc:creator>
 <dc:creator>Deng, Jia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents the first study on forecasting human dynamics from static
images. The problem is to input a single RGB image and generate a sequence of
upcoming human body poses in 3D. To address the problem, we propose the 3D Pose
Forecasting Network (3D-PFNet). Our 3D-PFNet integrates recent advances on
single-image human pose estimation and sequence prediction, and converts the 2D
predictions into 3D space. We train our 3D-PFNet using a three-step training
strategy to leverage a diverse source of training data, including image and
video based human pose datasets and 3D motion capture (MoCap) data. We
demonstrate competitive performance of our 3D-PFNet on 2D pose forecasting and
3D pose recovery through quantitative and qualitative results.
</dc:description>
 <dc:description>Comment: Accepted in CVPR 2017</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03432</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03441</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Node-centric community detection in multilayer networks with
  layer-coverage diversification bias</dc:title>
 <dc:creator>Interdonato, Roberto</dc:creator>
 <dc:creator>Tagarelli, Andrea</dc:creator>
 <dc:creator>Ienco, Dino</dc:creator>
 <dc:creator>Sallaberry, Arnaud</dc:creator>
 <dc:creator>Poncelet, Pascal</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The problem of node-centric, or local, community detection in information
networks refers to the identification of a community for a given input node,
having limited information about the network topology. Existing methods for
solving this problem, however, are not conceived to work on complex networks.
In this paper, we propose a novel framework for local community detection based
on the multilayer network model. Our approach relies on the maximization of the
ratio between the community internal connection density and the external
connection density, according to multilayer similarity-based community
relations. We also define a biasing scheme that allows the discovery of local
communities characterized by different degrees of layer-coverage
diversification. Experimental evaluation conducted on real-world multilayer
networks has shown the significance of our approach.
</dc:description>
 <dc:description>Comment: Accepted at 8th International Conference on Complex Networks
  (CompleNet'17)</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03441</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03443</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving the L1 regularized least square problem via a box-constrained
  smooth minimization</dc:title>
 <dc:creator>Mohammadi, Majid</dc:creator>
 <dc:creator>Hofman, Wout</dc:creator>
 <dc:creator>Tan, Yaohua</dc:creator>
 <dc:creator>Mousavi, S. Hamid</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, an equivalent smooth minimization for the L1 regularized least
square problem is proposed. The proposed problem is a convex box-constrained
smooth minimization which allows applying fast optimization methods to find its
solution. Further, it is investigated that the property &quot;the dual of dual is
primal&quot; holds for the L1 regularized least square problem. A solver for the
smooth problem is proposed, and its affinity to the proximal gradient is shown.
Finally, the experiments on L1 and total variation regularized problems are
performed, and the corresponding results are reported.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03443</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03446</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Directivity-Beamwidth Tradeoff of Massive MIMO Uplink Beamforming for
  High Speed Train Communication</dc:title>
 <dc:creator>Chen, Xuhong</dc:creator>
 <dc:creator>Lu, Jiaxun</dc:creator>
 <dc:creator>Li, Tao</dc:creator>
 <dc:creator>Fan, Pingyi</dc:creator>
 <dc:creator>Letaief, Khaled Ben</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  High-mobility adaption and massive Multiple-input Multiple-output (MIMO)
application are two primary evolving objectives for the next generation high
speed train (HST) wireless communication system. In this paper, we consider how
to design a location-aware beamforming for the massive MIMO system in the high
traffic density HST network. We first analyze the tradeoff between beam
directivity and beamwidth, based on which we present the sensitivity analysis
of positioning accuracy. Then, in order to guarantee a high efficient
transmission, we derive an optimal problem to maximize the beam directivity
under the restriction of diverse positioning accuracies. After that, we present
a low-complexity beamforming design by utilizing location information, which
requires neither eigen-decomposing (ED) the uplink channel covariance matrix
(CCM) nor ED the downlink CCM (DCCM). Finally, we study the beamforming scheme
in future high traffic density HST network, where a two HSTs encountering
scenario is emphasized. By utilizing the real-time location information, we
propose an optimal adaptive beamforming scheme to maximize the achievable rate
region under limited channel source constraint. Numerical simulation indicates
that a massive MIMO system with less than a certain positioning error can
guarantee a required performance with satisfying transmission efficiency in the
high traffic density HST scenario and the achievable rate region when two HSTs
encounter is greatly improved as well.
</dc:description>
 <dc:description>Comment: This paper has been accepted for future publication in IEEE ACCESS.
  arXiv admin note: substantial text overlap with arXiv:1702.02121</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03446</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03452</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bespoke Forensics GIS Tool</dc:title>
 <dc:creator>Tillekens, Almar</dc:creator>
 <dc:creator>Le-Khac, Nhien-An</dc:creator>
 <dc:creator>Pham-Thi, Thanh-Thoa</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Today a lot of digital evidences for crime investigation includes a
geospatial component. This data comes from various sources such as smartphones,
tablets, navigation systems, digital camera with global positioning system
(GPS), etc. The geospatial data plays a crucial role in crime investigation
such as helping to tracking suspects, profiling serial offenders, recognizing
trends in criminal activities, just a few. Many techniques and Geographic
Information Systems (GIS) tools have been used to extract, analyse and
visualise geospatial data. However, in some specific circumstances, the
existing tools are not suitable for use as they do not meet investigators
needs. This paper presents a bespoke forensic GIS tool based on specific
requirements of the investigators of a law enforcement Department. Firstly the
paper discusses some existing forensic GIS tools and environments in practices,
and then it presents some investigators requirements and show the unsuitability
of the existing tools. The paper continues with the presentation of the system
architecture of the new tool and its components. It also introduces various
applications and use cases which have been deploying at the Department as an
evaluation of the developed tool.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03452</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03453</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Space of Transferable Adversarial Examples</dc:title>
 <dc:creator>Tram&#xe8;r, Florian</dc:creator>
 <dc:creator>Papernot, Nicolas</dc:creator>
 <dc:creator>Goodfellow, Ian</dc:creator>
 <dc:creator>Boneh, Dan</dc:creator>
 <dc:creator>McDaniel, Patrick</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Adversarial examples are maliciously perturbed inputs designed to mislead
machine learning (ML) models at test-time. They often transfer: the same
adversarial example fools more than one model.
  In this work, we propose novel methods for estimating the previously unknown
dimensionality of the space of adversarial inputs. We find that adversarial
examples span a contiguous subspace of large (~25) dimensionality. Adversarial
subspaces with higher dimensionality are more likely to intersect. We find that
for two different models, a significant fraction of their subspaces is shared,
thus enabling transferability.
  In the first quantitative analysis of the similarity of different models'
decision boundaries, we show that these boundaries are actually close in
arbitrary directions, whether adversarial or benign. We conclude by formally
studying the limits of transferability. We derive (1) sufficient conditions on
the data distribution that imply transferability for simple model classes and
(2) examples of scenarios in which transfer does not occur. These findings
indicate that it may be possible to design defenses against transfer-based
attacks, even for models that are vulnerable to direct attacks.
</dc:description>
 <dc:description>Comment: 15 pages, 7 figures</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03453</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03458</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Personalized Survival Predictions for Cardiac Transplantation via Trees
  of Predictors</dc:title>
 <dc:creator>Yoon, J.</dc:creator>
 <dc:creator>Zame, W. R.</dc:creator>
 <dc:creator>Banerjee, A.</dc:creator>
 <dc:creator>Cadeiras, M.</dc:creator>
 <dc:creator>Alaa, A. M.</dc:creator>
 <dc:creator>van der Schaar, M.</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Given the limited pool of donor organs, accurate predictions of survival on
the wait list and post transplantation are crucial for cardiac transplantation
decisions and policy. However, current clinical risk scores do not yield
accurate predictions. We develop a new methodology (ToPs, Trees of Predictors)
built on the principle that specific predictors should be used for specific
clusters within the target population. ToPs discovers these specific clusters
of patients and the specific predictor that perform best for each cluster. In
comparison with current clinical risk scoring systems, our method provides
significant improvements in the prediction of survival time on the wait list
and post transplantation. For example, in terms of 3 month survival for
patients who were on the US patient wait list in the period 1985 to 2015, our
method achieves AUC of 0.847, the best commonly used clinical risk score
(MAGGIC) achieves 0.630. In terms of 3 month survival/mortality predictions (in
comparison to MAGGIC), holding specificity at 80.0 percents, our algorithm
correctly predicts survival for 1,228 (26.0 percents more patients out of 4,723
who actually survived, holding sensitivity at 80.0 percents, our algorithm
correctly predicts mortality for 839 (33.0 percents) more patients out of 2,542
who did not survive. Our method achieves similar improvements for other time
horizons and for predictions post transplantation. Therefore, we offer a more
accurate, personalized approach to survival analysis that can benefit patients,
clinicians and policymakers in making clinical decisions and setting clinical
policy. Because risk prediction is widely used in diagnostic and prognostic
clinical decision making across diseases and clinical specialties, the
implications of our methods are far reaching.
</dc:description>
 <dc:description>Comment: Main manuscript: 20 pages, Supplementary materials: 13 pages, 5
  figures, 3 tables. Submitted to Science Translational Medicine</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03458</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03470</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Two-Branch Neural Networks for Image-Text Matching Tasks</dc:title>
 <dc:creator>Wang, Liwei</dc:creator>
 <dc:creator>Li, Yin</dc:creator>
 <dc:creator>Huang, Jing</dc:creator>
 <dc:creator>Lazebnik, Svetlana</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image-language matching tasks have recently attracted a lot of attention in
the computer vision field. These tasks include image-sentence matching, i.e.,
given an image query, retrieving relevant sentences and vice versa, and
region-phrase matching or visual grounding, i.e., matching a phrase to relevant
regions. This paper investigates two-branch neural networks for learning the
similarity between these two data modalities. We propose two network structures
that produce different output representations. The first one, referred to as an
embedding network, learns an explicit shared latent embedding space with a
maximum-margin ranking loss and novel neighborhood constraints. Compared to
standard triplet sampling, we perform improved neighborhood sampling that takes
neighborhood information into consideration while constructing mini-batches.
The second network structure, referred to as a similarity network, fuses the
two branches via element-wise product and is trained with regression loss to
directly predict a similarity score. Extensive experiments show that our
networks achieve high accuracies for phrase localization on the Flickr30K
Entities dataset and for bi-directional image-sentence retrieval on Flickr30K
and MSCOCO datasets.
</dc:description>
 <dc:description>Comment: in submission for TPAMI</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03470</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03471</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What do Neural Machine Translation Models Learn about Morphology?</dc:title>
 <dc:creator>Belinkov, Yonatan</dc:creator>
 <dc:creator>Durrani, Nadir</dc:creator>
 <dc:creator>Dalvi, Fahim</dc:creator>
 <dc:creator>Sajjad, Hassan</dc:creator>
 <dc:creator>Glass, James</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Neural machine translation (MT) models obtain state-of-the-art performance
while maintaining a simple, end-to-end architecture. However, little is known
about what these models learn about source and target languages during the
training process. In this work, we analyze the representations learned by
neural MT models at various levels of granularity and empirically evaluate the
quality of the representations for learning morphology through extrinsic
part-of-speech and morphological tagging tasks. We conduct a thorough
investigation along several parameters: word-based vs. character-based
representations, depth of the encoding layer, the identity of the target
language, and encoder vs. decoder representations. Our data-driven,
quantitative evaluation sheds light on important aspects in the neural MT
system and its ability to capture word structure.
</dc:description>
 <dc:description>Comment: ACL 2017 camera-ready</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03471</dc:identifier>
 <dc:identifier>ACL 55 (2017), volume 1, 861-872</dc:identifier>
 <dc:identifier>doi:10.18653/v1/P17-1080</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03477</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Neural Representation of Sketch Drawings</dc:title>
 <dc:creator>Ha, David</dc:creator>
 <dc:creator>Eck, Douglas</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present sketch-rnn, a recurrent neural network (RNN) able to construct
stroke-based drawings of common objects. The model is trained on thousands of
crude human-drawn images representing hundreds of classes. We outline a
framework for conditional and unconditional sketch generation, and describe new
robust training methods for generating coherent sketch drawings in a vector
format.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03477</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03486</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simply Exponential Approximation of the Permanent of Positive
  Semidefinite Matrices</dc:title>
 <dc:creator>Anari, Nima</dc:creator>
 <dc:creator>Gurvits, Leonid</dc:creator>
 <dc:creator>Gharan, Shayan Oveis</dc:creator>
 <dc:creator>Saberi, Amin</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  We design a deterministic polynomial time $c^n$ approximation algorithm for
the permanent of positive semidefinite matrices where $c=e^{\gamma+1}\simeq
4.84$. We write a natural convex relaxation and show that its optimum solution
gives a $c^n$ approximation of the permanent. We further show that this factor
is asymptotically tight by constructing a family of positive semidefinite
matrices.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03486</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03488</identifier>
 <datestamp>2017-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Proximal Operators: Using Denoising Networks for Regularizing
  Inverse Imaging Problems</dc:title>
 <dc:creator>Meinhardt, Tim</dc:creator>
 <dc:creator>Moeller, Michael</dc:creator>
 <dc:creator>Hazirbas, Caner</dc:creator>
 <dc:creator>Cremers, Daniel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  While variational methods have been among the most powerful tools for solving
linear inverse problems in imaging, deep (convolutional) neural networks have
recently taken the lead in many challenging benchmarks. A remaining drawback of
deep learning approaches is their requirement for an expensive retraining
whenever the specific problem, the noise level, noise type, or desired measure
of fidelity changes. On the contrary, variational methods have a plug-and-play
nature as they usually consist of separate data fidelity and regularization
terms.
  In this paper we study the possibility of replacing the proximal operator of
the regularization used in many convex energy minimization algorithms by a
denoising neural network. The latter therefore serves as an implicit natural
image prior, while the data term can still be chosen independently. Using a
fixed denoising neural network in exemplary problems of image deconvolution
with different blur kernels and image demosaicking, we obtain state-of-the-art
reconstruction results. These indicate the high generalizability of our
approach and a reduction of the need for problem-specific training.
Additionally, we discuss novel results on the analysis of possible optimization
algorithms to incorporate the network into, as well as the choices of algorithm
parameters and their relation to the noise level the neural network is trained
on.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03488</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03489</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CNN-SLAM: Real-time dense monocular SLAM with learned depth prediction</dc:title>
 <dc:creator>Tateno, Keisuke</dc:creator>
 <dc:creator>Tombari, Federico</dc:creator>
 <dc:creator>Laina, Iro</dc:creator>
 <dc:creator>Navab, Nassir</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Given the recent advances in depth prediction from Convolutional Neural
Networks (CNNs), this paper investigates how predicted depth maps from a deep
neural network can be deployed for accurate and dense monocular reconstruction.
We propose a method where CNN-predicted dense depth maps are naturally fused
together with depth measurements obtained from direct monocular SLAM. Our
fusion scheme privileges depth prediction in image locations where monocular
SLAM approaches tend to fail, e.g. along low-textured regions, and vice-versa.
We demonstrate the use of depth prediction for estimating the absolute scale of
the reconstruction, hence overcoming one of the major limitations of monocular
SLAM. Finally, we propose a framework to efficiently fuse semantic labels,
obtained from a single frame, with dense SLAM, yielding semantically coherent
scene reconstruction from a single view. Evaluation results on two benchmark
datasets show the robustness and accuracy of our approach.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures, IEEE Computer Society Conference on Computer
  Vision and Pattern Recognition (CVPR), Hawaii, USA, June, 2017. The first two
  authors contribute equally to this paper</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03489</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03493</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Creativity: Generating Diverse Questions using Variational Autoencoders</dc:title>
 <dc:creator>Jain, Unnat</dc:creator>
 <dc:creator>Zhang, Ziyu</dc:creator>
 <dc:creator>Schwing, Alexander</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Generating diverse questions for given images is an important task for
computational education, entertainment and AI assistants. Different from many
conventional prediction techniques is the need for algorithms to generate a
diverse set of plausible questions, which we refer to as &quot;creativity&quot;. In this
paper we propose a creative algorithm for visual question generation which
combines the advantages of variational autoencoders with long short-term memory
networks. We demonstrate that our framework is able to generate a large set of
varying questions given a single input image.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2017</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03493</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03503</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>UC Merced Submission to the ActivityNet Challenge 2016</dc:title>
 <dc:creator>Zhu, Yi</dc:creator>
 <dc:creator>Newsam, Shawn</dc:creator>
 <dc:creator>Xu, Zaikun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  This notebook paper describes our system for the untrimmed classification
task in the ActivityNet challenge 2016. We investigate multiple
state-of-the-art approaches for action recognition in long, untrimmed videos.
We exploit hand-crafted motion boundary histogram features as well feature
activations from deep networks such as VGG16, GoogLeNet, and C3D. These
features are separately fed to linear, one-versus-rest support vector machine
classifiers to produce confidence scores for each action class. These
predictions are then fused along with the softmax scores of the recent
ultra-deep ResNet-101 using weighted averaging.
</dc:description>
 <dc:description>Comment: Notebook paper for ActivityNet 2016 challenge, untrimmed video
  classification track</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03503</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03507</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Learning of Parsimonious General-Purpose Embeddings for
  User and Location Modelling</dc:title>
 <dc:creator>Yang, Jing</dc:creator>
 <dc:creator>Eickhoff, Carsten</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Many social network applications depend on robust representations of
spatio-temporal data. In this work, we present an embedding model based on
feed-forward neural networks which transforms social media check-ins into dense
feature vectors encoding geographic, temporal, and functional aspects for
modelling places, neighborhoods, and users. We employ the embedding model in a
variety of applications including location recommendation, urban functional
zone study, and crime prediction. For location recommendation, we propose a
Spatio-Temporal Embedding Similarity algorithm (STES) based on the embedding
model.
  In a range of experiments on real life data collected from Foursquare, we
demonstrate our model's effectiveness at characterizing places and people and
its applicability in aforementioned problem domains. Finally, we select eight
major cities around the globe and verify the robustness and generality of our
model by porting pre-trained models from one city to another, thereby
alleviating the need for costly local training.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03507</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03519</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Codes over $\mathbb{F}_{q}+v\mathbb{F}_{q}+v^{2}\mathbb{F}_{q}$</dc:title>
 <dc:creator>Melakhessou, A.</dc:creator>
 <dc:creator>Guenda, K.</dc:creator>
 <dc:creator>Gulliver, T. A.</dc:creator>
 <dc:creator>Shi, M.</dc:creator>
 <dc:creator>Sol&#xe9;, P.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Rings and Algebras</dc:subject>
 <dc:description>  In this paper we investigate linear codes with complementary dual (LCD) codes
and formally self-dual codes over the ring $R=\F_{q}+v\F_{q}+v^{2}\F_{q}$,
where $v^{3}=v$, for $q$ odd. We give conditions on the existence of LCD codes
and present construction of formally self-dual codes over $R$. Further, we give
bounds on the minimum distance of LCD codes over $\F_q$ and extend these to
codes over $R$.
</dc:description>
 <dc:description>Comment: 19 pages</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03519</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03520</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Event Abstraction using Pattern Abstraction and Local
  Process Models</dc:title>
 <dc:creator>Mannhardt, Felix</dc:creator>
 <dc:creator>Tax, Niek</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Process mining analyzes business processes based on events stored in event
logs. However, some recorded events may correspond to activities on a very low
level of abstraction. When events are recorded on a too low level of
granularity, process discovery methods tend to generate overgeneralizing
process models. Grouping low-level events to higher level activities, i.e.,
event abstraction, can be used to discover better process models. Existing
event abstraction methods are mainly based on common sub-sequences and
clustering techniques. In this paper, we propose to first discover local
process models and then use those models to lift the event log to a higher
level of abstraction. Our conjecture is that process models discovered on the
obtained high-level event log return process models of higher quality: their
fitness and precision scores are more balanced. We show this with preliminary
results on several real-life event logs.
</dc:description>
 <dc:description>Comment: Accepted at Enabling Business Transformation by Business Process
  Modeling, Development, and Support Working Conference 2017 (BPMDS)</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03521</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Responsive Graphical User Interface (ReGUI) and its Implementation in
  MATLAB</dc:title>
 <dc:creator>Mikulszky, Matej</dc:creator>
 <dc:creator>Pocsova, Jana</dc:creator>
 <dc:creator>Mojzisova, Andrea</dc:creator>
 <dc:creator>Podlubny, Igor</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.2</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:description>  In this paper we introduce the responsive graphical user interface (ReGUI)
approach to creating applications, and demonstrate how this approach can be
implemented in MATLAB. The same general technique can be used in other
programming languages.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03521</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03522</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Fitness Functions in Genetic Programming for Classification on
  Unbalanced Credit Card Datasets</dc:title>
 <dc:creator>Cao, Van Loi</dc:creator>
 <dc:creator>Le-Khac, Nhien-An</dc:creator>
 <dc:creator>Nicolau, Miguel</dc:creator>
 <dc:creator>ONeill, Michael</dc:creator>
 <dc:creator>McDermott, James</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Credit card fraud detection based on machine learning has recently attracted
considerable interest from the research community. One of the most important
tasks in this area is the ability of classifiers to handle the imbalance in
credit card data. In this scenario, classifiers tend to yield poor accuracy on
the fraud class (minority class) despite realizing high overall accuracy. This
is due to the influence of the majority class on traditional training criteria.
In this paper, we aim to apply genetic programming to address this issue by
adapting existing fitness functions. We examine two fitness functions from
previous studies and develop two new fitness functions to evolve GP classifier
with superior accuracy on the minority class and overall. Two UCI credit card
datasets are used to evaluate the effectiveness of the proposed fitness
functions. The results demonstrate that the proposed fitness functions augment
GP classifiers, encouraging fitter solutions on both the minority and the
majority classes.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03522</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03524</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Forensic Analysis of TomTom Navigation Application</dc:title>
 <dc:creator>Le-Khac, Nhien-An</dc:creator>
 <dc:creator>Roeloffs, Mark</dc:creator>
 <dc:creator>Kechadi, M-Tahar</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In the forensic field of digital technology, there has been a great deal of
investigation into the decoding of navigation systems of the brand TomTom. As
TomTom is the market leader in navigation systems, a large number of these
devices are investigated. These devices can hold an abundance of significant
location information. Currently, it is possible with the use of multiple
methods to make physical copies of mobile devices running Android. The next
great forensic problem is all the various programs that can be installed on
these devices. There is now an application available from the company TomTom in
the Google Play Store. This application mimics a navigation system on your
Android mobile device. Indeed, the TomTom application on Android can hold a
great deal of information. In this paper, we present a process of forensic
acquisition and analysis of the TomTom Android application. We focus on the
following questions: Is there a possibility to find previously driven routes or
GPS coordinates with timestamps in the memory of the mobile device? To
investigate what is stored in these files, driving tests were performed. During
these driving tests a copy was made of the most important file using a
self-written program. The significant files were found and the data in these
files was decoded. We show and analyse our results with Samsung mobile devices.
We compare also these results with forensic acquisition from TomTom GPS
devices.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03524</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03526</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rich-clubness test: how to determine whether a complex network has or
  doesn't have a rich-club?</dc:title>
 <dc:creator>Muscoloni, Alessandro</dc:creator>
 <dc:creator>Cannistraci, Carlo Vittorio</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The rich-club concept has been introduced in order to characterize the
presence of a cohort of nodes with a large number of links (rich nodes) that
tend to be well connected between each other, creating a tight group (club).
Rich-clubness defines the extent to which a network displays a topological
organization characterized by the presence of a node rich-club. It is crucial
for the investigation of internal organization and function of networks arising
in systems of disparate fields such as transportation, social, communication
and neuroscience. Different methods have been proposed for assessing the
rich-clubness and various null-models have been adopted for performing
statistical tests. However, a procedure that assigns a unique value of
rich-clubness significance to a given network is still missing. Our solution to
this problem grows on the basis of three new pillars. We introduce: i) a
null-model characterized by a lower rich-club coefficient; ii) a fair strategy
to normalize the level of rich-clubness of a network in respect to the
null-model; iii) a statistical test that, exploiting the maximum deviation of
the normalized rich-club coefficient attributes a unique p-value of
rich-clubness to a given network. In conclusion, this study proposes the first
attempt to quantify, using a unique measure, whether a network presents a
significant rich-club topological organization. The general impact of our study
on engineering and science is that simulations investigating how the functional
performance of a network is changing in relation to rich-clubness might be more
easily tuned controlling one unique value: the proposed rich-clubness measure.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03526</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03527</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward a new approach for massive LiDAR data processing</dc:title>
 <dc:creator>Cao, V-H</dc:creator>
 <dc:creator>Chu, K-X</dc:creator>
 <dc:creator>Le-Khac, Nhien-An</dc:creator>
 <dc:creator>Kechadi, M-T</dc:creator>
 <dc:creator>Laefer, Debra F.</dc:creator>
 <dc:creator>Truong-Hong, Linh</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Laser scanning (also known as Light Detection And Ranging) has been widely
applied in various application. As part of that, aerial laser scanning (ALS)
has been used to collect topographic data points for a large area, which
triggers to million points to be acquired. Furthermore, today, with integrating
full wareform (FWF) technology during ALS data acquisition, all return
information of laser pulse is stored. Thus, ALS data are to be massive and
complexity since the FWF of each laser pulse can be stored up to 256 samples
and density of ALS data is also increasing significantly. Processing LiDAR data
demands heavy operations and the traditional approaches require significant
hardware and running time. On the other hand, researchers have recently
proposed parallel approaches for analysing LiDAR data. These approaches are
normally based on parallel architecture of target systems such as multi-core
processors, GPU, etc. However, there is still missing efficient
approaches/tools supporting the analysis of LiDAR data due to the lack of a
deep study on both library tools and algorithms used in processing this data.
In this paper, we present a comparative study of software libraries and
algorithms to optimise the processing of LiDAR data. We also propose new method
to improve this process with experiments on large LiDAR data. Finally, we
discuss on a parallel solution of our approach where we integrate parallel
computing in processing LiDAR data.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03527</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03530</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feature Selection Parallel Technique for Remotely Sensed Imagery
  Classification</dc:title>
 <dc:creator>Le-Khac, Nhien-An</dc:creator>
 <dc:creator>Kechadi, M-Tahar</dc:creator>
 <dc:creator>Wu, Bo</dc:creator>
 <dc:creator>Chen, C.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Remote sensing research focusing on feature selection has long attracted the
attention of the remote sensing community because feature selection is a
prerequisite for image processing and various applications. Different feature
selection methods have been proposed to improve the classification accuracy.
They vary from basic search techniques to clonal selections, and various
optimal criteria have been investigated. Recently, methods using
dependence-based measures have attracted much attention due to their ability to
deal with very high dimensional datasets. However, these methods are based on
Cramers V test, which has performance issues with large datasets. In this
paper, we propose a parallel approach to improve their performance. We evaluate
our approach on hyper-spectral and high spatial resolution images and compare
it to the proposed methods with a centralized version as preliminary results.
The results are very promising.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03530</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03533</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Detection with Diverse Proposals</dc:title>
 <dc:creator>Azadi, Samaneh</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:creator>Darrell, Trevor</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  To predict a set of diverse and informative proposals with enriched
representations, this paper introduces a differentiable Determinantal Point
Process (DPP) layer that is able to augment the object detection architectures.
Most modern object detection architectures, such as Faster R-CNN, learn to
localize objects by minimizing deviations from the ground-truth but ignore
correlation between multiple proposals and object categories. Non-Maximum
Suppression (NMS) as a widely used proposal pruning scheme ignores label- and
instance-level relations between object candidates resulting in multi-labeled
detections. In the multi-class case, NMS selects boxes with the largest
prediction scores ignoring the semantic relation between categories of
potential election. In contrast, our trainable DPP layer, allowing for Learning
Detection with Diverse Proposals (LDDP), considers both label-level contextual
information and spatial layout relationships between proposals without
increasing the number of parameters of the network, and thus improves location
and category specifications of final detected bounding boxes substantially
during both training and inference schemes. Furthermore, we show that LDDP
keeps it superiority over Faster R-CNN even if the number of proposals
generated by LDPP is only ~30% as many as those for Faster R-CNN.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2017</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03533</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03538</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward a Distributed Knowledge Discovery system for Grid systems</dc:title>
 <dc:creator>Le-Khac, Nhien-An</dc:creator>
 <dc:creator>Aouad, Lamine</dc:creator>
 <dc:creator>Kechadi, M-Tahar</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  During the last decade or so, we have had a deluge of data from not only
science fields but also industry and commerce fields. Although the amount of
data available to us is constantly increasing, our ability to process it
becomes more and more difficult. Efficient discovery of useful knowledge from
these datasets is therefore becoming a challenge and a massive economic need.
This led to the need of developing large-scale data mining (DM) techniques to
deal with these huge datasets either from science or economic applications. In
this chapter, we present a new DDM system combining dataset-driven and
architecture-driven strategies. Data-driven strategies will consider the size
and heterogeneity of the data, while architecture driven will focus on the
distribution of the datasets. This system is based on a Grid middleware tools
that integrate appropriate large data manipulation operations. Therefore, this
allows more dynamicity and autonomicity during the mining, integrating and
processing phases
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03538</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03543</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Term Banks for Answering Complex Questions: A Case for Sparse
  Vectors</dc:title>
 <dc:creator>Turney, Peter D.</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>H.3.1</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  While open-domain question answering (QA) systems have proven effective for
answering simple questions, they struggle with more complex questions. Our goal
is to answer more complex questions reliably, without incurring a significant
cost in knowledge resource construction to support the QA. One readily
available knowledge resource is a term bank, enumerating the key concepts in a
domain. We have developed an unsupervised learning approach that leverages a
term bank to guide a QA system, by representing the terminological knowledge
with thousands of specialized vector spaces. In experiments with complex
science questions, we show that this approach significantly outperforms several
state-of-the-art QA systems, demonstrating that significant leverage can be
gained from continuous vector representations of domain terminology.
</dc:description>
 <dc:description>Comment: Related datasets can be found at http://allenai.org/data.html</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03543</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03547</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Simultaneous Two-player Combinatorial Auctions</dc:title>
 <dc:creator>Braverman, Mark</dc:creator>
 <dc:creator>Mao, Jieming</dc:creator>
 <dc:creator>Weinberg, S. Matthew</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We consider the following communication problem: Alice and Bob each have some
valuation functions $v_1(\cdot)$ and $v_2(\cdot)$ over subsets of $m$ items,
and their goal is to partition the items into $S, \bar{S}$ in a way that
maximizes the welfare, $v_1(S) + v_2(\bar{S})$. We study both the allocation
problem, which asks for a welfare-maximizing partition and the decision
problem, which asks whether or not there exists a partition guaranteeing
certain welfare, for binary XOS valuations. For interactive protocols with
$poly(m)$ communication, a tight 3/4-approximation is known for both
[Fei06,DS06].
  For interactive protocols, the allocation problem is provably harder than the
decision problem: any solution to the allocation problem implies a solution to
the decision problem with one additional round and $\log m$ additional bits of
communication via a trivial reduction. Surprisingly, the allocation problem is
provably easier for simultaneous protocols. Specifically, we show:
  1) There exists a simultaneous, randomized protocol with polynomial
communication that selects a partition whose expected welfare is at least $3/4$
of the optimum. This matches the guarantee of the best interactive, randomized
protocol with polynomial communication.
  2) For all $\varepsilon &gt; 0$, any simultaneous, randomized protocol that
decides whether the welfare of the optimal partition is $\geq 1$ or $\leq 3/4 -
1/108+\varepsilon$ correctly with probability $&gt; 1/2 + 1/ poly(m)$ requires
exponential communication. This provides a separation between the attainable
approximation guarantees via interactive ($3/4$) versus simultaneous ($\leq
3/4-1/108$) protocols with polynomial communication.
  In other words, this trivial reduction from decision to allocation problems
provably requires the extra round of communication.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03549</identifier>
 <datestamp>2017-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attention-based Extraction of Structured Information from Street View
  Imagery</dc:title>
 <dc:creator>Wojna, Zbigniew</dc:creator>
 <dc:creator>Gorban, Alex</dc:creator>
 <dc:creator>Lee, Dar-Shyang</dc:creator>
 <dc:creator>Murphy, Kevin</dc:creator>
 <dc:creator>Yu, Qian</dc:creator>
 <dc:creator>Li, Yeqing</dc:creator>
 <dc:creator>Ibarz, Julian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a neural network model - based on CNNs, RNNs and a novel attention
mechanism - which achieves 84.2% accuracy on the challenging French Street Name
Signs (FSNS) dataset, significantly outperforming the previous state of the art
(Smith'16), which achieved 72.46%. Furthermore, our new method is much simpler
and more general than the previous approach. To demonstrate the generality of
our model, we show that it also performs well on an even more challenging
dataset derived from Google Street View, in which the goal is to extract
business names from store fronts. Finally, we study the speed/accuracy tradeoff
that results from using CNN feature extractors of different depths.
Surprisingly, we find that deeper is not always better (in terms of accuracy,
as well as speed). Our resulting model is simple, accurate and fast, allowing
it to be used at scale on a variety of challenging real-world text extraction
problems.
</dc:description>
 <dc:description>Comment: Updated references, added link to the source code</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03549</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03554</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Clarifying Trust in Social Internet of Things</dc:title>
 <dc:creator>Lin, Zhiting</dc:creator>
 <dc:creator>Dong, Liang</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  A social approach can be exploited for the Internet of Things (IoT) to manage
a large number of connected objects. These objects operate as autonomous agents
to request and provide information and services to users. Establishing
trustworthy relationships among the objects greatly improves the effectiveness
of node interaction in the social IoT and helps nodes overcome perceptions of
uncertainty and risk. However, there are limitations in the existing trust
models. In this paper, a comprehensive model of trust is proposed that is
tailored to the social IoT. The model includes ingredients such as trustor,
trustee, goal, trustworthiness evaluation, decision, action, result, and
context. Building on this trust model, we clarify the concept of trust in the
social IoT in five aspects such as (1) mutuality of trustor and trustee, (2)
inferential transfer of trust, (3) transitivity of trust, (4) trustworthiness
update, and (5) trustworthiness affected by dynamic environment. With network
connectivities that are from real-world social networks, a series of
simulations are conducted to evaluate the performance of the social IoT
operated with the proposed trust model. An experimental IoT network is used to
further validate the proposed trust model.
</dc:description>
 <dc:description>Comment: 14 pages, 16 figures. Submitted to IEEE Transactions on Knowledge and
  Data Engineering</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03554</dc:identifier>
 <dc:identifier>IEEE Transactions on Knowledge and Data Engineering, vol. 30, no.
  2, pp. 234-248, Feb. 2018</dc:identifier>
 <dc:identifier>doi:10.1109/TKDE.2017.2762678</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03555</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Underapproximation of Reach-Avoid Sets for Discrete-Time Stochastic
  Systems via Lagrangian Methods</dc:title>
 <dc:creator>Gleason, Joseph D.</dc:creator>
 <dc:creator>Vinod, Abraham P.</dc:creator>
 <dc:creator>Oishi, Meeko. M. K.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We examine Lagrangian techniques for computing underapproximations of
finite-time horizon, stochastic reach-avoid level-sets for discrete-time,
nonlinear systems. We use the concept of reachability of a target tube in the
control literature to define robust reach-avoid sets which are parameterized by
the target set, safe set, and the set in which the disturbance is drawn from.
We unify two existing Lagrangian approaches to compute these sets and establish
that there exists an optimal control policy of the robust reach-avoid sets
which is a Markov policy. Based on these results, we characterize the subset of
the disturbance space whose corresponding robust reach-avoid set for the given
target and safe set is a guaranteed underapproximation of the stochastic
reach-avoid level-set of interest. The proposed approach dramatically improves
the computational efficiency for obtaining an underapproximation of stochastic
reach-avoid level-sets when compared to the traditional approaches based on
gridding. Our method, while conservative, does not rely on a grid, implying
scalability as permitted by the known computational geometry constraints. We
demonstrate the method on two examples: a simple two-dimensional integrator,
and a space vehicle rendezvous-docking problem.
</dc:description>
 <dc:description>Comment: Submitted to CDC 2017</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03555</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03557</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cutting the Error by Half: Investigation of Very Deep CNN and Advanced
  Training Strategies for Document Image Classification</dc:title>
 <dc:creator>Afzal, Muhammad Zeshan</dc:creator>
 <dc:creator>K&#xf6;lsch, Andreas</dc:creator>
 <dc:creator>Ahmed, Sheraz</dc:creator>
 <dc:creator>Liwicki, Marcus</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present an exhaustive investigation of recent Deep Learning architectures,
algorithms, and strategies for the task of document image classification to
finally reduce the error by more than half. Existing approaches, such as the
DeepDocClassifier, apply standard Convolutional Network architectures with
transfer learning from the object recognition domain. The contribution of the
paper is threefold: First, it investigates recently introduced very deep neural
network architectures (GoogLeNet, VGG, ResNet) using transfer learning (from
real images). Second, it proposes transfer learning from a huge set of document
images, i.e. 400,000 documents. Third, it analyzes the impact of the amount of
training data (document images) and other parameters to the classification
abilities. We use two datasets, the Tobacco-3482 and the large-scale RVL-CDIP
dataset. We achieve an accuracy of 91.13% for the Tobacco-3482 dataset while
earlier approaches reach only 77.6%. Thus, a relative error reduction of more
than 60% is achieved. For the large dataset RVL-CDIP, an accuracy of 90.97% is
achieved, corresponding to a relative error reduction of 11.5%.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03557</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03560</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ConceptNet at SemEval-2017 Task 2: Extending Word Embeddings with
  Multilingual Relational Knowledge</dc:title>
 <dc:creator>Speer, Robert</dc:creator>
 <dc:creator>Lowry-Duda, Joanna</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper describes Luminoso's participation in SemEval 2017 Task 2,
&quot;Multilingual and Cross-lingual Semantic Word Similarity&quot;, with a system based
on ConceptNet. ConceptNet is an open, multilingual knowledge graph that focuses
on general knowledge that relates the meanings of words and phrases. Our
submission to SemEval was an update of previous work that builds high-quality,
multilingual word embeddings from a combination of ConceptNet and
distributional semantics. Our system took first place in both subtasks. It
ranked first in 4 out of 5 of the separate languages, and also ranked first in
all 10 of the cross-lingual language pairs.
</dc:description>
 <dc:description>Comment: 5 pages, accepted to the SemEval workshop at ACL 2017</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03560</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03564</identifier>
 <datestamp>2017-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active classification with comparison queries</dc:title>
 <dc:creator>Kane, Daniel M.</dc:creator>
 <dc:creator>Lovett, Shachar</dc:creator>
 <dc:creator>Moran, Shay</dc:creator>
 <dc:creator>Zhang, Jiapeng</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We study an extension of active learning in which the learning algorithm may
ask the annotator to compare the distances of two examples from the boundary of
their label-class. For example, in a recommendation system application (say for
restaurants), the annotator may be asked whether she liked or disliked a
specific restaurant (a label query); or which one of two restaurants did she
like more (a comparison query).
  We focus on the class of half spaces, and show that under natural
assumptions, such as large margin or bounded bit-description of the input
examples, it is possible to reveal all the labels of a sample of size $n$ using
approximately $O(\log n)$ queries. This implies an exponential improvement over
classical active learning, where only label queries are allowed. We complement
these results by showing that if any of these assumptions is removed then, in
the worst case, $\Omega(n)$ queries are required.
  Our results follow from a new general framework of active learning with
additional queries. We identify a combinatorial dimension, called the
\emph{inference dimension}, that captures the query complexity when each
additional query is determined by $O(1)$ examples (such as comparison queries,
each of which is determined by the two compared examples). Our results for half
spaces follow by bounding the inference dimension in the cases discussed above.
</dc:description>
 <dc:description>Comment: 23 pages (not including references), 1 figure. The new version
  contains a minor fix in the proof of Lemma 4.2</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03568</identifier>
 <datestamp>2017-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond Planar Symmetry: Modeling human perception of reflection and
  rotation symmetries in the wild</dc:title>
 <dc:creator>Funk, Christopher</dc:creator>
 <dc:creator>Liu, Yanxi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Humans take advantage of real world symmetries for various tasks, yet
capturing their superb symmetry perception mechanism with a computational model
remains elusive. Motivated by a new study demonstrating the extremely high
inter-person accuracy of human perceived symmetries in the wild, we have
constructed the first deep-learning neural network for reflection and rotation
symmetry detection (Sym-NET), trained on photos from MS-COCO (Microsoft-Common
Object in COntext) dataset with nearly 11K consistent symmetry-labels from more
than 400 human observers. We employ novel methods to convert discrete human
labels into symmetry heatmaps, capture symmetry densely in an image and
quantitatively evaluate Sym-NET against multiple existing computer vision
algorithms. On CVPR 2013 symmetry competition testsets and unseen MS-COCO
photos, Sym-NET significantly outperforms all other competitors. Beyond
mathematically well-defined symmetries on a plane, Sym-NET demonstrates
abilities to identify viewpoint-varied 3D symmetries, partially occluded
symmetrical objects, and symmetries at a semantic level.
</dc:description>
 <dc:description>Comment: To appear in the International Conference on Computer Vision (ICCV)
  2017</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03568</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03574</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CASP Solutions for Planning in Hybrid Domains</dc:title>
 <dc:creator>Balduccini, Marcello</dc:creator>
 <dc:creator>Magazzeni, Daniele</dc:creator>
 <dc:creator>Maratea, Marco</dc:creator>
 <dc:creator>LeBlanc, Emily</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  CASP is an extension of ASP that allows for numerical constraints to be added
in the rules. PDDL+ is an extension of the PDDL standard language of automated
planning for modeling mixed discrete-continuous dynamics.
  In this paper, we present CASP solutions for dealing with PDDL+ problems,
i.e., encoding from PDDL+ to CASP, and extensions to the algorithm of the EZCSP
CASP solver in order to solve CASP programs arising from PDDL+ domains. An
experimental analysis, performed on well-known linear and non-linear variants
of PDDL+ domains, involving various configurations of the EZCSP solver, other
CASP solvers, and PDDL+ planners, shows the viability of our solution.
</dc:description>
 <dc:description>Comment: Under consideration in Theory and Practice of Logic Programming
  (TPLP)</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03574</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03578</identifier>
 <datestamp>2017-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Homomorphic Encryption Schemes: Theory and Implementation</dc:title>
 <dc:creator>Acar, Abbas</dc:creator>
 <dc:creator>Aksu, Hidayet</dc:creator>
 <dc:creator>Uluagac, A. Selcuk</dc:creator>
 <dc:creator>Conti, Mauro</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>E.3</dc:subject>
 <dc:subject>K.6.5</dc:subject>
 <dc:subject>K.4.1</dc:subject>
 <dc:description>  Legacy encryption systems depend on sharing a key (public or private) among
the peers involved in exchanging an encrypted message. However, this approach
poses privacy concerns. Especially with popular cloud services, the control
over the privacy of the sensitive data is lost. Even when the keys are not
shared, the encrypted material is shared with a third party that does not
necessarily need to access the content. Moreover, untrusted servers, providers,
and cloud operators can keep identifying elements of users long after users end
the relationship with the services. Indeed, Homomorphic Encryption (HE), a
special kind of encryption scheme, can address these concerns as it allows any
third party to operate on the encrypted data without decrypting it in advance.
Although this extremely useful feature of the HE scheme has been known for over
30 years, the first plausible and achievable Fully Homomorphic Encryption (FHE)
scheme, which allows any computable function to perform on the encrypted data,
was introduced by Craig Gentry in 2009. Even though this was a major
achievement, different implementations so far demonstrated that FHE still needs
to be improved significantly to be practical on every platform. First, we
present the basics of HE and the details of the well-known Partially
Homomorphic Encryption (PHE) and Somewhat Homomorphic Encryption (SWHE), which
are important pillars of achieving FHE. Then, the main FHE families, which have
become the base for the other follow-up FHE schemes are presented. Furthermore,
the implementations and recent improvements in Gentry-type FHE schemes are also
surveyed. Finally, further research directions are discussed. This survey is
intended to give a clear knowledge and foundation to researchers and
practitioners interested in knowing, applying, as well as extending the state
of the art HE, PHE, SWHE, and FHE systems.
</dc:description>
 <dc:description>Comment: - Updated. (October 6, 2017) - This paper is an early draft of the
  survey that is being submitted to ACM CSUR and has been uploaded to arXiv for
  feedback from stakeholders</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-10-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03578</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03591</identifier>
 <datestamp>2017-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Optimal Data Detector for mmWave OFDM System with
  Low-Resolution ADC</dc:title>
 <dc:creator>Wang, Hanqing</dc:creator>
 <dc:creator>Wen, Chao-Kai</dc:creator>
 <dc:creator>Jin, Shi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Orthogonal frequency division multiplexing (OFDM) has been widely used in
communication systems operating in the millimeter wave (mmWave) band to combat
frequency-selective fading and achieve multi-Gbps transmissions, such as IEEE
802.15.3c and IEEE 802.11ad. For mmWave systems with ultra high sampling rate
requirements, the use of low-resolution analog-to-digital converters (ADCs)
(i.e., 1-3 bits) ensures an acceptable level of power consumption and system
costs. However, orthogonality among sub-channels in the OFDM system cannot be
maintained because of the severe non-linearity caused by low-resolution ADC,
which renders the design of data detector challenging. In this study, we
develop an efficient algorithm for optimal data detection in the mmWave OFDM
system with low-resolution ADCs. The analytical performance of the proposed
detector is derived and verified to achieve the fundamental limit of the
Bayesian optimal design. On the basis of the derived analytical expression, we
further propose a power allocation (PA) scheme that seeks to minimize the
average symbol error rate. In addition to the optimal data detector, we also
develop a feasible channel estimation method, which can provide high-quality
channel state information without significant pilot overhead. Simulation
results confirm the accuracy of our analysis and illustrate that the
performance of the proposed detector in conjunction with the proposed PA scheme
is close to the optimal performance of the OFDM system with infinite-resolution
ADC.
</dc:description>
 <dc:description>Comment: 32 pages, 12 figures; accepted by IEEE JSAC special issue on
  millimeter wave communications for future mobile networks</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03591</dc:identifier>
 <dc:identifier>IEEE Journal on Selected Areas in Communications ( Volume: 35,
  Issue: 9, Sept. 2017 )</dc:identifier>
 <dc:identifier>doi:10.1109/JSAC.2017.2720978</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03593</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reformulating Level Sets as Deep Recurrent Neural Network Approach to
  Semantic Segmentation</dc:title>
 <dc:creator>Le, Ngan</dc:creator>
 <dc:creator>Quach, Kha Gia</dc:creator>
 <dc:creator>Luu, Khoa</dc:creator>
 <dc:creator>Savvides, Marios</dc:creator>
 <dc:creator>Zhu, Chenchen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Variational Level Set (LS) has been a widely used method in medical
segmentation. However, it is limited when dealing with multi-instance objects
in the real world. In addition, its segmentation results are quite sensitive to
initial settings and highly depend on the number of iterations. To address
these issues and boost the classic variational LS methods to a new level of the
learnable deep learning approaches, we propose a novel definition of contour
evolution named Recurrent Level Set (RLS)} to employ Gated Recurrent Unit under
the energy minimization of a variational LS functional. The curve deformation
process in RLS is formed as a hidden state evolution procedure and updated by
minimizing an energy functional composed of fitting forces and contour length.
By sharing the convolutional features in a fully end-to-end trainable
framework, we extend RLS to Contextual RLS (CRLS) to address semantic
segmentation in the wild. The experimental results have shown that our proposed
RLS improves both computational time and segmentation accuracy against the
classic variations LS-based method, whereas the fully end-to-end system CRLS
achieves competitive performance compared to the state-of-the-art semantic
segmentation approaches.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03593</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03594</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Contextual Recurrent Residual Networks for Scene Labeling</dc:title>
 <dc:creator>Le, T. Hoang Ngan</dc:creator>
 <dc:creator>Duong, Chi Nhan</dc:creator>
 <dc:creator>Han, Ligong</dc:creator>
 <dc:creator>Luu, Khoa</dc:creator>
 <dc:creator>Savvides, Marios</dc:creator>
 <dc:creator>Pal, Dipan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Designed as extremely deep architectures, deep residual networks which
provide a rich visual representation and offer robust convergence behaviors
have recently achieved exceptional performance in numerous computer vision
problems. Being directly applied to a scene labeling problem, however, they
were limited to capture long-range contextual dependence, which is a critical
aspect. To address this issue, we propose a novel approach, Contextual
Recurrent Residual Networks (CRRN) which is able to simultaneously handle rich
visual representation learning and long-range context modeling within a fully
end-to-end deep network. Furthermore, our proposed end-to-end CRRN is
completely trained from scratch, without using any pre-trained models in
contrast to most existing methods usually fine-tuned from the state-of-the-art
pre-trained models, e.g. VGG-16, ResNet, etc. The experiments are conducted on
four challenging scene labeling datasets, i.e. SiftFlow, CamVid, Stanford
background and SUN datasets, and compared against various state-of-the-art
scene labeling methods.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03594</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03596</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Plane Constrained Bounded-Degree Spanners</dc:title>
 <dc:creator>Bose, Prosenjit</dc:creator>
 <dc:creator>Fagerberg, Rolf</dc:creator>
 <dc:creator>van Renssen, Andr&#xe9;</dc:creator>
 <dc:creator>Verdonschot, Sander</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Let $P$ be a finite set of points in the plane and $S$ a set of non-crossing
line segments with endpoints in $P$. The visibility graph of $P$ with respect
to $S$, denoted $Vis(P,S)$, has vertex set $P$ and an edge for each pair of
vertices $u,v$ in $P$ for which no line segment of $S$ properly intersects
$uv$. We show that the constrained half-$\theta_6$-graph (which is identical to
the constrained Delaunay graph whose empty visible region is an equilateral
triangle) is a plane 2-spanner of $Vis(P,S)$. We then show how to construct a
plane 6-spanner of $Vis(P,S)$ with maximum degree $6+c$, where $c$ is the
maximum number of segments of $S$ incident to a vertex.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03596</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03603</identifier>
 <datestamp>2017-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NOMA based Calibration for Large-Scale Spaceborne Antenna Arrays</dc:title>
 <dc:creator>Lin, Yujie</dc:creator>
 <dc:creator>Wang, Shuai</dc:creator>
 <dc:creator>Bu, Xiangyuan</dc:creator>
 <dc:creator>Xing, Chengwen</dc:creator>
 <dc:creator>An, Jianping</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In the parallel calibration for transmitting phased arrays, the calibration
receiver must separate the signals belonging to different antenna elements to
avoid mutual interference. Existing algorithms encode different antenna
elements' radiation with orthogonal signature codes, but these algorithms are
far from desired for large-scale spaceborne antenna arrays. Considering the
strictly limited resources on satellites, to improve hardware efficiency of
large-scale spaceborne antenna arrays, in this work inspired by the idea of
non-orthogonal multiple access (NOMA) we design a series of non-orthogonal
signature codes for different antenna elements by Cyclically Shifting an
m-Sequence (CSmS) with different offsets named as CSmS-NOMA signaling. This
design can strike an elegant balance between the performance and complexity and
is very suitable for large-scale spaceborne antenna arrays. It is shown that no
matter how many antenna elements there are to be calibrated simultaneously,
CSmS-NOMA signaling needs only one calibrating waveform generator and one
matched filter. Hence it is much more efficient than the existing fully
orthogonal schemes. In order to evaluate the achievable calibration accuracy, a
unified theoretical framework is developed based on which the relationship
between calibration accuracy and signal to noise ratio (SNR) has been clearly
revealed. Furthermore, a hardware experiment platform is also built to assess
the theoretical work. For all the considered scenarios, it can be concluded
that the theoretical, simulated and experimental results coincide with each
other perfectly.
</dc:description>
 <dc:description>Comment: 30 Pages, 8 Figures</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03603</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03604</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Instance-Level Salient Object Segmentation</dc:title>
 <dc:creator>Li, Guanbin</dc:creator>
 <dc:creator>Xie, Yuan</dc:creator>
 <dc:creator>Lin, Liang</dc:creator>
 <dc:creator>Yu, Yizhou</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image saliency detection has recently witnessed rapid progress due to deep
convolutional neural networks. However, none of the existing methods is able to
identify object instances in the detected salient regions. In this paper, we
present a salient instance segmentation method that produces a saliency mask
with distinct object instance labels for an input image. Our method consists of
three steps, estimating saliency map, detecting salient object contours and
identifying salient object instances. For the first two steps, we propose a
multiscale saliency refinement network, which generates high-quality salient
region masks and salient object contours. Once integrated with multiscale
combinatorial grouping and a MAP-based subset optimization framework, our
method can generate very promising salient object instance segmentation
results. To promote further research and evaluation of salient instance
segmentation, we also construct a new database of 1000 images and their
pixelwise salient instance annotations. Experimental results demonstrate that
our proposed method is capable of achieving state-of-the-art performance on all
public benchmarks for salient region detection as well as on our new dataset
for salient instance segmentation.
</dc:description>
 <dc:description>Comment: To appear in CVPR2017</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03604</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03606</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy-Aware Guessing Efficiency</dc:title>
 <dc:creator>Asoodeh, Shahab</dc:creator>
 <dc:creator>Diaz, Mario</dc:creator>
 <dc:creator>Alajaji, Fady</dc:creator>
 <dc:creator>Linder, Tam&#xe1;s</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We investigate the problem of guessing a discrete random variable $Y$ under a
privacy constraint dictated by another correlated discrete random variable $X$,
where both guessing efficiency and privacy are assessed in terms of the
probability of correct guessing. We define $h(P_{XY}, \epsilon)$ as the maximum
probability of correctly guessing $Y$ given an auxiliary random variable $Z$,
where the maximization is taken over all $P_{Z|Y}$ ensuring that the
probability of correctly guessing $X$ given $Z$ does not exceed $\epsilon$. We
show that the map $\epsilon\mapsto h(P_{XY}, \epsilon)$ is strictly increasing,
concave, and piecewise linear, which allows us to derive a closed form
expression for $h(P_{XY}, \epsilon)$ when $X$ and $Y$ are connected via a
binary-input binary-output channel. For $(X^n, Y^n)$ being pairs of independent
and identically distributed binary random vectors, we similarly define
$\underline{h}_n(P_{X^nY^n}, \epsilon)$ under the assumption that $Z^n$ is also
a binary vector. Then we obtain a closed form expression for
$\underline{h}_n(P_{X^nY^n}, \epsilon)$ for sufficiently large, but nontrivial
values of $\epsilon$.
</dc:description>
 <dc:description>Comment: ISIT 2017</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03607</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Discovery, Association Estimation and Learning of Semantic
  Attributes for a Thousand Categories</dc:title>
 <dc:creator>Al-Halah, Ziad</dc:creator>
 <dc:creator>Stiefelhagen, Rainer</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Attribute-based recognition models, due to their impressive performance and
their ability to generalize well on novel categories, have been widely adopted
for many computer vision applications. However, usually both the attribute
vocabulary and the class-attribute associations have to be provided manually by
domain experts or large number of annotators. This is very costly and not
necessarily optimal regarding recognition performance, and most importantly, it
limits the applicability of attribute-based models to large scale data sets. To
tackle this problem, we propose an end-to-end unsupervised attribute learning
approach. We utilize online text corpora to automatically discover a salient
and discriminative vocabulary that correlates well with the human concept of
semantic attributes. Moreover, we propose a deep convolutional model to
optimize class-attribute associations with a linguistic prior that accounts for
noise and missing data in text. In a thorough evaluation on ImageNet, we
demonstrate that our model is able to efficiently discover and learn semantic
attributes at a large scale. Furthermore, we demonstrate that our model
outperforms the state-of-the-art in zero-shot learning on three data sets:
ImageNet, Animals with Attributes and aPascal/aYahoo. Finally, we enable
attribute-based learning on ImageNet and will share the attributes and
associations for future research.
</dc:description>
 <dc:description>Comment: Accepted as a conference paper at CVPR 2017</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03610</identifier>
 <datestamp>2017-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Blockchains for Business Process Management - Challenges and
  Opportunities</dc:title>
 <dc:creator>Mendling, Jan</dc:creator>
 <dc:creator>Weber, Ingo</dc:creator>
 <dc:creator>van der Aalst, Wil</dc:creator>
 <dc:creator>Brocke, Jan vom</dc:creator>
 <dc:creator>Cabanillas, Cristina</dc:creator>
 <dc:creator>Daniel, Florian</dc:creator>
 <dc:creator>Debois, Soren</dc:creator>
 <dc:creator>Di Ciccio, Claudio</dc:creator>
 <dc:creator>Dumas, Marlon</dc:creator>
 <dc:creator>Dustdar, Schahram</dc:creator>
 <dc:creator>Gal, Avigdor</dc:creator>
 <dc:creator>Garcia-Banuelos, Luciano</dc:creator>
 <dc:creator>Governatori, Guido</dc:creator>
 <dc:creator>Hull, Richard</dc:creator>
 <dc:creator>La Rosa, Marcello</dc:creator>
 <dc:creator>Leopold, Henrik</dc:creator>
 <dc:creator>Leymann, Frank</dc:creator>
 <dc:creator>Recker, Jan</dc:creator>
 <dc:creator>Reichert, Manfred</dc:creator>
 <dc:creator>Reijers, Hajo A.</dc:creator>
 <dc:creator>Rinderle-Ma, Stefanie</dc:creator>
 <dc:creator>Rogge-Solti, Andreas</dc:creator>
 <dc:creator>Rosemann, Michael</dc:creator>
 <dc:creator>Schulte, Stefan</dc:creator>
 <dc:creator>Singh, Munindar P.</dc:creator>
 <dc:creator>Slaats, Tijs</dc:creator>
 <dc:creator>Staples, Mark</dc:creator>
 <dc:creator>Weber, Barbara</dc:creator>
 <dc:creator>Weidlich, Matthias</dc:creator>
 <dc:creator>Weske, Mathias</dc:creator>
 <dc:creator>Xu, Xiwei</dc:creator>
 <dc:creator>Zhu, Liming</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Blockchain technology promises a sizable potential for executing
inter-organizational business processes without requiring a central party
serving as a single point of trust (and failure). This paper analyzes its
impact on business process management (BPM). We structure the discussion using
two BPM frameworks, namely the six BPM core capabilities and the BPM lifecycle.
This paper provides research directions for investigating the application of
blockchain technology to BPM.
</dc:description>
 <dc:description>Comment: 1st revision</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:date>2017-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03610</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03611</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid Beamforming via the Kronecker Decomposition for the
  Millimeter-Wave Massive MIMO Systems</dc:title>
 <dc:creator>Zhu, Guangxu</dc:creator>
 <dc:creator>Huang, Kaibin</dc:creator>
 <dc:creator>Lau, Vincent K. N.</dc:creator>
 <dc:creator>Xia, Bin</dc:creator>
 <dc:creator>Li, Xiaofan</dc:creator>
 <dc:creator>Zhang, Sha</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Despite its promising performance gain, the realization of mmWave massive
MIMO still faces several practical challenges. In particular, implementing
massive MIMO in the digital domain requires hundreds of RF chains matching the
number of antennas. Furthermore, designing these components to operate at the
mmWave frequencies is challenging and costly. These motivated the recent
development of hybrid-beamforming where MIMO processing is divided for separate
implementation in the analog and digital domains, called the analog and digital
beamforming, respectively. Analog beamforming using a phase array introduces
uni-modulus constraints on the beamforming coefficients, rendering the
conventional MIMO techniques unsuitable and call for new designs. In this
paper, we present a systematic design framework for hybrid beamforming for
multi-cell multiuser massive MIMO systems over mmWave channels characterized by
sparse propagation paths. The framework relies on the decomposition of analog
beamforming vectors and path observation vectors into Kronecker products of
factors being uni-modulus vectors. Exploiting properties of Kronecker mixed
products, different factors of the analog beamformer are designed for either
nulling interference paths or coherently combining data paths. Furthermore, a
channel estimation scheme is designed for enabling the proposed hybrid
beamforming. The scheme estimates the AoA of data and interference paths by
analog beam scanning and data-path gains by analog beam steering. The
performance of the channel estimation scheme is analyzed. In particular, the
AoA spectrum resulting from beam scanning, which displays the magnitude
distribution of paths over the AoA range, is derived in closed-form. It is
shown that the inter-cell interference level diminishes inversely with the
array size, the square root of pilot sequence length and the spatial separation
between paths.
</dc:description>
 <dc:description>Comment: Submitted to IEEE JSAC Special Issue on Millimeter Wave
  Communications for Future Mobile Networks, minor revision</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03611</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03612</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding Modes by Probabilistic Hypergraphs Shifting</dc:title>
 <dc:creator>Wang, Yang</dc:creator>
 <dc:creator>Wu, Lin</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper, we develop a novel paradigm, namely hypergraph shift, to find
robust graph modes by probabilistic voting strategy, which are semantically
sound besides the self-cohesiveness requirement in forming graph modes. Unlike
the existing techniques to seek graph modes by shifting vertices based on
pair-wise edges (i.e, an edge with $2$ ends), our paradigm is based on shifting
high-order edges (hyperedges) to deliver graph modes. Specifically, we convert
the problem of seeking graph modes as the problem of seeking maximizers of a
novel objective function with the aim to generate good graph modes based on
sifting edges in hypergraphs. As a result, the generated graph modes based on
dense subhypergraphs may more accurately capture the object semantics besides
the self-cohesiveness requirement. We also formally prove that our technique is
always convergent. Extensive empirical studies on synthetic and real world data
sets are conducted on clustering and graph matching. They demonstrate that our
techniques significantly outperform the existing techniques.
</dc:description>
 <dc:description>Comment: Fixing some minor issues in PAKDD 2014</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03612</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03615</identifier>
 <datestamp>2017-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predictive-Corrective Networks for Action Detection</dc:title>
 <dc:creator>Dave, Achal</dc:creator>
 <dc:creator>Russakovsky, Olga</dc:creator>
 <dc:creator>Ramanan, Deva</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  While deep feature learning has revolutionized techniques for static-image
understanding, the same does not quite hold for video processing. Architectures
and optimization techniques used for video are largely based off those for
static images, potentially underutilizing rich video information. In this work,
we rethink both the underlying network architecture and the stochastic learning
paradigm for temporal data. To do so, we draw inspiration from classic theory
on linear dynamic systems for modeling time series. By extending such models to
include nonlinear mappings, we derive a series of novel recurrent neural
networks that sequentially make top-down predictions about the future and then
correct those predictions with bottom-up observations. Predictive-corrective
networks have a number of desirable properties: (1) they can adaptively focus
computation on &quot;surprising&quot; frames where predictions require large corrections,
(2) they simplify learning in that only &quot;residual-like&quot; corrective terms need
to be learned over time and (3) they naturally decorrelate an input data stream
in a hierarchical fashion, producing a more reliable signal for learning at
each layer of a network. We provide an extensive analysis of our lightweight
and interpretable framework, and demonstrate that our model is competitive with
the two-stream network on three challenging datasets without the need for
computationally expensive optical flow.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2017. [v2]: Updated Multi-LSTM mAP on MultiTHUMOS
  (should be 29.7, was initially reported as 29.6). [Project URL]:
  http://www.achaldave.com/projects/predictive-corrective/</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03615</dc:identifier>
 <dc:identifier>doi:10.1109/CVPR.2017.223</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03617</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Representation Stability as a Regularizer for Improved Text Analytics
  Transfer Learning</dc:title>
 <dc:creator>Riemer, Matthew</dc:creator>
 <dc:creator>Khabiri, Elham</dc:creator>
 <dc:creator>Goodwin, Richard</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Although neural networks are well suited for sequential transfer learning
tasks, the catastrophic forgetting problem hinders proper integration of prior
knowledge. In this work, we propose a solution to this problem by using a
multi-task objective based on the idea of distillation and a mechanism that
directly penalizes forgetting at the shared representation layer during the
knowledge integration phase of training. We demonstrate our approach on a
Twitter domain sentiment analysis task with sequential knowledge transfer from
four related tasks. We show that our technique outperforms networks fine-tuned
to the target task. Additionally, we show both through empirical evidence and
examples that it does not forget useful knowledge from the source task that is
forgotten during standard fine-tuning. Surprisingly, we find that first
distilling a human made rule based sentiment engine into a recurrent neural
network and then integrating the knowledge with the target task data leads to a
substantial gain in generalization performance. Our experiments demonstrate the
power of multi-source transfer techniques in practical text analytics problems
when paired with distillation. In particular, for the SemEval 2016 Task 4
Subtask A (Nakov et al., 2016) dataset we surpass the state of the art
established during the competition with a comparatively simple model
architecture that is not even competitive when trained on only the labeled task
specific data.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03617</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03620</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inter-Operator Resource Management for Millimeter Wave, Multi-Hop
  Backhaul Networks</dc:title>
 <dc:creator>Semiari, Omid</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:creator>Bennis, Mehdi</dc:creator>
 <dc:creator>Dawy, Zaher</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, a novel framework is proposed for optimizing the operation and
performance of a large-scale, multi-hop millimeter wave (mmW) backhaul within a
wireless small cell network (SCN) that encompasses multiple mobile network
operators (MNOs). The proposed framework enables the small base stations (SBSs)
to jointly decide on forming the multi-hop, mmW links over backhaul
infrastructure that belongs to multiple, independent MNOs, while properly
allocating resources across those links. In this regard, the problem is
addressed using a novel framework based on matching theory that is composed to
two, highly inter-related stages: a multi-hop network formation stage and a
resource management stage. One unique feature of this framework is that it
jointly accounts for both wireless channel characteristics and economic factors
during both network formation and resource management. The multi-hop network
formation stage is formulated as a one-to-many matching game which is solved
using a novel algorithm, that builds on the so-called deferred acceptance
algorithm and is shown to yield a stable and Pareto optimal multi-hop mmW
backhaul network. Then, a one-to-many matching game is formulated to enable
proper resource allocation across the formed multi-hop network. This game is
then shown to exhibit peer effects and, as such, a novel algorithm is developed
to find a stable and optimal resource management solution that can properly
cope with these peer effects. Simulation results show that the proposed
framework yields substantial gains, in terms of the average sum rate, reaching
up to 27% and 54%, respectively, compared to a non-cooperative scheme in which
inter-operator sharing is not allowed and a random allocation approach. The
results also show that our framework provides insights on how to manage pricing
and the cost of the cooperative mmW backhaul network for the MNOs.
</dc:description>
 <dc:description>Comment: Accepted in IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03620</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03624</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Loklak - A Distributed Crawler and Data Harvester for Overcoming Rate
  Limits</dc:title>
 <dc:creator>Singanamalla, Sudheesh</dc:creator>
 <dc:creator>Christen, Michael Peter</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Modern social networks have become sources for vast quantities of data.
Having access to such big data can be very useful for various researchers and
data scientists. In this paper we describe Loklak, an open source distributed
peer to peer crawler and scraper for supporting such research on platforms like
Twitter, Weibo and other social networks. Social networks such as Twitter and
Weibo pose various limitations to the user on the rate at which one could
freely collect such data for research. Our crawler enables researchers to
continuously collect data while overcoming the barriers of authentication and
rate limits imposed to provide a repository of open data as a service.
</dc:description>
 <dc:description>Comment: 4 pages, 1 figure</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03624</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03626</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sampling-based speech parameter generation using moment-matching
  networks</dc:title>
 <dc:creator>Takamichi, Shinnosuke</dc:creator>
 <dc:creator>Koriyama, Tomoki</dc:creator>
 <dc:creator>Saruwatari, Hiroshi</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper presents sampling-based speech parameter generation using
moment-matching networks for Deep Neural Network (DNN)-based speech synthesis.
Although people never produce exactly the same speech even if we try to express
the same linguistic and para-linguistic information, typical statistical speech
synthesis produces completely the same speech, i.e., there is no
inter-utterance variation in synthetic speech. To give synthetic speech natural
inter-utterance variation, this paper builds DNN acoustic models that make it
possible to randomly sample speech parameters. The DNNs are trained so that
they make the moments of generated speech parameters close to those of natural
speech parameters. Since the variation of speech parameters is compressed into
a low-dimensional simple prior noise vector, our algorithm has lower
computation cost than direct sampling of speech parameters. As the first step
towards generating synthetic speech that has natural inter-utterance variation,
this paper investigates whether or not the proposed sampling-based generation
deteriorates synthetic speech quality. In evaluation, we compare speech quality
of conventional maximum likelihood-based generation and proposed sampling-based
generation. The result demonstrates the proposed generation causes no
degradation in speech quality.
</dc:description>
 <dc:description>Comment: Submitted to INTERSPEECH 2017</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03626</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03627</identifier>
 <datestamp>2017-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-time On-Demand Crowd-powered Entity Extraction</dc:title>
 <dc:creator>Huang, Ting-Hao 'Kenneth'</dc:creator>
 <dc:creator>Chen, Yun-Nung</dc:creator>
 <dc:creator>Bigham, Jeffrey P.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Output-agreement mechanisms such as ESP Game have been widely used in human
computation to obtain reliable human-generated labels. In this paper, we argue
that a &quot;time-limited&quot; output-agreement mechanism can be used to create a fast
and robust crowd-powered component in interactive systems, particularly
dialogue systems, to extract key information from user utterances on the fly.
Our experiments on Amazon Mechanical Turk using the Airline Travel Information
System (ATIS) dataset showed that the proposed approach achieves high-quality
results with an average response time shorter than 9 seconds.
</dc:description>
 <dc:description>Comment: Accepted by the 5th Edition Of The Collective Intelligence Conference
  (CI 2017) as an oral presentation. Interface code and data are available at:
  https://github.com/windx0303/dialogue-esp-game</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03627</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03636</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy Propagation in Deep Convolutional Neural Networks</dc:title>
 <dc:creator>Wiatowski, Thomas</dc:creator>
 <dc:creator>Grohs, Philipp</dc:creator>
 <dc:creator>B&#xf6;lcskei, Helmut</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Many practical machine learning tasks employ very deep convolutional neural
networks. Such large depths pose formidable computational challenges in
training and operating the network. It is therefore important to understand how
fast the energy contained in the propagated signals (a.k.a. feature maps)
decays across layers. In addition, it is desirable that the feature extractor
generated by the network be informative in the sense of the only signal mapping
to the all-zeros feature vector being the zero input signal. This &quot;trivial
null-space&quot; property can be accomplished by asking for &quot;energy conservation&quot; in
the sense of the energy in the feature vector being proportional to that of the
corresponding input signal. This paper establishes conditions for energy
conservation (and thus for a trivial null-space) for a wide class of deep
convolutional neural network-based feature extractors and characterizes
corresponding feature map energy decay rates. Specifically, we consider general
scattering networks employing the modulus non-linearity and we find that under
mild analyticity and high-pass conditions on the filters (which encompass,
inter alia, various constructions of Weyl-Heisenberg filters, wavelets,
ridgelets, ($\alpha$)-curvelets, and shearlets) the feature map energy decays
at least polynomially fast. For broad families of wavelets and Weyl-Heisenberg
filters, the guaranteed decay rate is shown to be exponential. Moreover, we
provide handy estimates of the number of layers needed to have at least
$((1-\varepsilon)\cdot 100)\%$ of the input signal energy be contained in the
feature vector.
</dc:description>
 <dc:description>Comment: IEEE Transactions on Information Theory, September 2017, to appear</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-09-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03636</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03640</identifier>
 <datestamp>2017-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hardness of classically sampling one clean qubit model with constant
  total variation distance error</dc:title>
 <dc:creator>Morimae, Tomoyuki</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The one clean qubit model (or the DQC1 model) is a restricted model of
quantum computing where only a single input qubit is pure and all other input
qubits are maximally mixed. In spite of the severe restriction, the model can
solve several problems (such as calculating Jones polynomials) whose classical
efficient solutions are not known. Furthermore, it was shown that if the output
probability distribution of the one clean qubit model can be classically
efficiently sampled with a constant multiplicative error, then the polynomial
hierarchy collapses to the second level. Is it possible to improve the
multiplicative error hardness result to a constant total variation distance
error one like other sub-universal quantum computing models such as the IQP
model, the Boson Sampling model, and the Fourier Sampling model? In this paper,
we show that it is indeed possible if we accept a modified version of the
average case hardness conjecture. Interestingly, the anti-concentration lemma
can be easily shown by using the special property of the one clean qubit model
that each output probability is so small that no concentration occurs.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03640</dc:identifier>
 <dc:identifier>Phys. Rev. A 96, 040302(R) (2017)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevA.96.040302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03641</identifier>
 <datestamp>2017-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Optimal Two-Sided Pricing of Congested Networks</dc:title>
 <dc:creator>Wang, Xin</dc:creator>
 <dc:creator>Ma, Richard T. B.</dc:creator>
 <dc:creator>Xu, Yinlong</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Traditionally, Internet Access Providers (APs) only charge end-users for
Internet access services; however, to recoup infrastructure costs and increase
revenues, some APs have recently adopted two-sided pricing schemes under which
both end-users and content providers are charged. Meanwhile, with the rapid
growth of traffic, network congestion could seriously degrade user experiences
and influence providers' utility. To optimize profit and social welfare, APs
and regulators need to design appropriate pricing strategies and regulatory
policies that take the effects of network congestion into consideration. In
this paper, we model two-sided networks under which users' traffic demands are
influenced by exogenous pricing and endogenous congestion parameters and derive
the system congestion under an equilibrium. We characterize the structures and
sensitivities of profit- and welfare-optimal two-sided pricing schemes and
reveal that 1) the elasticity of system throughput plays a crucial role in
determining the structures of optimal pricing, 2) the changes of optimal
pricing under varying AP's capacity and users' congestion sensitivity are
largely driven by the type of data traffic, e.g., text or video, and 3) APs and
regulators will be incentivized to shift from one-sided to two-sided pricing
when APs' capacities and user demand for video traffic grow. Our results can
help APs design optimal two-sided pricing and guide regulators to legislate
desirable policies.
</dc:description>
 <dc:description>Comment: A typo in the proof of Theorem 3.6 is corrected</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-06-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03647</identifier>
 <datestamp>2017-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Component-Based Dual Decomposition Method for the OPF Problem</dc:title>
 <dc:creator>Mhanna, Sleiman</dc:creator>
 <dc:creator>Verbic, Gregor</dc:creator>
 <dc:creator>Chapman, Archie</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper proposes a component-based dual decomposition of the nonconvex AC
optimal power flow (OPF) problem, where the modified dual function is solved in
a distributed fashion. The main contribution of this work is that is
demonstrates that a distributed method with carefully tuned parameters can
converge to globally optimal solutions despite the inherent nonconvexity of the
problem and the absence of theoretical guarantees of convergence. This paper is
the first to conduct extensive numerical analysis resulting in the
identification and tabulation of the algorithmic parameter settings that are
crucial for the convergence of the method on 72 AC OPF test instances.
Moreover, this work provides a deeper insight into the geometry of the modified
Lagrange dual function of the OPF problem and highlights the conditions that
make this function differentiable. This numerical demonstration of convergence
coupled with the scalability and the privacy preserving nature of the proposed
method makes it well suited for smart grid applications such as multi-period
OPF with demand response (DR) and security constrained unit commitment (SCUC)
with contingency constraints and multiple transmission system operators (TSOs).
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03647</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03652</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Abnormal Working Hours: Effect of Rapid Releases and Implications to
  Work Content</dc:title>
 <dc:creator>Claes, Ma&#xeb;lick</dc:creator>
 <dc:creator>M&#xe4;ntyl&#xe4;, Mika</dc:creator>
 <dc:creator>Kuutila, Miikka</dc:creator>
 <dc:creator>Adams, Bram</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  During the past years, overload at work leading to psychological diseases,
such as burnouts, have drawn more public attention. This paper is a preliminary
step toward an analysis of the work patterns and possible indicators of
overload and time pressure on software developers with mining software
repositories approach. We explore the working pattern of developers in the
context of Mozilla Firefox, a large and long-lived open source project. To that
end we investigate the impact of the move from traditional to rapid release
cycle on work pattern. Moreover we compare Mozilla Firefox work pattern with
another Mozilla product, Firefox OS, which has a different release cycle than
Firefox. We find that both projects exhibit healthy working patterns, i.e.
lower activity during the weekends and outside of office hours. Firefox
experiences proportionally more activity on weekends than Firefox OS (Cohen's d
= 0.94). We find that switching to rapid releases has reduced weekend work
(Cohen's d = 1.43) and working during the night (Cohen's d = 0.45). This result
holds even when we limit the analyzes on the hired resources, i.e. considering
only individuals with Mozilla foundation email address, although, the effect
sizes are smaller for weekends (Cohen's d = 0.64) and nights (Cohen's d =
0.23). Moreover, we use dissimilarity word clouds and find that work during the
weekend is more technical while work during the week expresses more positive
sentiment with words like &quot;good&quot; and &quot;nice&quot;. Our results suggest that moving to
rapid releases have positive impact on the work health and work-life-balance of
software engineers. However, caution is needed as our results are based on a
limited set of quantitative data from a single organization.
</dc:description>
 <dc:description>Comment: MSR 2017 conference, short paper</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03652</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03660</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feature Tracking Cardiac Magnetic Resonance via Deep Learning and Spline
  Optimization</dc:title>
 <dc:creator>Vigneault, Davis M.</dc:creator>
 <dc:creator>Xie, Weidi</dc:creator>
 <dc:creator>Bluemke, David A.</dc:creator>
 <dc:creator>Noble, J. Alison</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Feature tracking Cardiac Magnetic Resonance (CMR) has recently emerged as an
area of interest for quantification of regional cardiac function from balanced,
steady state free precession (SSFP) cine sequences. However, currently
available techniques lack full automation, limiting reproducibility. We propose
a fully automated technique whereby a CMR image sequence is first segmented
with a deep, fully convolutional neural network (CNN) architecture, and
quadratic basis splines are fitted simultaneously across all cardiac frames
using least squares optimization. Experiments are performed using data from 42
patients with hypertrophic cardiomyopathy (HCM) and 21 healthy control
subjects. In terms of segmentation, we compared state-of-the-art CNN
frameworks, U-Net and dilated convolution architectures, with and without
temporal context, using cross validation with three folds. Performance relative
to expert manual segmentation was similar across all networks: pixel accuracy
was ~97%, intersection-over-union (IoU) across all classes was ~87%, and IoU
across foreground classes only was ~85%. Endocardial left ventricular
circumferential strain calculated from the proposed pipeline was significantly
different in control and disease subjects (-25.3% vs -29.1%, p = 0.006), in
agreement with the current clinical literature.
</dc:description>
 <dc:description>Comment: Accepted to Functional Imaging and Modeling of the Heart (FIMH) 2017</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03664</identifier>
 <datestamp>2017-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximating Optimization Problems using EAs on Scale-Free Networks</dc:title>
 <dc:creator>Chauhan, Ankit</dc:creator>
 <dc:creator>Friedrich, Tobias</dc:creator>
 <dc:creator>Quinzan, Francesco</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  It has been experimentally observed that real-world networks follow certain
topological properties, such as small-world, power-law etc. To study these
networks, many random graph models, such as Preferential Attachment, have been
proposed.
  In this paper, we consider the deterministic properties which capture
power-law degree distribution and degeneracy. Networks with these properties
are known as scale-free networks in the literature. Many interesting problems
remain NP-hard on scale-free networks. We study the relationship between
scale-free properties and the approximation-ratio of some commonly used
evolutionary algorithms.
  For the Vertex Cover, we observe experimentally that the (1+1)-EA always
gives the better result than a greedy local search, even when it runs for only
$\mathcal{O}(n \log (n))$ steps. We give the construction of a scale-free
network in which the (1+1)-EA takes $\Omega(n^2)$ steps to obtain a solution as
good as the greedy algorithm with constant probability.
  We prove that for the Dominating Set, Vertex Cover, Connected Dominating Set
and Independent Set, the (1+1)-EA obtains constant-factor approximation in
expected run time $\mathcal{O}(n \log (n))$ and $\mathcal{O}(n^4)$
respectively. Whereas, the GSEMO gives even better approximation than (1+1)-EA
in the expected run time of $\mathcal{O}(n^3)$ for Dominating Set, Vertex Cover
and Connected Dominating Set on such networks.
</dc:description>
 <dc:description>Comment: 27 pages, 5 figures, 2 tables and Accepted at GECCO'17</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-06-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03664</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03667</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stigmergy-based modeling to discover urban activity patterns from
  positioning data</dc:title>
 <dc:creator>Alfeo, Antonio L.</dc:creator>
 <dc:creator>Cimino, Mario G. C. A.</dc:creator>
 <dc:creator>Egidi, Sara</dc:creator>
 <dc:creator>Lepri, Bruno</dc:creator>
 <dc:creator>Pentland, Alex</dc:creator>
 <dc:creator>Vaglini, Gigliola</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>I.5.2</dc:subject>
 <dc:description>  Positioning data offer a remarkable source of information to analyze crowds
urban dynamics. However, discovering urban activity patterns from the emergent
behavior of crowds involves complex system modeling. An alternative approach is
to adopt computational techniques belonging to the emergent paradigm, which
enables self-organization of data and allows adaptive analysis. Specifically,
our approach is based on stigmergy. By using stigmergy each sample position is
associated with a digital pheromone deposit, which progressively evaporates and
aggregates with other deposits according to their spatiotemporal proximity.
Based on this principle, we exploit positioning data to identify high density
areas (hotspots) and characterize their activity over time. This
characterization allows the comparison of dynamics occurring in different days,
providing a similarity measure exploitable by clustering techniques. Thus, we
cluster days according to their activity behavior, discovering unexpected urban
activity patterns. As a case study, we analyze taxi traces in New York City
during 2015.
</dc:description>
 <dc:description>Comment: It will be presented at the International Conference on Social,
  Cultural, and Behavioral Modeling &amp; Prediction and Behavior Representation in
  Modeling and Simulation, SBP-BRiMS 2017</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03667</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03669</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dilated Convolutional Neural Networks for Cardiovascular MR Segmentation
  in Congenital Heart Disease</dc:title>
 <dc:creator>Wolterink, Jelmer M.</dc:creator>
 <dc:creator>Leiner, Tim</dc:creator>
 <dc:creator>Viergever, Max A.</dc:creator>
 <dc:creator>I&#x161;gum, Ivana</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose an automatic method using dilated convolutional neural networks
(CNNs) for segmentation of the myocardium and blood pool in cardiovascular MR
(CMR) of patients with congenital heart disease (CHD).
  Ten training and ten test CMR scans cropped to an ROI around the heart were
provided in the MICCAI 2016 HVSMR challenge. A dilated CNN with a receptive
field of 131x131 voxels was trained for myocardium and blood pool segmentation
in axial, sagittal and coronal image slices. Performance was evaluated within
the HVSMR challenge.
  Automatic segmentation of the test scans resulted in Dice indices of
0.80$\pm$0.06 and 0.93$\pm$0.02, average distances to boundaries of
0.96$\pm$0.31 and 0.89$\pm$0.24 mm, and Hausdorff distances of 6.13$\pm$3.76
and 7.07$\pm$3.01 mm for the myocardium and blood pool, respectively.
Segmentation took 41.5$\pm$14.7 s per scan.
  In conclusion, dilated CNNs trained on a small set of CMR images of CHD
patients showing large anatomical variability provide accurate myocardium and
blood pool segmentations.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03669</dc:identifier>
 <dc:identifier>RAMBO 2016, HVSMR 2016. LNCS 10129. pp. 95-102</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-52280-7_9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03670</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Eigenvalues of symmetric tridiagonal interval matrices revisited</dc:title>
 <dc:creator>Hlad&#xed;k, Milan</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>15A18, 65G40</dc:subject>
 <dc:description>  In this short note, we present a novel method for computing exact lower and
upper bounds of a symmetric tridiagonal interval matrix. Compared to the known
methods, our approach is fast, simple to present and to implement, and avoids
any assumptions Our construction explicitly yields those matrices for which
particular lower and upper bounds are attained.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03670</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03672</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Arguing from Hazard Analysis in Safety Cases: A Modular Argument Pattern</dc:title>
 <dc:creator>Gleirscher, Mario</dc:creator>
 <dc:creator>Carlan, Carmen</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We observed that safety arguments are prone to stay too abstract, e.g.
solutions refer to large packages, argument strategies to complex reasoning
steps, contexts and assumptions lack traceability. These issues can reduce the
confidence we require of such arguments. In this paper, we investigate the
construction of confident arguments from (i) hazard analysis (HA) results and
(ii) the design of safety measures, i.e., both used for confidence evaluation.
We present an argument pattern integrating three HA techniques, i.e., FTA,
FMEA, and STPA, as well as the reactions on the results of these analyses,
i.e., safety requirements and design increments. We provide an example of how
our pattern can help in argument construction and discuss steps towards using
our pattern in formal analysis and computer-assisted construction of safety
cases.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03672</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03690</identifier>
 <datestamp>2018-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Symbolic Models for Retarded Jump-Diffusion Systems</dc:title>
 <dc:creator>Jagtap, Pushpak</dc:creator>
 <dc:creator>Zamani, Majid</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>93E99</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:description>  In this paper, we provide for the first time an automated,
correct-by-construction, controller synthesis scheme for a class of infinite
dimensional stochastic systems, namely, retarded jump-diffusion systems. First,
we construct finite dimensional abstractions approximately bisimilar to
original retarded jump-diffusion systems having some stability property,
namely, incremental input-to-state stability. Second, we construct finite
abstractions approximately bisimilar to constructed finite dimensional
abstractions. Both types of abstractions are derived without any state-space
discretization. By using the transitivity property of approximate bisimulation
relations, we establish that the constructed finite abstractions are also
approximately bisimilar to original retarded jump-diffusion systems with a
precision that can be chosen a-priori. Given those finite abstractions, one can
synthesize controllers for original systems satisfying high-level logic
requirements in a systematic way. Moreover, we provide sufficient conditions
for the proposed notion of incremental stability in terms of the existence of
incremental Lyapunov functions which reduce to linear matrix inequalities (LMI)
for the linear systems. Finally, the effectiveness of the results is
illustrated by synthesizing a controller regulating the temperatures in a
ten-room building modeled as a delayed jump-diffusion system.
</dc:description>
 <dc:description>Comment: 19 pages, 4 figures</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03690</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03693</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trainable Referring Expression Generation using Overspecification
  Preferences</dc:title>
 <dc:creator>Ferreira, Thiago castro</dc:creator>
 <dc:creator>Paraboni, Ivandre</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Referring expression generation (REG) models that use speaker-dependent
information require a considerable amount of training data produced by every
individual speaker, or may otherwise perform poorly. In this work we present a
simple REG experiment that allows the use of larger training data sets by
grouping speakers according to their overspecification preferences. Intrinsic
evaluation shows that this method generally outperforms the personalised method
found in previous work.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03693</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03696</identifier>
 <datestamp>2017-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Repair Layering for Erasure-Coded Data Centers: From Theory to
  Practice</dc:title>
 <dc:creator>Hu, Yuchong</dc:creator>
 <dc:creator>Li, Xiaolu</dc:creator>
 <dc:creator>Zhang, Mi</dc:creator>
 <dc:creator>Lee, Patrick P. C.</dc:creator>
 <dc:creator>Zhang, Xiaoyang</dc:creator>
 <dc:creator>Zhou, Pan</dc:creator>
 <dc:creator>Feng, Dan</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Repair performance in hierarchical data centers is often bottlenecked by
cross-rack network transfer. Recent theoretical results show that the
cross-rack repair traffic can be minimized through repair layering, whose idea
is to partition a repair operation into inner-rack and cross-rack layers.
However, how repair layering should be implemented and deployed in practice
remains an open issue. In this paper, we address this issue by proposing a
practical repair layering framework called DoubleR. We design two families of
practical double regenerating codes (DRC), which not only minimize the
cross-rack repair traffic, but also have several practical properties that
improve state-of-the-art regenerating codes. We implement and deploy DoubleR
atop Hadoop Distributed File System (HDFS), and show that DoubleR maintains the
theoretical guarantees of DRC and improves the repair performance of
regenerating codes in both node recovery and degraded read operations.
</dc:description>
 <dc:description>Comment: 24 pages. Accepted by ACM Transactions on Storage</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-09-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03696</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03704</identifier>
 <datestamp>2017-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Full-Duplex Device-to-Device Collaboration for Low-Latency Wireless
  Video Distribution</dc:title>
 <dc:creator>Naslcheraghi, Mansour</dc:creator>
 <dc:creator>Ghorashi, Seyed Ali</dc:creator>
 <dc:creator>Shikh-Bahaei, Mohammad</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Growing demand for video services is the main driver for increasing traffic
in wireless cellular data networks. Wireless video distribution schemes have
recently been proposed to offload data via Device-to-Device (D2D)
communications. These offloading schemes increase capacity and reduce
end-to-end delay in cellular networks and help to serve the dramatically
increasing demand for high quality video. In this paper, we propose a new
scheme for video distribution over cellular networks by exploiting full-duplex
(FD) D2D communication in two scenarios; scenario one: two nodes exchange their
desired video files simultaneously with each other, and scenario two: each node
can concurrently transmit to and receive from two different nodes. In the
latter case, an intermediate transceiver can serve one or multiple users' file
requests whilst capturing its desired file from another device in the vicinity.
Analytic and simulation results are used to compare the proposed scheme with
its half-duplex (HD) counterpart under the same transmitter establishment
criteria to show the achievable gain of FD-D2D scheme in video content
delivery, in terms of sum throughput and latency.
</dc:description>
 <dc:description>Comment: Accepted for publication in 24'th International Conference on
  Telecommunication (ICT 2017)</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03704</dc:identifier>
 <dc:identifier>doi:10.1109/ICT.2017.7998228</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03706</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Object proposal generation applying the distance dependent Chinese
  restaurant process</dc:title>
 <dc:creator>Lauri, Mikko</dc:creator>
 <dc:creator>Frintrop, Simone</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In application domains such as robotics, it is useful to represent the
uncertainty related to the robot's belief about the state of its environment.
Algorithms that only yield a single &quot;best guess&quot; as a result are not
sufficient. In this paper, we propose object proposal generation based on
non-parametric Bayesian inference that allows quantification of the likelihood
of the proposals. We apply Markov chain Monte Carlo to draw samples of image
segmentations via the distance dependent Chinese restaurant process. Our method
achieves state-of-the-art performance on an indoor object discovery data set,
while additionally providing a likelihood term for each proposal. We show that
the likelihood term can effectively be used to rank proposals according to
their quality.
</dc:description>
 <dc:description>Comment: To appear at Scandinavian Conference on Image Analysis (SCIA) 2017</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03706</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03711</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Investigation on the use of Hidden-Markov Models in automatic
  transcription of music</dc:title>
 <dc:creator>Cazau, D.</dc:creator>
 <dc:creator>Nuel, G.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Hidden Markov Models (HMMs) are a ubiquitous tool to model time series data,
and have been widely used in two main tasks of Automatic Music Transcription
(AMT): note segmentation, i.e. identifying the played notes after a multi-pitch
estimation, and sequential post-processing, i.e. correcting note segmentation
using training data. In this paper, we employ the multi-pitch estimation method
called Probabilistic Latent Component Analysis (PLCA), and develop AMT systems
by integrating different HMM-based modules in this framework. For note
segmentation, we use two different twostate on/o? HMMs, including a
higher-order one for duration modeling. For sequential post-processing, we
focused on a musicological modeling of polyphonic harmonic transitions, using a
first- and second-order HMMs whose states are defined through candidate note
mixtures. These different PLCA plus HMM systems have been evaluated
comparatively on two different instrument repertoires, namely the piano (using
the MAPS database) and the marovany zither. Our results show that the use of
HMMs could bring noticeable improvements to transcription results, depending on
the instrument repertoire.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1703.09772</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03711</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03718</identifier>
 <datestamp>2017-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Extreme Multi-label Learning</dc:title>
 <dc:creator>Zhang, Wenjie</dc:creator>
 <dc:creator>Yan, Junchi</dc:creator>
 <dc:creator>Wang, Xiangfeng</dc:creator>
 <dc:creator>Zha, Hongyuan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Extreme multi-label learning (XML) or classification has been a practical and
important problem since the boom of big data. The main challenge lies in the
exponential label space which involves $2^L$ possible label sets when the label
dimension $L$ is very large, e.g., in millions for Wikipedia labels. This paper
is motivated to better explore the label space by building and modeling an
explicit label graph. In the meanwhile, deep learning has been widely studied
and used in various classification problems including multi-label
classification, however it has not been sufficiently studied in this extreme
but practical case, where the label space can be as large as in millions. In
this paper, we propose a practical deep embedding method for extreme
multi-label classification. Our method harvests the ideas of non-linear
embedding and modeling label space with graph priors at the same time.
Extensive experiments on public datasets for XML show that our method performs
competitively against state-of-the-art result.
</dc:description>
 <dc:description>Comment: 9 pages, 8 figures</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-10-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03723</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beliefs in Markov Trees - From Local Computations to Local Valuation</dc:title>
 <dc:creator>K&#x142;opotek, Mieczys&#x142;aw A.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper is devoted to expressiveness of hypergraphs for which uncertainty
propagation by local computations via Shenoy/Shafer method applies. It is
demonstrated that for this propagation method for a given joint belief
distribution no valuation of hyperedges of a hypergraph may provide with
simpler hypergraph structure than valuation of hyperedges by conditional
distributions. This has vital implication that methods recovering belief
networks from data have no better alternative for finding the simplest
hypergraph structure for belief propagation. A method for recovery
tree-structured belief networks has been developed and specialized for
Dempster-Shafer belief functions
</dc:description>
 <dc:description>Comment: Preliminary versioin of conference paper: M.A. K{\l}opotek: Beliefs
  in Markov Trees - From Local Computations to Local Valuation. [in:] R.
  Trappl, Ed.: Cybernetics and Systems Research , Proc. 12th European Meeting
  on Cybernetics and System Research, Vienna 5-8 April 1994, World Scientific
  Publishers, Vol.1. pp. 351-358</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03723</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03724</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Construction of Human Body Models Using Principles of
  Organic Computing</dc:title>
 <dc:creator>Walther, Thomas</dc:creator>
 <dc:creator>W&#xfc;rtz, Rolf P.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:description>  Unsupervised learning of a generalizable model of the visual appearance of
humans from video data is of major importance for computing systems interacting
naturally with their users and others. We propose a step towards automatic
behavior understanding by integrating principles of Organic Computing into the
posture estimation cycle, thereby relegating the need for human intervention
while simultaneously raising the level of system autonomy. The system extracts
coherent motion from moving upper bodies and autonomously decides about limbs
and their possible spatial relationships. The models from many videos are
integrated into meta-models, which show good generalization to different
individuals, backgrounds, and attire. These models allow robust interpretation
of single video frames without temporal continuity and posture mimicking by an
android robot.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03724</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03730</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On computational complexity of Set Automata</dc:title>
 <dc:creator>Rubtsov, Alexander A.</dc:creator>
 <dc:creator>Vyalyi, Mikhail N.</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We consider a computational model which is known as set automata.
  The set automata are one-way finite automata with an additional storage---the
set. There are two kinds of set automata---the deterministic and the
nondeterministic ones. We denote them as DSA and NSA respectively. The model
was introduced by M. Kutrib, A. Malcher, M. Wendlandt in 2014. It was shown
that DSA-languages look similar to DCFL due to their closure properties and
NSA-languages look similar to CFL due to their undecidability properties.
  In this paper we show that this similarity is natural: we prove that
languages recognizable by NSA form a rational cone, so as CFL.
  The main topic of this paper is computational complexity: we prove that
  - languages recognizable by DSA belong to P and there are P-complete
languages among them;
  - languages recognizable by NSA are in NP and there are NP-complete languages
among them;
  - the word membership problem is P-complete for DSA without epsilon-loops and
PSPACE-complete for general DSA;
  - the emptiness problem is in PSPACE for NSA and, moreover, it is
PSPACE-complete for DSA.
</dc:description>
 <dc:description>Comment: 31 pages, an extended version of the conference paper (DLT 2017),
  includes new results and omitted proofs</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03730</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03732</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Q-learning from Demonstrations</dc:title>
 <dc:creator>Hester, Todd</dc:creator>
 <dc:creator>Vecerik, Matej</dc:creator>
 <dc:creator>Pietquin, Olivier</dc:creator>
 <dc:creator>Lanctot, Marc</dc:creator>
 <dc:creator>Schaul, Tom</dc:creator>
 <dc:creator>Piot, Bilal</dc:creator>
 <dc:creator>Horgan, Dan</dc:creator>
 <dc:creator>Quan, John</dc:creator>
 <dc:creator>Sendonaris, Andrew</dc:creator>
 <dc:creator>Dulac-Arnold, Gabriel</dc:creator>
 <dc:creator>Osband, Ian</dc:creator>
 <dc:creator>Agapiou, John</dc:creator>
 <dc:creator>Leibo, Joel Z.</dc:creator>
 <dc:creator>Gruslys, Audrunas</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep reinforcement learning (RL) has achieved several high profile successes
in difficult decision-making problems. However, these algorithms typically
require a huge amount of data before they reach reasonable performance. In
fact, their performance during learning can be extremely poor. This may be
acceptable for a simulator, but it severely limits the applicability of deep RL
to many real-world tasks, where the agent must learn in the real environment.
In this paper we study a setting where the agent may access data from previous
control of the system. We present an algorithm, Deep Q-learning from
Demonstrations (DQfD), that leverages small sets of demonstration data to
massively accelerate the learning process even from relatively small amounts of
demonstration data and is able to automatically assess the necessary ratio of
demonstration data while learning thanks to a prioritized replay mechanism.
DQfD works by combining temporal difference updates with supervised
classification of the demonstrator's actions. We show that DQfD has better
initial performance than Prioritized Dueling Double Deep Q-Networks (PDD DQN)
as it starts with better scores on the first million steps on 41 of 42 games
and on average it takes PDD DQN 83 million steps to catch up to DQfD's
performance. DQfD learns to out-perform the best demonstration given in 14 of
42 games. In addition, DQfD leverages human demonstrations to achieve
state-of-the-art results for 11 games. Finally, we show that DQfD performs
better than three related algorithms for incorporating demonstration data into
DQN.
</dc:description>
 <dc:description>Comment: Published at AAAI 2018. Previously on arxiv as &quot;Learning from
  Demonstrations for Real World Reinforcement Learning&quot;</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03732</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03738</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Counterexample Guided Inductive Optimization</dc:title>
 <dc:creator>Araujo, Rodrigo F.</dc:creator>
 <dc:creator>Albuquerque, Higo F.</dc:creator>
 <dc:creator>de Bessa, Iury V.</dc:creator>
 <dc:creator>Cordeiro, Lucas C.</dc:creator>
 <dc:creator>Filho, Joao Edgar C.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  This paper describes three variants of a counterexample guided inductive
optimization (CEGIO) approach based on Satisfiability Modulo Theories (SMT)
solvers. In particular, CEGIO relies on iterative executions to constrain a
verification procedure, in order to perform inductive generalization, based on
counterexamples extracted from SMT solvers. CEGIO is able to successfully
optimize a wide range of functions, including non-linear and non-convex
optimization problems based on SMT solvers, in which data provided by
counterexamples are employed to guide the verification engine, thus reducing
the optimization domain. The present algorithms are evaluated using a large set
of benchmarks typically employed for evaluating optimization techniques.
Experimental results show the efficiency and effectiveness of the proposed
algorithms, which find the optimal solution in all evaluated benchmarks, while
traditional techniques are usually trapped by local minima.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03738</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03740</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modelling collaborative services: The COSEMO model</dc:title>
 <dc:creator>Thi, Thanh Thoa Pham</dc:creator>
 <dc:creator>Dinh, Thang Le</dc:creator>
 <dc:creator>Helfert, Markus</dc:creator>
 <dc:creator>Leonard, Michel</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Despite the dominance of the service sector in the last decades, there is
still a need for a strong foundation on service design and innovation. Little
attention has paid on service modelling, particularly in the collaboration
context. Collaboration is considered as one of solutions for surviving or
sustaining the business in the high competitive atmosphere. Collaborative
services require various service providers working together according to
agreements between them, along with service consumers, in order to co-produce
services. In this paper, we address crucial issues in collaborative services
such as collaboration levels, sharing data and processes due to business
inter-dependencies between service stakeholders. Afterward, we propose a model
for Collaborative Service Modelling, which is able to cover identified issues.
We also apply our proposed model to modelling an example of healthcare services
in order to illustrate the relevance of our modelling approach to the matter in
hand.
</dc:description>
 <dc:description>Comment: 5th International Conference on Software and Data Technologies, 9
  pages</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03740</dc:identifier>
 <dc:identifier>doi:10.5220/0002929800790082</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03743</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep-FExt: Deep Feature Extraction for Vessel Segmentation and
  Centerline Prediction</dc:title>
 <dc:creator>Tetteh, Giles</dc:creator>
 <dc:creator>Rempfler, Markus</dc:creator>
 <dc:creator>Menze, Bjoern H.</dc:creator>
 <dc:creator>Zimmer, Claus</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Feature extraction is a very crucial task in image and pixel (voxel)
classification and regression in biomedical image modeling. In this work we
present a machine learning based feature extraction scheme based on inception
models for pixel classification tasks. We extract features under multi-scale
and multi-layer schemes through convolutional operators. Layers of Fully
Convolutional Network are later stacked on this feature extraction layers and
trained end-to-end for the purpose of classification. We test our model on the
DRIVE and STARE public data sets for the purpose of segmentation and centerline
detection and it out performs most existing hand crafted or deterministic
feature schemes found in literature. We achieve an average maximum Dice of 0.85
on the DRIVE data set which out performs the scores from the second human
annotator of this data set. We also achieve an average maximum Dice of 0.85 and
kappa of 0.84 on the STARE data set. Though these datasets are mainly 2-D we
also propose ways of extending this feature extraction scheme to handle 3-D
datasets.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03743</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03751</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enabling Embedded Inference Engine with ARM Compute Library: A Case
  Study</dc:title>
 <dc:creator>Sun, Dawei</dc:creator>
 <dc:creator>Liu, Shaoshan</dc:creator>
 <dc:creator>Gaudiot, Jean-Luc</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  When you need to enable deep learning on low-cost embedded SoCs, is it better
to port an existing deep learning framework or should you build one from
scratch? In this paper, we share our practical experiences of building an
embedded inference engine using ARM Compute Library (ACL). The results show
that, contradictory to conventional wisdoms, for simple models, it takes much
less development time to build an inference engine from scratch compared to
porting existing frameworks. In addition, by utilizing ACL, we managed to build
an inference engine that outperforms TensorFlow by 25%. Our conclusion is that,
on embedded devices, we most likely will use very simple deep learning models
for inference, and with well-developed building blocks such as ACL, it may be
better in both performance and development time to build the engine from
scratch.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03751</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03754</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Proof of Orthogonal Double Machine Learning with $Z$-Estimators</dc:title>
 <dc:creator>Syrgkanis, Vasilis</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We consider two stage estimation with a non-parametric first stage and a
generalized method of moments second stage, in a simpler setting than
(Chernozhukov et al. 2016). We give an alternative proof of the theorem given
in (Chernozhukov et al. 2016) that orthogonal second stage moments, sample
splitting and $n^{1/4}$-consistency of the first stage, imply
$\sqrt{n}$-consistency and asymptotic normality of second stage estimates. Our
proof is for a variant of their estimator, which is based on the empirical
version of the moment condition (Z-estimator), rather than a minimization of a
norm of the empirical vector of moments (M-estimator). This note is meant
primarily for expository purposes, rather than as a new technical contribution.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03754</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03755</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised part learning for visual recognition</dc:title>
 <dc:creator>Sicre, Ronan</dc:creator>
 <dc:creator>Avrithis, Yannis</dc:creator>
 <dc:creator>Kijak, Ewa</dc:creator>
 <dc:creator>Jurie, Frederic</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Part-based image classification aims at representing categories by small sets
of learned discriminative parts, upon which an image representation is built.
Considered as a promising avenue a decade ago, this direction has been
neglected since the advent of deep neural networks. In this context, this paper
brings two contributions: first, it shows that despite the recent success of
end-to-end holistic models, explicit part learning can boosts classification
performance. Second, this work proceeds one step further than recent part-based
models (PBM), focusing on how to learn parts without using any labeled data.
Instead of learning a set of parts per class, as generally done in the PBM
literature, the proposed approach both constructs a partition of a given set of
images into visually similar groups, and subsequently learn a set of
discriminative parts per group in a fully unsupervised fashion. This strategy
opens the door to the use of PBM in new applications for which the notion of
image categories is irrelevant, such as instance-based image retrieval, for
example. We experimentally show that our learned parts can help building
efficient image representations, for classification as well as for indexing
tasks, resulting in performance superior to holistic state-of-the art Deep
Convolutional Neural Networks (DCNN) encoding.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03755</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03758</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the complexity of finding and counting solution-free sets of integers</dc:title>
 <dc:creator>Meeks, Kitty</dc:creator>
 <dc:creator>Treglown, Andrew</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Given a linear equation $\mathcal{L}$, a set $A$ of integers is
$\mathcal{L}$-free if $A$ does not contain any `non-trivial' solutions to
$\mathcal{L}$. This notion incorporates many central topics in combinatorial
number theory such as sum-free and progression-free sets. In this paper we
initiate the study of (parameterised) complexity questions involving
$\mathcal{L}$-free sets of integers. The main questions we consider involve
deciding whether a finite set of integers $A$ has an $\mathcal{L}$-free subset
of a given size, and counting all such $\mathcal{L}$-free subsets. We also
raise a number of open problems.
</dc:description>
 <dc:description>Comment: 27 pages</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03758</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03761</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From ds-bounds for cyclic codes to true distance for abelian codes</dc:title>
 <dc:creator>Bernal, J. J.</dc:creator>
 <dc:creator>Guerreiro, M.</dc:creator>
 <dc:creator>Sim&#xf3;n, J. J.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94B65 (primary), 13M10 (secondary)</dc:subject>
 <dc:subject>E.4</dc:subject>
 <dc:description>  In this paper we develop a technique to extend any bound for the minimum
distance of cyclic codes constructed from its defining sets (ds-bounds) to
abelian (or multivariate) codes through the notion of $\mathbb{B}$-apparent
distance. We use this technique to improve the searching for new bounds for the
minimum distance of abelian codes. We also study conditions for an abelian code
to verify that its $\mathbb{B}$-apparent distance reaches its (true) minimum
distance. Then we construct some tables of such codes as an application
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1604.02949</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03761</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03764</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NG2C: Pretenuring N-Generational GC for HotSpot Big Data Applications</dc:title>
 <dc:creator>Bruno, Rodrigo</dc:creator>
 <dc:creator>Oliveira, Lu&#xed;s</dc:creator>
 <dc:creator>Ferreira, Paulo</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Big Data applications suffer from unpredictable and unacceptably high pause
times due to Garbage Collection (GC). This is the case in latency-sensitive
applications such as on-line credit-card fraud detection, graph-based computing
for analysis on social networks, etc. Such pauses compromise latency
requirements of the whole application stack and result from applications'
aggressive buffering/caching of data, exposing an ill-suited GC design, which
assumes that most objects will die young and does not consider that
applications hold large amounts of middle-lived data in memory.
  To avoid such pauses, we propose NG2C, a new GC algorithm that combines
pretenuring with an N-Generational heap. By being able to allocate objects into
different generations, NG2C is able to group objects with similar lifetime
profiles in the same generation. By allocating objects with similar lifetime
profiles close to each other, i.e. in the same generation, we avoid object
promotion (copying between generations) and heap fragmentation (which leads to
heap compactions) both responsible for most of the duration of HotSpot GC pause
times.
  NG2C is implemented for the OpenJDK 8 HotSpot Java Virtual Machine, as an
extension of the Garbage First GC. We evaluate NG2C using Cassandra, Lucene,
and GraphChi with three different GCs: Garbage First (G1), Concurrent Mark
Sweep (CMS), and NG2C. Results show that NG2C decreases the worst observable GC
pause time by up to 94.8% for Cassandra, 85.0% for Lucene and 96.45% for
GraphChi, when compared to current collectors (G1 and CMS). In addition, NG2C
has no negative impact on application throughput or memory usage.
</dc:description>
 <dc:description>Comment: Accepted at ISMM'17</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03764</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03767</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallelized Kendall's Tau Coefficient Computation via SIMD Vectorized
  Sorting On Many-Integrated-Core Processors</dc:title>
 <dc:creator>Liu, Yongchao</dc:creator>
 <dc:creator>Pan, Tony</dc:creator>
 <dc:creator>Green, Oded</dc:creator>
 <dc:creator>Aluru, Srinivas</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Pairwise association measure is an important operation in data analytics.
Kendall's tau coefficient is one widely used correlation coefficient
identifying non-linear relationships between ordinal variables. In this paper,
we investigated a parallel algorithm accelerating all-pairs Kendall's tau
coefficient computation via single instruction multiple data (SIMD) vectorized
sorting on Intel Xeon Phis by taking advantage of many processing cores and
512-bit SIMD vector instructions. To facilitate workload balancing and overcome
on-chip memory limitation, we proposed a generic framework for symmetric
all-pairs computation by building provable bijective functions between job
identifier and coordinate space. Performance evaluation demonstrated that our
algorithm on one 5110P Phi achieves two orders-of-magnitude speedups over
16-threaded MATLAB and three orders-of-magnitude speedups over sequential R,
both running on high-end CPUs. Besides, our algorithm exhibited rather good
distributed computing scalability with respect to number of Phis. Source code
and datasets are publicly available at http://lightpcc.sourceforge.net.
</dc:description>
 <dc:description>Comment: 29 pages, 6 figures, 5 tables, submitted to Journal of Parallel and
  Distributed Computing</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03767</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03768</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The scientific influence of nations on global scientific and
  technological development</dc:title>
 <dc:creator>Patelli, Aurelio</dc:creator>
 <dc:creator>Cimini, Giulio</dc:creator>
 <dc:creator>Pugliese, Emanuele</dc:creator>
 <dc:creator>Gabrielli, Andrea</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Determining how scientific achievements influence the subsequent process of
knowledge creation is a fundamental step in order to build a unified ecosystem
for studying the dynamics of innovation and competitiveness. Relying separately
on data about scientific production on one side, through bibliometric
indicators, and about technological advancements on the other side, through
patents statistics, gives only a limited insight on the key interplay between
science and technology which, as a matter of fact, move forward together within
the innovation space. In this paper, using citation data of both research
papers and patents, we quantify the direct influence of the scientific outputs
of nations on further advancements in science and on the introduction of new
technologies. Our analysis highlights the presence of geo-cultural clusters of
nations with similar innovation system features, and unveils the heterogeneous
coupled dynamics of scientific and technological advancements. This study
represents a step forward in the buildup of an inclusive framework for
knowledge creation and innovation.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03768</dc:identifier>
 <dc:identifier>Journal of Informetrics 11(4), 1229-1237 (2017)</dc:identifier>
 <dc:identifier>doi:10.1016/j.joi.2017.10.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03772</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>$\aleph1 AND THE MODAL $\mu$-CALCULUS</dc:title>
 <dc:creator>Gouveia, Maria Joao</dc:creator>
 <dc:creator>Santocanale, Luigi</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  For a regular cardinal $\kappa$, a formula of the modal $\mu$-calculus is
$\kappa$-continuous in a variable x if, on every model, its interpretation as a
unary function of x is monotone and preserves unions of $\kappa$-directed sets.
We define the fragment C $\aleph 1 (x) of the modal $\mu$-calculus and prove
that all the formulas in this fragment are $\aleph 1-continuous. For each
formula $\phi$(x) of the modal $\mu$-calculus, we construct a formula $\psi$(x)
$\in$ C $\aleph 1 (x) such that $\phi$(x) is $\kappa$-continuous, for some
$\kappa$, if and only if $\phi$(x) is equivalent to $\psi$(x). Consequently, we
prove that (i) the problem whether a formula is $\kappa$-continuous for some
$\kappa$ is decidable, (ii) up to equivalence, there are only two fragments
determined by continuity at some regular cardinal: the fragment C $\aleph 0 (x)
studied by Fontaine and the fragment C $\aleph 1 (x). We apply our
considerations to the problem of characterizing closure ordinals of formulas of
the modal $\mu$-calculus. An ordinal $\alpha$ is the closure ordinal of a
formula $\phi$(x) if its interpretation on every model converges to its least
fixed-point in at most $\alpha$ steps and if there is a model where the
convergence occurs exactly in $\alpha$ steps. We prove that $\omega$ 1 , the
least uncountable ordinal, is such a closure ordinal. Moreover we prove that
closure ordinals are closed under ordinal sum. Thus, any formal expression
built from 0, 1, $\omega$, $\omega$ 1 by using the binary operator symbol +
gives rise to a closure ordinal.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03772</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03777</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal strategies for weighted ray search</dc:title>
 <dc:creator>Angelopoulos, Spyros</dc:creator>
 <dc:creator>Panagiotou, Konstantinos</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Searching for a hidden target is an important algorithmic paradigm with
numerous applications. We introduce and study the general setting in which a
number of targets, each with a certain weight, are hidden in a star-like
environment that consists of $m$ infinite, concurrent rays, with a common
origin. A mobile searcher, initially located at the origin, explores this
environment in order to locate a set of targets whose aggregate weight is at
least a given value $W$. The cost of the search strategy is defined as the
total distance traversed by the searcher, and its performance is evaluated by
the worst-case ratio of the cost incurred by the searcher over the cost of an
on optimal, offline strategy with (some) access to the instance. This setting
is a broad generalization of well-studied problems in search theory; namely, it
generalizes the setting in which only a single target is sought, as well as the
case in which all targets have unit weights.
  We consider two models depending on the amount of information allowed to the
offline algorithm. In the first model, which is the canonical model in search
theory, the offline algorithm has complete information. Here, we propose and
analyze a strategy that attains optimal performance, using a parameterized
approach. In the second model, the offline algorithm has only partial
information on the problem instance (i.e., the target locations). Here, we
present a strategy of asymptotically optimal performance that is
logarithmically related to $m$. This is in stark contrast to the full
information model in which a linear dependency is unavoidable.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03777</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03801</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ensemble classifier approach in breast cancer detection and malignancy
  grading- A review</dc:title>
 <dc:creator>Ameta, Deepti</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The diagnosed cases of Breast cancer is increasing annually and unfortunately
getting converted into a high mortality rate. Cancer, at the early stages, is
hard to detect because the malicious cells show similar properties (density) as
shown by the non-malicious cells. The mortality ratio could have been minimized
if the breast cancer could have been detected in its early stages. But the
current systems have not been able to achieve a fully automatic system which is
not just capable of detecting the breast cancer but also can detect the stage
of it. Estimation of malignancy grading is important in diagnosing the degree
of growth of malicious cells as well as in selecting a proper therapy for the
patient. Therefore, a complete and efficient clinical decision support system
is proposed which is capable of achieving breast cancer malignancy grading
scheme very efficiently. The system is based on Image processing and machine
learning domains. Classification Imbalance problem, a machine learning problem,
occurs when instances of one class is much higher than the instances of the
other class resulting in an inefficient classification of samples and hence a
bad decision support system. Therefore EUSBoost, ensemble based classifier is
proposed which is efficient and is able to outperform other classifiers as it
takes the benefits of both-boosting algorithm with Random Undersampling
techniques. Also comparison of EUSBoost with other techniques is shown in the
paper.
</dc:description>
 <dc:description>Comment: 10 pages,1 figure,5 tables</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03801</dc:identifier>
 <dc:identifier>International Journal of Managing Public Sector Information and
  Communication Technologies (IJMPICT) Vol. 8, No. 1, March 2017</dc:identifier>
 <dc:identifier>doi:10.5121/ijmpict.2017.8102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03805</identifier>
 <datestamp>2017-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attention-Set based Metric Learning for Video Face Recognition</dc:title>
 <dc:creator>Hu, Yibo</dc:creator>
 <dc:creator>Wu, Xiang</dc:creator>
 <dc:creator>He, Ran</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Face recognition has made great progress with the development of deep
learning. However, video face recognition (VFR) is still an ongoing task due to
various illumination, low-resolution, pose variations and motion blur. Most
existing CNN-based VFR methods only obtain a feature vector from a single image
and simply aggregate the features in a video, which less consider the
correlations of face images in one video. In this paper, we propose a novel
Attention-Set based Metric Learning (ASML) method to measure the statistical
characteristics of image sets. It is a promising and generalized extension of
Maximum Mean Discrepancy with memory attention weighting. First, we define an
effective distance metric on image sets, which explicitly minimizes the
intra-set distance and maximizes the inter-set distance simultaneously. Second,
inspired by Neural Turing Machine, a Memory Attention Weighting is proposed to
adapt set-aware global contents. Then ASML is naturally integrated into CNNs,
resulting in an end-to-end learning scheme. Our method achieves
state-of-the-art performance for the task of video face recognition on the
three widely used benchmarks including YouTubeFace, YouTube Celebrities and
Celebrity-1000.
</dc:description>
 <dc:description>Comment: modify for ACPR</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03805</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03809</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Neural Parametric Singing Synthesizer</dc:title>
 <dc:creator>Blaauw, Merlijn</dc:creator>
 <dc:creator>Bonada, Jordi</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present a new model for singing synthesis based on a modified version of
the WaveNet architecture. Instead of modeling raw waveform, we model features
produced by a parametric vocoder that separates the influence of pitch and
timbre. This allows conveniently modifying pitch to match any target melody,
facilitates training on more modest dataset sizes, and significantly reduces
training and generation times. Our model makes frame-wise predictions using
mixture density outputs rather than categorical outputs in order to reduce the
required parameter count. As we found overfitting to be an issue with the
relatively small datasets used in our experiments, we propose a method to
regularize the model and make the autoregressive generation process more robust
to prediction errors. Using a simple multi-stream architecture, harmonic,
aperiodic and voiced/unvoiced components can all be predicted in a coherent
manner. We compare our method to existing parametric statistical and
state-of-the-art concatenative methods using quantitative metrics and a
listening test. While naive implementations of the autoregressive generation
algorithm tend to be inefficient, using a smart algorithm we can greatly speed
up the process and obtain a system that's competitive in both speed and
quality.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03809</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03816</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Quadratic Cheap Talk and Signaling Games</dc:title>
 <dc:creator>Sar&#x131;ta&#x15f;, Serkan</dc:creator>
 <dc:creator>Y&#xfc;ksel, Serdar</dc:creator>
 <dc:creator>Gezici, Sinan</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Simultaneous (Nash) and sequential (Stackelberg) equilibria of two-player
dynamic quadratic cheap talk and signaling game problems are investigated under
a perfect Bayesian formulation. For the dynamic scalar cheap talk, a zero-delay
communication setup is considered for i.i.d. and Markov sources; it is shown
that the final stage equilibrium is always quantized and under further
restrictive conditions the equilibria for all time stages are quantized.
Contrarily, the Stackelberg equilibria are always fully revealing for both
scalar and multi-dimensional sources. In the dynamic signaling game where the
transmission of a Gauss-Markov source over a memoryless Gaussian channel is
considered, affine policies constitute an invariant subspace under best
response maps for both scalar and multi-dimensional sources under Nash
equilibria; whereas the Stackelberg equilibria always admit linear policies for
scalar sources but such policies may be non-linear for multi-dimensional
sources. A dynamic programming formulation is presented for multi-dimensional
sources for optimal linear encoding policies, and conditions under which the
Stackelberg equilibria are non-informative are derived.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03816</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03817</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MAGAN: Margin Adaptation for Generative Adversarial Networks</dc:title>
 <dc:creator>Wang, Ruohan</dc:creator>
 <dc:creator>Cully, Antoine</dc:creator>
 <dc:creator>Chang, Hyung Jin</dc:creator>
 <dc:creator>Demiris, Yiannis</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose the Margin Adaptation for Generative Adversarial Networks (MAGANs)
algorithm, a novel training procedure for GANs to improve stability and
performance by using an adaptive hinge loss function. We estimate the
appropriate hinge loss margin with the expected energy of the target
distribution, and derive principled criteria for when to update the margin. We
prove that our method converges to its global optimum under certain
assumptions. Evaluated on the task of unsupervised image generation, the
proposed training procedure is simple yet robust on a diverse set of data, and
achieves qualitative and quantitative improvements compared to the
state-of-the-art.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03817</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03822</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Connecting Look and Feel: Associating the visual and tactile properties
  of physical materials</dc:title>
 <dc:creator>Yuan, Wenzhen</dc:creator>
 <dc:creator>Wang, Shaoxiong</dc:creator>
 <dc:creator>Dong, Siyuan</dc:creator>
 <dc:creator>Adelson, Edward</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  For machines to interact with the physical world, they must understand the
physical properties of objects and materials they encounter. We use fabrics as
an example of a deformable material with a rich set of mechanical properties. A
thin flexible fabric, when draped, tends to look different from a heavy stiff
fabric. It also feels different when touched. Using a collection of 118 fabric
sample, we captured color and depth images of draped fabrics along with tactile
data from a high resolution touch sensor. We then sought to associate the
information from vision and touch by jointly training CNNs across the three
modalities. Through the CNN, each input, regardless of the modality, generates
an embedding vector that records the fabric's physical property. By comparing
the embeddings, our system is able to look at a fabric image and predict how it
will feel, and vice versa. We also show that a system jointly trained on vision
and touch data can outperform a similar system trained only on visual data when
tested purely with visual inputs.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03822</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03834</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Neural Network Based Precursor microRNA Prediction on Eleven
  Species</dc:title>
 <dc:creator>Thomas, Jaya</dc:creator>
 <dc:creator>Sael, Lee</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  MicroRNA (miRNA) are small non-coding RNAs that regulates the gene expression
at the post-transcriptional level. Determining whether a sequence segment is
miRNA is experimentally challenging. Also, experimental results are sensitive
to the experimental environment. These limitations inspire the development of
computational methods for predicting the miRNAs. We propose a deep learning
based classification model, called DP-miRNA, for predicting precursor miRNA
sequence that contains the miRNA sequence. The feature set based Restricted
Boltzmann Machine method, which we call DP-miRNA, uses 58 features that are
categorized into four groups: sequence features, folding measures, stem-loop
features and statistical feature. We evaluate the performance of the DP-miRNA
on eleven twelve data sets of varying species, including the human. The deep
neural network based classification outperformed support vector machine, neural
network, naive Baye's classifiers, k-nearest neighbors, random forests, and a
hybrid system combining support vector machine and genetic algorithm.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures, extended from BigComp2017 short paper</dc:description>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03834</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03844</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Determining Song Similarity via Machine Learning Techniques and Tagging
  Information</dc:title>
 <dc:creator>Cunha, Renato L. F.</dc:creator>
 <dc:creator>Caldeira, Evandro</dc:creator>
 <dc:creator>Fujii, Luciana</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The task of determining item similarity is a crucial one in a recommender
system. This constitutes the base upon which the recommender system will work
to determine which items are more likely to be enjoyed by a user, resulting in
more user engagement. In this paper we tackle the problem of determining song
similarity based solely on song metadata (such as the performer, and song
title) and on tags contributed by users. We evaluate our approach under a
series of different machine learning algorithms. We conclude that tf-idf
achieves better results than Word2Vec to model the dataset to feature vectors.
We also conclude that k-NN models have better performance than SVMs and Linear
Regression for this problem.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03844</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03847</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic3D.net: A new Large-scale Point Cloud Classification Benchmark</dc:title>
 <dc:creator>Hackel, Timo</dc:creator>
 <dc:creator>Savinov, Nikolay</dc:creator>
 <dc:creator>Ladicky, Lubor</dc:creator>
 <dc:creator>Wegner, Jan D.</dc:creator>
 <dc:creator>Schindler, Konrad</dc:creator>
 <dc:creator>Pollefeys, Marc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents a new 3D point cloud classification benchmark data set
with over four billion manually labelled points, meant as input for data-hungry
(deep) learning methods. We also discuss first submissions to the benchmark
that use deep convolutional neural networks (CNNs) as a work horse, which
already show remarkable performance improvements over state-of-the-art. CNNs
have become the de-facto standard for many tasks in computer vision and machine
learning like semantic segmentation or object detection in images, but have no
yet led to a true breakthrough for 3D point cloud labelling tasks due to lack
of training data. With the massive data set presented in this paper, we aim at
closing this data gap to help unleash the full potential of deep learning
methods for 3D labelling tasks. Our semantic3D.net data set consists of dense
point clouds acquired with static terrestrial laser scanners. It contains 8
semantic classes and covers a wide range of urban outdoor scenes: churches,
streets, railroad tracks, squares, villages, soccer fields and castles. We
describe our labelling interface and show that our data set provides more dense
and complete point clouds with much higher overall number of labelled points
compared to those already available to the research community. We further
provide baseline method descriptions and comparison between methods submitted
to our online system. We hope semantic3D.net will pave the way for deep
learning methods in 3D point cloud labelling to learn richer, more general 3D
representations, and first submissions after only a few months indicate that
this might indeed be the case.
</dc:description>
 <dc:description>Comment: Accepted to ISPRS Annals. The benchmark website is available at
  http://www.semantic3d.net/ . The baseline code is available at
  https://github.com/nsavinov/semantic3dnet</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03847</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03851</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Numerical solution of time-dependent problems with fractional power
  elliptic operator</dc:title>
 <dc:creator>Vabishchevich, Petr N.</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>26A33, 35R11, 65F60, 65M06</dc:subject>
 <dc:description>  An unsteady problem is considered for a space-fractional equation in a
bounded domain. A first-order evolutionary equation involves a fractional power
of an elliptic operator of second order. Finite element approximation in space
is employed. To construct approximation in time, standard two-level schemes are
used. The approximate solution at a new time-level is obtained as a solution of
a discrete problem with the fractional power of the elliptic operator. A
Pade-type approximation is constructed on the basis of special quadrature
formulas for an integral representation of the fractional power elliptic
operator using explicit schemes. A similar approach is applied in the numerical
implementation of implicit schemes. The results of numerical experiments are
presented for a test two-dimensional problem.
</dc:description>
 <dc:description>Comment: 25 pages, 13 figures, 6 tables. arXiv admin note: text overlap with
  arXiv:1510.08297, arXiv:1412.5706</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03851</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03864</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Matrix Expander Chernoff Bound</dc:title>
 <dc:creator>Garg, Ankit</dc:creator>
 <dc:creator>Lee, Yin Tat</dc:creator>
 <dc:creator>Song, Zhao</dc:creator>
 <dc:creator>Srivastava, Nikhil</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We prove a Chernoff-type bound for sums of matrix-valued random variables
sampled via a random walk on an expander, confirming a conjecture due to
Wigderson and Xiao. Our proof is based on a new multi-matrix extension of the
Golden-Thompson inequality which improves in some ways the inequality of
Sutter, Berta, and Tomamichel, and may be of independent interest, as well as
an adaptation of an argument for the scalar case due to Healy. Secondarily, we
also provide a generic reduction showing that any concentration inequality for
vector-valued martingales implies a concentration inequality for the
corresponding expander walk, with a weakening of parameters proportional to the
squared mixing time.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03864</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03866</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robustly Learning a Gaussian: Getting Optimal Error, Efficiently</dc:title>
 <dc:creator>Diakonikolas, Ilias</dc:creator>
 <dc:creator>Kamath, Gautam</dc:creator>
 <dc:creator>Kane, Daniel M.</dc:creator>
 <dc:creator>Li, Jerry</dc:creator>
 <dc:creator>Moitra, Ankur</dc:creator>
 <dc:creator>Stewart, Alistair</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the fundamental problem of learning the parameters of a
high-dimensional Gaussian in the presence of noise -- where an
$\varepsilon$-fraction of our samples were chosen by an adversary. We give
robust estimators that achieve estimation error $O(\varepsilon)$ in the total
variation distance, which is optimal up to a universal constant that is
independent of the dimension.
  In the case where just the mean is unknown, our robustness guarantee is
optimal up to a factor of $\sqrt{2}$ and the running time is polynomial in $d$
and $1/\epsilon$. When both the mean and covariance are unknown, the running
time is polynomial in $d$ and quasipolynomial in $1/\varepsilon$. Moreover all
of our algorithms require only a polynomial number of samples. Our work shows
that the same sorts of error guarantees that were established over fifty years
ago in the one-dimensional setting can also be achieved by efficient algorithms
in high-dimensional settings.
</dc:description>
 <dc:description>Comment: To appear in SODA 2018</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03866</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03867</identifier>
 <datestamp>2017-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Conceptual Model for the Organisational Adoption of Information System
  Security Innovations</dc:title>
 <dc:creator>Hameed, Mumtaz Abdul</dc:creator>
 <dc:creator>Arachchilage, Nalin Asanka Gamagedara</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Information System (IS) Security threats is still a major concern for many
organisations. However, most organisations fall short in achieving a successful
adoption and implementation of IS security measures. In this paper, we
developed a theoretical model for the adoption process of IS Security
innovations in organisations. The model was derived by combining four
theoretical models of innovation adoption, namely: Diffusion of Innovation
theory (DOI), the Technology Acceptance Model (TAM), the Theory of Planned
Behaviour (TPB) and the Technology-Organisation-Environment (TOE) framework.
The model depicts IS security innovation adoption in organisations, as two
decision proceedings. The adoption process from the initiation stage until the
acquisition of innovation is considered as a decision made by organisation
while the process of innovation assimilation is assumed as a result of the user
acceptance of innovation within the organisation. In addition, the model
describes the IS Security adoption process progressing in three sequential
stages, i.e. pre-adoption, adoption- decision and post-adoption phases. The
model also introduces several factors that influence the different stages of IS
Security innovation adoption process. This study contributes to IS security
literature by proposing an overall model of IS security adoption that includes
organisational adoption and user acceptance of innovation in a single
illustration. Also, IS security adoption model proposed in this study provides
important practical implications for research and practice.
</dc:description>
 <dc:description>Comment: 38 pages. arXiv admin note: substantial text overlap with
  arXiv:1609.07911</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-05-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03867</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03873</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Architectural Challenges and Solutions for Collocated LWIP - A Network
  Layer Perspective</dc:title>
 <dc:creator>Pasca, Thomas S Valerrian</dc:creator>
 <dc:creator>Amogh, P C</dc:creator>
 <dc:creator>Mishra, Debashisha</dc:creator>
 <dc:creator>Dheeravath, Nagamani</dc:creator>
 <dc:creator>Rangisetti, Anil Kumar</dc:creator>
 <dc:creator>Tamma, Bheemarjuna Reddy</dc:creator>
 <dc:creator>Franklin, Antony A</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Achieving a tighter level of aggregation between LTE and Wi-Fi networks at
the radio access network (a.k.a. LTE-Wi-Fi Aggregation or LWA) has become one
of the most prominent solutions in the era of 5G to boost network capacity and
improve end user's quality of experience. LWA offers flexible resource
scheduling decisions for steering user traffic via LTE and Wi-Fi links. In this
work, we propose a Collocated LTE/WLAN Radio Level Integration architecture at
IP layer (C-LWIP), an enhancement over 3GPP non-collocated LWIP architecture.
We have evaluated C-LWIP performance in various link aggregation strategies
(LASs). A C-LWIP node (i.e., the node having collocated, aggregated LTE eNodeB
and Wi-Fi access point functionalities) is implemented in NS-3 which introduces
a traffic steering layer (i.e., Link Aggregation Layer) for efficient
integration of LTE and Wi-Fi. Using extensive simulations, we verified the
correctness of C-LWIP module in NS-3 and evaluated the aggregation benefits
over standalone LTE and Wi-Fi networks with respect to varying number of users
and traffic types. We found that split bearer performs equivalently to switched
bearer for UDP flows and switched bearer outperforms split bearer in the case
of TCP flows. Also, we have enumerated the potential challenges to be addressed
for unleashing C-LWIP capabilities. Our findings also include WoD-Link
Aggregation Strategy which is shown to improve system throughput by 50% as
compared to Naive-LAS in a densely populated indoor stadium environment.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03873</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03885</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lago Distributed Network Of Data Repositories</dc:title>
 <dc:creator>Asorey, H.</dc:creator>
 <dc:creator>Mart&#xed;nez-M&#xe9;ndez, A.</dc:creator>
 <dc:creator>N&#xfa;&#xf1;ez, L. A.</dc:creator>
 <dc:creator>Valbuena-Delgado, A.</dc:creator>
 <dc:creator>Collaboration, for the LAGO</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  We describe a set of tools, services and strategies of the Latin American
Giant Observatory (LAGO) data repository network, to implement Data
Accessibility, Reproducibility and Trustworthiness.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03885</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03886</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Threshold Design for Quanta Image Sensor</dc:title>
 <dc:creator>Elgendy, Omar A.</dc:creator>
 <dc:creator>Chan, Stanley H.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Quanta Image Sensor (QIS) is a binary imaging device envisioned to be the
next generation image sensor after CCD and CMOS. Equipped with a massive number
of single photon detectors, the sensor has a threshold $q$ above which the
number of arriving photons will trigger a binary response &quot;1&quot;, or &quot;0&quot;
otherwise. Existing methods in the device literature typically assume that
$q=1$ uniformly. We argue that a spatially varying threshold can significantly
improve the signal-to-noise ratio of the reconstructed image. In this paper, we
present an optimal threshold design framework. We make two contributions.
First, we derive a set of oracle results to theoretically inform the maximally
achievable performance. We show that the oracle threshold should match exactly
with the underlying pixel intensity. Second, we show that around the oracle
threshold there exists a set of thresholds that give asymptotically unbiased
reconstructions. The asymptotic unbiasedness has a phase transition behavior
which allows us to develop a practical threshold update scheme using a
bisection method. Experimentally, the new threshold design method achieves
better rate of convergence than existing methods.
</dc:description>
 <dc:description>Comment: 12 pages main paper, and 8 pages supplementary</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03886</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03892</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximating the Largest Root and Applications to Interlacing Families</dc:title>
 <dc:creator>Anari, Nima</dc:creator>
 <dc:creator>Gharan, Shayan Oveis</dc:creator>
 <dc:creator>Saberi, Amin</dc:creator>
 <dc:creator>Srivastava, Nikhil</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We study the problem of approximating the largest root of a real-rooted
polynomial of degree $n$ using its top $k$ coefficients and give nearly
matching upper and lower bounds. We present algorithms with running time
polynomial in $k$ that use the top $k$ coefficients to approximate the maximum
root within a factor of $n^{1/k}$ and $1+O(\tfrac{\log n}{k})^2$ when $k\leq
\log n$ and $k&gt;\log n$ respectively. We also prove corresponding
information-theoretic lower bounds of $n^{\Omega(1/k)}$ and
$1+\Omega\left(\frac{\log \frac{2n}{k}}{k}\right)^2$, and show strong lower
bounds for noisy version of the problem in which one is given access to
approximate coefficients.
  This problem has applications in the context of the method of interlacing
families of polynomials, which was used for proving the existence of Ramanujan
graphs of all degrees, the solution of the Kadison-Singer problem, and bounding
the integrality gap of the asymmetric traveling salesman problem. All of these
involve computing the maximum root of certain real-rooted polynomials for which
the top few coefficients are accessible in subexponential time. Our results
yield an algorithm with the running time of $2^{\tilde O(\sqrt[3]n)}$ for all
of them.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03892</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03895</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What's in a Question: Using Visual Questions as a Form of Supervision</dc:title>
 <dc:creator>Ganju, Siddha</dc:creator>
 <dc:creator>Russakovsky, Olga</dc:creator>
 <dc:creator>Gupta, Abhinav</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Collecting fully annotated image datasets is challenging and expensive. Many
types of weak supervision have been explored: weak manual annotations, web
search results, temporal continuity, ambient sound and others. We focus on one
particular unexplored mode: visual questions that are asked about images. The
key observation that inspires our work is that the question itself provides
useful information about the image (even without the answer being available).
For instance, the question &quot;what is the breed of the dog?&quot; informs the AI that
the animal in the scene is a dog and that there is only one dog present. We
make three contributions: (1) providing an extensive qualitative and
quantitative analysis of the information contained in human visual questions,
(2) proposing two simple but surprisingly effective modifications to the
standard visual question answering models that allow them to make use of weak
supervision in the form of unanswered questions associated with images and (3)
demonstrating that a simple data augmentation strategy inspired by our insights
results in a 7.1% improvement on the standard VQA benchmark.
</dc:description>
 <dc:description>Comment: CVPR 2017 Spotlight paper and supplementary</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03895</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03899</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Reinforcement Learning-based Image Captioning with Embedding Reward</dc:title>
 <dc:creator>Ren, Zhou</dc:creator>
 <dc:creator>Wang, Xiaoyu</dc:creator>
 <dc:creator>Zhang, Ning</dc:creator>
 <dc:creator>Lv, Xutao</dc:creator>
 <dc:creator>Li, Li-Jia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Image captioning is a challenging problem owing to the complexity in
understanding the image content and diverse ways of describing it in natural
language. Recent advances in deep neural networks have substantially improved
the performance of this task. Most state-of-the-art approaches follow an
encoder-decoder framework, which generates captions using a sequential
recurrent prediction model. However, in this paper, we introduce a novel
decision-making framework for image captioning. We utilize a &quot;policy network&quot;
and a &quot;value network&quot; to collaboratively generate captions. The policy network
serves as a local guidance by providing the confidence of predicting the next
word according to the current state. Additionally, the value network serves as
a global and lookahead guidance by evaluating all possible extensions of the
current state. In essence, it adjusts the goal of predicting the correct words
towards the goal of generating captions similar to the ground truth captions.
We train both networks using an actor-critic reinforcement learning model, with
a novel reward defined by visual-semantic embedding. Extensive experiments and
analyses on the Microsoft COCO dataset show that the proposed framework
outperforms state-of-the-art approaches across different evaluation metrics.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03899</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03911</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Persistent Spread Measurement for Big Network Data Based on Register
  Intersection</dc:title>
 <dc:creator>Zhou, You</dc:creator>
 <dc:creator>Zhou, Yian</dc:creator>
 <dc:creator>Chen, Min</dc:creator>
 <dc:creator>Chen, Shigang</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Persistent spread measurement is to count the number of distinct elements
that persist in each network flow for predefined time periods. It has many
practical applications, including detecting long-term stealthy network
activities in the background of normal-user activities, such as stealthy DDoS
attack, stealthy network scan, or faked network trend, which cannot be detected
by traditional flow cardinality measurement. With big network data, one
challenge is to measure the persistent spreads of a massive number of flows
without incurring too much memory overhead as such measurement may be performed
at the line speed by network processors with fast but small on-chip memory. We
propose a highly compact Virtual Intersection HyperLogLog (VI-HLL) architecture
for this purpose. It achieves far better memory efficiency than the best prior
work of V-Bitmap, and in the meantime drastically extends the measurement
range. Theoretical analysis and extensive experiments demonstrate that VI-HLL
provides good measurement accuracy even in very tight memory space of less than
1 bit per flow.
</dc:description>
 <dc:description>Comment: ACM SIGMETRICS 2017</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03911</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03913</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Higher-order clustering in networks</dc:title>
 <dc:creator>Yin, Hao</dc:creator>
 <dc:creator>Benson, Austin R.</dc:creator>
 <dc:creator>Leskovec, Jure</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A fundamental property of complex networks is the tendency for edges to
cluster. The extent of the clustering is typically quantified by the clustering
coefficient, which is the probability that a length-2 path is closed, i.e.,
induces a triangle in the network. However, higher-order cliques beyond
triangles are crucial to understanding complex networks, and the clustering
behavior with respect to such higher-order network structures is not well
understood. Here we introduce higher-order clustering coefficients that measure
the closure probability of higher-order network cliques and provide a more
comprehensive view of how the edges of complex networks cluster. Our
higher-order clustering coefficients are a natural generalization of the
traditional clustering coefficient. We derive several properties about
higher-order clustering coefficients and analyze them under common random graph
models. Finally, we use higher-order clustering coefficients to gain new
insights into the structure of real-world networks from several domains.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2018-01-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03913</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03915</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Laplacian Pyramid Networks for Fast and Accurate Super-Resolution</dc:title>
 <dc:creator>Lai, Wei-Sheng</dc:creator>
 <dc:creator>Huang, Jia-Bin</dc:creator>
 <dc:creator>Ahuja, Narendra</dc:creator>
 <dc:creator>Yang, Ming-Hsuan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional neural networks have recently demonstrated high-quality
reconstruction for single-image super-resolution. In this paper, we propose the
Laplacian Pyramid Super-Resolution Network (LapSRN) to progressively
reconstruct the sub-band residuals of high-resolution images. At each pyramid
level, our model takes coarse-resolution feature maps as input, predicts the
high-frequency residuals, and uses transposed convolutions for upsampling to
the finer level. Our method does not require the bicubic interpolation as the
pre-processing step and thus dramatically reduces the computational complexity.
We train the proposed LapSRN with deep supervision using a robust Charbonnier
loss function and achieve high-quality reconstruction. Furthermore, our network
generates multi-scale predictions in one feed-forward pass through the
progressive reconstruction, thereby facilitates resource-aware applications.
Extensive quantitative and qualitative evaluations on benchmark datasets show
that the proposed algorithm performs favorably against the state-of-the-art
methods in terms of speed and accuracy.
</dc:description>
 <dc:description>Comment: This work is accepted in CVPR 2017. The code and datasets are
  available on http://vllab.ucmerced.edu/wlai24/LapSRN/</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-10-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03915</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03925</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Provable Self-Representation Based Outlier Detection in a Union of
  Subspaces</dc:title>
 <dc:creator>You, Chong</dc:creator>
 <dc:creator>Robinson, Daniel P.</dc:creator>
 <dc:creator>Vidal, Ren&#xe9;</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Many computer vision tasks involve processing large amounts of data
contaminated by outliers, which need to be detected and rejected. While outlier
detection methods based on robust statistics have existed for decades, only
recently have methods based on sparse and low-rank representation been
developed along with guarantees of correct outlier detection when the inliers
lie in one or more low-dimensional subspaces. This paper proposes a new outlier
detection method that combines tools from sparse representation with random
walks on a graph. By exploiting the property that data points can be expressed
as sparse linear combinations of each other, we obtain an asymmetric affinity
matrix among data points, which we use to construct a weighted directed graph.
By defining a suitable Markov Chain from this graph, we establish a connection
between inliers/outliers and essential/inessential states of the Markov chain,
which allows us to detect outliers by using random walks. We provide a
theoretical analysis that justifies the correctness of our method under
geometric and connectivity assumptions. Experimental results on image databases
demonstrate its superiority with respect to state-of-the-art sparse and
low-rank outlier detection methods.
</dc:description>
 <dc:description>Comment: 16 pages. CVPR 2017 spotlight oral presentation</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03925</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03926</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Value Directed Exploration in Multi-Armed Bandits with Structured Priors</dc:title>
 <dc:creator>Cserna, Bence</dc:creator>
 <dc:creator>Petrik, Marek</dc:creator>
 <dc:creator>Russel, Reazul Hasan</dc:creator>
 <dc:creator>Ruml, Wheeler</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Multi-armed bandits are a quintessential machine learning problem requiring
the balancing of exploration and exploitation. While there has been progress in
developing algorithms with strong theoretical guarantees, there has been less
focus on practical near-optimal finite-time performance. In this paper, we
propose an algorithm for Bayesian multi-armed bandits that utilizes
value-function-driven online planning techniques. Building on previous work on
UCB and Gittins index, we introduce linearly-separable value functions that
take both the expected return and the benefit of exploration into consideration
to perform n-step lookahead. The algorithm enjoys a sub-linear performance
guarantee and we present simulation results that confirm its strength in
problems with structured priors. The simplicity and generality of our approach
makes it a strong candidate for analyzing more complex multi-armed bandit
problems.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03926</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03928</identifier>
 <datestamp>2017-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Quantitative Hardness of CVP</dc:title>
 <dc:creator>Bennett, Huck</dc:creator>
 <dc:creator>Golovnev, Alexander</dc:creator>
 <dc:creator>Stephens-Davidowitz, Noah</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  $ \newcommand{\eps}{\varepsilon}
\newcommand{\problem}[1]{\ensuremath{\mathrm{#1}} }
\newcommand{\CVP}{\problem{CVP}} \newcommand{\SVP}{\problem{SVP}}
\newcommand{\CVPP}{\problem{CVPP}} \newcommand{\ensuremath}[1]{#1} $For odd
integers $p \geq 1$ (and $p = \infty$), we show that the Closest Vector Problem
in the $\ell_p$ norm ($\CVP_p$) over rank $n$ lattices cannot be solved in
$2^{(1-\eps) n}$ time for any constant $\eps &gt; 0$ unless the Strong Exponential
Time Hypothesis (SETH) fails. We then extend this result to &quot;almost all&quot; values
of $p \geq 1$, not including the even integers. This comes tantalizingly close
to settling the quantitative time complexity of the important special case of
$\CVP_2$ (i.e., $\CVP$ in the Euclidean norm), for which a $2^{n +o(n)}$-time
algorithm is known. In particular, our result applies for any $p = p(n) \neq 2$
that approaches $2$ as $n \to \infty$.
  We also show a similar SETH-hardness result for $\SVP_\infty$; hardness of
approximating $\CVP_p$ to within some constant factor under the so-called
Gap-ETH assumption; and other quantitative hardness results for $\CVP_p$ and
$\CVPP_p$ for any $1 \leq p &lt; \infty$ under different assumptions.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-10-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03931</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Healthcare Robotics</dc:title>
 <dc:creator>Riek, Laurel D.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Robots have the potential to be a game changer in healthcare: improving
health and well-being, filling care gaps, supporting care givers, and aiding
health care workers. However, before robots are able to be widely deployed, it
is crucial that both the research and industrial communities work together to
establish a strong evidence-base for healthcare robotics, and surmount likely
adoption barriers. This article presents a broad contextualization of robots in
healthcare by identifying key stakeholders, care settings, and tasks; reviewing
recent advances in healthcare robotics; and outlining major challenges and
opportunities to their adoption.
</dc:description>
 <dc:description>Comment: 8 pages, Communications of the ACM, 2017</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03931</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03934</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>i Vector used in Speaker Identification by Dimension Compactness</dc:title>
 <dc:creator>Kanrar, Soumen</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  The automatic speaker identification procedure is used to extract features
that help to identify the components of the acoustic signal by discarding all
the other stuff like background noise, emotion, hesitation, etc. The acoustic
signal is generated by a human that is filtered by the shape of the vocal
tract, including tongue, teeth, etc. The shape of the vocal tract determines
and produced, what signal comes out in real time. The analytically develops
shape of the vocal tract, which exhibits envelop for the short time power
spectrum. The ASR needs efficient way of extracting features from the acoustic
signal that is used effectively to makes the shape of the individual vocal
tract. To identify any acoustic signal in the large collection of acoustic
signal i.e. corpora, it needs dimension compactness of total variability space
by using the GMM mean super vector. This work presents the efficient way to
implement dimension compactness in total variability space and using cosine
distance scoring to predict a fast output score for small size utterance.
</dc:description>
 <dc:description>Comment: 6 pages,7 figures</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03934</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03937</identifier>
 <datestamp>2017-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Status updates through M/G/1/1 queues with HARQ</dc:title>
 <dc:creator>Najm, Elie</dc:creator>
 <dc:creator>Yates, Roy D.</dc:creator>
 <dc:creator>Soljanin, Emina</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a system where randomly generated updates are to be transmitted
to a monitor, but only a single update can be in the transmission service at a
time. Therefore, the source has to prioritize between the two possible
transmission policies: preempting the current update or discarding the new one.
We consider Poisson arrivals and general service time, and refer to this system
as the M/G/1/1 queue. We start by studying the average status update age and
the optimal update arrival rate for these two schemes under general service
time distribution. We then apply these results on two practical scenarios in
which updates are sent through an erasure channel using (a) an infinite
incremental redundancy (IIR) HARQ system and (b) a fixed redundancy (FR) HARQ
system. We show that in both schemes the best strategy would be not to preempt.
Moreover, we also prove that, from an age point of view, IIR is better than FR.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-05-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03937</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03939</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Speaker Identification by GMM based i Vector</dc:title>
 <dc:creator>Kanrar, Soumen</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Speaker Identification process is to identify a particular vocal cord from a
set of existing speakers. In the speaker identification processes, unknown
speaker voice sample targets each of the existing speakers present in the
system and gives a predication. The predication may be more than one existing
known speaker voice and is very close to the unknown speaker voice. The model
is a Gaussian mixture model built by the extracted acoustic feature vectors
from voice. The i-vector based dimension compression mapping function of the
channel depended speaker, and super vector give better predicted scores
according to cosine distance scoring associated with the order pair of
speakers. In the order pair, the first coordinate is the unknown speaker i.e.
test speaker, and the second coordinates is the existing known speaker i.e.
target speaker. This paper presents the enhancement of the prediction based on
i- vector in compare to the normalized set of predicted score. In the
simulation, known speaker voices are collected through different channels and
in different languages. In the testing, the GMM voice models, and GMM based
i-Vector speaker voice models of the known speakers are used among the numbers
of clusters in the test data set.
</dc:description>
 <dc:description>Comment: 6 Pages, 12 figures</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03939</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03940</identifier>
 <datestamp>2017-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PACRR: A Position-Aware Neural IR Model for Relevance Matching</dc:title>
 <dc:creator>Hui, Kai</dc:creator>
 <dc:creator>Yates, Andrew</dc:creator>
 <dc:creator>Berberich, Klaus</dc:creator>
 <dc:creator>de Melo, Gerard</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In order to adopt deep learning for information retrieval, models are needed
that can capture all relevant information required to assess the relevance of a
document to a given user query. While previous works have successfully captured
unigram term matches, how to fully employ position-dependent information such
as proximity and term dependencies has been insufficiently explored. In this
work, we propose a novel neural IR model named PACRR aiming at better modeling
position-dependent interactions between a query and a document. Extensive
experiments on six years' TREC Web Track data confirm that the proposed model
yields better results under multiple benchmarks.
</dc:description>
 <dc:description>Comment: To appear in EMNLP2017</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-07-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03940</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03943</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two-walks degree assortativity in graphs and networks</dc:title>
 <dc:creator>Allen-Perkins, Alfonso</dc:creator>
 <dc:creator>Pastor, Juan Manuel</dc:creator>
 <dc:creator>Estrada, Ernesto</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>05C82, 05C75, 91D30, 92C42</dc:subject>
 <dc:description>  Degree ssortativity is the tendency for nodes of high degree (resp.low
degree) in a graph to be connected to high degree nodes (resp. to low degree
ones). It is sually quantified by the Pearson correlation coefficient of the
degree-degree correlation. Here we extend this concept to account for the
effect of second neighbours to a given node in a graph. That is, we consider
the two-walks degree of a node as the sum of all the degrees of its adjacent
nodes. The two-walks degree assortativity of a graph is then the Pearson
correlation coefficient of the two-walks degree-degree correlation. We found
here analytical expression for this two-walks degree assortativity index as a
function of contributing subgraphs. We then study all the 261,000 connected
graphs with 9 nodes and observe the existence of assortative-assortative and
disassortative-disassortative graphs according to degree and two-walks degree,
respectively. More surprinsingly, we observe a class of graphs which are degree
disassortative and two-walks degree assortative. We explain the existence of
some of these graphs due to the presence of certain topological features, such
as a node of low-degree connected to high-degree ones. More importantly, we
study a series of 49 real-world networks, where we observe the existence of the
disassortative-assortative class in several of them. In particular, all
biological networks studied here were in this class. We also conclude that no
graphs/networks are possible with assortative-disassortative structure.
</dc:description>
 <dc:description>Comment: 15 pages, 5 figures, 2 tables</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03943</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03944</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discriminative Bimodal Networks for Visual Localization and Detection
  with Natural Language Queries</dc:title>
 <dc:creator>Zhang, Yuting</dc:creator>
 <dc:creator>Yuan, Luyao</dc:creator>
 <dc:creator>Guo, Yijie</dc:creator>
 <dc:creator>He, Zhiyuan</dc:creator>
 <dc:creator>Huang, I-An</dc:creator>
 <dc:creator>Lee, Honglak</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Associating image regions with text queries has been recently explored as a
new way to bridge visual and linguistic representations. A few pioneering
approaches have been proposed based on recurrent neural language models trained
generatively (e.g., generating captions), but achieving somewhat limited
localization accuracy. To better address natural-language-based visual entity
localization, we propose a discriminative approach. We formulate a
discriminative bimodal neural network (DBNet), which can be trained by a
classifier with extensive use of negative samples. Our training objective
encourages better localization on single images, incorporates text phrases in a
broad range, and properly pairs image regions with text phrases into positive
and negative examples. Experiments on the Visual Genome dataset demonstrate the
proposed DBNet significantly outperforms previous state-of-the-art methods both
for localization on single images and for detection on multiple images. We we
also establish an evaluation protocol for natural-language visual detection.
</dc:description>
 <dc:description>Comment: IEEE Conference on Computer Vision and Pattern Recognition (CVPR),
  2017</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03944</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03946</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymmetric Feature Maps with Application to Sketch Based Retrieval</dc:title>
 <dc:creator>Tolias, Giorgos</dc:creator>
 <dc:creator>Chum, Ond&#x159;ej</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel concept of asymmetric feature maps (AFM), which allows to
evaluate multiple kernels between a query and database entries without
increasing the memory requirements. To demonstrate the advantages of the AFM
method, we derive a short vector image representation that, due to asymmetric
feature maps, supports efficient scale and translation invariant sketch-based
image retrieval. Unlike most of the short-code based retrieval systems, the
proposed method provides the query localization in the retrieved image. The
efficiency of the search is boosted by approximating a 2D translation search
via trigonometric polynomial of scores by 1D projections. The projections are a
special case of AFM. An order of magnitude speed-up is achieved compared to
traditional trigonometric polynomials. The results are boosted by an
image-based average query expansion, exceeding significantly the state of the
art on standard benchmarks.
</dc:description>
 <dc:description>Comment: CVPR 2017</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03946</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03949</identifier>
 <datestamp>2017-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Sensemaking Tools Influence Display Space Usage</dc:title>
 <dc:creator>Geymayer, Thomas</dc:creator>
 <dc:creator>Waldner, Manuela</dc:creator>
 <dc:creator>Lex, Alexander</dc:creator>
 <dc:creator>Schmalstieg, Dieter</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:description>  We explore how the availability of a sensemaking tool influences users'
knowledge externalization strategies. On a large display, users were asked to
solve an intelligence analysis task with or without a bidirectionally linked
concept-graph (BLC) to organize insights into concepts (nodes) and relations
(edges). In BLC, both nodes and edges maintain &quot;deep links&quot; to the exact source
phrases and sections in associated documents. In our control condition, we were
able to reproduce previously described spatial organization behaviors using
document windows on the large display. When using BLC, however, we found that
analysts apply spatial organization to BLC nodes instead, use significantly
less display space and have significantly fewer open windows.
</dc:description>
 <dc:description>Comment: To appear in EuroVis Workshop on Visual Analytics (2017)</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03949</dc:identifier>
 <dc:identifier>doi:10.2312/eurova.20171112</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03951</identifier>
 <datestamp>2018-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparsity-Sensitive Finite Abstraction</dc:title>
 <dc:creator>Gruber, Felix</dc:creator>
 <dc:creator>Kim, Eric S.</dc:creator>
 <dc:creator>Arcak, Murat</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Abstraction of a continuous-space model into a finite state and input
dynamical model is a key step in formal controller synthesis tools. To date,
these software tools have been limited to systems of modest size (typically
$\leq$ 6 dimensions) because the abstraction procedure suffers from an
exponential runtime with respect to the sum of state and input dimensions. We
present a simple modification to the abstraction algorithm that dramatically
reduces the computation time for systems exhibiting a sparse interconnection
structure. This modified procedure recovers the same abstraction as the one
computed by a brute force algorithm that disregards the sparsity. Examples
highlight speed-ups from existing benchmarks in the literature, synthesis of a
safety supervisory controller for a 12-dimensional and abstraction of a
51-dimensional vehicular traffic network.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03951</dc:identifier>
 <dc:identifier>doi:10.1109/CDC.2017.8263995</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03952</identifier>
 <datestamp>2017-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Virtual to Real Reinforcement Learning for Autonomous Driving</dc:title>
 <dc:creator>Pan, Xinlei</dc:creator>
 <dc:creator>You, Yurong</dc:creator>
 <dc:creator>Wang, Ziyan</dc:creator>
 <dc:creator>Lu, Cewu</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Reinforcement learning is considered as a promising direction for driving
policy learning. However, training autonomous driving vehicle with
reinforcement learning in real environment involves non-affordable
trial-and-error. It is more desirable to first train in a virtual environment
and then transfer to the real environment. In this paper, we propose a novel
realistic translation network to make model trained in virtual environment be
workable in real world. The proposed network can convert non-realistic virtual
image input into a realistic one with similar scene structure. Given realistic
frames as input, driving policy trained by reinforcement learning can nicely
adapt to real world driving. Experiments show that our proposed virtual to real
(VR) reinforcement learning (RL) works pretty well. To our knowledge, this is
the first successful case of driving policy trained by reinforcement learning
that can adapt to real world driving data.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-09-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03952</dc:identifier>
 <dc:identifier>Proceedings of the British Machine Vision Conference (BMVC) 2017
  (Spotlight)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03955</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shape-independent Hardness Estimation Using Deep Learning and a GelSight
  Tactile Sensor</dc:title>
 <dc:creator>Yuan, Wenzhen</dc:creator>
 <dc:creator>Zhu, Chenzhuo</dc:creator>
 <dc:creator>Owens, Andrew</dc:creator>
 <dc:creator>Srinivasan, Mandayam A.</dc:creator>
 <dc:creator>Adelson, Edward H.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Hardness is among the most important attributes of an object that humans
learn about through touch. However, approaches for robots to estimate hardness
are limited, due to the lack of information provided by current tactile
sensors. In this work, we address these limitations by introducing a novel
method for hardness estimation, based on the GelSight tactile sensor, and the
method does not require accurate control of contact conditions or the shape of
objects. A GelSight has a soft contact interface, and provides high resolution
tactile images of contact geometry, as well as contact force and slip
conditions. In this paper, we try to use the sensor to measure hardness of
objects with multiple shapes, under a loosely controlled contact condition. The
contact is made manually or by a robot hand, while the force and trajectory are
unknown and uneven. We analyze the data using a deep constitutional (and
recurrent) neural network. Experiments show that the neural net model can
estimate the hardness of objects with different shapes and hardness ranging
from 8 to 87 in Shore 00 scale.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03955</dc:identifier>
 <dc:identifier>doi:10.1109/ICRA.2017.7989116</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03956</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incremental Skip-gram Model with Negative Sampling</dc:title>
 <dc:creator>Kaji, Nobuhiro</dc:creator>
 <dc:creator>Kobayashi, Hayato</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper explores an incremental training strategy for the skip-gram model
with negative sampling (SGNS) from both empirical and theoretical perspectives.
Existing methods of neural word embeddings, including SGNS, are multi-pass
algorithms and thus cannot perform incremental model update. To address this
problem, we present a simple incremental extension of SGNS and provide a
thorough theoretical analysis to demonstrate its validity. Empirical
experiments demonstrated the correctness of the theoretical analysis as well as
the practical usefulness of the incremental algorithm.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03956</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03958</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Sparse Subspace Clustering by Nearest Neighbour Filtering</dc:title>
 <dc:creator>Tierney, Stephen</dc:creator>
 <dc:creator>Guo, Yi</dc:creator>
 <dc:creator>Gao, Junbin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Sparse Subspace Clustering (SSC) has been used extensively for subspace
identification tasks due to its theoretical guarantees and relative ease of
implementation. However SSC has quadratic computation and memory requirements
with respect to the number of input data points. This burden has prohibited
SSCs use for all but the smallest datasets. To overcome this we propose a new
method, k-SSC, that screens out a large number of data points to both reduce
SSC to linear memory and computational requirements. We provide theoretical
analysis for the bounds of success for k-SSC. Our experiments show that k-SSC
exceeds theoretical expectations and outperforms existing SSC approximations by
maintaining the classification performance of SSC. Furthermore in the spirit of
reproducible research we have publicly released the source code for k-SSC
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03958</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03963</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tractable Clustering of Data on the Curve Manifold</dc:title>
 <dc:creator>Tierney, Stephen</dc:creator>
 <dc:creator>Gao, Junbin</dc:creator>
 <dc:creator>Guo, Yi</dc:creator>
 <dc:creator>Zhang, Zheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In machine learning it is common to interpret each data point as a vector in
Euclidean space. However the data may actually be functional i.e.\ each data
point is a function of some variable such as time and the function is
discretely sampled. The naive treatment of functional data as traditional
multivariate data can lead to poor performance since the algorithms are
ignoring the correlation in the curvature of each function. In this paper we
propose a tractable method to cluster functional data or curves by adapting the
Euclidean Low-Rank Representation (LRR) to the curve manifold. Experimental
evaluation on synthetic and real data reveals that this method massively
outperforms prior clustering methods in both speed and accuracy when clustering
functional data.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1601.00732</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03963</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03965</identifier>
 <datestamp>2017-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Distance Between Filtered Spaces Via Tripods</dc:title>
 <dc:creator>Memoli, Facundo</dc:creator>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We present a simplified treatment of stability of filtrations on finite
spaces. Interestingly, we can lift the stability result for combinatorial
filtrations from [CSEM06] to the case when two filtrations live on different
spaces without directly invoking the concept of interleaving. We then prove
that this distance is intrinsic by constructing explicit geodesics between any
pair of filtered spaces. Finally we use this construction to obtain a
strengthening of the stability result.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03965</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03966</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collaborative Low-Rank Subspace Clustering</dc:title>
 <dc:creator>Tierney, Stephen</dc:creator>
 <dc:creator>Guo, Yi</dc:creator>
 <dc:creator>Gao, Junbin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we present Collaborative Low-Rank Subspace Clustering. Given
multiple observations of a phenomenon we learn a unified representation matrix.
This unified matrix incorporates the features from all the observations, thus
increasing the discriminative power compared with learning the representation
matrix on each observation separately. Experimental evaluation shows that our
method outperforms subspace clustering on separate observations and the state
of the art collaborative learning algorithm.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03966</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03969</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence analysis of the information matrix in Gaussian belief
  propagation</dc:title>
 <dc:creator>Du, Jian</dc:creator>
 <dc:creator>Ma, Shaodan</dc:creator>
 <dc:creator>Wu, Yik-Chung</dc:creator>
 <dc:creator>Kar, Soummya</dc:creator>
 <dc:creator>Moura, Jos&#xe9; M. F.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Gaussian belief propagation (BP) has been widely used for distributed
estimation in large-scale networks such as the smart grid, communication
networks, and social networks, where local measurements/observations are
scattered over a wide geographical area. However, the convergence of Gaus- sian
BP is still an open issue. In this paper, we consider the convergence of
Gaussian BP, focusing in particular on the convergence of the information
matrix. We show analytically that the exchanged message information matrix
converges for arbitrary positive semidefinite initial value, and its dis- tance
to the unique positive definite limit matrix decreases exponentially fast.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1611.02010</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03969</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03970</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient and Effective Tail Latency Minimization in Multi-Stage
  Retrieval Systems</dc:title>
 <dc:creator>Mackenzie, Joel</dc:creator>
 <dc:creator>Culpepper, J. Shane</dc:creator>
 <dc:creator>Blanco, Roi</dc:creator>
 <dc:creator>Crane, Matt</dc:creator>
 <dc:creator>Clarke, Charles L. A.</dc:creator>
 <dc:creator>Lin, Jimmy</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Scalable web search systems typically employ multi-stage retrieval
architectures, where an initial stage generates a set of candidate documents
that are then pruned and re-ranked. Since subsequent stages typically exploit a
multitude of features of varying costs using machine-learned models, reducing
the number of documents that are considered at each stage improves latency. In
this work, we propose and validate a unified framework that can be used to
predict a wide range of performance-sensitive parameters which minimize
effectiveness loss, while simultaneously minimizing query latency, across all
stages of a multi-stage search architecture. Furthermore, our framework can be
easily applied in large-scale IR systems, can be trained without explicitly
requiring relevance judgments, and can target a variety of different
efficiency-effectiveness trade-offs, making it well suited to a wide range of
search scenarios. Our results show that we can reliably predict a number of
different parameters on a per-query basis, while simultaneously detecting and
minimizing the likelihood of tail-latency queries that exceed a pre-specified
performance budget. As a proof of concept, we use the prediction framework to
help alleviate the problem of tail-latency queries in early stage retrieval. On
the standard ClueWeb09B collection and 31k queries, we show that our new hybrid
system can reliably achieve a maximum query time of 200 ms with a 99.99%
response time guarantee without a significant loss in overall effectiveness.
The solutions presented are practical, and can easily be used in large-scale
distributed search engine deployments with a small amount of additional
overhead.
</dc:description>
 <dc:description>Comment: Update 1: Edited email address</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03970</dc:identifier>
 <dc:identifier>doi:10.1145/3159652.3159676</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03971</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Effects of Batch and Weight Normalization in Generative
  Adversarial Networks</dc:title>
 <dc:creator>Xiang, Sitao</dc:creator>
 <dc:creator>Li, Hao</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Generative adversarial networks (GANs) are highly effective unsupervised
learning frameworks that can generate very sharp data, even for data such as
images with complex, highly multimodal distributions. However GANs are known to
be very hard to train, suffering from problems such as mode collapse and
disturbing visual artifacts. Batch normalization (BN) techniques have been
introduced to address the training. Though BN accelerates the training in the
beginning, our experiments show that the use of BN can be unstable and
negatively impact the quality of the trained model. The evaluation of BN and
numerous other recent schemes for improving GAN training is hindered by the
lack of an effective objective quality measure for GAN models. To address these
issues, we first introduce a weight normalization (WN) approach for GAN
training that significantly improves the stability, efficiency and the quality
of the generated samples. To allow a methodical evaluation, we introduce
squared Euclidean reconstruction error on a test set as a new objective
measure, to assess training performance in terms of speed, stability, and
quality of generated samples. Our experiments with a standard DCGAN
architecture on commonly used datasets (CelebA, LSUN bedroom, and CIFAR-10)
indicate that training using WN is generally superior to BN for GANs, achieving
10% lower mean squared loss for reconstruction and significantly better
qualitative results than BN. We further demonstrate the stability of WN on a
21-layer ResNet trained with the CelebA data set. The code for this paper is
available at https://github.com/stormraiser/gan-weightnorm-resnet
</dc:description>
 <dc:description>Comment: v3 rejected by NIPS 2017, updated and re-submitted to CVPR 2018. v4:
  add experiments with ResNet and like to new code</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03971</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03972</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Register automata with linear arithmetic</dc:title>
 <dc:creator>Chen, Yu-Fang</dc:creator>
 <dc:creator>Lengal, Ondrej</dc:creator>
 <dc:creator>Tan, Tony</dc:creator>
 <dc:creator>Wu, Zhilin</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F.4.3</dc:subject>
 <dc:description>  We propose a novel automata model over the alphabet of rational numbers,
which we call register automata over the rationals (RA-Q). It reads a sequence
of rational numbers and outputs another rational number. RA-Q is an extension
of the well-known register automata (RA) over infinite alphabets, which are
finite automata equipped with a finite number of registers/variables for
storing values. Like in the standard RA, the RA-Q model allows both equality
and ordering tests between values. It, moreover, allows to perform linear
arithmetic between certain variables. The model is quite expressive: in
addition to the standard RA, it also generalizes other well-known models such
as affine programs and arithmetic circuits.
  The main feature of RA-Q is that despite the use of linear arithmetic, the
so-called invariant problem---a generalization of the standard non-emptiness
problem---is decidable. We also investigate other natural decision problems,
namely, commutativity, equivalence, and reachability. For deterministic RA-Q,
commutativity and equivalence are polynomial-time inter-reducible with the
invariant problem.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03972</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03975</identifier>
 <datestamp>2017-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Throughput and Robustness Guaranteed Beam Tracking for mmWave Wireless
  Networks</dc:title>
 <dc:creator>Zhou, Pei</dc:creator>
 <dc:creator>Fang, Xuming</dc:creator>
 <dc:creator>Long, Yan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  With the increasing demand of ultra-high-speed wireless communications and
the existing low frequency band (e.g., sub-6GHz) becomes more and more crowded,
millimeter-wave (mmWave) with large spectra available is considered as the most
promising frequency band for future wireless communications. Since the mmWave
suffers a serious path-loss, beamforming techniques shall be adopted to
concentrate the transmit power and receive region on a narrow beam for
achieving long distance communications. However, the mobility of users will
bring frequent beam handoff, which will decrease the quality of experience
(QoE). Therefore, efficient beam tracking mechanism should be carefully
researched. However, the existing beam tracking mechanisms concentrate on
system throughput maximization without considering beam handoff and link
robustness. This paper proposes a throughput and robustness guaranteed beam
tracking mechanism for mobile mmWave communication systems which takes account
of both system throughput and handoff probability. Simulation results show that
the proposed throughput and robustness guaranteed beam tracking mechanism can
provide better performance than the other beam tracking mechanisms.
</dc:description>
 <dc:description>Comment: Accepted by IEEE/CIC ICCC 2017</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-09-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03975</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03976</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Virtual Adversarial Training: a Regularization Method for Supervised and
  Semi-supervised Learning</dc:title>
 <dc:creator>Miyato, Takeru</dc:creator>
 <dc:creator>Maeda, Shin-ichi</dc:creator>
 <dc:creator>Koyama, Masanori</dc:creator>
 <dc:creator>Ishii, Shin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a new regularization method based on virtual adversarial loss: a
new measure of local smoothness of the output distribution. Virtual adversarial
loss is defined as the robustness of the model's posterior distribution against
local perturbation around each input data point. Our method is similar to
adversarial training, but differs from adversarial training in that it
determines the adversarial direction based only on the output distribution and
that it is applicable to a semi-supervised setting. Because the directions in
which we smooth the model are virtually adversarial, we call our method virtual
adversarial training (VAT). The computational cost of VAT is relatively low.
For neural networks, the approximated gradient of virtual adversarial loss can
be computed with no more than two pairs of forward and backpropagations. In our
experiments, we applied VAT to supervised and semi-supervised learning on
multiple benchmark datasets. With additional improvement based on entropy
minimization principle, our VAT achieves the state-of-the-art performance on
SVHN and CIFAR-10 for semi-supervised learning tasks.
</dc:description>
 <dc:description>Comment: Extended version of the paper published at ICLR2016</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03976</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03978</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reverse k Nearest Neighbor Search over Trajectories</dc:title>
 <dc:creator>Wang, Sheng</dc:creator>
 <dc:creator>Bao, Zhifeng</dc:creator>
 <dc:creator>Culpepper, J. Shane</dc:creator>
 <dc:creator>Sellis, Timos</dc:creator>
 <dc:creator>Cong, Gao</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  GPS enables mobile devices to continuously provide new opportunities to
improve our daily lives. For example, the data collected in applications
created by Uber or Public Transport Authorities can be used to plan
transportation routes, estimate capacities, and proactively identify low
coverage areas. In this paper, we study a new kind of query-Reverse k Nearest
Neighbor Search over Trajectories (RkNNT), which can be used for route planning
and capacity estimation. Given a set of existing routes DR, a set of passenger
transitions DT, and a query route Q, a RkNNT query returns all transitions that
take Q as one of its k nearest travel routes. To solve the problem, we first
develop an index to handle dynamic trajectory updates, so that the most
up-to-date transition data are available for answering a RkNNT query. Then we
introduce a filter refinement framework for processing RkNNT queries using the
proposed indexes. Next, we show how to use RkNNT to solve the optimal route
planning problem MaxRkNNT (MinRkNNT), which is to search for the optimal route
from a start location to an end location that could attract the maximum (or
minimum) number of passengers based on a pre-defined travel distance threshold.
Experiments on real datasets demonstrate the efficiency and scalability of our
approaches. To the best of our best knowledge, this is the first work to study
the RkNNT problem for route planning.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03978</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03986</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>2D-3D Pose Consistency-based Conditional Random Fields for 3D Human Pose
  Estimation</dc:title>
 <dc:creator>Chang, Ju Yong</dc:creator>
 <dc:creator>Lee, Kyoung Mu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This study considers the 3D human pose estimation problem in a single RGB
image by proposing a conditional random field (CRF) model over 2D poses, in
which the 3D pose is obtained as a byproduct of the inference process. The
unary term of the proposed CRF model is defined based on a powerful heat-map
regression network, which has been proposed for 2D human pose estimation. This
study also presents a regression network for lifting the 2D pose to 3D pose and
proposes the prior term based on the consistency between the estimated 3D pose
and the 2D pose. To obtain the approximate solution of the proposed CRF model,
the N-best strategy is adopted. The proposed inference algorithm can be viewed
as sequential processes of bottom-up generation of 2D and 3D pose proposals
from the input 2D image based on deep networks and top-down verification of
such proposals by checking their consistencies. To evaluate the proposed
method, we use two large-scale datasets: Human3.6M and HumanEva. Experimental
results show that the proposed method achieves the state-of-the-art 3D human
pose estimation performance.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03986</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03987</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mobile Keyboard Input Decoding with Finite-State Transducers</dc:title>
 <dc:creator>Ouyang, Tom</dc:creator>
 <dc:creator>Rybach, David</dc:creator>
 <dc:creator>Beaufays, Fran&#xe7;oise</dc:creator>
 <dc:creator>Riley, Michael</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We propose a finite-state transducer (FST) representation for the models used
to decode keyboard inputs on mobile devices. Drawing from learnings from the
field of speech recognition, we describe a decoding framework that can satisfy
the strict memory and latency constraints of keyboard input. We extend this
framework to support functionalities typically not present in speech
recognition, such as literal decoding, autocorrections, word completions, and
next word predictions.
  We describe the general framework of what we call for short the keyboard &quot;FST
decoder&quot; as well as the implementation details that are new compared to a
speech FST decoder. We demonstrate that the FST decoder enables new UX features
such as post-corrections. Finally, we sketch how this decoder can support
advanced features such as personalization and contextualization.
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03987</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03991</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Architectural Techniques to Enable Reliable and Scalable Memory Systems</dc:title>
 <dc:creator>Nair, Prashant J.</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  High capacity and scalable memory systems play a vital role in enabling our
desktops, smartphones, and pervasive technologies like Internet of Things
(IoT). Unfortunately, memory systems are becoming increasingly prone to faults.
This is because we rely on technology scaling to improve memory density, and at
small feature sizes, memory cells tend to break easily. Today, memory
reliability is seen as the key impediment towards using high-density devices,
adopting new technologies, and even building the next Exascale supercomputer.
To ensure even a bare-minimum level of reliability, present-day solutions tend
to have high performance, power and area overheads. Ideally, we would like
memory systems to remain robust, scalable, and implementable while keeping the
overheads to a minimum. This dissertation describes how simple cross-layer
architectural techniques can provide orders of magnitude higher reliability and
enable seamless scalability for memory systems while incurring negligible
overheads.
</dc:description>
 <dc:description>Comment: PhD thesis, Georgia Institute of Technology (May 2017)</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03991</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03992</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fully Distributed and Asynchronized Stochastic Gradient Descent for
  Networked Systems</dc:title>
 <dc:creator>Zhang, Ying</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  This paper considers a general data-fitting problem over a networked system,
in which many computing nodes are connected by an undirected graph. This kind
of problem can find many real-world applications and has been studied
extensively in the literature. However, existing solutions either need a
central controller for information sharing or requires slot synchronization
among different nodes, which increases the difficulty of practical
implementations, especially for a very large and heterogeneous system.
  As a contrast, in this paper, we treat the data-fitting problem over the
network as a stochastic programming problem with many constraints. By adapting
the results in a recent paper, we design a fully distributed and asynchronized
stochastic gradient descent (SGD) algorithm. We show that our algorithm can
achieve global optimality and consensus asymptotically by only local
computations and communications. Additionally, we provide a sharp lower bound
for the convergence speed in the regular graph case. This result fits the
intuition and provides guidance to design a `good' network topology to speed up
the convergence. Also, the merit of our design is validated by experiments on
both synthetic and real-world datasets.
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03992</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03993</identifier>
 <datestamp>2017-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ApproxDBN: Approximate Computing for Discriminative Deep Belief Networks</dc:title>
 <dc:creator>Xu, Xiaojing</dc:creator>
 <dc:creator>Das, Srinjoy</dc:creator>
 <dc:creator>Kreutz-Delgado, Ken</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Probabilistic generative neural networks are useful for many applications,
such as image classification, speech recognition and occlusion removal.
However, the power budget for hardware implementations of neural networks can
be extremely tight. To address this challenge we describe a design methodology
for using approximate computing methods to implement Approximate Deep Belief
Networks (ApproxDBNs) by systematically exploring the use of (1) limited
precision of variables; (2) criticality analysis to identify the nodes in the
network which can operate with such limited precision while allowing the
network to maintain target accuracy levels; and (3) a greedy search methodology
with incremental retraining to determine the optimal reduction in precision to
enable maximize power savings under user-specified accuracy constraints.
Experimental results show that significant bit-length reduction can be achieved
by our ApproxDBN with constrained accuracy loss.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-05-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03993</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03998</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Min-Max Design of Feedback Quantizers for Netorwked Control Systems</dc:title>
 <dc:creator>Ohno, Shuichi</dc:creator>
 <dc:creator>Ishihara, Yuma</dc:creator>
 <dc:creator>Nagahara, Masaaki</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In a networked control system, quantization is inevitable to transmit control
and measurement signals. While uniform quantizers are often used in practical
systems, the overloading, which is due to the limitation on the number of bits
in the quantizer, may significantly degrade the control performance. In this
paper, we design an overloading-free feedback quantizer based on a Delta-Sigma
modulator,composed of an error feedback filter and a static quantizer. To
guarantee no-overloading in the quantizer, we impose an $l_{\infty}$ norm
constraint on the feedback signal in the quantizer. Then, for a prescribed
$l_{\infty}$ norm constraint on the error at the system output induced by the
quantizer, we design the error feedback filter that requires the minimum number
of bits that achieves the constraint. Next, for a fixed number of bits for the
quantizer, we investigate the achievable minimum $l_{\infty}$ norm of the error
at the system output with an overloading-free quantizer. Numerical examples are
provided to validate our analysis and synthesis.
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.03998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04000</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dempster-Shafer Belief Function - A New Interpretation</dc:title>
 <dc:creator>K&#x142;opotek, Mieczys&#x142;aw</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We develop our interpretation of the joint belief distribution and of
evidential updating that matches the following basic requirements:
  * there must exist an efficient method for reasoning within this framework
  * there must exist a clear correspondence between the contents of the
knowledge base and the real world
  * there must be a clear correspondence between the reasoning method and some
real world process
  * there must exist a clear correspondence between the results of the
reasoning process and the results of the real world process corresponding to
the reasoning process.
</dc:description>
 <dc:description>Comment: 70 pages, an internat intermediate research report, dating back to
  1993</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04007</identifier>
 <datestamp>2017-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Matroid Theory and Storage Codes: Bounds and Constructions</dc:title>
 <dc:creator>Freij-Hollanti, Ragnar</dc:creator>
 <dc:creator>Hollanti, Camilla</dc:creator>
 <dc:creator>Westerb&#xe4;ck, Thomas</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Recent research on distributed storage systems (DSSs) has revealed
interesting connections between matroid theory and locally repairable codes
(LRCs). The goal of this chapter is to introduce the reader to matroids and
polymatroids, and illustrate their relation to distribute storage systems.
While many of the results are rather technical in nature, effort is made to
increase accessibility via simple examples. The chapter embeds all the
essential features of LRCs, namely locality, availability, and hierarchy
alongside with related generalised Singleton bounds.
</dc:description>
 <dc:description>Comment: Invited book chapter in Network Coding and Subspace Designs,
  Springer, to appear</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04008</identifier>
 <datestamp>2017-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Neural Model for User Geolocation and Lexical Dialectology</dc:title>
 <dc:creator>Rahimi, Afshin</dc:creator>
 <dc:creator>Cohn, Trevor</dc:creator>
 <dc:creator>Baldwin, Timothy</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We propose a simple yet effective text- based user geolocation model based on
a neural network with one hidden layer, which achieves state of the art
performance over three Twitter benchmark geolocation datasets, in addition to
producing word and phrase embeddings in the hidden layer that we show to be
useful for detecting dialectal terms. As part of our analysis of dialectal
terms, we release DAREDS, a dataset for evaluating dialect term detection
methods.
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-04-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04010</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ZigZag: A new approach to adaptive online learning</dc:title>
 <dc:creator>Foster, Dylan J.</dc:creator>
 <dc:creator>Rakhlin, Alexander</dc:creator>
 <dc:creator>Sridharan, Karthik</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We develop a novel family of algorithms for the online learning setting with
regret against any data sequence bounded by the empirical Rademacher complexity
of that sequence. To develop a general theory of when this type of adaptive
regret bound is achievable we establish a connection to the theory of
decoupling inequalities for martingales in Banach spaces. When the hypothesis
class is a set of linear functions bounded in some norm, such a regret bound is
achievable if and only if the norm satisfies certain decoupling inequalities
for martingales. Donald Burkholder's celebrated geometric characterization of
decoupling inequalities (1984) states that such an inequality holds if and only
if there exists a special function called a Burkholder function satisfying
certain restricted concavity properties. Our online learning algorithms are
efficient in terms of queries to this function.
  We realize our general theory by giving novel efficient algorithms for
classes including lp norms, Schatten p-norms, group norms, and reproducing
kernel Hilbert spaces. The empirical Rademacher complexity regret bound implies
--- when used in the i.i.d. setting --- a data-dependent complexity bound for
excess risk after online-to-batch conversion. To showcase the power of the
empirical Rademacher complexity regret bound, we derive improved rates for a
supervised learning generalization of the online learning with low rank experts
task and for the online matrix prediction task.
  In addition to obtaining tight data-dependent regret bounds, our algorithms
enjoy improved efficiency over previous techniques based on Rademacher
complexity, automatically work in the infinite horizon setting, and are
scale-free. To obtain such adaptive methods, we introduce novel machinery, and
the resulting algorithms are not based on the standard tools of online convex
optimization.
</dc:description>
 <dc:description>Comment: 49 pages</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04023</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interspecies Knowledge Transfer for Facial Keypoint Detection</dc:title>
 <dc:creator>Rashid, Maheen</dc:creator>
 <dc:creator>Gu, Xiuye</dc:creator>
 <dc:creator>Lee, Yong Jae</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a method for localizing facial keypoints on animals by
transferring knowledge gained from human faces. Instead of directly finetuning
a network trained to detect keypoints on human faces to animal faces (which is
sub-optimal since human and animal faces can look quite different), we propose
to first adapt the animal images to the pre-trained human detection network by
correcting for the differences in animal and human face shape. We first find
the nearest human neighbors for each animal image using an unsupervised shape
matching method. We use these matches to train a thin plate spline warping
network to warp each animal face to look more human-like. The warping network
is then jointly finetuned with a pre-trained human facial keypoint detection
network using an animal dataset. We demonstrate state-of-the-art results on
both horse and sheep facial keypoint detection, and significant improvement
over simple finetuning, especially when training data is scarce. Additionally,
we present a new dataset with 3717 images with horse face and facial keypoint
annotations.
</dc:description>
 <dc:description>Comment: CVPR 2017 Camera Ready</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04029</identifier>
 <datestamp>2017-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Free constructions and coproducts of d-frames</dc:title>
 <dc:creator>Jakl, Tom&#xe1;&#x161;</dc:creator>
 <dc:creator>Jung, Achim</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  A general theory of presentations for d-frames does not yet exist. We review
the difficulties and give sufficient conditions for when they can be overcome.
As an application we prove that the category of d-frames is closed under
coproducts.
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-04-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04037</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Zero-order Reverse Filtering</dc:title>
 <dc:creator>Tao, Xin</dc:creator>
 <dc:creator>Zhou, Chao</dc:creator>
 <dc:creator>Shen, Xiaoyong</dc:creator>
 <dc:creator>Wang, Jue</dc:creator>
 <dc:creator>Jia, Jiaya</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we study an unconventional but practically meaningful
reversibility problem of commonly used image filters. We broadly define filters
as operations to smooth images or to produce layers via global or local
algorithms. And we raise the intriguingly problem if they are reservable to the
status before filtering. To answer it, we present a novel strategy to
understand general filter via contraction mappings on a metric space. A very
simple yet effective zero-order algorithm is proposed. It is able to
practically reverse most filters with low computational cost. We present quite
a few experiments in the paper and supplementary file to thoroughly verify its
performance. This method can also be generalized to solve other inverse
problems and enables new applications.
</dc:description>
 <dc:description>Comment: 9 pages, submitted to conference</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04038</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Denoising a Point Cloud for Surface Reconstruction</dc:title>
 <dc:creator>Cheng, Siu-Wing</dc:creator>
 <dc:creator>Lau, Man-Kit</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Surface reconstruction from an unorganized point cloud is an important
problem due to its widespread applications. White noise, possibly clustered
outliers, and noisy perturbation may be generated when a point cloud is sampled
from a surface. Most existing methods handle limited amount of noise. We
develop a method to denoise a point cloud so that the users can run their
surface reconstruction codes or perform other analyses afterwards. Our
experiments demonstrate that our method is computationally efficient and it has
significantly better noise handling ability than several existing surface
reconstruction codes.
</dc:description>
 <dc:description>Comment: 13 pages, 6 figures</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04039</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D Deep Learning for Biological Function Prediction from Physical Fields</dc:title>
 <dc:creator>Golkov, Vladimir</dc:creator>
 <dc:creator>Skwark, Marcin J.</dc:creator>
 <dc:creator>Mirchev, Atanas</dc:creator>
 <dc:creator>Dikov, Georgi</dc:creator>
 <dc:creator>Geanes, Alexander R.</dc:creator>
 <dc:creator>Mendenhall, Jeffrey</dc:creator>
 <dc:creator>Meiler, Jens</dc:creator>
 <dc:creator>Cremers, Daniel</dc:creator>
 <dc:subject>Quantitative Biology - Biomolecules</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:description>  Predicting the biological function of molecules, be it proteins or drug-like
compounds, from their atomic structure is an important and long-standing
problem. Function is dictated by structure, since it is by spatial interactions
that molecules interact with each other, both in terms of steric
complementarity, as well as intermolecular forces. Thus, the electron density
field and electrostatic potential field of a molecule contain the &quot;raw
fingerprint&quot; of how this molecule can fit to binding partners. In this paper,
we show that deep learning can predict biological function of molecules
directly from their raw 3D approximated electron density and electrostatic
potential fields. Protein function based on EC numbers is predicted from the
approximated electron density field. In another experiment, the activity of
small molecules is predicted with quality comparable to state-of-the-art
descriptor-based methods. We propose several alternative computational models
for the GPU with different memory and runtime requirements for different sizes
of molecules and of databases. We also propose application-specific
multi-channel data representations. With future improvements of training
datasets and neural network settings in combination with complementary
information sources (sequence, genomic context, expression level), deep
learning can be expected to show its generalization power and revolutionize the
field of molecular function prediction.
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04039</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04047</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the interplay between Babai and Cerny's conjectures</dc:title>
 <dc:creator>Gonze, Fran&#xe7;ois</dc:creator>
 <dc:creator>Gusev, Vladimir</dc:creator>
 <dc:creator>Gerencs&#xe9;r, Bal&#xe1;zs</dc:creator>
 <dc:creator>Jungers, Rapha&#xeb;l M.</dc:creator>
 <dc:creator>Volkov, Mikhail V.</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:description>  Motivated by the Babai conjecture and the Cerny conjecture, we study the
reset thresholds of automata with the transition monoid equal to the full
monoid of transformations of the state set. For automata with $n$ states in
this class, we prove that the reset thresholds are upper-bounded by $2n^2-6n+5$
and can attain the value $\tfrac{n(n-1)}{2}$. In addition, we study diameters
of the pair digraphs of permutation automata and construct $n$-state
permutation automata with diameter $\tfrac{n^2}{4} + o(n^2)$.
</dc:description>
 <dc:description>Comment: 21 pages version with full proofs</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04047</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04050</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Neighboring Selection Algorithm Based on Curvature Prediction
  in Manifold Learning</dc:title>
 <dc:creator>Ma, Lin</dc:creator>
 <dc:creator>Zhou, Caifa</dc:creator>
 <dc:creator>Liu, Xi</dc:creator>
 <dc:creator>Xu, Yubin</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recently manifold learning algorithm for dimensionality reduction attracts
more and more interests, and various linear and nonlinear, global and local
algorithms are proposed. The key step of manifold learning algorithm is the
neighboring region selection. However, so far for the references we know, few
of which propose a generally accepted algorithm to well select the neighboring
region. So in this paper, we propose an adaptive neighboring selection
algorithm, which successfully applies the LLE and ISOMAP algorithms in the
test. It is an algorithm that can find the optimal K nearest neighbors of the
data points on the manifold. And the theoretical basis of the algorithm is the
approximated curvature of the data point on the manifold. Based on Riemann
Geometry, Jacob matrix is a proper mathematical concept to predict the
approximated curvature. By verifying the proposed algorithm on embedding Swiss
roll from R3 to R2 based on LLE and ISOMAP algorithm, the simulation results
show that the proposed adaptive neighboring selection algorithm is feasible and
able to find the optimal value of K, making the residual variance relatively
small and better visualization of the results. By quantitative analysis, the
embedding quality measured by residual variance is increased 45.45% after using
the proposed algorithm in LLE.
</dc:description>
 <dc:description>Comment: 3 figures, from Journal of Harbin Institute of Technology</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04050</dc:identifier>
 <dc:identifier>Journal of Harbin Institute of Technology, 20(3), pp.119--123
  (2013)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04053</identifier>
 <datestamp>2017-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling a Traffic Remapping Attack Game in a Multi-hop Ad Hoc Network</dc:title>
 <dc:creator>Konorski, Jerzy</dc:creator>
 <dc:creator>Szott, Szymon</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>91A06, 91A10, 91A80</dc:subject>
 <dc:subject>C.2.0</dc:subject>
 <dc:subject>C.2.5</dc:subject>
 <dc:description>  In multi-hop ad hoc networks, selfish nodes may unduly acquire high quality
of service (QoS) by assigning higher priority to source packets and lower
priority to transit packets. Such traffic remapping attacks (TRAs) are cheap to
launch, impossible to prevent, hard to detect, and harmful to non-selfish
nodes. While studied mostly in single-hop wireless network settings, TRAs have
resisted analysis in multi-hop settings. In this paper we offer a
game-theoretic approach: we derive a formal model of opportunistic TRAs, define
a TRA game with a heuristic rank-based payoff function, and propose a boundedly
rational multistage attack strategy that both selfish and non-selfish nodes are
free to use. Thus non-selfish nodes are allowed to respond in kind to selfish
ones. We characterize the form of equilibrium that the multistage play reaches
and verify via simulation that it often coincides with a Nash equilibrium in
which harmful TRAs are curbed in the first place, whereas harmless ones need
not be.
</dc:description>
 <dc:description>Comment: Accepted for IEEE GLOBECOM 2017</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04054</identifier>
 <datestamp>2017-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Saliency-guided Adaptive Seeding for Supervoxel Segmentation</dc:title>
 <dc:creator>Gao, Ge</dc:creator>
 <dc:creator>Lauri, Mikko</dc:creator>
 <dc:creator>Zhang, Jianwei</dc:creator>
 <dc:creator>Frintrop, Simone</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a new saliency-guided method for generating supervoxels in 3D
space. Rather than using an evenly distributed spatial seeding procedure, our
method uses visual saliency to guide the process of supervoxel generation. This
results in densely distributed, small, and precise supervoxels in salient
regions which often contain objects, and larger supervoxels in less salient
regions that often correspond to background. Our approach largely improves the
quality of the resulting supervoxel segmentation in terms of boundary recall
and under-segmentation error on publicly available benchmarks.
</dc:description>
 <dc:description>Comment: 6 pages, accepted to IROS2017</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-10-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04054</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04055</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Land Cover Classification via Multi-temporal Spatial Data by Recurrent
  Neural Networks</dc:title>
 <dc:creator>Ienco, Dino</dc:creator>
 <dc:creator>Gaetano, Raffaele</dc:creator>
 <dc:creator>Dupaquier, Claire</dc:creator>
 <dc:creator>Maurel, Pierre</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Nowadays, modern earth observation programs produce huge volumes of satellite
images time series (SITS) that can be useful to monitor geographical areas
through time. How to efficiently analyze such kind of information is still an
open question in the remote sensing field. Recently, deep learning methods
proved suitable to deal with remote sensing data mainly for scene
classification (i.e. Convolutional Neural Networks - CNNs - on single images)
while only very few studies exist involving temporal deep learning approaches
(i.e Recurrent Neural Networks - RNNs) to deal with remote sensing time series.
In this letter we evaluate the ability of Recurrent Neural Networks, in
particular the Long-Short Term Memory (LSTM) model, to perform land cover
classification considering multi-temporal spatial data derived from a time
series of satellite images. We carried out experiments on two different
datasets considering both pixel-based and object-based classification. The
obtained results show that Recurrent Neural Networks are competitive compared
to state-of-the-art classifiers, and may outperform classical approaches in
presence of low represented and/or highly mixed classes. We also show that
using the alternative feature representation generated by LSTM can improve the
performances of standard classifiers.
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04055</dc:identifier>
 <dc:identifier>doi:10.1109/LGRS.2017.2728698</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04057</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DCFNet: Discriminant Correlation Filters Network for Visual Tracking</dc:title>
 <dc:creator>Wang, Qiang</dc:creator>
 <dc:creator>Gao, Jin</dc:creator>
 <dc:creator>Xing, Junliang</dc:creator>
 <dc:creator>Zhang, Mengdan</dc:creator>
 <dc:creator>Hu, Weiming</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Discriminant Correlation Filters (DCF) based methods now become a kind of
dominant approach to online object tracking. The features used in these
methods, however, are either based on hand-crafted features like HoGs, or
convolutional features trained independently from other tasks like image
classification. In this work, we present an end-to-end lightweight network
architecture, namely DCFNet, to learn the convolutional features and perform
the correlation tracking process simultaneously. Specifically, we treat DCF as
a special correlation filter layer added in a Siamese network, and carefully
derive the backpropagation through it by defining the network output as the
probability heatmap of object location. Since the derivation is still carried
out in Fourier frequency domain, the efficiency property of DCF is preserved.
This enables our tracker to run at more than 60 FPS during test time, while
achieving a significant accuracy gain compared with KCF using HoGs. Extensive
evaluations on OTB-2013, OTB-2015, and VOT2015 benchmarks demonstrate that the
proposed DCFNet tracker is competitive with several state-of-the-art trackers,
while being more compact and much faster.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04057</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04058</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving ill-posed inverse problems using iterative deep neural networks</dc:title>
 <dc:creator>Adler, Jonas</dc:creator>
 <dc:creator>&#xd6;ktem, Ozan</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We propose a partially learned approach for the solution of ill posed inverse
problems with not necessarily linear forward operators. The method builds on
ideas from classical regularization theory and recent advances in deep learning
to perform learning while making use of prior information about the inverse
problem encoded in the forward operator, noise model and a regularizing
functional. The method results in a gradient-like iterative scheme, where the
&quot;gradient&quot; component is learned using a convolutional network that includes the
gradients of the data discrepancy and regularizer as input in each iteration.
We present results of such a partially learned gradient scheme on a non-linear
tomographic inversion problem with simulated data from both the Sheep-Logan
phantom as well as a head CT. The outcome is compared against FBP and TV
reconstruction and the proposed method provides a 5.4 dB PSNR improvement over
the TV reconstruction while being significantly faster, giving reconstructions
of 512 x 512 volumes in about 0.4 seconds using a single GPU.
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04058</dc:identifier>
 <dc:identifier>Inverse Problems 2017</dc:identifier>
 <dc:identifier>doi:10.1088/1361-6420/aa9581</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04081</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Estimate Pose by Watching Videos</dc:title>
 <dc:creator>Chakraborty, Prabuddha</dc:creator>
 <dc:creator>Namboodiri, Vinay P.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we propose a technique for obtaining coarse pose estimation of
humans in an image that does not require any manual supervision. While a
general unsupervised technique would fail to estimate human pose, we suggest
that sufficient information about coarse pose can be obtained by observing
human motion in multiple frames. Specifically, we consider obtaining surrogate
supervision through videos as a means for obtaining motion based grouping cues.
We supplement the method using a basic object detector that detects persons.
With just these components we obtain a rough estimate of the human pose.
  With these samples for training, we train a fully convolutional neural
network (FCNN)[20] to obtain accurate dense blob based pose estimation. We show
that the results obtained are close to the ground-truth and to the results
obtained using a fully supervised convolutional pose estimation method [31] as
evaluated on a challenging dataset [15]. This is further validated by
evaluating the obtained poses using a pose based action recognition method [5].
In this setting we outperform the results as obtained using the baseline method
that uses a fully supervised pose estimation algorithm and is competitive with
a new baseline created using convolutional pose estimation with full
supervision.
</dc:description>
 <dc:description>Comment: 11 pages, 8 figures, under review</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04083</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constructions of optimal LCD codes over large finite fields</dc:title>
 <dc:creator>Sok, Lin</dc:creator>
 <dc:creator>Shi, Minjia</dc:creator>
 <dc:creator>Sol&#xe9;, Patrick</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we prove existence of optimal complementary dual codes (LCD
codes) over large finite fields. We also give methods to generate orthogonal
matrices over finite fields and then apply them to construct LCD codes.
Construction methods include random sampling in the orthogonal group, code
extension, matrix product codes and projection over a self-dual basis.
</dc:description>
 <dc:description>Comment: This paper was presented in part at the International Conference on
  Coding, Cryptography and Related Topics April 7-10, 2017, Shandong, China</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04083</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04084</identifier>
 <datestamp>2017-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two variants of the Froiduire-Pin Algorithm for finite semigroups</dc:title>
 <dc:creator>Jonu&#x161;as, J.</dc:creator>
 <dc:creator>Mitchell, J. D.</dc:creator>
 <dc:creator>Pfeiffer, M.</dc:creator>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>20M10</dc:subject>
 <dc:description>  In this paper, we present two algorithms based on the Froidure-Pin Algorithm
for computing the structure of a finite semigroup from a generating set. As was
the case with the original algorithm of Froidure and Pin, the algorithms
presented here produce the left and right Cayley graphs, a confluent
terminating rewriting system, and a reduced word of the rewriting system for
every element of the semigroup.
  If $U$ is any semigroup, and $A$ is a subset of $U$, then we denote by
$\langle A\rangle$ the least subsemigroup of $U$ containing $A$. If $B$ is any
other subset of $U$, then, roughly speaking, the first algorithm we present
describes how to use any information about $\langle A\rangle$, that has been
found using the Froidure-Pin Algorithm, to compute the semigroup $\langle A\cup
B\rangle$. More precisely, we describe the data structure for a finite
semigroup $S$ given by Froidure and Pin, and how to obtain such a data
structure for $\langle A\cup B\rangle$ from that for $\langle A\rangle$. The
second algorithm is a lock-free concurrent version of the Froidure-Pin
Algorithm.
</dc:description>
 <dc:description>Comment: 19 pages, 7 figures (v2 revised according to referees comments to
  improve the readability, and add a further 1198 examples)</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-06-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04086</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond Face Rotation: Global and Local Perception GAN for Photorealistic
  and Identity Preserving Frontal View Synthesis</dc:title>
 <dc:creator>Huang, Rui</dc:creator>
 <dc:creator>Zhang, Shu</dc:creator>
 <dc:creator>Li, Tianyu</dc:creator>
 <dc:creator>He, Ran</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Photorealistic frontal view synthesis from a single face image has a wide
range of applications in the field of face recognition. Although data-driven
deep learning methods have been proposed to address this problem by seeking
solutions from ample face data, this problem is still challenging because it is
intrinsically ill-posed. This paper proposes a Two-Pathway Generative
Adversarial Network (TP-GAN) for photorealistic frontal view synthesis by
simultaneously perceiving global structures and local details. Four landmark
located patch networks are proposed to attend to local textures in addition to
the commonly used global encoder-decoder network. Except for the novel
architecture, we make this ill-posed problem well constrained by introducing a
combination of adversarial loss, symmetry loss and identity preserving loss.
The combined loss function leverages both frontal face distribution and
pre-trained discriminative deep face models to guide an identity preserving
inference of frontal views from profiles. Different from previous deep learning
methods that mainly rely on intermediate features for recognition, our method
directly leverages the synthesized identity preserving image for downstream
tasks like face recognition and attribution estimation. Experimental results
demonstrate that our method not only presents compelling perceptual results but
also outperforms state-of-the-art results on large pose face recognition.
</dc:description>
 <dc:description>Comment: accepted at ICCV 2017, main paper &amp; supplementary material, 11 pages</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04086</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04095</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training Neural Networks Based on Imperialist Competitive Algorithm for
  Predicting Earthquake Intensity</dc:title>
 <dc:creator>Moradi, Mohsen</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>68T50</dc:subject>
 <dc:description>  In this study we determined neural network weights and biases by Imperialist
Competitive Algorithm (ICA) in order to train network for predicting earthquake
intensity in Richter. For this reason, we used dependent parameters like
earthquake occurrence time, epicenter's latitude and longitude in degree, focal
depth in kilometer, and the seismological center distance from epicenter and
earthquake focal center in kilometer which has been provided by Berkeley data
base. The studied neural network has two hidden layer: its first layer has 16
neurons and the second layer has 24 neurons. By using ICA algorithm, average
error for testing data is 0.0007 with a variance equal to 0.318. The earthquake
prediction error in Richter by MSE criteria for ICA algorithm is 0.101, but by
using GA, the MSE value is 0.115.
</dc:description>
 <dc:description>Comment: 5 pages, 6 figures</dc:description>
 <dc:date>2017-02-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04095</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04097</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recognizing Activities of Daily Living from Egocentric Images</dc:title>
 <dc:creator>Cartas, Alejandro</dc:creator>
 <dc:creator>Mar&#xed;n, Juan</dc:creator>
 <dc:creator>Radeva, Petia</dc:creator>
 <dc:creator>Dimiccoli, Mariella</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recognizing Activities of Daily Living (ADLs) has a large number of health
applications, such as characterize lifestyle for habit improvement, nursing and
rehabilitation services. Wearable cameras can daily gather large amounts of
image data that provide rich visual information about ADLs than using other
wearable sensors. In this paper, we explore the classification of ADLs from
images captured by low temporal resolution wearable camera (2fpm) by using a
Convolutional Neural Networks (CNN) approach. We show that the classification
accuracy of a CNN largely improves when its output is combined, through a
random decision forest, with contextual information from a fully connected
layer. The proposed method was tested on a subset of the NTCIR-12 egocentric
dataset, consisting of 18,674 images and achieved an overall accuracy of 86%
activity recognition on 21 classes.
</dc:description>
 <dc:description>Comment: To appear in the Proceedings of IbPRIA 2017</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04097</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04100</identifier>
 <datestamp>2017-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-lingual and cross-domain discourse segmentation of entire
  documents</dc:title>
 <dc:creator>Braud, Chlo&#xe9;</dc:creator>
 <dc:creator>Lacroix, Oph&#xe9;lie</dc:creator>
 <dc:creator>S&#xf8;gaard, Anders</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Discourse segmentation is a crucial step in building end-to-end discourse
parsers. However, discourse segmenters only exist for a few languages and
domains. Typically they only detect intra-sentential segment boundaries,
assuming gold standard sentence and token segmentation, and relying on
high-quality syntactic parses and rich heuristics that are not generally
available across languages and domains. In this paper, we propose statistical
discourse segmenters for five languages and three domains that do not rely on
gold pre-annotations. We also consider the problem of learning discourse
segmenters when no labeled data is available for a language. Our fully
supervised system obtains 89.5% F1 for English newswire, with slight drops in
performance on other domains, and we report supervised and unsupervised
(cross-lingual) results for five languages in total.
</dc:description>
 <dc:description>Comment: To appear in Proceedings of ACL 2017</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-04-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04110</identifier>
 <datestamp>2017-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks</dc:title>
 <dc:creator>Flunkert, Valentin</dc:creator>
 <dc:creator>Salinas, David</dc:creator>
 <dc:creator>Gasthaus, Jan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A key enabler for optimizing business processes is accurately estimating the
probability distribution of a time series future given its past. Such
probabilistic forecasts are crucial for example for reducing excess inventory
in supply chains. In this paper we propose DeepAR, a novel methodology for
producing accurate probabilistic forecasts, based on training an
auto-regressive recurrent network model on a large number of related time
series. We show through extensive empirical evaluation on several real-world
forecasting data sets that our methodology is more accurate than
state-of-the-art models, while requiring minimal feature engineering.
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04110</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04118</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Data to Decisions: Distributionally Robust Optimization is Optimal</dc:title>
 <dc:creator>Van Parys, Bart P. G.</dc:creator>
 <dc:creator>Esfahani, Peyman Mohajerin</dc:creator>
 <dc:creator>Kuhn, Daniel</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study stochastic programs where the decision-maker cannot observe the
distribution of the exogenous uncertainties but has access to a finite set of
independent samples from this distribution. In this setting, the goal is to
find a procedure that transforms the data to an estimate of the expected cost
function under the unknown data-generating distribution, i.e., a predictor, and
an optimizer of the estimated cost function that serves as a near-optimal
candidate decision, i.e., a prescriptor. As functions of the data, predictors
and prescriptors constitute statistical estimators. We propose a
meta-optimization problem to find the least conservative predictors and
prescriptors subject to constraints on their out-of-sample disappointment. The
out-of-sample disappointment quantifies the probability that the actual
expected cost of the candidate decision under the unknown true distribution
exceeds its predicted cost. Leveraging tools from large deviations theory, we
prove that this meta-optimization problem admits a unique solution: The best
predictor-prescriptor pair is obtained by solving a distributionally robust
optimization problem over all distributions within a given relative entropy
distance from the empirical distribution of the data.
</dc:description>
 <dc:description>Comment: 30 pages, 2 figures. Submitted to Management Science</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04118</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04119</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Search for Improved Performance in Regular Expressions</dc:title>
 <dc:creator>Cody-Kenny, Brendan</dc:creator>
 <dc:creator>Fenton, Michael</dc:creator>
 <dc:creator>Ronayne, Adrian</dc:creator>
 <dc:creator>Considine, Eoghan</dc:creator>
 <dc:creator>McGuire, Thomas</dc:creator>
 <dc:creator>O'Neill, Michael</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The primary aim of automated performance improvement is to reduce the running
time of programs while maintaining (or improving on) functionality. In this
paper, Genetic Programming is used to find performance improvements in regular
expressions for an array of target programs, representing the first application
of automated software improvement for run-time performance in the Regular
Expression language. This particular problem is interesting as there may be
many possible alternative regular expressions which perform the same task while
exhibiting subtle differences in performance. A benchmark suite of candidate
regular expressions is proposed for improvement. We show that the application
of Genetic Programming techniques can result in performance improvements in all
cases.
  As we start evolution from a known good regular expression, diversity is
critical in escaping the local optima of the seed expression. In order to
understand diversity during evolution we compare an initial population
consisting of only seed programs with a population initialised using a
combination of a single seed individual with individuals generated using PI
Grow and Ramped-half-and-half initialisation mechanisms.
</dc:description>
 <dc:description>Comment: Submitted to the Search-Based Software Engineering (SBSE) track at
  the Genetic and Evolutionary Computation Conference (GECCO) 2017</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04119</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04126</identifier>
 <datestamp>2017-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Single Image Super-Resolution based on Wiener Filter in Similarity
  Domain</dc:title>
 <dc:creator>Cruz, Crist&#xf3;v&#xe3;o</dc:creator>
 <dc:creator>Mehta, Rakesh</dc:creator>
 <dc:creator>Katkovnik, Vladimir</dc:creator>
 <dc:creator>Egiazarian, Karen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Single image super resolution (SISR) is an ill-posed problem aiming at
estimating a plausible high resolution (HR) image from a single low resolution
(LR) image. Current state-of-the-art SISR methods are patch-based. They use
either external data or internal self-similarity to learn a prior for a HR
image. External data based methods utilize large number of patches from the
training data, while self-similarity based approaches leverage one or more
similar patches from the input image. In this paper we propose a
self-similarity based approach that is able to use large groups of similar
patches extracted from the input image to solve the SISR problem. We introduce
a novel prior leading to collaborative filtering of patch groups in 1D
similarity domain and couple it with an iterative back-projection framework.
The performance of the proposed algorithm is evaluated on a number of SISR
benchmark datasets. Without using any external data, the proposed approach
outperforms the current non-CNN based methods on the tested datasets for
various scaling factors. On certain datasets, the gain is over 1 dB, when
compared to the recent method A+. For high sampling rate (x4) the proposed
method performs similarly to very recent state-of-the-art deep convolutional
network based approaches.
</dc:description>
 <dc:description>Comment: Paper accepted for publication on IEEE Transactions on Image
  Processing</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04126</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2017.2779265</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04131</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Face Editing with Intrinsic Image Disentangling</dc:title>
 <dc:creator>Shu, Zhixin</dc:creator>
 <dc:creator>Yumer, Ersin</dc:creator>
 <dc:creator>Hadap, Sunil</dc:creator>
 <dc:creator>Sunkavalli, Kalyan</dc:creator>
 <dc:creator>Shechtman, Eli</dc:creator>
 <dc:creator>Samaras, Dimitris</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Traditional face editing methods often require a number of sophisticated and
task specific algorithms to be applied one after the other --- a process that
is tedious, fragile, and computationally intensive. In this paper, we propose
an end-to-end generative adversarial network that infers a face-specific
disentangled representation of intrinsic face properties, including shape (i.e.
normals), albedo, and lighting, and an alpha matte. We show that this network
can be trained on &quot;in-the-wild&quot; images by incorporating an in-network
physically-based image formation module and appropriate loss functions. Our
disentangling latent representation allows for semantically relevant edits,
where one aspect of facial appearance can be manipulated while keeping
orthogonal properties fixed, and we demonstrate its use for a number of facial
editing applications.
</dc:description>
 <dc:description>Comment: CVPR 2017 oral</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04131</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04133</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Explaining the Unexplained: A CLass-Enhanced Attentive Response (CLEAR)
  Approach to Understanding Deep Neural Networks</dc:title>
 <dc:creator>Kumar, Devinder</dc:creator>
 <dc:creator>Wong, Alexander</dc:creator>
 <dc:creator>Taylor, Graham W.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  In this work, we propose CLass-Enhanced Attentive Response (CLEAR): an
approach to visualize and understand the decisions made by deep neural networks
(DNNs) given a specific input. CLEAR facilitates the visualization of attentive
regions and levels of interest of DNNs during the decision-making process. It
also enables the visualization of the most dominant classes associated with
these attentive regions of interest. As such, CLEAR can mitigate some of the
shortcomings of heatmap-based methods associated with decision ambiguity, and
allows for better insights into the decision-making process of DNNs.
Quantitative and qualitative experiments across three different datasets
demonstrate the efficacy of CLEAR for gaining a better understanding of the
inner workings of DNNs during the decision-making process.
</dc:description>
 <dc:description>Comment: Accepted at Computer Vision and Patter Recognition Workshop (CVPR-W)
  on Explainable Computer Vision, 2017</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04133</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04137</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fashion Conversation Data on Instagram</dc:title>
 <dc:creator>Ha, Yu-I</dc:creator>
 <dc:creator>Kwon, Sejeong</dc:creator>
 <dc:creator>Cha, Meeyoung</dc:creator>
 <dc:creator>Joo, Jungseock</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The fashion industry is establishing its presence on a number of
visual-centric social media like Instagram. This creates an interesting clash
as fashion brands that have traditionally practiced highly creative and
editorialized image marketing now have to engage with people on the platform
that epitomizes impromptu, realtime conversation. What kinds of fashion images
do brands and individuals share and what are the types of visual features that
attract likes and comments? In this research, we take both quantitative and
qualitative approaches to answer these questions. We analyze visual features of
fashion posts first via manual tagging and then via training on convolutional
neural networks. The classified images were examined across four types of
fashion brands: mega couture, small couture, designers, and high street. We
find that while product-only images make up the majority of fashion
conversation in terms of volume, body snaps and face images that portray
fashion items more naturally tend to receive a larger number of likes and
comments by the audience. Our findings bring insights into building an
automated tool for classifying or generating influential fashion information.
We make our novel dataset of {24,752} labeled images on fashion conversations,
containing visual and textual cues, available for the research community.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures, This paper will be presented at ICWSM'17</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04137</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04141</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Procedural Texture Generation Framework Based on Semantic Descriptions</dc:title>
 <dc:creator>Dong, Junyu</dc:creator>
 <dc:creator>Wang, Lina</dc:creator>
 <dc:creator>Liu, Jun</dc:creator>
 <dc:creator>Sun, Xin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Procedural textures are normally generated from mathematical models with
parameters carefully selected by experienced users. However, for naive users,
the intuitive way to obtain a desired texture is to provide semantic
descriptions such as &quot;regular,&quot; &quot;lacelike,&quot; and &quot;repetitive&quot; and then a
procedural model with proper parameters will be automatically suggested to
generate the corresponding textures. By contrast, it is less practical for
users to learn mathematical models and tune parameters based on multiple
examinations of large numbers of generated textures. In this study, we propose
a novel framework that generates procedural textures according to user-defined
semantic descriptions, and we establish a mapping between procedural models and
semantic texture descriptions. First, based on a vocabulary of semantic
attributes collected from psychophysical experiments, a multi-label learning
method is employed to annotate a large number of textures with semantic
attributes to form a semantic procedural texture dataset. Then, we derive a low
dimensional semantic space in which the semantic descriptions can be separated
from one other. Finally, given a set of semantic descriptions, the diverse
properties of the samples in the semantic space can lead the framework to find
an appropriate generation model that uses appropriate parameters to produce a
desired texture. The experimental results show that the proposed framework is
effective and that the generated textures closely correlate with the input
semantic descriptions.
</dc:description>
 <dc:description>Comment: 9 pages, 10 figures</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04141</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04146</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Traffic Minimizing Caching and Latent Variable Distributions of Order
  Statistics</dc:title>
 <dc:creator>P&#xe4;&#xe4;kk&#xf6;nen, Joonas</dc:creator>
 <dc:creator>Dharmawansa, Prathapasinghe</dc:creator>
 <dc:creator>Freij-Hollanti, Ragnar</dc:creator>
 <dc:creator>Hollanti, Camilla</dc:creator>
 <dc:creator>Tirkkonen, Olav</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Given a statistical model for the request frequencies and sizes of data
objects in a caching system, we derive the probability density of the size of
the file that accounts for the largest amount of data traffic. This is
equivalent to finding the required size of the cache for a caching placement
that maximizes the expected byte hit ratio for given file size and popularity
distributions. The file that maximizes the expected byte hit ratio is the file
for which the product of its size and popularity is the highest -- thus, it is
the file that incurs the greatest load on the network. We generalize this
theoretical problem to cover factors and addends of arbitrary order statistics
for given parent distributions. Further, we study the asymptotic behavior of
these distributions. We give several factor and addend densities of widely-used
distributions, and verify our results by extensive computer simulations.
</dc:description>
 <dc:description>Comment: 24 pages, 6 figures, submitted to IEEE Transactions on Communications</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04146</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04149</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Transfer of Energy and Information in a Two-hop Relay Channel</dc:title>
 <dc:creator>Bafghi, Ali H. Abdollahi</dc:creator>
 <dc:creator>Mirmohseni, Mahtab</dc:creator>
 <dc:creator>Aref, Mohammad Reza</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the problem of joint information and energy transfer in a two-hop
channel with a Radio frequency (RF) energy harvesting relay. We consider a
finite battery size at the relay and deterministic energy loss in transmitting
energy. In other words, to be able to send an energy-contained symbol, the
relay must receive multiple energy-contained symbols. Thus, we face a kind of
channel with memory. We model the energy saved in battery as channel state with
the challenge that the receiver does not know the channel state. First, we
consider the problem without any channel noise and derive an achievable rate.
Next, we extend the results to the case with an independent and identically
distributed noise in the second hop (the relay-receiver link).
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04149</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04154</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Joint Multilingual Sentence Representations with Neural Machine
  Translation</dc:title>
 <dc:creator>Schwenk, Holger</dc:creator>
 <dc:creator>Douze, Matthijs</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>68T50</dc:subject>
 <dc:description>  In this paper, we use the framework of neural machine translation to learn
joint sentence representations across six very different languages. Our aim is
that a representation which is independent of the language, is likely to
capture the underlying semantics. We define a new cross-lingual similarity
measure, compare up to 1.4M sentence representations and study the
characteristics of close sentences. We provide experimental evidence that
sentences that are close in embedding space are indeed semantically highly
related, but often have quite different structure and syntax. These relations
also hold when comparing sentences in different languages.
</dc:description>
 <dc:description>Comment: 11 pages, 2 figures, published at ACL workshop RepL4NLP</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04154</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04155</identifier>
 <datestamp>2017-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Timely Updates over an Erasure Channel</dc:title>
 <dc:creator>Yates, Roy D.</dc:creator>
 <dc:creator>Najm, Elie</dc:creator>
 <dc:creator>Soljanin, Emina</dc:creator>
 <dc:creator>Zhong, Jing</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Using an age of information (AoI) metric, we examine the transmission of
coded updates through a binary erasure channel to a monitor/receiver. We start
by deriving the average status update age of an infinite incremental redundancy
(IIR) system in which the transmission of a k-symbol update continuesuntil k
symbols are received. This system is then compared to a fixed redundancy (FR)
system in which each update is transmitted as an n symbol packet and the packet
is successfully received if and only if at least k symbols are received. If
fewer than k symbols are received, the update is discarded. Unlike the IIR
system, the FR system requires no feedback from the receiver. For a single
monitor system, we show that tuning the redundancy to the symbol erasure rate
enables the FR system to perform as well as the IIR system. As the number of
monitors is increased, the FR system outperforms the IIR system that guarantees
delivery of all updates to all monitors.
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-05-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04155</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04157</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accurate and reduced SISO Sequence Impedance Models of Grid-tied Voltage
  Source Converter for Small Signal Stability Analysis</dc:title>
 <dc:creator>Zhang, Chen</dc:creator>
 <dc:creator>Cai, Xu</dc:creator>
 <dc:creator>Rygg, Atle</dc:creator>
 <dc:creator>Molinas, Marta</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Impedance models are widely used in assessing small signal stability of
grid-tied voltage source converter (VSC) systems. Recent research has proven
that impedance models of grid-tied VSC in both dq and sequence domains are
generally Multi-Input Multi-Output (MIMO) systems, and the generalized Nyquist
criterion has to be applied for stability analysis to these MIMO systems.
However, finding Single-Input and Single-Output (SISO) equivalents for this
system is always appealing because of the simplicity and the convenience for
physical interpretation when assessing the stability, compared to MIMO systems.
This paper presents two types of SISO impedance models of grid-tied VSC system,
one is derived from the strong grid assumption, and the other is from the
closed-loop equivalence. The accuracy of these models is assessed with respect
to the measured impedances in PSCAD/EMTDC, and their effects on the stability
assessment were analyzed as well. It is proven that the accurate SISO model
gives identical result as the MIMO (matrix-based) impedance model with respect
to stability analysis. However, the reduced SISO model may lead to wrong
results if the bandwidth of phase locked loop is large.
</dc:description>
 <dc:description>Comment: 17 pages, 8 figures</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04157</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04158</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>I-MMSE relations in random linear estimation and a sub-extensive
  interpolation method</dc:title>
 <dc:creator>Barbier, Jean</dc:creator>
 <dc:creator>Macris, Nicolas</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:description>  Consider random linear estimation with Gaussian measurement matrices and
noise. One can compute infinitesimal variations of the mutual information under
infinitesimal variations of the signal-to-noise ratio or of the measurement
rate. We discuss how each variation is related to the minimum mean-square error
and deduce that the two variations are directly connected through a very simple
identity. The main technical ingredient is a new interpolation method called
&quot;sub-extensive interpolation method&quot;. We use it to provide a new proof of an
I-MMSE relation recently found by Reeves and Pfister [1] when the measurement
rate is varied. Our proof makes it clear that this relation is intimately
related to another I-MMSE relation also recently proved in [2]. One can
directly verify that the identity relating the two types of variation of mutual
information is indeed consistent with the one letter replica symmetric formula
for the mutual information, first derived by Tanaka [3] for binary signals, and
recently proved in more generality in [1,2,4,5] (by independent methods).
However our proof is independent of any knowledge of Tanaka's formula.
</dc:description>
 <dc:description>Comment: Presented at the International Symposium on Information Theory (ISIT)
  2017, Aachen, Germany</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04158</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04163</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectrum Approximation Beyond Fast Matrix Multiplication: Algorithms and
  Hardness</dc:title>
 <dc:creator>Musco, Cameron</dc:creator>
 <dc:creator>Netrapalli, Praneeth</dc:creator>
 <dc:creator>Sidford, Aaron</dc:creator>
 <dc:creator>Ubaru, Shashanka</dc:creator>
 <dc:creator>Woodruff, David P.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  Understanding the singular value spectrum of a matrix $A \in \mathbb{R}^{n
\times n}$ is a fundamental task in countless applications. In matrix
multiplication time, it is possible to perform a full SVD and directly compute
the singular values $\sigma_1,...,\sigma_n$. However, little is known about
algorithms that break this runtime barrier.
  Using tools from stochastic trace estimation, polynomial approximation, and
fast system solvers, we show how to efficiently isolate different ranges of
$A$'s spectrum and approximate the number of singular values in these ranges.
We thus effectively compute a histogram of the spectrum, which can stand in for
the true singular values in many applications.
  We use this primitive to give the first algorithms for approximating a wide
class of symmetric matrix norms in faster than matrix multiplication time. For
example, we give a $(1 + \epsilon)$ approximation algorithm for the
Schatten-$1$ norm (the nuclear norm) running in just $\tilde O((nnz(A)n^{1/3} +
n^2)\epsilon^{-3})$ time for $A$ with uniform row sparsity or $\tilde
O(n^{2.18} \epsilon^{-3})$ time for dense matrices. The runtime scales smoothly
for general Schatten-$p$ norms, notably becoming $\tilde O (p \cdot nnz(A)
\epsilon^{-3})$ for any $p \ge 2$.
  At the same time, we show that the complexity of spectrum approximation is
inherently tied to fast matrix multiplication in the small $\epsilon$ regime.
We prove that achieving milder $\epsilon$ dependencies in our algorithms would
imply faster than matrix multiplication time triangle detection for general
graphs. This further implies that highly accurate algorithms running in
subcubic time yield subcubic time matrix multiplication. As an application of
our bounds, we show that precisely computing all effective resistances in a
graph in less than matrix multiplication time is likely difficult, barring a
major algorithmic breakthrough.
</dc:description>
 <dc:description>Comment: To appear, ITCS 2018</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04163</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04173</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Microservices: Migration of a Mission Critical System</dc:title>
 <dc:creator>Dragoni, Nicola</dc:creator>
 <dc:creator>Dustdar, Schahram</dc:creator>
 <dc:creator>Larsen, Stephan T.</dc:creator>
 <dc:creator>Mazzara, Manuel</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The microservices paradigm aims at changing the way in which software is
perceived, conceived and designed. One of the foundational characteristics of
this new promising paradigm, compared for instance to monolithic architectures,
is scalability. In this paper, we present a real world case study in order to
demonstrate how scalability is positively affected by re-implementing a
monolithic architecture into microservices. The case study is based on the FX
Core system, a mission critical system of Danske Bank, the largest bank in
Denmark and one of the leading financial institutions in Northern Europe.
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04173</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04174</identifier>
 <datestamp>2017-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Does Bidirectional Traffic Do More Harm Than Good in LoRaWAN Based LPWA
  Networks?</dc:title>
 <dc:creator>Pop, Alexandru-Ioan</dc:creator>
 <dc:creator>Raza, Usman</dc:creator>
 <dc:creator>Kulkarni, Parag</dc:creator>
 <dc:creator>Sooriyabandara, Mahesh</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The need for low power, long range and low cost connectivity to meet the
requirements of IoT applications has led to the emergence of Low Power Wide
Area (LPWA) networking technologies. The promise of these technologies to
wirelessly connect massive numbers of geographically dispersed devices at a low
cost continues to attract a great deal of attention in the academic and
commercial communities. Several rollouts are already underway even though the
performance of these technologies is yet to be fully understood. In light of
these developments, tools to carry out `what-if analyses' and pre-deployment
studies are needed to understand the implications of choices that are made at
design time. While there are several promising technologies in the LPWA space,
this paper specifically focuses on the LoRa/LoRaWAN technology. In particular,
we present LoRaWANSim, a simulator which extends the LoRaSim tool to add
support for the LoRaWAN MAC protocol, which employs bidirectional
communication. This is a salient feature not available in any other LoRa
simulator. Subsequently, we provide vital insights into the performance of
LoRaWAN based networks through extensive simulations. In particular, we show
that the achievable network capacity reported in earlier studies is quite
optimistic. The introduction of downlink traffic can have a significant impact
on the uplink throughput. The number of transmit attempts recommended in the
LoRaWAN specification may not always be the best choice. We also highlight the
energy consumption versus reliability trade-offs associated with the choice of
number of retransmission attempts.
</dc:description>
 <dc:description>Comment: Includes updated graphs after applying bug fixes present in original
  LoRaSim from which LoRaWANSim was derieved - 6 pages, 6 figures, 1 table</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-12-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04178</identifier>
 <datestamp>2017-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Blind Demixing and Deconvolution at Near-Optimal Rate</dc:title>
 <dc:creator>Jung, Peter</dc:creator>
 <dc:creator>Krahmer, Felix</dc:creator>
 <dc:creator>St&#xf6;ger, Dominik</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider simultaneous blind deconvolution of r source signals from their
noisy superposition, a problem also referred to blind demixing and
deconvolution. This signal processing problem occurs in the context of the
Internet of Things where a massive number of sensors sporadically communicate
only short messages over unknown channels. We show that robust recovery of
message and channel vectors can be achieved via convex optimization when random
linear encoding using i.i.d. complex Gaussian matrices is used at the devices
and the number of required measurements at the receiver scales with the degrees
of freedom of the overall estimation problem. Since the scaling is linear in r
our result significantly improves over recent works.
</dc:description>
 <dc:description>Comment: 49 pages, 1 figure; v2: a few typos removed</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-05-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04178</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04182</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Rate Control for Traffic Engineering with Aggregated Flows in
  Software Defined Networks</dc:title>
 <dc:creator>Kuo, Jian-Jhih</dc:creator>
 <dc:creator>Wang, Chih-Hang</dc:creator>
 <dc:creator>Tsai, Cheng-Da</dc:creator>
 <dc:creator>Yang, De-Nian</dc:creator>
 <dc:creator>Chen, Wen-Tsuen</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  To increase the scalability of Software Defined Networks (SDNs), flow
aggregation schemes have been proposed to merge multiple mouse flows into an
elephant aggregated flow for traffic engineering. In this paper, we first
notice that the user bit-rate requirements of mouse flows are no longer
guaranteed in the aggregated flow since the flow rate decided by the TCP
allocation is usually different from the desired bit-rate of each user. To
address the above issue, we present a novel architecture, named Flexible Flow
And Rate Management (F$^2$ARM), to control the rates of only a few flows in
order to increase the scalability of SDN, while leaving the uncontrolled flows
managed by TCP. We formulate a new optimization problem, named Scalable
Per-Flow Rate Control for SDN (SPFRCS), which aims to find a minimum subset of
flows as controlled flows but ensure that the flow rates of all uncontrolled
flows can still satisfy the minimum required rates by TCP. We prove that SPFRCS
is NP-hard and design an efficient algorithm, named Joint Flow Selection and
Rate Determination (JFSRD). Simulation results based on real networks manifest
that JFSRD performs nearly optimally in small-scale networks, and the number of
controlled flows can be effectively reduced by 50% in real networks.
</dc:description>
 <dc:description>Comment: Corrected Version</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04182</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04186</identifier>
 <datestamp>2017-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Video Acceleration Magnification</dc:title>
 <dc:creator>Zhang, Yichao</dc:creator>
 <dc:creator>Pintea, Silvia L.</dc:creator>
 <dc:creator>van Gemert, Jan C.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The ability to amplify or reduce subtle image changes over time is useful in
contexts such as video editing, medical video analysis, product quality control
and sports. In these contexts there is often large motion present which
severely distorts current video amplification methods that magnify change
linearly. In this work we propose a method to cope with large motions while
still magnifying small changes. We make the following two observations: i)
large motions are linear on the temporal scale of the small changes; ii) small
changes deviate from this linearity. We ignore linear motion and propose to
magnify acceleration. Our method is pure Eulerian and does not require any
optical flow, temporal alignment or region annotations. We link temporal
second-order derivative filtering to spatial acceleration magnification. We
apply our method to moving objects where we show motion magnification and color
magnification. We provide quantitative as well as qualitative evidence for our
method while comparing to the state-of-the-art.
</dc:description>
 <dc:description>Comment: Accepted paper at CVPR 2017. Project webpage:
  http://acceleration-magnification.github.io/</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-04-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04186</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04189</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Seamless Requirements</dc:title>
 <dc:creator>Naumchev, Alexandr</dc:creator>
 <dc:creator>Meyer, Bertrand</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Popular notations for functional requirements specifications frequently
ignore developers' needs, target specific development models, or require
translation of requirements into tests for verification; the results can give
out-of-sync or downright incompatible artifacts. Seamless Requirements, a new
approach to specifying functional requirements, contributes to developers'
understanding of requirements and to software quality regardless of the
process, while the process itself becomes lighter due to the absence of tests
in the presence of formal verification. A development case illustrates these
benefits, and a discussion compares seamless requirements to other approaches.
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04189</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04190</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Static Analysis of Deterministic Negotiations</dc:title>
 <dc:creator>Esparza, Javier</dc:creator>
 <dc:creator>Muscholl, Anca</dc:creator>
 <dc:creator>Walukiewicz, Igor</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  Negotiation diagrams are a model of concurrent computation akin to workflow
Petri nets. Deterministic negotiation diagrams, equivalent to the much studied
and used free-choice workflow Petri nets, are surprisingly amenable to
verification. Soundness (a property close to deadlock-freedom) can be decided
in PTIME. Further, other fundamental questions like computing summaries or the
expected cost, can also be solved in PTIME for sound deterministic negotiation
diagrams, while they are PSPACE-complete in the general case.
  In this paper we generalize and explain these results. We extend the
classical &quot;meet-over-all-paths&quot; (MOP) formulation of static analysis problems
to our concurrent setting, and introduce Mazurkiewicz-invariant analysis
problems, which encompass the questions above and new ones. We show that any
Mazurkiewicz-invariant analysis problem can be solved in PTIME for sound
deterministic negotiations whenever it is in PTIME for sequential
flow-graphs---even though the flow-graph of a deterministic negotiation diagram
can be exponentially larger than the diagram itself. This gives a common
explanation to the low-complexity of all the analysis questions studied so far.
Finally, we show that classical gen/kill analyses are also an instance of our
framework, and obtain a PTIME algorithm for detecting anti-patterns in
free-choice workflow Petri nets.
  Our result is based on a novel decomposition theorem, of independent
interest, showing that sound deterministic negotiation diagrams can be
hierarchically decomposed into (possibly overlapping) smaller sound diagrams.
</dc:description>
 <dc:description>Comment: To appear in the Proceedings of LICS 2017, IEEE Computer Society</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04190</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04194</identifier>
 <datestamp>2017-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ultrametrics in the genetic code and the genome</dc:title>
 <dc:creator>Dragovich, Branko</dc:creator>
 <dc:creator>Khrennikov, Andrei Yu.</dc:creator>
 <dc:creator>Mi&#x161;i&#x107;, Nata&#x161;a &#x17d;.</dc:creator>
 <dc:subject>Quantitative Biology - Other Quantitative Biology</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:description>  Ultrametric approach to the genetic code and the genome is considered and
developed. $p$-Adic degeneracy of the genetic code is pointed out. Ultrametric
tree of the codon space is presented. It is shown that codons and amino acids
can be treated as $p$-adic ultrametric networks. Ultrametric modification of
the Hamming distance is defined and noted how it can be useful. Ultrametric
approach with $p$-adic distance is an attractive and promising trend towards
investigation of bioinformation.
</dc:description>
 <dc:description>Comment: 20 pages. Accepted for publication in Applied Mathematics and
  Computation</dc:description>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04194</dc:identifier>
 <dc:identifier>Applied Mathematics and Computation 309 (2017) 359-358</dc:identifier>
 <dc:identifier>doi:10.1016/j.amc.2017.04.012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04198</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Room for improvement in automatic image description: an error analysis</dc:title>
 <dc:creator>van Miltenburg, Emiel</dc:creator>
 <dc:creator>Elliott, Desmond</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In recent years we have seen rapid and significant progress in automatic
image description but what are the open problems in this area? Most work has
been evaluated using text-based similarity metrics, which only indicate that
there have been improvements, without explaining what has improved. In this
paper, we present a detailed error analysis of the descriptions generated by a
state-of-the-art attention-based model. Our analysis operates on two levels:
first we check the descriptions for accuracy, and then we categorize the types
of errors we observe in the inaccurate descriptions. We find only 20% of the
descriptions are free from errors, and surprisingly that 26% are unrelated to
the image. Finally, we manually correct the most frequently occurring error
types (e.g. gender identification) to estimate the performance reward for
addressing these errors, observing gains of 0.2--1 BLEU point per type.
</dc:description>
 <dc:description>Comment: Submitted</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04199</identifier>
 <datestamp>2017-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evolution and Analysis of Embodied Spiking Neural Networks Reveals
  Task-Specific Clusters of Effective Networks</dc:title>
 <dc:creator>Vasu, Madhavun Candadai</dc:creator>
 <dc:creator>Izquierdo, Eduardo J.</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Elucidating principles that underlie computation in neural networks is
currently a major research topic of interest in neuroscience. Transfer Entropy
(TE) is increasingly used as a tool to bridge the gap between network
structure, function, and behavior in fMRI studies. Computational models allow
us to bridge the gap even further by directly associating individual neuron
activity with behavior. However, most computational models that have analyzed
embodied behaviors have employed non-spiking neurons. On the other hand,
computational models that employ spiking neural networks tend to be restricted
to disembodied tasks. We show for the first time the artificial evolution and
TE-analysis of embodied spiking neural networks to perform a
cognitively-interesting behavior. Specifically, we evolved an agent controlled
by an Izhikevich neural network to perform a visual categorization task. The
smallest networks capable of performing the task were found by repeating
evolutionary runs with different network sizes. Informational analysis of the
best solution revealed task-specific TE-network clusters, suggesting that
within-task homogeneity and across-task heterogeneity were key to behavioral
success. Moreover, analysis of the ensemble of solutions revealed that
task-specificity of TE-network clusters correlated with fitness. This provides
an empirically testable hypothesis that links network structure to behavior.
</dc:description>
 <dc:description>Comment: Camera ready version of accepted for GECCO'17</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04199</dc:identifier>
 <dc:identifier>doi:10.1145/3071178.3071336</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04205</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybridizing Non-dominated Sorting Algorithms: Divide-and-Conquer Meets
  Best Order Sort</dc:title>
 <dc:creator>Markina, Margarita</dc:creator>
 <dc:creator>Buzdalov, Maxim</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Many production-grade algorithms benefit from combining an asymptotically
efficient algorithm for solving big problem instances, by splitting them into
smaller ones, and an asymptotically inefficient algorithm with a very small
implementation constant for solving small subproblems. A well-known example is
stable sorting, where mergesort is often combined with insertion sort to
achieve a constant but noticeable speed-up.
  We apply this idea to non-dominated sorting. Namely, we combine the
divide-and-conquer algorithm, which has the currently best known asymptotic
runtime of $O(N (\log N)^{M - 1})$, with the Best Order Sort algorithm, which
has the runtime of $O(N^2 M)$ but demonstrates the best practical performance
out of quadratic algorithms.
  Empirical evaluation shows that the hybrid's running time is typically not
worse than of both original algorithms, while for large numbers of points it
outperforms them by at least 20%. For smaller numbers of objectives, the
speedup can be as large as four times.
</dc:description>
 <dc:description>Comment: A two-page abstract of this paper will appear in the proceedings
  companion of the 2017 Genetic and Evolutionary Computation Conference (GECCO
  2017)</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04205</dc:identifier>
 <dc:identifier>doi:10.1145/3067695.3076074</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04206</identifier>
 <datestamp>2017-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Molecular Communication using Magnetic Nanoparticles</dc:title>
 <dc:creator>Wicke, Wayan</dc:creator>
 <dc:creator>Ahmadzadeh, Arman</dc:creator>
 <dc:creator>Jamali, Vahid</dc:creator>
 <dc:creator>Unterweger, Harald</dc:creator>
 <dc:creator>Alexiou, Christoph</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose to use magnetic nanoparticles as information
carriers for molecular communication. This enables the use of an external
magnetic field to guide information-carrying particles towards the receiver. We
show that the particle movement can be mathematically modeled as diffusion with
drift. Thereby, we reveal that the key parameters determining the magnetic
force are particle size and magnetic field gradient. As an example, we consider
magnetic nanoparticle based communication in a bounded two-dimensional
environment. For this model, we derive an analytical expression for the channel
impulse response subject to fluid flow and magnetic drift. Furthermore,
adopting the symbol error rate as performance metric, we show that using
magnetic nanoparticles facilitates reliable communication, even in the presence
of fluid flow.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, 1 table. Submitted to the IEEE Wireless
  Communications and Networking Conference (IEEE WCNC) 2018. Changes: Clarified
  two-dimensional environment</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-09-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04213</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Managing Service-Heterogeneity using Osmotic Computing</dc:title>
 <dc:creator>Sharma, Vishal</dc:creator>
 <dc:creator>Srinivasan, Kathiravan</dc:creator>
 <dc:creator>Jayakody, Dushantha Nalin K.</dc:creator>
 <dc:creator>Rana, Omer</dc:creator>
 <dc:creator>Kumar, Ravinder</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Computational resource provisioning that is closer to a user is becoming
increasingly important, with a rise in the number of devices making continuous
service requests and with the significant recent take up of latency-sensitive
applications, such as streaming and real-time data processing. Fog computing
provides a solution to such types of applications by bridging the gap between
the user and public/private cloud infrastructure via the inclusion of a &quot;fog&quot;
layer. Such approach is capable of reducing the overall processing latency, but
the issues of redundancy, cost-effectiveness in utilizing such computing
infrastructure and handling services on the basis of a difference in their
characteristics remain. This difference in characteristics of services because
of variations in the requirement of computational resources and processes is
termed as service heterogeneity. A potential solution to these issues is the
use of Osmotic Computing -- a recently introduced paradigm that allows division
of services on the basis of their resource usage, based on parameters such as
energy, load, processing time on a data center vs. a network edge resource.
Service provisioning can then be divided across different layers of a
computational infrastructure, from edge devices, in-transit nodes, and a data
center, and supported through an Osmotic software layer. In this paper, a
fitness-based Osmosis algorithm is proposed to provide support for osmotic
computing by making more effective use of existing Fog server resources. The
proposed approach is capable of efficiently distributing and allocating
services by following the principle of osmosis. The results are presented using
numerical simulations demonstrating gains in terms of lower allocation time and
a higher probability of services being handled with high resource utilization.
</dc:description>
 <dc:description>Comment: 7 pages, 4 Figures, International Conference on Communication,
  Management and Information Technology (ICCMIT 2017), At Warsaw, Poland, 3-5
  April 2017, http://www.iccmit.net/ (Best Paper Award)</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04213</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04215</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parameterized Local Lexing</dc:title>
 <dc:creator>Obua, Steven</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Building on the concept of local lexing the concept of parameterized local
lexing is introduced.
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04218</identifier>
 <datestamp>2017-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Contractive Approach to Separable Lyapunov Functions for Monotone
  Systems</dc:title>
 <dc:creator>Coogan, Samuel</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Monotone systems preserve a partial ordering of states along system
trajectories and are often amenable to separable Lyapunov functions that are
either the sum or the maximum of a collection of functions of a scalar
argument. In this paper, we consider constructing separable Lyapunov functions
for monotone systems that are also contractive, that is, the distance between
any pair of trajectories exponentially decreases. The distance is defined in
terms of a possibly state-dependent norm. When this norm is a weighted
one-norm, we obtain conditions which lead to sum-separable Lyapunov functions,
and when this norm is a weighted infinity-norm, symmetric conditions lead to
max-separable Lyapunov functions. In addition, we consider two classes of
Lyapunov functions: the first class is separable along the system's state, and
the second class is separable along components of the system's vector field.
The latter case is advantageous for many practically motivated systems for
which it is difficult to measure the system's state but easier to measure the
system's velocity or rate of change. In addition, we present an algorithm based
on sum-of-squares programming to compute such separable Lyapunov functions. We
provide several examples to demonstrate our results.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1609.06258</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04222</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Latent Representations for Speech Generation and Transformation</dc:title>
 <dc:creator>Hsu, Wei-Ning</dc:creator>
 <dc:creator>Zhang, Yu</dc:creator>
 <dc:creator>Glass, James</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  An ability to model a generative process and learn a latent representation
for speech in an unsupervised fashion will be crucial to process vast
quantities of unlabelled speech data. Recently, deep probabilistic generative
models such as Variational Autoencoders (VAEs) have achieved tremendous success
in modeling natural images. In this paper, we apply a convolutional VAE to
model the generative process of natural speech. We derive latent space
arithmetic operations to disentangle learned latent representations. We
demonstrate the capability of our model to modify the phonetic content or the
speaker identity for speech segments using the derived operations, without the
need for parallel supervisory data.
</dc:description>
 <dc:description>Comment: Accepted to Interspeech 2017</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04222</dc:identifier>
 <dc:identifier>Interspeech 2017, pp 1273-1277</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04224</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial Memory for Context Reasoning in Object Detection</dc:title>
 <dc:creator>Chen, Xinlei</dc:creator>
 <dc:creator>Gupta, Abhinav</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Modeling instance-level context and object-object relationships is extremely
challenging. It requires reasoning about bounding boxes of different classes,
locations \etc. Above all, instance-level spatial reasoning inherently requires
modeling conditional distributions on previous detections. Unfortunately, our
current object detection systems do not have any {\bf memory} to remember what
to condition on! The state-of-the-art object detectors still detect all object
in parallel followed by non-maximal suppression (NMS). While memory has been
used for tasks such as captioning, they mostly use image-level memory cells
without capturing the spatial layout. On the other hand, modeling object-object
relationships requires {\bf spatial} reasoning -- not only do we need a memory
to store the spatial layout, but also a effective reasoning module to extract
spatial patterns. This paper presents a conceptually simple yet powerful
solution -- Spatial Memory Network (SMN), to model the instance-level context
efficiently and effectively. Our spatial memory essentially assembles object
instances back into a pseudo &quot;image&quot; representation that is easy to be fed into
another ConvNet for object-object context reasoning. This leads to a new
sequential reasoning architecture where image and memory are processed in
parallel to obtain detections which update the memory again. We show our SMN
direction is promising as it provides 2.2\% improvement over baseline Faster
RCNN on the COCO dataset so far.
</dc:description>
 <dc:description>Comment: Draft submitted to ICCV 2017</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04232</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hide-and-Seek: Forcing a Network to be Meticulous for Weakly-supervised
  Object and Action Localization</dc:title>
 <dc:creator>Singh, Krishna Kumar</dc:creator>
 <dc:creator>Lee, Yong Jae</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose `Hide-and-Seek', a weakly-supervised framework that aims to
improve object localization in images and action localization in videos. Most
existing weakly-supervised methods localize only the most discriminative parts
of an object rather than all relevant parts, which leads to suboptimal
performance. Our key idea is to hide patches in a training image randomly,
forcing the network to seek other relevant parts when the most discriminative
part is hidden. Our approach only needs to modify the input image and can work
with any network designed for object localization. During testing, we do not
need to hide any patches. Our Hide-and-Seek approach obtains superior
performance compared to previous methods for weakly-supervised object
localization on the ILSVRC dataset. We also demonstrate that our framework can
be easily extended to weakly-supervised action localization.
</dc:description>
 <dc:description>Comment: Camera-Ready Version (ICCV 2017)</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04235</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Close Yet Distinctive Domain Adaptation</dc:title>
 <dc:creator>Luo, Lingkun</dc:creator>
 <dc:creator>Wang, Xiaofang</dc:creator>
 <dc:creator>Hu, Shiqiang</dc:creator>
 <dc:creator>Wang, Chao</dc:creator>
 <dc:creator>Tang, Yuxing</dc:creator>
 <dc:creator>Chen, Liming</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Domain adaptation is transfer learning which aims to generalize a learning
model across training and testing data with different distributions. Most
previous research tackle this problem in seeking a shared feature
representation between source and target domains while reducing the mismatch of
their data distributions. In this paper, we propose a close yet discriminative
domain adaptation method, namely CDDA, which generates a latent feature
representation with two interesting properties. First, the discrepancy between
the source and target domain, measured in terms of both marginal and
conditional probability distribution via Maximum Mean Discrepancy is minimized
so as to attract two domains close to each other. More importantly, we also
design a repulsive force term, which maximizes the distances between each label
dependent sub-domain to all others so as to drag different class dependent
sub-domains far away from each other and thereby increase the discriminative
power of the adapted domain. Moreover, given the fact that the underlying data
manifold could have complex geometric structure, we further propose the
constraints of label smoothness and geometric structure consistency for label
propagation. Extensive experiments are conducted on 36 cross-domain image
classification tasks over four public datasets. The comprehensive results show
that the proposed method consistently outperforms the state-of-the-art methods
with significant margins.
</dc:description>
 <dc:description>Comment: 11pages, 3 figures, ICCV2017</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04235</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04238</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A dynamic connectome supports the emergence of stable computational
  function of neural circuits through reward-based learning</dc:title>
 <dc:creator>Kappel, David</dc:creator>
 <dc:creator>Legenstein, Robert</dc:creator>
 <dc:creator>Habenschuss, Stefan</dc:creator>
 <dc:creator>Hsieh, Michael</dc:creator>
 <dc:creator>Maass, Wolfgang</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Synaptic connections between neurons in the brain are dynamic because of
continuously ongoing spine dynamics, axonal sprouting, and other processes. In
fact, it was recently shown that the spontaneous synapse-autonomous component
of spine dynamics is at least as large as the component that depends on the
history of pre- and postsynaptic neural activity. These data are inconsistent
with common models for network plasticity, and raise the questions how neural
circuits can maintain a stable computational function in spite of these
continuously ongoing processes, and what functional uses these ongoing
processes might have. Here, we present a rigorous theoretical framework for
these seemingly stochastic spine dynamics and rewiring processes in the context
of reward-based learning tasks. We show that spontaneous synapse-autonomous
processes, in combination with reward signals such as dopamine, can explain the
capability of networks of neurons in the brain to configure themselves for
specific computational tasks, and to compensate automatically for later changes
in the network or task. Furthermore we show theoretically and through computer
simulations that stable computational performance is compatible with
continuously ongoing synapse-autonomous changes. After reaching good
computational performance it causes primarily a slow drift of network
architecture and dynamics in task-irrelevant dimensions, as observed for neural
activity in motor cortex and other areas. On the more abstract level of
reinforcement learning the resulting model gives rise to an understanding of
reward-driven network plasticity as continuous sampling of network
configurations.
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2018-01-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04238</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04244</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>General three and four person two color Hat Game</dc:title>
 <dc:creator>van Uem, Theo</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  N distinguishable players are randomly fitted with a white or black hat,
where the probabilities of getting a white or black hat may be different for
each player, but known to all the players. All players guess simultaneously the
color of their own hat observing only the hat colors of the other N-1 players.
It is also allowed for each player to pass: no color is guessed. The team wins
if at least one player guesses his hat color correctly and none of the players
has an incorrect guess. No communication of any sort is allowed, except for an
initial strategy session before the game begins. Our goal is to maximize the
probability of winning the game and to describe winning strategies, using the
concept of an adequate set. We find explicit solutions in case of N =3 and N
=4.
</dc:description>
 <dc:description>Comment: 7 pages. arXiv admin note: text overlap with arXiv:1612.00276</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04244</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04249</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parameterized Complexity and Approximability of Directed Odd Cycle
  Transversal</dc:title>
 <dc:creator>Lokshtanov, Daniel</dc:creator>
 <dc:creator>Ramanujan, M. S.</dc:creator>
 <dc:creator>Saurabh, Saket</dc:creator>
 <dc:creator>Zehavi, Meirav</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  A directed odd cycle transversal of a directed graph (digraph) $D$ is a
vertex set $S$ that intersects every odd directed cycle of $D$. In the Directed
Odd Cycle Transversal (DOCT) problem, the input consists of a digraph $D$ and
an integer $k$. The objective is to determine whether there exists a directed
odd cycle transversal of $D$ of size at most $k$.
  In this paper, we settle the parameterized complexity of DOCT when
parameterized by the solution size $k$ by showing that DOCT does not admit an
algorithm with running time $f(k)n^{O(1)}$ unless FPT = W[1]. On the positive
side, we give a factor $2$ fixed parameter tractable (FPT) approximation
algorithm for the problem. More precisely, our algorithm takes as input $D$ and
$k$, runs in time $2^{O(k^2)}n^{O(1)}$, and either concludes that $D$ does not
have a directed odd cycle transversal of size at most $k$, or produces a
solution of size at most $2k$. Finally, we provide evidence that there exists
$\epsilon &gt; 0$ such that DOCT does not admit a factor $(1+\epsilon)$
FPT-approximation algorithm.
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04251</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visual Recognition of Paper Analytical Device Images for Detection of
  Falsified Pharmaceuticals</dc:title>
 <dc:creator>Banerjee, Sandipan</dc:creator>
 <dc:creator>Sweet, James</dc:creator>
 <dc:creator>Sweet, Christopher</dc:creator>
 <dc:creator>Lieberman, Marya</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Falsification of medicines is a big problem in many developing countries,
where technological infrastructure is inadequate to detect these harmful
products. We have developed a set of inexpensive paper cards, called Paper
Analytical Devices (PADs), which can efficiently classify drugs based on their
chemical composition, as a potential solution to the problem. These cards have
different reagents embedded in them which produce a set of distinctive color
descriptors upon reacting with the chemical compounds that constitute
pharmaceutical dosage forms. If a falsified version of the medicine lacks the
active ingredient or includes substitute fillers, the difference in color is
perceivable by humans. However, reading the cards with accuracy takes training
and practice, which may hamper their scaling and implementation in low resource
settings. To deal with this, we have developed an automatic visual recognition
system to read the results from the PAD images. At first, the optimal set of
reagents was found by running singular value decomposition on the intensity
values of the color tones in the card images. A dataset of cards embedded with
these reagents is produced to generate the most distinctive results for a set
of 26 different active pharmaceutical ingredients (APIs) and excipients. Then,
we train two popular convolutional neural network (CNN) models, with the card
images. We also extract some &quot;hand-crafted&quot; features from the images and train
a nearest neighbor classifier and a non-linear support vector machine with
them. On testing, higher-level features performed much better in accurately
classifying the PAD images, with the CNN models reaching the highest average
accuracy of over 94\%.
</dc:description>
 <dc:description>Comment: in Proc. IEEE Winter Conference on Applications of Computer Vision
  (WACV), 2016</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04251</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04257</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On LoRaWAN Scalability: Empirical Evaluation of Susceptibility to
  Inter-Network Interference</dc:title>
 <dc:creator>Mikhaylov, Konstantin</dc:creator>
 <dc:creator>Petajajarvi, Juha</dc:creator>
 <dc:creator>Janhunen, Janne</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Appearing on the stage quite recently, the Low Power Wide Area Networks
(LPWANs) are currently getting much of attention. In the current paper we study
the susceptibility of one LPWAN technology, namely LoRaWAN, to the
inter-network interferences. By means of excessive empirical measurements
employing the certified commercial transceivers, we characterize the effect of
modulation coding schemes (known for LoRaWAN as data rates (DRs)) of a
transmitter and an interferer on probability of successful packet delivery
while operating in EU 868 MHz band. We show that in reality the transmissions
with different DRs in the same frequency channel can negatively affect each
other and that the high DRs are influenced by interferences more severely than
the low ones. Also, we show that the LoRa-modulated DRs are affected by the
interferences much less than the FSK-modulated one. Importantly, the presented
results provide insight into the network-level operation of the LoRa LPWAN
technology in general, and its scalability potential in particular. The results
can also be used as a reference for simulations and analyses or for defining
the communication parameters for real-life applications.
</dc:description>
 <dc:description>Comment: This is a preprint of an accepted article scheduled to be presented
  at the European Conference on Networking and Communications (EUCNC), to be
  held June 12-15, 2017, in Oulu, Finland</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04257</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04259</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identity and Granularity of Events in Text</dc:title>
 <dc:creator>Vossen, Piek</dc:creator>
 <dc:creator>Cybulska, Agata</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper we describe a method to detect event descrip- tions in
different news articles and to model the semantics of events and their
components using RDF representations. We compare these descriptions to solve a
cross-document event coreference task. Our com- ponent approach to event
semantics defines identity and granularity of events at different levels. It
performs close to state-of-the-art approaches on the cross-document event
coreference task, while outperforming other works when assuming similar quality
of event detection. We demonstrate how granularity and identity are
interconnected and we discuss how se- mantic anomaly could be used to define
differences between coreference, subevent and topical relations.
</dc:description>
 <dc:description>Comment: Invited keynote speech by Piek Vossen at Cicling 2016</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04262</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Odd holes in bull-free graphs</dc:title>
 <dc:creator>Chudnovsky, Maria</dc:creator>
 <dc:creator>Sivaraman, Vaidy</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C85</dc:subject>
 <dc:description>  The complexity of testing whether a graph contains an induced odd cycle of
length at least five is currently unknown. In this paper we show that this can
be done in polynomial time if the input graph has no induced subgraph
isomorphic to the bull (a triangle with two disjoint pendant edges).
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04262</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04274</identifier>
 <datestamp>2017-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Much Spectrum is Too Much in Millimeter Wave Wireless Access</dc:title>
 <dc:creator>Du, Jinfeng</dc:creator>
 <dc:creator>Valenzuela, Reinaldo A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A great increase in wireless access rates might be attainable by using the
large amount of spectrum available in the millimeter wave (mmWave, 30 - 300
GHz) band. However, due to higher propagation losses inherent in these
frequencies, to use wider bandwidth for transmission at ranges beyond 100
meters or in non-line-of-sight (NLOS) settings may be ineffective or even
counterproductive when the penalty for estimating the channel is taken into
account. In this work we quantify the maximum beneficial bandwidth for mmWave
transmission in some typical deployment scenarios which use pilot-based channel
estimation and assume a minimum mean square error (MMSE) channel estimator at
the receiver. We find that for an I.I.D. block fading model with coherence time
$T_c$ and coherence bandwidth $B_c$, for transmitters and receivers equipped
with a single antenna, the optimal (rate-maximizing) signal-to-noise-ratio is a
constant that only depends on the product $B_cT_c$, which measures the channel
coherence and equals the average number of orthogonal symbols per each
independent channel coefficient. That is, for fixed channel coherence, the
optimal bandwidth scales linearly with the received signal power. Under some
typical deployment scenarios with both transmit and receive side beamforming, 1
GHz bandwidth can be too much.
</dc:description>
 <dc:description>Comment: Accepted for publication for IEEE Journal on Selected Areas in
  Communications (JSAC) Special Issue on Millimeter Wave Communications for
  Future Mobile Networks</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04274</dc:identifier>
 <dc:identifier>doi:10.1109/JSAC.2017.2698859</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04277</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gbps User Rates Using mmWave Relayed Backhaul with High Gain Antennas</dc:title>
 <dc:creator>Du, Jinfeng</dc:creator>
 <dc:creator>Onaran, Efe</dc:creator>
 <dc:creator>Chizhik, Dmitry</dc:creator>
 <dc:creator>Venkatesan, Sivarama</dc:creator>
 <dc:creator>Valenzuela, Reinaldo A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Delivering Gbps high user rate over long distances (around 1 km) is
challenging, and the abundant spectrum available in millimeter wave band cannot
solve the challenge by its own due to the severe path loss and other
limitations. Since it is economically challenging to deploy wired backhaul
every few hundred meters, relays (e.g., wireless access points) have been
proposed to extend the coverage of a base station which has wired connection to
the core network. These relays, deployed every few hundred meters, serve the
users in their vicinity and are backhauled to the base station through wireless
connections. In this work, the wireless relayed backhaul design has been
formulated as a topology-bandwidth-power joint optimization problem, and the
influence of path loss, angular spread, array size, and RF power limitation on
the user rate has been evaluated. It has been shown that for a linear network
deployed along the street at 28 GHz, when high joint directional gain (50 dBi)
is available, 1 Gbps user rate within cell range of 1 km can be delivered using
1.5 GHz of bandwidth (using single polarization antennas). The user rates drop
precipitously when joint directional gain is reduced, or when the path loss is
much more severe. When the number of RF chains is limited, the benefit of
larger arrays will eventually be surpassed by the increased channel estimation
penalty as the effective beamforming gain saturates owing to the channel
angular spread.
</dc:description>
 <dc:description>Comment: Accepted for publication for IEEE Journal on Selected Areas in
  Communications (JSAC), Special Issue on Deployment and Performance Challenges
  for 5G</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04277</dc:identifier>
 <dc:identifier>doi:10.1109/JSAC.2017.2686578</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04278</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Moment-based parameter estimation in binomial random intersection graph
  models</dc:title>
 <dc:creator>Karjalainen, Joona</dc:creator>
 <dc:creator>Leskel&#xe4;, Lasse</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>62F12, 05C80</dc:subject>
 <dc:description>  Binomial random intersection graphs can be used as parsimonious statistical
models of large and sparse networks, with one parameter for the average degree
and another for transitivity, the tendency of neighbours of a node to be
connected. This paper discusses the estimation of these parameters from a
single observed instance of the graph, using moment estimators based on
observed degrees and frequencies of 2-stars and triangles. The observed data
set is assumed to be a subgraph induced by a set of $n_0$ nodes sampled from
the full set of $n$ nodes. We prove the consistency of the proposed estimators
by showing that the relative estimation error is small with high probability
for $n_0 \gg n^{2/3} \gg 1$. As a byproduct, our analysis confirms that the
empirical transitivity coefficient of the graph is with high probability close
to the theoretical clustering coefficient of the model.
</dc:description>
 <dc:description>Comment: 15 pages, 6 figures</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04278</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04281</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applying High-Resolution Visible Imagery to Satellite Melt Pond Fraction
  Retrieval: A Neural Network Approach</dc:title>
 <dc:creator>Liu, Qi</dc:creator>
 <dc:creator>Zhang, Yawen</dc:creator>
 <dc:creator>Lv, Qin</dc:creator>
 <dc:creator>Shang, Li</dc:creator>
 <dc:subject>Physics - Atmospheric and Oceanic Physics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  During summer, melt ponds have a significant influence on Arctic sea-ice
albedo. The melt pond fraction (MPF) also has the ability to forecast the
Arctic sea-ice in a certain period. It is important to retrieve accurate melt
pond fraction (MPF) from satellite data for Arctic research. This paper
proposes a satellite MPF retrieval model based on the multi-layer neural
network, named MPF-NN. Our model uses multi-spectral satellite data as model
input and MPF information from multi-site and multi-period visible imagery as
prior knowledge for modeling. It can effectively model melt ponds evolution of
different regions and periods over the Arctic. Evaluation results show that the
MPF retrieved from MODIS data using the proposed model has an RMSE of 3.91% and
a correlation coefficient of 0.73. The seasonal distribution of MPF is also
consistent with previous results.
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04281</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04289</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Gradient Descent as Approximate Bayesian Inference</dc:title>
 <dc:creator>Mandt, Stephan</dc:creator>
 <dc:creator>Hoffman, Matthew D.</dc:creator>
 <dc:creator>Blei, David M.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Stochastic Gradient Descent with a constant learning rate (constant SGD)
simulates a Markov chain with a stationary distribution. With this perspective,
we derive several new results. (1) We show that constant SGD can be used as an
approximate Bayesian posterior inference algorithm. Specifically, we show how
to adjust the tuning parameters of constant SGD to best match the stationary
distribution to a posterior, minimizing the Kullback-Leibler divergence between
these two distributions. (2) We demonstrate that constant SGD gives rise to a
new variational EM algorithm that optimizes hyperparameters in complex
probabilistic models. (3) We also propose SGD with momentum for sampling and
show how to adjust the damping coefficient accordingly. (4) We analyze MCMC
algorithms. For Langevin Dynamics and Stochastic Gradient Fisher Scoring, we
quantify the approximation errors due to finite learning rates. Finally (5), we
use the stochastic process perspective to give a short proof of why Polyak
averaging is optimal. Based on this idea, we propose a scalable approximate
MCMC algorithm, the Averaged Stochastic Gradient Sampler.
</dc:description>
 <dc:description>Comment: 35 pages, published version (JMLR 2017)</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04289</dc:identifier>
 <dc:identifier>Journal of Machine Learning Research 18 (2017) 1-35</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04293</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model Predictive Control of Voltage Source Converter in a HVDC System</dc:title>
 <dc:creator>Amin, Mohammad</dc:creator>
 <dc:creator>Molinas, Marta</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Model Predictive Control (MPC) method is a class of advanced control
techniques most widely applied in industry. The major advantages of the MPC are
its straightforward procedure which can be applied for both linear and
nonlinear system. This paper proposes the use of MPC for voltage source
converter (VSC) in a high voltage direct current (HVDC) system. A MPC
controller is modeled based on the state-space model of a single VSC-HVDC
station including the dynamics of the main ac grid. A full scale nonlinear
switching model of point-to-point connected VSC-based HVDC system is developed
in Matlab/Simulink association with SimPower system to demonstrate the
application of the proposed controller.
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04293</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04296</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FastVentricle: Cardiac Segmentation with ENet</dc:title>
 <dc:creator>Lieman-Sifry, Jesse</dc:creator>
 <dc:creator>Le, Matthieu</dc:creator>
 <dc:creator>Lau, Felix</dc:creator>
 <dc:creator>Sall, Sean</dc:creator>
 <dc:creator>Golden, Daniel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Cardiac Magnetic Resonance (CMR) imaging is commonly used to assess cardiac
structure and function. One disadvantage of CMR is that post-processing of
exams is tedious. Without automation, precise assessment of cardiac function
via CMR typically requires an annotator to spend tens of minutes per case
manually contouring ventricular structures. Automatic contouring can lower the
required time per patient by generating contour suggestions that can be lightly
modified by the annotator. Fully convolutional networks (FCNs), a variant of
convolutional neural networks, have been used to rapidly advance the
state-of-the-art in automated segmentation, which makes FCNs a natural choice
for ventricular segmentation. However, FCNs are limited by their computational
cost, which increases the monetary cost and degrades the user experience of
production systems. To combat this shortcoming, we have developed the
FastVentricle architecture, an FCN architecture for ventricular segmentation
based on the recently developed ENet architecture. FastVentricle is 4x faster
and runs with 6x less memory than the previous state-of-the-art ventricular
segmentation architecture while still maintaining excellent clinical accuracy.
</dc:description>
 <dc:description>Comment: 11 pages, 6 figures, Accepted to Functional Imaging and Modeling of
  the Heart (FIMH) 2017</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04296</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04299</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Empirical Analysis of Linkability in the Monero Blockchain</dc:title>
 <dc:creator>Miller, Andrew</dc:creator>
 <dc:creator>Moeser, Malte</dc:creator>
 <dc:creator>Lee, Kevin</dc:creator>
 <dc:creator>Narayanan, Arvind</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Monero is a privacy-centric cryptocurrency that allows users to obscure their
transaction graph by including chaff coins, called &quot;mixins,&quot; along with the
actual coins they spend. In this report, we empirically evaluate two weak-
nesses in Monero's mixin sampling strategy. First, about 62% of transaction
inputs with one or more mixins are vulnerable to &quot;chain-reaction&quot; analysis --
that is, the real input can be deduced by elimination, e.g. because the mixins
they include are spent by 0-mixin transactions. Sec- ond, Monero mixins are
sampled in such a way that the mixins can be easily distinguished from the real
coins by their age distribution; in short, the real input is usually the
&quot;newest&quot; input. We estimate that this heuristic can be used to guess the real
input with 80% accuracy over all transactions with 1 or more mixins. Our
analysis uses only public blockchain data, in contrast to earlier attacks
requiring active participation in the network. While the first weakness
primarily affects Monero transactions made by older software versions (i.e.,
prior to RingCT), the second weakness is applicable to the newest versions as
well. We propose and evaluate a countermeasure de- rived from blockchain data
that can improve the privacy of future transactions.
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04299</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04301</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Tree-based Approach for Detecting Redundant Business Rules in very
  Large Financial Datasets</dc:title>
 <dc:creator>Le-Khac, Nhien-An</dc:creator>
 <dc:creator>Markos, Sammer</dc:creator>
 <dc:creator>Kechadi, M-Tahar</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Net Asset Value (NAV) calculation and validation is the principle task of a
fund administrator. If the NAV of a fund is calculated incorrectly then there
is huge impact on the fund administrator; such as monetary compensation,
reputational loss, or loss of business. In general, these companies use the
same methodology to calculate the NAV of a fund, however the type of fund in
question dictates the set of business rules used to validate this. Today, most
Fund Administrators depend heavily on human resources due to the lack of an
automated standardized solutions, however due to economic climate and the need
for efficiency and costs reduction many banks are now looking for an automated
solution with minimal human interaction; i.e., straight through processing
(STP). Within the scope of a collaboration project that focuses on building an
optimal solution for NAV validation, in this paper, we will present a new
approach for detecting correlated business rules. We also show how we evaluate
this approach using real-world financial data.
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04301</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04302</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On a Distributed Approach for Density-based Clustering</dc:title>
 <dc:creator>Le-Khac, Nhien-An</dc:creator>
 <dc:creator>Kechadi, M-Tahar</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Efficient extraction of useful knowledge from these data is still a
challenge, mainly when the data is distributed, heterogeneous and of different
quality depending on its corresponding local infrastructure. To reduce the
overhead cost, most of the existing distributed clustering approaches generate
global models by aggregating local results obtained on each individual node.
The complexity and quality of solutions depend highly on the quality of the
aggregation. In this respect, we proposed for distributed density-based
clustering that both reduces the communication overheads due to the data
exchange and improves the quality of the global models by considering the
shapes of local clusters. From preliminary results we show that this algorithm
is very promising.
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04313</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CBinfer: Change-Based Inference for Convolutional Neural Networks on
  Video Data</dc:title>
 <dc:creator>Cavigelli, Lukas</dc:creator>
 <dc:creator>Degen, Philippe</dc:creator>
 <dc:creator>Benini, Luca</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  Extracting per-frame features using convolutional neural networks for
real-time processing of video data is currently mainly performed on powerful
GPU-accelerated workstations and compute clusters. However, there are many
applications such as smart surveillance cameras that require or would benefit
from on-site processing. To this end, we propose and evaluate a novel algorithm
for change-based evaluation of CNNs for video data recorded with a static
camera setting, exploiting the spatio-temporal sparsity of pixel changes. We
achieve an average speed-up of 8.6x over a cuDNN baseline on a realistic
benchmark with a negligible accuracy loss of less than 0.1% and no retraining
of the network. The resulting energy efficiency is 10x higher than that of
per-frame evaluation and reaches an equivalent of 328 GOp/s/W on the Tegra X1
platform.
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04313</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04322</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Belief State Planning for Autonomously Navigating Urban Intersections</dc:title>
 <dc:creator>Bouton, Maxime</dc:creator>
 <dc:creator>Cosgun, Akansel</dc:creator>
 <dc:creator>Kochenderfer, Mykel J.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Urban intersections represent a complex environment for autonomous vehicles
with many sources of uncertainty. The vehicle must plan in a stochastic
environment with potentially rapid changes in driver behavior. Providing an
efficient strategy to navigate through urban intersections is a difficult task.
This paper frames the problem of navigating unsignalized intersections as a
partially observable Markov decision process (POMDP) and solves it using a
Monte Carlo sampling method. Empirical results in simulation show that the
resulting policy outperforms a threshold-based heuristic strategy on several
relevant metrics that measure both safety and efficiency.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures, accepted to IV2017</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04322</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04326</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dataset Augmentation for Pose and Lighting Invariant Face Recognition</dc:title>
 <dc:creator>Crispell, Daniel</dc:creator>
 <dc:creator>Biris, Octavian</dc:creator>
 <dc:creator>Crosswhite, Nate</dc:creator>
 <dc:creator>Byrne, Jeffrey</dc:creator>
 <dc:creator>Mundy, Joseph L.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The performance of modern face recognition systems is a function of the
dataset on which they are trained. Most datasets are largely biased toward
&quot;near-frontal&quot; views with benign lighting conditions, negatively effecting
recognition performance on images that do not meet these criteria. The proposed
approach demonstrates how a baseline training set can be augmented to increase
pose and lighting variability using semi-synthetic images with simulated pose
and lighting conditions. The semi-synthetic images are generated using a fast
and robust 3-d shape estimation and rendering pipeline which includes the full
head and background. Various methods of incorporating the semi-synthetic
renderings into the training procedure of a state of the art deep neural
network-based recognition system without modifying the structure of the network
itself are investigated. Quantitative results are presented on the challenging
IJB-A identification dataset using a state of the art recognition pipeline as a
baseline.
</dc:description>
 <dc:description>Comment: Appeared in 2016 IEEE Applied Imagery Pattern Recognition Workshop
  (AIPR)</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04326</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04327</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep API Programmer: Learning to Program with APIs</dc:title>
 <dc:creator>Bhupatiraju, Surya</dc:creator>
 <dc:creator>Singh, Rishabh</dc:creator>
 <dc:creator>Mohamed, Abdel-rahman</dc:creator>
 <dc:creator>Kohli, Pushmeet</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present DAPIP, a Programming-By-Example system that learns to program with
APIs to perform data transformation tasks. We design a domain-specific language
(DSL) that allows for arbitrary concatenations of API outputs and constant
strings. The DSL consists of three family of APIs: regular expression-based
APIs, lookup APIs, and transformation APIs. We then present a novel neural
synthesis algorithm to search for programs in the DSL that are consistent with
a given set of examples. The search algorithm uses recently introduced neural
architectures to encode input-output examples and to model the program search
in the DSL. We show that synthesis algorithm outperforms baseline methods for
synthesizing programs on both synthetic and real-world benchmarks.
</dc:description>
 <dc:description>Comment: 8 pages + 4 pages of supplementary material. Submitted to IJCAI 2017</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04327</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04332</identifier>
 <datestamp>2017-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Point Sweep Coverage on Path</dc:title>
 <dc:creator>Liang, Dieyan</dc:creator>
 <dc:creator>Shen, Hong</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  An important application of wireless sensor networks is the deployment of
mobile sensors to periodically monitor (cover) a set of points of interest
(PoIs). The problem of Point Sweep Coverage is to deploy fewest sensors to
periodically cover the set of PoIs. For PoIs in a Eulerian graph, this problem
is known NP-Hard even if all sensors are with uniform velocity. In this paper,
we study the problem when PoIs are on a line and prove that the decision
version of the problem is NP-Complete if the sensors are with different
velocities. We first formulate the problem of Max-PoI sweep coverage on path
(MPSCP) to find the maximum number of PoIs covered by a given set of sensors,
and then show it is NP-Hard. We also extend it to the weighted case, Max-Weight
sweep coverage on path (MWSCP) problem to maximum the sum of the weight of PoIs
covered. For sensors with uniform velocity, we give a polynomial-time optimal
solution to MWSCP. For sensors with constant kinds of velocities, we present a
$\frac{1}{2}$-approximation algorithm. For the general case of arbitrary
velocities, we propose two algorithms. One is a
$\frac{1}{2\alpha}$-approximation algorithm family scheme, where integer
$\alpha\ge2$ is the tradeoff factor to balance the time complexity and
approximation ratio. The other is a $\frac{1}{2}(1-1/e)$-approximation
algorithm by randomized analysis.
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:date>2017-06-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04332</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04333</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-media Similarity Metric Learning with Unified Deep Networks</dc:title>
 <dc:creator>Qi, Jinwei</dc:creator>
 <dc:creator>Huang, Xin</dc:creator>
 <dc:creator>Peng, Yuxin</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  As a highlighting research topic in the multimedia area, cross-media
retrieval aims to capture the complex correlations among multiple media types.
Learning better shared representation and distance metric for multimedia data
is important to boost the cross-media retrieval. Motivated by the strong
ability of deep neural network in feature representation and comparison
functions learning, we propose the Unified Network for Cross-media Similarity
Metric (UNCSM) to associate cross-media shared representation learning with
distance metric in a unified framework. First, we design a two-pathway deep
network pretrained with contrastive loss, and employ double triplet similarity
loss for fine-tuning to learn the shared representation for each media type by
modeling the relative semantic similarity. Second, the metric network is
designed for effectively calculating the cross-media similarity of the shared
representation, by modeling the pairwise similar and dissimilar constraints.
Compared to the existing methods which mostly ignore the dissimilar constraints
and only use sample distance metric as Euclidean distance separately, our UNCSM
approach unifies the representation learning and distance metric to preserve
the relative similarity as well as embrace more complex similarity functions
for further improving the cross-media retrieval accuracy. The experimental
results show that our UNCSM approach outperforms 8 state-of-the-art methods on
4 widely-used cross-media datasets.
</dc:description>
 <dc:description>Comment: 19 pages, submitted to Multimedia Tools and Applications</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04333</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04336</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An entity-driven recursive neural network model for chinese discourse
  coherence modeling</dc:title>
 <dc:creator>Xu, Fan</dc:creator>
 <dc:creator>Du, Shujing</dc:creator>
 <dc:creator>Li, Maoxi</dc:creator>
 <dc:creator>Wang, Mingwen</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Chinese discourse coherence modeling remains a challenge taskin Natural
Language Processing field.Existing approaches mostlyfocus on the need for
feature engineering, whichadoptthe sophisticated features to capture the logic
or syntactic or semantic relationships acrosssentences within a text.In this
paper, we present an entity-drivenrecursive deep modelfor the Chinese discourse
coherence evaluation based on current English discourse coherenceneural network
model. Specifically, to overcome the shortage of identifying the entity(nouns)
overlap across sentences in the currentmodel, Our combined modelsuccessfully
investigatesthe entities information into the recursive neural network
freamework.Evaluation results on both sentence ordering and machine translation
coherence rating task show the effectiveness of the proposed model, which
significantly outperforms the existing strong baseline.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04336</dc:identifier>
 <dc:identifier>International Journal of Artificial Intelligence and Applications
  (IJAIA), Vol.8, No.2, March 2017</dc:identifier>
 <dc:identifier>doi:10.5121/ijaia.2017.8201</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04341</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Environment-Independent Task Specifications via GLTL</dc:title>
 <dc:creator>Littman, Michael L.</dc:creator>
 <dc:creator>Topcu, Ufuk</dc:creator>
 <dc:creator>Fu, Jie</dc:creator>
 <dc:creator>Isbell, Charles</dc:creator>
 <dc:creator>Wen, Min</dc:creator>
 <dc:creator>MacGlashan, James</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We propose a new task-specification language for Markov decision processes
that is designed to be an improvement over reward functions by being
environment independent. The language is a variant of Linear Temporal Logic
(LTL) that is extended to probabilistic specifications in a way that permits
approximations to be learned in finite time. We provide several small
environments that demonstrate the advantages of our geometric LTL (GLTL)
language and illustrate how it can be used to specify standard
reinforcement-learning tasks straightforwardly.
</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04341</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04347</identifier>
 <datestamp>2017-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Cross-Sentence Context for Neural Machine Translation</dc:title>
 <dc:creator>Wang, Longyue</dc:creator>
 <dc:creator>Tu, Zhaopeng</dc:creator>
 <dc:creator>Way, Andy</dc:creator>
 <dc:creator>Liu, Qun</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In translation, considering the document as a whole can help to resolve
ambiguities and inconsistencies. In this paper, we propose a cross-sentence
context-aware approach and investigate the influence of historical contextual
information on the performance of neural machine translation (NMT). First, this
history is summarized in a hierarchical way. We then integrate the historical
representation into NMT in two strategies: 1) a warm-start of encoder and
decoder states, and 2) an auxiliary context source for updating decoder states.
Experimental results on a large Chinese-English translation task show that our
approach significantly improves upon a strong attention-based NMT system by up
to +2.1 BLEU points.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-07-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04359</identifier>
 <datestamp>2017-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Polynomial Interpolation with Finitely Many Values for the
  Coefficients</dc:title>
 <dc:creator>Huang, Qiao-Long</dc:creator>
 <dc:creator>Gao, Xiao-Shan</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  In this paper, we give new sparse interpolation algorithms for black box
polynomial f whose coefficients are from a finite set. In the univariate case,
we recover f from one evaluation of f(a) for a sufficiently large number a. In
the multivariate case, we introduce the modified Kronecker substitution to
reduce the interpolation of a multivariate polynomial to the univariate case.
Both algorithms have polynomial bit-size complexity.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-06-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04359</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04360</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Camera Calibration by Global Constraints on the Motion of Silhouettes</dc:title>
 <dc:creator>Ben-Artzi, Gil</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We address the problem of epipolar geometry using the motion of silhouettes.
Such methods match epipolar lines or frontier points across views, which are
then used as the set of putative correspondences. We introduce an approach that
improves by two orders of magnitude the performance over state-of-the-art
methods, by significantly reducing the number of outliers in the putative
matching. We model the frontier points' correspondence problem as constrained
flow optimization, requiring small differences between their coordinates over
consecutive frames. Our approach is formulated as a Linear Integer Program and
we show that due to the nature of our problem, it can be solved efficiently in
an iterative manner. Our method was validated on four standard datasets
providing accurate calibrations across very different viewpoints.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04360</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04362</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Monte Carlo Algorithms for Tensor Operations</dc:title>
 <dc:creator>Tarzanagh, Davoud Ataee</dc:creator>
 <dc:creator>Michailidis, George</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>68P05, 68P30</dc:subject>
 <dc:description>  We consider scalable {\em randomized} algorithms for many common tensor
operations, including tensor multiplication, low-rank decomposition, and
nuclear norm minimization. Such operations arise in a number of modern day
applications of tensors in machine learning and signal processing.
Specifically, we introduce polynomial time algorithms that employ a small
number of lateral and/or horizontal slices of the underlying 3-rd order tensor,
that offer relative error guarantees for the quality of the solutions. All
results can easily be extended to higher order tensors. The proposed methods
are illustrated on selected real data sets.
</dc:description>
 <dc:description>Comment: Including supplementary appendix</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04362</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04365</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Limited Feedback in Single and Multi-user MIMO Systems with Finite-Bit
  ADCs</dc:title>
 <dc:creator>Mo, Jianhua</dc:creator>
 <dc:creator>Heath Jr, Robert W.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Communication systems with low-resolution analog-to-digital-converters (ADCs)
can exploit channel state information at the transmitter and receiver. This
paper presents codebook designs and performance analyses for limited feedback
MIMO systems with finite-bit ADCs. A point-to-point single-user channel is
firstly considered. When the received signal is sliced by 1-bit ADCs, the
absolute phase at the receiver is important to align the phase of the received
signals. A new codebook design for beamforming, which separately quantizes the
channel direction and the residual phase, is therefore proposed. For the
multi-bit case where the optimal transmission method is unknown, suboptimal
Gaussian signaling and eigenvector beamforming is assumed to obtain a lower
bound of the achievable rate. It is found that to limit the rate loss, more
feedback bits are needed in the medium SNR regime than the low and high SNR
regimes, which is quite different from the conventional infinite-bit ADC case.
Second, a multi-user system where a multiple-antenna transmitter sends signals
to multiple single-antenna receivers with finite-bit ADCs is considered. Based
on the derived performance loss due to finite-bit ADCs and finite-bit CSI
feedback, the number of bits per feedback should increase linearly with the ADC
resolution in order to restrict the rate loss.
</dc:description>
 <dc:description>Comment: 30 pages, 12 figures, submitted to IEEE Transactions on Wireless
  Communications</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04365</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04366</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Runtime Analysis of the $(1+(\lambda,\lambda))$ Genetic Algorithm on
  Random Satisfiable 3-CNF Formulas</dc:title>
 <dc:creator>Buzdalov, Maxim</dc:creator>
 <dc:creator>Doerr, Benjamin</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The $(1+(\lambda,\lambda))$ genetic algorithm, first proposed at GECCO 2013,
showed a surprisingly good performance on so me optimization problems. The
theoretical analysis so far was restricted to the OneMax test function, where
this GA profited from the perfect fitness-distance correlation. In this work,
we conduct a rigorous runtime analysis of this GA on random 3-SAT instances in
the planted solution model having at least logarithmic average degree, which
are known to have a weaker fitness distance correlation.
  We prove that this GA with fixed not too large population size again obtains
runtimes better than $\Theta(n \log n)$, which is a lower bound for most
evolutionary algorithms on pseudo-Boolean problems with unique optimum.
However, the self-adjusting version of the GA risks reaching population sizes
at which the intermediate selection of the GA, due to the weaker
fitness-distance correlation, is not able to distinguish a profitable offspring
from others. We show that this problem can be overcome by equipping the
self-adjusting GA with an upper limit for the population size. Apart from
sparse instances, this limit can be chosen in a way that the asymptotic
performance does not worsen compared to the idealistic OneMax case. Overall,
this work shows that the $(1+(\lambda,\lambda))$ GA can provably have a good
performance on combinatorial search and optimization problems also in the
presence of a weaker fitness-distance correlation.
</dc:description>
 <dc:description>Comment: An extended abstract of this report will appear in the proceedings of
  the 2017 Genetic and Evolutionary Computation Conference (GECCO 2017)</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04366</dc:identifier>
 <dc:identifier>doi:10.1145/3071178.3071297</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04368</identifier>
 <datestamp>2017-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Get To The Point: Summarization with Pointer-Generator Networks</dc:title>
 <dc:creator>See, Abigail</dc:creator>
 <dc:creator>Liu, Peter J.</dc:creator>
 <dc:creator>Manning, Christopher D.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Neural sequence-to-sequence models have provided a viable new approach for
abstractive text summarization (meaning they are not restricted to simply
selecting and rearranging passages from the original text). However, these
models have two shortcomings: they are liable to reproduce factual details
inaccurately, and they tend to repeat themselves. In this work we propose a
novel architecture that augments the standard sequence-to-sequence attentional
model in two orthogonal ways. First, we use a hybrid pointer-generator network
that can copy words from the source text via pointing, which aids accurate
reproduction of information, while retaining the ability to produce novel words
through the generator. Second, we use coverage to keep track of what has been
summarized, which discourages repetition. We apply our model to the CNN / Daily
Mail summarization task, outperforming the current abstractive state-of-the-art
by at least 2 ROUGE points.
</dc:description>
 <dc:description>Comment: Add METEOR evaluation results, add some citations, fix some equations
  (what are now equations 1, 8 and 11 were missing a bias term), fix url to
  pyrouge package, add acknowledgments</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-04-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04370</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Similarity Sketching</dc:title>
 <dc:creator>Dahlgaard, S&#xf8;ren</dc:creator>
 <dc:creator>Knudsen, Mathias B&#xe6;k Tejs</dc:creator>
 <dc:creator>Thorup, Mikkel</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the Similarity Sketching problem: Given a universe $[u]=
\{0,\ldots,u-1\}$ we want a random function $S$ mapping subsets $A\subseteq
[u]$ into vectors $S(A)$ of size $t$, such that similarity is preserved. More
precisely: Given sets $A,B\subseteq [u]$, define $X_i=[S(A)[i]= S(B)[i]]$ and
$X=\sum_{i\in [t]}X_i$. We want to have $E[X]=t\cdot J(A,B)$, where
$J(A,B)=|A\cap B|/|A\cup B|$ and furthermore to have strong concentration
guarantees (i.e. Chernoff-style bounds) for $X$. This is a fundamental problem
which has found numerous applications in data mining, large-scale
classification, computer vision, similarity search, etc. via the classic
MinHash algorithm. The vectors $S(A)$ are also called sketches.
  The seminal $t\times$MinHash algorithm uses $t$ random hash functions
$h_1,\ldots, h_t$, and stores $\left(\min_{a\in A}h_1(A),\ldots, \min_{a\in
A}h_t(A)\right)$ as the sketch of $A$. The main drawback of MinHash is,
however, its $O(t\cdot |A|)$ running time, and finding a sketch with similar
properties and faster running time has been the subject of several papers.
Addressing this, Li et al. [NIPS'12] introduced one permutation hashing (OPH),
which creates a sketch of size $t$ in $O(t + |A|)$ time, but with the drawback
that possibly some of the $t$ entries are &quot;empty&quot; when $|A| = O(t)$. One could
argue that sketching is not necessary in this case, however the desire in most
applications is to have one sketching procedure that works for sets of all
sizes. Therefore, filling out these empty entries is the subject of several
follow-up papers initiated by Shrivastava and Li [ICML'14]. However, these
&quot;densification&quot; schemes fail to provide good concentration bounds exactly in
the case $|A| = O(t)$, where they are needed. (continued...)
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04370</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04372</identifier>
 <datestamp>2017-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impulse-Based Hybrid Motion Control</dc:title>
 <dc:creator>Ruderman, Michael</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The impulse-based discrete feedback control has been proposed in previous
work for the second-order motion systems with damping uncertainties. The
sate-dependent discrete impulse action takes place at zero crossing of one of
both states, either relative position or velocity. In this paper, the proposed
control method is extended to a general hybrid motion control form. We are
using the paradigm of hybrid system modeling while explicitly specifying the
state trajectories each time the continuous system state hits the guards that
triggers impulsive control actions. The conditions for a stable convergence to
zero equilibrium are derived in relation to the control parameters, while
requiring only the upper bound of damping uncertainties to be known. Numerical
examples are shown for an underdamped closed-loop dynamics with oscillating
transients, an upper bounded time-varying positive system damping, and system
with an additional Coulomb friction damping.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, IEEE conference</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04372</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04374</identifier>
 <datestamp>2017-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HPTT: A High-Performance Tensor Transposition C++ Library</dc:title>
 <dc:creator>Springer, Paul</dc:creator>
 <dc:creator>Su, Tong</dc:creator>
 <dc:creator>Bientinesi, Paolo</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:description>  Recently we presented TTC, a domain-specific compiler for tensor
transpositions. Despite the fact that the performance of the generated code is
nearly optimal, due to its offline nature, TTC cannot be utilized in all the
application codes in which the tensor sizes and the necessary tensor
permutations are determined at runtime. To overcome this limitation, we
introduce the open-source C++ library High-Performance Tensor Transposition
(HPTT). Similar to TTC, HPTT incorporates optimizations such as blocking,
multi-threading, and explicit vectorization; furthermore it decomposes any
transposition into multiple loops around a so called micro-kernel. This modular
design---inspired by BLIS---makes HPTT easy to port to different architectures,
by only replacing the hand-vectorized micro-kernel (e.g., a 4x4 transpose).
HPTT also offers an optional autotuning framework---guided by a performance
model---that explores a vast search space of implementations at runtime
(similar to FFTW). Across a wide range of different tensor transpositions and
architectures (e.g., Intel Ivy Bridge, Intel Knights Landing, ARMv7, IBM
Power7), HPTT attains a bandwidth comparable to that of SAXPY, and yields
remarkable speedups over Eigen's tensor transposition implementation. Most
importantly, the integration of HPTT into the Cyclops Tensor Framework (CTF)
improves the overall performance of tensor contractions by up to 3.1x.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-05-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04374</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04378</identifier>
 <datestamp>2017-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weaving Rules into Models@run.time for Embedded Smart Systems</dc:title>
 <dc:creator>Mouline, Ludovic</dc:creator>
 <dc:creator>Hartmann, Thomas</dc:creator>
 <dc:creator>Fouquet, Fran&#xe7;ois</dc:creator>
 <dc:creator>Traon, Yves Le</dc:creator>
 <dc:creator>Bourcier, Johann</dc:creator>
 <dc:creator>Barais, Olivier</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Smart systems are characterised by their ability to analyse measured data in
live and to react to changes according to expert rules. Therefore, such systems
exploit appropriate data models together with actions, triggered by
domain-related conditions. The challenge at hand is that smart systems usually
need to process thousands of updates to detect which rules need to be
triggered, often even on restricted hardware like a Raspberry Pi. Despite
various approaches have been investigated to efficiently check conditions on
data models, they either assume to fit into main memory or rely on high latency
persistence storage systems that severely damage the reactivity of smart
systems. To tackle this challenge, we propose a novel composition process,
which weaves executable rules into a data model with lazy loading abilities. We
quantitatively show, on a smart building case study, that our approach can
handle, at low latency, big sets of rules on top of large-scale data models on
restricted hardware.
</dc:description>
 <dc:description>Comment: pre-print version, published in the proceedings of MOMO-17 Workshop</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04378</dc:identifier>
 <dc:identifier>doi:10.1145/3079368.3079394</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04379</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ultrafast photonic reinforcement learning based on laser chaos</dc:title>
 <dc:creator>Naruse, Makoto</dc:creator>
 <dc:creator>Terashima, Yuta</dc:creator>
 <dc:creator>Uchida, Atsushi</dc:creator>
 <dc:creator>Kim, Song-Ju</dc:creator>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Reinforcement learning involves decision making in dynamic and uncertain
environments, and constitutes one important element of artificial intelligence
(AI). In this paper, we experimentally demonstrate that the ultrafast chaotic
oscillatory dynamics of lasers efficiently solve the multi-armed bandit problem
(MAB), which requires decision making concerning a class of difficult
trade-offs called the exploration-exploitation dilemma. To solve the MAB, a
certain degree of randomness is required for exploration purposes. However,
pseudo-random numbers generated using conventional electronic circuitry
encounter severe limitations in terms of their data rate and the quality of
randomness due to their algorithmic foundations. We generate laser chaos
signals using a semiconductor laser sampled at a maximum rate of 100 GSample/s,
and combine it with a simple decision-making principle called tug-of-war with a
variable threshold, to ensure ultrafast, adaptive and accurate decision making
at a maximum adaptation speed of 1 GHz. We found that decision-making
performance was maximized with an optimal sampling interval, and we highlight
the exact coincidence between the negative autocorrelation inherent in laser
chaos and decision-making performance. This study paves the way for a new realm
of ultrafast photonics in the age of AI, where the ultrahigh bandwidth of
photons can provide new value.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04383</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Source Code Metrics and Ensemble Methods for Fault Proneness
  Prediction</dc:title>
 <dc:creator>Kumar, Lov</dc:creator>
 <dc:creator>Rath, Santanu</dc:creator>
 <dc:creator>Sureka, Ashish</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>K.6.3</dc:subject>
 <dc:description>  Software fault prediction model are employed to optimize testing resource
allocation by identifying fault-prone classes before testing phases. Several
researchers' have validated the use of different classification techniques to
develop predictive models for fault prediction. The performance of the
statistical models are proven to be influenced by the training and testing
dataset. Ensemble method learning algorithms have been widely used because it
combines the capabilities of its constituent models towards a dataset to come
up with a potentially higher performance as compared to individual models
(improves generalizability). In the study presented in this paper, three
different ensemble methods have been applied to develop a model for predicting
fault proneness. The efficacy and usefulness of a fault prediction model also
depends on the source code metrics which are considered as the input for the
model.
  In this paper, we propose a framework to validate the source code metrics and
select the right set of metrics with the objective to improve the performance
of the fault prediction model. The fault prediction models are then validated
using a cost evaluation framework. We conduct a series of experiments on 45
open source project dataset. Key conclusions from our experiments are: (1)
Majority Voting Ensemble (MVE) methods outperformed other methods; (2) selected
set of source code metrics using the suggested source code metrics using
validation framework as the input achieves better results compared to all other
metrics; (3) fault prediction method is effective for software projects with a
percentage of faulty classes lower than the threshold value (low - 54.82%,
medium - 41.04%, high - 28.10%)
</dc:description>
 <dc:description>Comment: Extended version of the COMPSAC 2017 Paper by same authors</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04389</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Encoding Cardinality Constraints using Generalized Selection Networks</dc:title>
 <dc:creator>Karpi&#x144;ski, Micha&#x142;</dc:creator>
 <dc:creator>Piotr&#xf3;w, Marek</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Boolean cardinality constraints state that at most (at least, or exactly) $k$
out of $n$ propositional literals can be true. We propose a new class of
selection networks that can be used for an efficient encoding of them. Several
comparator networks have been proposed recently for encoding cardinality
constraints and experiments have proved their efficiency. Those were based
mainly on the odd-even or pairwise comparator networks. We use similar ideas,
but we extend the model of comparator networks so that the basic components are
not only comparators (2-sorters) but more general $m$-sorters, for $m \geq 2$.
The inputs are organized into $m$ columns, in which elements are recursively
selected and, after that, columns are merged using an idea of multi-way
merging. We present two algorithms parametrized by $m \geq 2$. We call those
networks $m$-Wise Selection Network and $m$-Odd-Even Selection Network. We give
detailed construction of the mergers when $m=4$. The construction can be
directly applied to any values of $k$ and $n$. The proposed encoding of sorters
is standard, therefore the arc-consistency is preserved. We prove correctness
of the constructions and present the theoretical and experimental evaluation,
which show that the new encodings are competitive to the other state-of-art
encodings.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04389</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04390</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Track selection in Multifunction Radars: Nash and correlated equilibria</dc:title>
 <dc:creator>Bogdanovic, Nikola</dc:creator>
 <dc:creator>Driessen, Hans</dc:creator>
 <dc:creator>Yarovoy, Alexander</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We consider a track selection problem for multi-target tracking in a
multifunction radar network from a game-theoretic perspective. The problem is
formulated as a non-cooperative game. The radars are considered to be players
in this game with utilities modeled using a proper tracking accuracy criterion
and their strategies are the observed targets whose number is known. Initially,
for the problem of coordination, the Nash equilibria are characterized and, in
order to find equilibria points, a distributed algorithm based on the
best-response dynamics is proposed. Afterwards, the analysis is extended to the
case of partial target observability and radar connectivity and heterogeneous
interests among radars. The solution concept of correlated equilibria is
employed and a distributed algorithm based on the regret-matching is proposed.
The proposed algorithms are shown to perform well compared to the centralized
approach of significantly higher complexity.
</dc:description>
 <dc:description>Comment: 13 pages, 14 figures</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04390</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04394</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DESIRE: Distant Future Prediction in Dynamic Scenes with Interacting
  Agents</dc:title>
 <dc:creator>Lee, Namhoon</dc:creator>
 <dc:creator>Choi, Wongun</dc:creator>
 <dc:creator>Vernaza, Paul</dc:creator>
 <dc:creator>Choy, Christopher B.</dc:creator>
 <dc:creator>Torr, Philip H. S.</dc:creator>
 <dc:creator>Chandraker, Manmohan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce a Deep Stochastic IOC RNN Encoderdecoder framework, DESIRE, for
the task of future predictions of multiple interacting agents in dynamic
scenes. DESIRE effectively predicts future locations of objects in multiple
scenes by 1) accounting for the multi-modal nature of the future prediction
(i.e., given the same context, future may vary), 2) foreseeing the potential
future outcomes and make a strategic prediction based on that, and 3) reasoning
not only from the past motion history, but also from the scene context as well
as the interactions among the agents. DESIRE achieves these in a single
end-to-end trainable neural network model, while being computationally
efficient. The model first obtains a diverse set of hypothetical future
prediction samples employing a conditional variational autoencoder, which are
ranked and refined by the following RNN scoring-regression module. Samples are
scored by accounting for accumulated future rewards, which enables better
long-term strategic decisions similar to IOC frameworks. An RNN scene context
fusion module jointly captures past motion histories, the semantic scene
context and interactions among multiple agents. A feedback mechanism iterates
over the ranking and refinement to further boost the prediction accuracy. We
evaluate our model on two publicly available datasets: KITTI and Stanford Drone
Dataset. Our experiments show that the proposed model significantly improves
the prediction accuracy compared to other baseline methods.
</dc:description>
 <dc:description>Comment: Accepted at CVPR 2017</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04394</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04408</identifier>
 <datestamp>2017-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incremental learning of high-level concepts by imitation</dc:title>
 <dc:creator>Alibeigi, Mina</dc:creator>
 <dc:creator>Ahmadabadi, Majid Nili</dc:creator>
 <dc:creator>Araabi, Babak Nadjar</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Nowadays, robots become a companion in everyday life. To be well-accepted by
humans, robots should efficiently understand meanings of their partners'
motions and body language, and respond accordingly. Learning concepts by
imitation brings them this ability in a user-friendly way.
  This paper presents a fast and robust model for Incremental Learning of
Concepts by Imitation (ILoCI). In ILoCI, observed multimodal spatio-temporal
demonstrations are incrementally abstracted and generalized based on both their
perceptual and functional similarities during the imitation. In this method,
perceptually similar demonstrations are abstracted by a dynamic model of mirror
neuron system. An incremental method is proposed to learn their functional
similarities through a limited number of interactions with the teacher.
Learning all concepts together by the proposed memory rehearsal enables robot
to utilize the common structural relations among concepts which not only
expedites the learning process especially at the initial stages, but also
improves the generalization ability and the robustness against discrepancies
between observed demonstrations.
  Performance of ILoCI is assessed using standard LASA handwriting benchmark
data set. The results show efficiency of ILoCI in concept acquisition,
recognition and generation in addition to its robustness against variability in
demonstrations.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures, 2 tables, supplementary material, conference</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04408</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04416</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Control of Asynchronous Imitation Dynamics on Networks</dc:title>
 <dc:creator>Riehl, James</dc:creator>
 <dc:creator>Ramazi, Pouria</dc:creator>
 <dc:creator>Cao, Ming</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:description>  Imitation is widely observed in populations of decision-making agents. Using
our recent convergence results for asynchronous imitation dynamics on networks,
we consider how such networks can be efficiently driven to a desired
equilibrium state by offering payoff incentives for using a certain strategy,
either uniformly or targeted to individuals. In particular, if for each
available strategy, agents playing that strategy receive maximum payoff when
their neighbors play that same strategy, we show that providing incentives to
agents in a network that is at equilibrium will result in convergence to a
unique new equilibrium. For the case when a uniform incentive can be offered to
all agents, this result allows the computation of the optimal incentive using a
binary search algorithm. When incentives can be targeted to individual agents,
we propose an algorithm to select which agents should be chosen based on
iteratively maximizing a ratio of the number of agents who adopt the desired
strategy to the payoff incentive required to get those agents to do so.
Simulations demonstrate that the proposed algorithm computes near-optimal
targeted payoff incentives for a range of networks and payoff distributions in
coordination games.
</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04416</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04422</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning a collaborative multiscale dictionary based on robust empirical
  mode decomposition</dc:title>
 <dc:creator>Chen, Rui</dc:creator>
 <dc:creator>Jia, Huizhu</dc:creator>
 <dc:creator>Xie, Xiaodong</dc:creator>
 <dc:creator>Gao, Wen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Dictionary learning is a challenge topic in many image processing areas. The
basic goal is to learn a sparse representation from an overcomplete basis set.
Due to combining the advantages of generic multiscale representations with
learning based adaptivity, multiscale dictionary representation approaches have
the power in capturing structural characteristics of natural images. However,
existing multiscale learning approaches still suffer from three main
weaknesses: inadaptability to diverse scales of image data, sensitivity to
noise and outliers, difficulty to determine optimal dictionary structure. In
this paper, we present a novel multiscale dictionary learning paradigm for
sparse image representations based on an improved empirical mode decomposition.
This powerful data-driven analysis tool for multi-dimensional signal can fully
adaptively decompose the image into multiscale oscillating components according
to intrinsic modes of data self. This treatment can obtain a robust and
effective sparse representation, and meanwhile generates a raw base dictionary
at multiple geometric scales and spatial frequency bands. This dictionary is
refined by selecting optimal oscillating atoms based on frequency clustering.
In order to further enhance sparsity and generalization, a tolerance dictionary
is learned using a coherence regularized model. A fast proximal scheme is
developed to optimize this model. The multiscale dictionary is considered as
the product of oscillating dictionary and tolerance dictionary. Experimental
results demonstrate that the proposed learning approach has the superior
performance in sparse image representations as compared with several competing
methods. We also show the promising results in image denoising application.
</dc:description>
 <dc:description>Comment: to be published in Neurocomputing</dc:description>
 <dc:date>2017-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04422</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04428</identifier>
 <datestamp>2017-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel Multi Channel Convolution using General Matrix Multiplication</dc:title>
 <dc:creator>Vasudevan, Aravind</dc:creator>
 <dc:creator>Anderson, Andrew</dc:creator>
 <dc:creator>Gregg, David</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Convolutional neural networks (CNNs) have emerged as one of the most
successful machine learning technologies for image and video processing. The
most computationally intensive parts of CNNs are the convolutional layers,
which convolve multi-channel images with multiple kernels. A common approach to
implementing convolutional layers is to expand the image into a column matrix
(im2col) and perform Multiple Channel Multiple Kernel (MCMK) convolution using
an existing parallel General Matrix Multiplication (GEMM) library. This im2col
conversion greatly increases the memory footprint of the input matrix and
reduces data locality.
  In this paper we propose a new approach to MCMK convolution that is based on
General Matrix Multiplication (GEMM), but not on im2col. Our algorithm
eliminates the need for data replication on the input thereby enabling us to
apply the convolution kernels on the input images directly. We have implemented
several variants of our algorithm on a CPU processor and an embedded ARM
processor. On the CPU, our algorithm is faster than im2col in most cases.
</dc:description>
 <dc:description>Comment: Camera ready version to be published at ASAP 2017 - The 28th Annual
  IEEE International Conference on Application-specific Systems, Architectures
  and Processors. 6 pages</dc:description>
 <dc:date>2017-04-06</dc:date>
 <dc:date>2017-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04428</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04429</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D seismic data denoising using two-dimensional sparse coding scheme</dc:title>
 <dc:creator>Su, Ming-Jun</dc:creator>
 <dc:creator>Chang, Jingbo</dc:creator>
 <dc:creator>Qian, Feng</dc:creator>
 <dc:creator>Hu, Guangmin</dc:creator>
 <dc:creator>Liu, Xiao-Yang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Seismic data denoising is vital to geophysical applications and the
transform-based function method is one of the most widely used techniques.
However, it is challenging to design a suit- able sparse representation to
express a transform-based func- tion group due to the complexity of seismic
data. In this paper, we apply a seismic data denoising method based on
learning- type overcomplete dictionaries which uses two-dimensional sparse
coding (2DSC). First, we model the input seismic data and dictionaries as
third-order tensors and introduce tensor- linear combinations for data
approximation. Second, we ap- ply learning-type overcomplete dictionary, i.e.,
optimal sparse data representation is achieved through learning and training.
Third, we exploit the alternating minimization algorithm to solve the
optimization problem of seismic denoising. Finally we evaluate its denoising
performance on synthetic seismic data and land data survey. Experiment results
show that the two-dimensional sparse coding scheme reduces computational costs
and enhances the signal-to-noise ratio.
</dc:description>
 <dc:date>2017-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04429</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04441</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Robust Are Character-Based Word Embeddings in Tagging and MT Against
  Wrod Scramlbing or Randdm Nouse?</dc:title>
 <dc:creator>Heigold, Georg</dc:creator>
 <dc:creator>Neumann, G&#xfc;nter</dc:creator>
 <dc:creator>van Genabith, Josef</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper investigates the robustness of NLP against perturbed word forms.
While neural approaches can achieve (almost) human-like accuracy for certain
tasks and conditions, they often are sensitive to small changes in the input
such as non-canonical input (e.g., typos). Yet both stability and robustness
are desired properties in applications involving user-generated content, and
the more as humans easily cope with such noisy or adversary conditions. In this
paper, we study the impact of noisy input. We consider different noise
distributions (one type of noise, combination of noise types) and mismatched
noise distributions for training and testing. Moreover, we empirically evaluate
the robustness of different models (convolutional neural networks, recurrent
neural networks, non-neural models), different basic units (characters, byte
pair encoding units), and different NLP tasks (morphological tagging, machine
translation).
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04441</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04448</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive TTL-Based Caching for Content Delivery</dc:title>
 <dc:creator>Basu, Soumya</dc:creator>
 <dc:creator>Sundarrajan, Aditya</dc:creator>
 <dc:creator>Ghaderi, Javad</dc:creator>
 <dc:creator>Shakkottai, Sanjay</dc:creator>
 <dc:creator>Sitaraman, Ramesh</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Content Delivery Networks (CDNs) deliver a majority of the user-requested
content on the Internet, including web pages, videos, and software downloads. A
CDN server caches and serves the content requested by users. Designing caching
algorithms that automatically adapt to the heterogeneity, burstiness, and
non-stationary nature of real-world content requests is a major challenge and
is the focus of our work. While there is much work on caching algorithms for
stationary request traffic, the work on non-stationary request traffic is very
limited. Consequently, most prior models are inaccurate for production CDN
traffic that is non-stationary.
  We propose two TTL-based caching algorithms and provide provable guarantees
for content request traffic that is bursty and non-stationary. The first
algorithm called d-TTL dynamically adapts a TTL parameter using a stochastic
approximation approach. Given a feasible target hit rate, we show that the hit
rate of d-TTL converges to its target value for a general class of bursty
traffic that allows Markov dependence over time and non-stationary arrivals.
The second algorithm called f-TTL uses two caches, each with its own TTL. The
first-level cache adaptively filters out non-stationary traffic, while the
second-level cache stores frequently-accessed stationary traffic. Given
feasible targets for both the hit rate and the expected cache size, f-TTL
asymptotically achieves both targets. We implement d-TTL and f-TTL and evaluate
both algorithms using an extensive nine-day trace consisting of 500 million
requests from a production CDN server. We show that both d-TTL and f-TTL
converge to their hit rate targets with an error of about 1.3%. But, f-TTL
requires a significantly smaller cache size than d-TTL to achieve the same hit
rate, since it effectively filters out the non-stationary traffic for
rarely-accessed objects.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04448</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04451</identifier>
 <datestamp>2017-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing Differentiable Relaxations of Coreference Evaluation Metrics</dc:title>
 <dc:creator>Le, Phong</dc:creator>
 <dc:creator>Titov, Ivan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Coreference evaluation metrics are hard to optimize directly as they are
non-differentiable functions, not easily decomposable into elementary
decisions. Consequently, most approaches optimize objectives only indirectly
related to the end goal, resulting in suboptimal performance. Instead, we
propose a differentiable relaxation that lends itself to gradient-based
optimisation, thus bypassing the need for reinforcement learning or heuristic
modification of cross-entropy. We show that by modifying the training objective
of a competitive neural coreference system, we obtain a substantial gain in
performance. This suggests that our approach can be regarded as a viable
alternative to using reinforcement learning or more computationally expensive
imitation learning.
</dc:description>
 <dc:description>Comment: 10 pages. CoNLL</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-06-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04451</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04452</identifier>
 <datestamp>2017-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bringing Structure into Summaries: Crowdsourcing a Benchmark Corpus of
  Concept Maps</dc:title>
 <dc:creator>Falke, Tobias</dc:creator>
 <dc:creator>Gurevych, Iryna</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Concept maps can be used to concisely represent important information and
bring structure into large document collections. Therefore, we study a variant
of multi-document summarization that produces summaries in the form of concept
maps. However, suitable evaluation datasets for this task are currently
missing. To close this gap, we present a newly created corpus of concept maps
that summarize heterogeneous collections of web documents on educational
topics. It was created using a novel crowdsourcing approach that allows us to
efficiently determine important elements in large document collections. We
release the corpus along with a baseline system and proposed evaluation
protocol to enable further research on this variant of summarization.
</dc:description>
 <dc:description>Comment: Published at EMNLP 2017</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-07-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04452</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04455</identifier>
 <datestamp>2017-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cardinal Virtues: Extracting Relation Cardinalities from Text</dc:title>
 <dc:creator>Mirza, Paramita</dc:creator>
 <dc:creator>Razniewski, Simon</dc:creator>
 <dc:creator>Darari, Fariz</dc:creator>
 <dc:creator>Weikum, Gerhard</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Information extraction (IE) from text has largely focused on relations
between individual entities, such as who has won which award. However, some
facts are never fully mentioned, and no IE method has perfect recall. Thus, it
is beneficial to also tap contents about the cardinalities of these relations,
for example, how many awards someone has won. We introduce this novel problem
of extracting cardinalities and discusses the specific challenges that set it
apart from standard IE. We present a distant supervision method using
conditional random fields. A preliminary evaluation results in precision
between 3% and 55%, depending on the difficulty of relations.
</dc:description>
 <dc:description>Comment: 5 pages, ACL 2017 (short paper)</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-05-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04455</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04456</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Liquid Splash Modeling with Neural Networks</dc:title>
 <dc:creator>Um, Kiwon</dc:creator>
 <dc:creator>Hu, Xiangyu</dc:creator>
 <dc:creator>Thuerey, Nils</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper proposes a new data-driven approach for modeling detailed splashes
for liquid simulations with neural networks. Our model learns to generate
small-scale splash detail for fluid-implicit-particle methods using training
data acquired from physically accurate, high-resolution simulations. We use
neural networks to model the regression of splash formation using a classifier
together with a velocity modification term. More specifically, we employ a
heteroscedastic model for the velocity updates. Our simulation results
demonstrate that our model significantly improves visual fidelity with a large
amount of realistic droplet formation and yields splash detail much more
efficiently than finer discretizations. We show this for two different spatial
scales and simulation setups.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04456</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04459</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Power Splitting for Simultaneous Information Detection and
  Energy Harvesting</dc:title>
 <dc:creator>Kariminezhad, Ali</dc:creator>
 <dc:creator>Gherekhloo, Soheil</dc:creator>
 <dc:creator>Sezgin, Aydin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This letter deals with the joint information and energy processing at a
receiver of a point-to-point communication channel. In particular, the
trade-off between the achievable information rate and harvested energy for a
multiple-antenna power splitting (PS) receiver is investigated. Here, the rate-
energy region characterization is of particular interest, which is
intrinsically a non-convex problem. In this letter, an efficient algorithm is
proposed for obtaining an approximate solution to the problem in polynomial
time. This algorithm is mainly based on the Taylor approximation in conjunction
with semidefinite relaxation (SDR) which is solved by interior-point methods.
Moreover, we utilize the Gaussian randomization procedure to obtain a feasible
solution for the original problem. It is shown that by proper receiver design
the rate-energy region can be significantly enlarged compared to the state of
the art, while at the same time the receiver hardware costs is reduced by
utilizing less number of energy harvesting circuitry.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04459</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04460</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Qumin, a minimalist quantum programming language</dc:title>
 <dc:creator>Singh, Alexander</dc:creator>
 <dc:creator>Giannakis, Konstantinos</dc:creator>
 <dc:creator>Andronikos, Theodore</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>D.3</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:description>  In this work we introduce Qumin, a novel quantum programming language with a
focus on providing an easy to use, minimalist, high-level, and easily
extensible platform for quantum programming. Qumin's design concentrates on
encompassing the various interactions between classical and quantum computation
via the use of two sublanguages: an untyped one that handles classical
preparation and control, and one linearly typed that explicitly handles quantum
routines. This allows the classical part of the language to be freely used for
general programming while placing restrictions on the quantum part that enforce
rules of quantum computing like the no-cloning of qubits.
  We describe both the language's theoretical foundations in terms of lambda
calculi and linear type systems, and more practical matters such as
implementations of algorithms and useful programming tools like matrix and
oracle generators that streamline the interaction of the classical and quantum
fragments of a program. Finally, we provide an experimental open-source
implementation of an interpreter, typechecker and related tools for the
language (which can be found in \url{https://github.com/wintershammer/QImp}).
</dc:description>
 <dc:description>Comment: 34 pages</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04460</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04463</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Generalized Bellman Equations and Temporal-Difference Learning</dc:title>
 <dc:creator>Yu, Huizhen</dc:creator>
 <dc:creator>Mahmood, A. Rupam</dc:creator>
 <dc:creator>Sutton, Richard S.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>90C40, 60J05, 65C05, 68W40</dc:subject>
 <dc:description>  We consider off-policy temporal-difference (TD) learning in discounted Markov
decision processes, where the goal is to evaluate a policy in a model-free way
by using observations of a state process generated without executing the
policy. To curb the high variance issue in off-policy TD learning, we propose a
new scheme of setting the $\lambda$-parameters of TD, based on generalized
Bellman equations. Our scheme is to set $\lambda$ according to the eligibility
trace iterates calculated in TD, thereby easily keeping these traces in a
desired bounded range. Compared to prior works, this scheme is more direct and
flexible, and allows much larger $\lambda$ values for off-policy TD learning
with bounded traces. Using Markov chain theory, we prove the ergodicity of the
joint state-trace process under nonrestrictive conditions, and we show that
associated with our scheme is a generalized Bellman equation (for the policy to
be evaluated) that depends on both the evolution of $\lambda$ and the unique
invariant probability measure of the state-trace process. These results not
only lead immediately to a characterization of the convergence behavior of
least-squares based implementation of our scheme, but also prepare the ground
for further analysis of gradient-based implementations.
</dc:description>
 <dc:description>Comment: 35 pages; an abridged version to appear at The 30th Canadian
  Conference on Artificial Intelligence, May, 2017</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04463</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04464</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy Attacks on Mobile Devices</dc:title>
 <dc:creator>Kundu, Ashish</dc:creator>
 <dc:creator>Lin, Zhiqiang</dc:creator>
 <dc:creator>Hammond, Joshua</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  All mobile devices are energy-constrained. They use batteries that allows
using the device for a limited amount of time. In general, energy attacks on
mobile devices are denial of service (DoS) type of attacks. While previous
studies have analyzed the energy attacks in servers, no existing work has
analyzed the energy attacks on mobile devices. As such, in this paper, we
present the first systematic study on how to exploit the energy attacks on
smartphones. In particular, we explore energy attacks from the following
aspect: hardware components, software resources, and network communications
through the design and implementation of concrete malicious apps, and malicious
web pages. We quantitatively show how quickly we can drain the battery through
each individual attack, as well as their combinations. Finally, we believe
energy exploit will be a practical attack vector and mobile users should be
aware of this type of attacks.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04464</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04465</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Low-Complexity Approach to Distributed Cooperative Caching with
  Geographic Constraints</dc:title>
 <dc:creator>Avrachenkov, Konstantin</dc:creator>
 <dc:creator>Goseling, Jasper</dc:creator>
 <dc:creator>Serbetci, Berksan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider caching in cellular networks in which each base station is
equipped with a cache that can store a limited number of files. The popularity
of the files is known and the goal is to place files in the caches such that
the probability that a user at an arbitrary location in the plane will find the
file that she requires in one of the covering caches is maximized.
  We develop distributed asynchronous algorithms for deciding which contents to
store in which cache. Such cooperative algorithms require communication only
between caches with overlapping coverage areas and can operate in asynchronous
manner. The development of the algorithms is principally based on an
observation that the problem can be viewed as a potential game. Our basic
algorithm is derived from the best response dynamics. We demonstrate that the
complexity of each best response step is independent of the number of files,
linear in the cache capacity and linear in the maximum number of base stations
that cover a certain area. Then, we show that the overall algorithm complexity
for a discrete cache placement is polynomial in both network size and catalog
size. In practical examples, the algorithm converges in just a few iterations.
Also, in most cases of interest, the basic algorithm finds the best Nash
equilibrium corresponding to the global optimum. We provide two extensions of
our basic algorithm based on stochastic and deterministic simulated annealing
which find the global optimum.
  Finally, we demonstrate the hit probability evolution on real and synthetic
networks numerically and show that our distributed caching algorithm performs
significantly better than storing the most popular content, probabilistic
content placement policy and Multi-LRU caching policies.
</dc:description>
 <dc:description>Comment: 24 pages, 9 figures, presented at SIGMETRICS'17</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04465</dc:identifier>
 <dc:identifier>Proc. ACM Meas. Anal. Comput. Syst. (Vol. 1, No. 1, Article 27,
  June 2017)</dc:identifier>
 <dc:identifier>doi:10.1145/3084465</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04470</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lean From Thy Neighbor: Stochastic &amp; Adversarial Bandits in a Network</dc:title>
 <dc:creator>Celis, L. Elisa</dc:creator>
 <dc:creator>Salehi, Farnood</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  An individual's decisions are often guided by those of his or her peers,
i.e., neighbors in a social network. Presumably, being privy to the experiences
of others aids in learning and decision making, but how much advantage does an
individual gain by observing her neighbors? Such problems make appearances in
sociology and economics and, in this paper, we present a novel model to capture
such decision-making processes and appeal to the classical multi-armed bandit
framework to analyze it. Each individual, in addition to her own actions, can
observe the actions and rewards obtained by her neighbors, and can use all of
this information in order to minimize her own regret. We provide algorithms for
this setting, both for stochastic and adversarial bandits, and show that their
regret smoothly interpolates between the regret in the classical bandit setting
and that of the full-information setting as a function of the neighbors'
exploration. In the stochastic setting the additional information must simply
be incorporated into the usual estimation of the rewards, while in the
adversarial setting this is attained by constructing a new unbiased estimator
for the rewards and appropriately bounding the amount of additional information
provided by the neighbors. These algorithms are optimal up to log factors;
despite the fact that the agents act independently and selfishly, this implies
that it is an approximate Nash equilibria for all agents to use our algorithms.
Further, we show via empirical simulations that our algorithms, often
significantly, outperform existing algorithms that one could apply to this
setting.
</dc:description>
 <dc:description>Comment: This article was first circulated in January 2015 and presented at
  ISMP 2015 under the title &quot;Bandit in a Network&quot;
  (https://informs.emeetingsonline.com/emeetings/formbuilder/clustersessiondtl.asp?csnno=22329&amp;mmnno=264&amp;ppnno=85856)</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04470</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04472</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximal Unbordered Factors of Random Strings</dc:title>
 <dc:creator>Cording, Patrick Hagge</dc:creator>
 <dc:creator>Knudsen, Mathias B&#xe6;k Tejs</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A border of a string is a non-empty prefix of the string that is also a
suffix of the string, and a string is unbordered if it has no border. Loptev,
Kucherov, and Starikovskaya [CPM '15] conjectured the following: If we pick a
string of length $n$ from a fixed alphabet uniformly at random, then the
expected length of the maximal unbordered factor is $n - O(1)$. We prove that
this conjecture is true by proving that the expected value is in fact $n -
\Theta(\sigma^{-1})$, where $\sigma$ is the size of the alphabet. We discuss
some of the consequences of this theorem.
</dc:description>
 <dc:description>Comment: Appeared at SPIRE '16</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04472</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-46049-9_9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04473</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Additive Spanners and Distance Oracles in Quadratic Time</dc:title>
 <dc:creator>Knudsen, Mathias B&#xe6;k Tejs</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Let $G$ be an unweighted, undirected graph. An additive $k$-spanner of $G$ is
a subgraph $H$ that approximates all distances between pairs of nodes up to an
additive error of $+k$, that is, it satisfies $d_H(u,v) \le d_G(u,v)+k$ for all
nodes $u,v$, where $d$ is the shortest path distance. We give a deterministic
algorithm that constructs an additive $O\!\left(1\right)$-spanner with
$O\!\left(n^{4/3}\right)$ edges in $O\!\left(n^2\right)$ time. This should be
compared with the randomized Monte Carlo algorithm by Woodruff [ICALP 2010]
giving an additive $6$-spanner with $O\!\left(n^{4/3}\log^3 n\right)$ edges in
expected time $O\!\left(n^2\log^2 n\right)$.
  An $(\alpha,\beta)$-approximate distance oracle for $G$ is a data structure
that supports the following distance queries between pairs of nodes in $G$.
Given two nodes $u$, $v$ it can in constant time compute a distance estimate
$\tilde{d}$ that satisfies $d \le \tilde{d} \le \alpha d + \beta$ where $d$ is
the distance between $u$ and $v$ in $G$. Sommer [ICALP 2016] gave a randomized
Monte Carlo $(2,1)$-distance oracle of size $O\!\left(n^{5/3}\text{poly} \log
n\right)$ in expected time $O\!\left(n^2\text{poly} \log n\right)$. As an
application of the additive $O(1)$-spanner we improve the construction by
Sommer [ICALP 2016] and give a Las Vegas $(2,1)$-distance oracle of size
$O\!\left(n^{5/3}\right)$ in time $O\!\left(n^2\right)$. This also implies an
algorithm that in $O\!\left(n^2\right)$ gives approximate distance for all
pairs of nodes in $G$ improving on the $O\!\left(n^2 \log n\right)$ algorithm
by Baswana and Kavitha [SICOMP 2010].
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04473</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04478</identifier>
 <datestamp>2017-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graphical Models: An Extension to Random Graphs, Trees, and Other
  Objects</dc:title>
 <dc:creator>Hallonquist, Neil</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this work, we consider an extension of graphical models to random graphs,
trees, and other objects. To do this, many fundamental concepts for
multivariate random variables (e.g., marginal variables, Gibbs distribution,
Markov properties) must be extended to other mathematical objects; it turns out
that this extension is possible, as we will discuss, if we have a consistent,
complete system of projections on a given object. Each projection defines a
marginal random variable, allowing one to specify independence assumptions
between them. Furthermore, these independencies can be specified in terms of a
small subset of these marginal variables (which we call the atomic variables),
allowing the compact representation of independencies by a directed graph.
Projections also define factors, functions on the projected object space, and
hence a projection family defines a set of possible factorizations for a
distribution; these can be compactly represented by an undirected graph.
  The invariances used in graphical models are essential for learning
distributions, not just on multivariate random variables, but also on other
objects. When they are applied to random graphs and random trees, the result is
a general class of models that is applicable to a broad range of problems,
including those in which the graphs and trees have complicated edge structures.
These models need not be conditioned on a fixed number of vertices, as is often
the case in the literature for random graphs, and can be used for problems in
which attributes are associated with vertices and edges. For graphs,
applications include the modeling of molecules, neural networks, and relational
real-world scenes; for trees, applications include the modeling of infectious
diseases, cell fusion, the structure of language, and the structure of objects
in visual scenes. Many classic models are particular instances of this
framework.
</dc:description>
 <dc:description>Comment: 111 pages, with extended discussion</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-05-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04478</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04481</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Structured Learning for Facial Action Unit Intensity Estimation</dc:title>
 <dc:creator>Walecki, Robert</dc:creator>
 <dc:creator>Ognjen</dc:creator>
 <dc:creator>Rudovic</dc:creator>
 <dc:creator>Pavlovic, Vladimir</dc:creator>
 <dc:creator>Schuller, Bj&#xf6;rn</dc:creator>
 <dc:creator>Pantic, Maja</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We consider the task of automated estimation of facial expression intensity.
This involves estimation of multiple output variables (facial action units ---
AUs) that are structurally dependent. Their structure arises from statistically
induced co-occurrence patterns of AU intensity levels. Modeling this structure
is critical for improving the estimation performance; however, this performance
is bounded by the quality of the input features extracted from face images. The
goal of this paper is to model these structures and estimate complex feature
representations simultaneously by combining conditional random field (CRF)
encoded AU dependencies with deep learning. To this end, we propose a novel
Copula CNN deep learning approach for modeling multivariate ordinal variables.
Our model accounts for $ordinal$ structure in output variables and their
$non$-$linear$ dependencies via copula functions modeled as cliques of a CRF.
These are jointly optimized with deep CNN feature encoding layers using a newly
introduced balanced batch iterative training algorithm. We demonstrate the
effectiveness of our approach on the task of AU intensity estimation on two
benchmark datasets. We show that joint learning of the deep features and the
target output structure results in significant performance gains compared to
existing deep structured models for analysis of facial expressions.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04490</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parity Objectives in Countable MDPs</dc:title>
 <dc:creator>Kiefer, Stefan</dc:creator>
 <dc:creator>Mayr, Richard</dc:creator>
 <dc:creator>Shirmohammadi, Mahsa</dc:creator>
 <dc:creator>Wojtczak, Dominik</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We study countably infinite MDPs with parity objectives, and special cases
with a bounded number of colors in the Mostowski hierarchy (including
reachability, safety, Buchi and co-Buchi).
  In finite MDPs there always exist optimal memoryless deterministic (MD)
strategies for parity objectives, but this does not generally hold for
countably infinite MDPs. In particular, optimal strategies need not exist. For
countable infinite MDPs, we provide a complete picture of the memory
requirements of optimal (resp., $\epsilon$-optimal) strategies for all
objectives in the Mostowski hierarchy. In particular, there is a strong
dichotomy between two different types of objectives. For the first type,
optimal strategies, if they exist, can be chosen MD, while for the second type
optimal strategies require infinite memory. (I.e., for all objectives in the
Mostowski hierarchy, if finite-memory randomized strategies suffice then also
MD strategies suffice.) Similarly, some objectives admit $\epsilon$-optimal
MD-strategies, while for others $\epsilon$-optimal strategies require infinite
memory. Such a dichotomy also holds for the subclass of countably infinite MDPs
that are finitely branching, though more objectives admit MD-strategies here.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04490</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04497</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TGIF-QA: Toward Spatio-Temporal Reasoning in Visual Question Answering</dc:title>
 <dc:creator>Jang, Yunseok</dc:creator>
 <dc:creator>Song, Yale</dc:creator>
 <dc:creator>Yu, Youngjae</dc:creator>
 <dc:creator>Kim, Youngjin</dc:creator>
 <dc:creator>Kim, Gunhee</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Vision and language understanding has emerged as a subject undergoing intense
study in Artificial Intelligence. Among many tasks in this line of research,
visual question answering (VQA) has been one of the most successful ones, where
the goal is to learn a model that understands visual content at region-level
details and finds their associations with pairs of questions and answers in the
natural language form. Despite the rapid progress in the past few years, most
existing work in VQA have focused primarily on images. In this paper, we focus
on extending VQA to the video domain and contribute to the literature in three
important ways. First, we propose three new tasks designed specifically for
video VQA, which require spatio-temporal reasoning from videos to answer
questions correctly. Next, we introduce a new large-scale dataset for video VQA
named TGIF-QA that extends existing VQA work with our new tasks. Finally, we
propose a dual-LSTM based approach with both spatial and temporal attention,
and show its effectiveness over conventional VQA techniques through empirical
evaluations.
</dc:description>
 <dc:description>Comment: Accepted paper at CVPR 2017 (Spotlight)</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04497</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04503</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Soft-NMS -- Improving Object Detection With One Line of Code</dc:title>
 <dc:creator>Bodla, Navaneeth</dc:creator>
 <dc:creator>Singh, Bharat</dc:creator>
 <dc:creator>Chellappa, Rama</dc:creator>
 <dc:creator>Davis, Larry S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Non-maximum suppression is an integral part of the object detection pipeline.
First, it sorts all detection boxes on the basis of their scores. The detection
box M with the maximum score is selected and all other detection boxes with a
significant overlap (using a pre-defined threshold) with M are suppressed. This
process is recursively applied on the remaining boxes. As per the design of the
algorithm, if an object lies within the predefined overlap threshold, it leads
to a miss. To this end, we propose Soft-NMS, an algorithm which decays the
detection scores of all other objects as a continuous function of their overlap
with M. Hence, no object is eliminated in this process. Soft-NMS obtains
consistent improvements for the coco-style mAP metric on standard datasets like
PASCAL VOC 2007 (1.7% for both R-FCN and Faster-RCNN) and MS-COCO (1.3% for
R-FCN and 1.1% for Faster-RCNN) by just changing the NMS algorithm without any
additional hyper-parameters. Using Deformable-RFCN, Soft-NMS improves
state-of-the-art in object detection from 39.8% to 40.9% with a single model.
Further, the computational complexity of Soft-NMS is the same as traditional
NMS and hence it can be efficiently implemented. Since Soft-NMS does not
require any extra training and is simple to implement, it can be easily
integrated into any object detection pipeline. Code for Soft-NMS is publicly
available on GitHub (http://bit.ly/2nJLNMu).
</dc:description>
 <dc:description>Comment: ICCV 2017 camera ready version</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04503</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04509</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Entropy of Backwards Analysis</dc:title>
 <dc:creator>Knudsen, Mathias B&#xe6;k Tejs</dc:creator>
 <dc:creator>Thorup, Mikkel</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Backwards analysis, first popularized by Seidel, is often the simplest most
elegant way of analyzing a randomized algorithm. It applies to incremental
algorithms where elements are added incrementally, following some random
permutation, e.g., incremental Delauney triangulation of a pointset, where
points are added one by one, and where we always maintain the Delauney
triangulation of the points added thus far. For backwards analysis, we think of
the permutation as generated backwards, implying that the $i$th point in the
permutation is picked uniformly at random from the $i$ points not picked yet in
the backwards direction. Backwards analysis has also been applied elegantly by
Chan to the randomized linear time minimum spanning tree algorithm of Karger,
Klein, and Tarjan.
  The question considered in this paper is how much randomness we need in order
to trust the expected bounds obtained using backwards analysis, exactly and
approximately. For the exact case, it turns out that a random permutation works
if and only if it is minwise, that is, for any given subset, each element has
the same chance of being first. Minwise permutations are known to have
$\Theta(n)$ entropy, and this is then also what we need for exact backwards
analysis.
  However, when it comes to approximation, the two concepts diverge
dramatically. To get backwards analysis to hold within a factor $\alpha$, the
random permutation needs entropy $\Omega(n/\alpha)$. This contrasts with
minwise permutations, where it is known that a $1+\varepsilon$ approximation
only needs $\Theta(\log (n/\varepsilon))$ entropy. Our negative result for
backwards analysis essentially shows that it is as abstract as any analysis
based on full randomness.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04509</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04511</identifier>
 <datestamp>2017-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recovery of damped exponentials using structured low rank matrix
  completion</dc:title>
 <dc:creator>Balachandrasekaran, Arvind</dc:creator>
 <dc:creator>Magnotta, Vincent</dc:creator>
 <dc:creator>Jacob, Mathews</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce a structured low rank matrix completion algorithm to recover a
series of images from their under-sampled measurements, where the signal along
the parameter dimension at every pixel is described by a linear combination of
exponentials. We exploit the exponential behavior of the signal at every pixel,
along with the spatial smoothness of the exponential parameters to derive an
annihilation relation in the Fourier domain. This relation translates to a
low-rank property on a structured matrix constructed from the Fourier samples.
We enforce the low rank property of the structured matrix as a regularization
prior to recover the images. Since the direct use of current low rank matrix
recovery schemes to this problem is associated with high computational
complexity and memory demand, we adopt an iterative re-weighted least squares
(IRLS) algorithm, which facilitates the exploitation of the convolutional
structure of the matrix. Novel approximations involving two dimensional Fast
Fourier Transforms (FFT) are introduced to drastically reduce the memory demand
and computational complexity, which facilitates the extension of structured low
rank methods to large scale three dimensional problems. We demonstrate our
algorithm in the MR parameter mapping setting and show improvement over the
state-of-the-art methods.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE Transactions on Medical Imaging</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04511</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04516</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpretable 3D Human Action Analysis with Temporal Convolutional
  Networks</dc:title>
 <dc:creator>Kim, Tae Soo</dc:creator>
 <dc:creator>Reiter, Austin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>68T45, 68T10 (Primary)</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:description>  The discriminative power of modern deep learning models for 3D human action
recognition is growing ever so potent. In conjunction with the recent
resurgence of 3D human action representation with 3D skeletons, the quality and
the pace of recent progress have been significant. However, the inner workings
of state-of-the-art learning based methods in 3D human action recognition still
remain mostly black-box. In this work, we propose to use a new class of models
known as Temporal Convolutional Neural Networks (TCN) for 3D human action
recognition. Compared to popular LSTM-based Recurrent Neural Network models,
given interpretable input such as 3D skeletons, TCN provides us a way to
explicitly learn readily interpretable spatio-temporal representations for 3D
human action recognition. We provide our strategy in re-designing the TCN with
interpretability in mind and how such characteristics of the model is leveraged
to construct a powerful 3D activity recognition method. Through this work, we
wish to take a step towards a spatio-temporal model that is easier to
understand, explain and interpret. The resulting model, Res-TCN, achieves
state-of-the-art results on the largest 3D human action recognition dataset,
NTU-RGBD.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures, BNMW CVPR 2017 Submission</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04516</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04517</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ShapeWorld - A new test methodology for multimodal language
  understanding</dc:title>
 <dc:creator>Kuhnle, Alexander</dc:creator>
 <dc:creator>Copestake, Ann</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce a novel framework for evaluating multimodal deep learning models
with respect to their language understanding and generalization abilities. In
this approach, artificial data is automatically generated according to the
experimenter's specifications. The content of the data, both during training
and evaluation, can be controlled in detail, which enables tasks to be created
that require true generalization abilities, in particular the combination of
previously introduced concepts in novel ways. We demonstrate the potential of
our methodology by evaluating various visual question answering models on four
different tasks, and show how our framework gives us detailed insights into
their capabilities and limitations. By open-sourcing our framework, we hope to
stimulate progress in the field of multimodal language understanding.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04517</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04520</identifier>
 <datestamp>2017-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Machine Translation Model with a Large Vocabulary Selected by
  Branching Entropy</dc:title>
 <dc:creator>Long, Zi</dc:creator>
 <dc:creator>Kimura, Ryuichiro</dc:creator>
 <dc:creator>Utsuro, Takehito</dc:creator>
 <dc:creator>Mitsuhashi, Tomoharu</dc:creator>
 <dc:creator>Yamamoto, Mikio</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Neural machine translation (NMT), a new approach to machine translation, has
achieved promising results comparable to those of traditional approaches such
as statistical machine translation (SMT). Despite its recent success, NMT
cannot handle a larger vocabulary because the training complexity and decoding
complexity proportionally increase with the number of target words. This
problem becomes even more serious when translating patent documents, which
contain many technical terms that are observed infrequently. In this paper, we
propose to select phrases that contain out-of-vocabulary words using the
statistical approach of branching entropy. This allows the proposed NMT system
to be applied to a translation task of any language pair without any
language-specific knowledge about technical term identification. The selected
phrases are then replaced with tokens during training and post-translated by
the phrase translation table of SMT. Evaluation on Japanese-to-Chinese,
Chinese-to-Japanese, Japanese-to-English and English-to-Japanese patent
sentence translation proved the effectiveness of phrases selected with
branching entropy, where the proposed NMT model achieves a substantial
improvement over a baseline NMT model without our proposed technique. Moreover,
the number of translation errors of under-translation by the baseline NMT model
without our proposed technique reduces to around half by the proposed NMT
model.
</dc:description>
 <dc:description>Comment: MT summit 2017 poster</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-09-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04521</identifier>
 <datestamp>2017-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Translation of Patent Sentences with a Large Vocabulary of Technical
  Terms Using Neural Machine Translation</dc:title>
 <dc:creator>Long, Zi</dc:creator>
 <dc:creator>Utsuro, Takehito</dc:creator>
 <dc:creator>Mitsuhashi, Tomoharu</dc:creator>
 <dc:creator>Yamamoto, Mikio</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Neural machine translation (NMT), a new approach to machine translation, has
achieved promising results comparable to those of traditional approaches such
as statistical machine translation (SMT). Despite its recent success, NMT
cannot handle a larger vocabulary because training complexity and decoding
complexity proportionally increase with the number of target words. This
problem becomes even more serious when translating patent documents, which
contain many technical terms that are observed infrequently. In NMTs, words
that are out of vocabulary are represented by a single unknown token. In this
paper, we propose a method that enables NMT to translate patent sentences
comprising a large vocabulary of technical terms. We train an NMT system on
bilingual data wherein technical terms are replaced with technical term tokens;
this allows it to translate most of the source sentences except technical
terms. Further, we use it as a decoder to translate source sentences with
technical term tokens and replace the tokens with technical term translations
using SMT. We also use it to rerank the 1,000-best SMT translations on the
basis of the average of the SMT score and that of the NMT rescoring of the
translated sentences with technical term tokens. Our experiments on
Japanese-Chinese patent sentences show that the proposed NMT system achieves a
substantial improvement of up to 3.1 BLEU points and 2.3 RIBES points over
traditional SMT systems and an improvement of approximately 0.6 BLEU points and
0.8 RIBES points over an equivalent NMT system without our proposed technique.
</dc:description>
 <dc:description>Comment: WAT 2016. arXiv admin note: substantial text overlap with
  arXiv:1704.04520</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04521</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04522</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchic Kernel Recursive Least-Squares</dc:title>
 <dc:creator>Mohamadipanah, Hossein</dc:creator>
 <dc:creator>Chowdhary, Girish</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present a new hierarchic kernel based modeling technique for modeling
evenly distributed multidimensional datasets that does not rely on input space
sparsification. The presented method reorganizes the typical single-layer
kernel based model in a hierarchical structure, such that the weights of a
kernel model over each dimension are modeled over the adjacent dimension. We
show that the imposition of the hierarchical structure in the kernel based
model leads to significant computational speedup and improved modeling accuracy
(over an order of magnitude in many cases). For instance the presented method
is about five times faster and more accurate than Sparsified Kernel Recursive
Least- Squares in modeling of a two-dimensional real-world data set.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04522</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04530</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Extractive Summarization with Side Information</dc:title>
 <dc:creator>Narayan, Shashi</dc:creator>
 <dc:creator>Papasarantopoulos, Nikos</dc:creator>
 <dc:creator>Cohen, Shay B.</dc:creator>
 <dc:creator>Lapata, Mirella</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Most extractive summarization methods focus on the main body of the document
from which sentences need to be extracted. However, the gist of the document
may lie in side information, such as the title and image captions which are
often available for newswire articles. We propose to explore side information
in the context of single-document extractive summarization. We develop a
framework for single-document summarization composed of a hierarchical document
encoder and an attention-based extractor with attention over side information.
We evaluate our model on a large scale news dataset. We show that extractive
summarization with side information consistently outperforms its counterpart
that does not use any side information, in terms of both informativeness and
fluency.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-09-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04530</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04538</identifier>
 <datestamp>2017-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple Randomized Algorithm to Compute Harmonic Numbers and Logarithms</dc:title>
 <dc:creator>Dasdan, Ali</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Given a list of N numbers, the maximum can be computed in N iterations.
During these N iterations, the maximum gets updated on average as many times as
the Nth harmonic number. We first use this fact to approximate the Nth harmonic
number as a side effect. Further, using the fact the Nth harmonic number is
equal to the natural logarithm of N plus a constant that goes to zero with N,
we approximate the natural logarithm from the harmonic number. To improve
accuracy, we repeat the computation over many lists of uniformly generated
random numbers. The algorithm is easily extended to approximate logarithms with
integer bases or rational arguments.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures, unpublished</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-04-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04538</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04539</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-lingual Abstract Meaning Representation Parsing</dc:title>
 <dc:creator>Damonte, Marco</dc:creator>
 <dc:creator>Cohen, Shay B.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Abstract Meaning Representation (AMR) annotation efforts have mostly focused
on English. In order to train parsers on other languages, we propose a method
based on annotation projection, which involves exploiting annotations in a
source language and a parallel corpus of the source language and a target
language. Using English as the source language, we show promising results for
Italian, Spanish, German and Chinese as target languages. Besides evaluating
the target parsers on non-gold datasets, we further propose an evaluation
method that exploits the English gold annotations and does not require access
to gold annotations for the target languages. This is achieved by inverting the
projection process: a new English parser is learned from the target language
parser and evaluated on the existing English gold standard.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04539</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04542</identifier>
 <datestamp>2017-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Determinants of public cooperation in multiplex networks</dc:title>
 <dc:creator>Battiston, Federico</dc:creator>
 <dc:creator>Perc, Matjaz</dc:creator>
 <dc:creator>Latora, Vito</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  Synergies between evolutionary game theory and statistical physics have
significantly improved our understanding of public cooperation in structured
populations. Multiplex networks, in particular, provide the theoretical
framework within network science that allows us to mathematically describe the
rich structure of interactions characterizing human societies. While research
has shown that multiplex networks may enhance the resilience of cooperation,
the interplay between the overlap in the structure of the layers and the
control parameters of the corresponding games has not yet been investigated.
With this aim, we consider here the public goods game on a multiplex network,
and we unveil the role of the number of layers and the overlap of links, as
well as the impact of different synergy factors in different layers, on the
onset of cooperation. We show that enhanced public cooperation emerges only
when a significant edge overlap is combined with at least one layer being able
to sustain some cooperation by means of a sufficiently high synergy factor. In
the absence of either of these conditions, the evolution of cooperation in
multiplex networks is determined by the bounds of traditional network
reciprocity with no enhanced resilience. These results caution against overly
optimistic predictions that the presence of multiple social domains may in
itself promote cooperation, and they help us better understand the complexity
behind prosocial behavior in layered social systems.
</dc:description>
 <dc:description>Comment: 12 pages, 3 figures; accepted for publication in New Journal of
  Physics</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04542</dc:identifier>
 <dc:identifier>New J. Phys. 19, 073017 (2017)</dc:identifier>
 <dc:identifier>doi:10.1088/1367-2630/aa6ea1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04543</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Space-Valued Diagrams, Type-Theoretically (Extended Abstract)</dc:title>
 <dc:creator>Kraus, Nicolai</dc:creator>
 <dc:creator>Sattler, Christian</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:description>  Topologists are sometimes interested in space-valued diagrams over a given
index category, but it is tricky to say what such a diagram even is if we look
for a notion that is stable under equivalence. The same happens in (homotopy)
type theory, where it is known only for special cases how one can define a type
of type-valued diagrams over a given index category. We offer several
constructions. We first show how to define homotopy coherent diagrams which
come with all higher coherence laws explicitly, with two variants that come
with assumption on the index category or on the type theory. Further, we
present a construction of diagrams over certain Reedy categories. As an
application, we add the degeneracies to the well-known construction of
semisimplicial types, yielding a construction of simplicial types up to any
given finite level. The current paper is only an extended abstract, and a full
version is to follow. In the full paper, we will show that the different
notions of diagrams are equivalent to each other and to the known notion of
Reedy fibrant diagrams whenever the statement makes sense. In the current
paper, we only sketch some core ideas of the proofs.
</dc:description>
 <dc:description>Comment: 22 pages</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04543</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04546</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SETH-Based Lower Bounds for Subset Sum and Bicriteria Path</dc:title>
 <dc:creator>Abboud, Amir</dc:creator>
 <dc:creator>Bringmann, Karl</dc:creator>
 <dc:creator>Hermelin, Danny</dc:creator>
 <dc:creator>Shabtay, Dvir</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Subset-Sum and k-SAT are two of the most extensively studied problems in
computer science, and conjectures about their hardness are among the
cornerstones of fine-grained complexity. One of the most intriguing open
problems in this area is to base the hardness of one of these problems on the
other.
  Our main result is a tight reduction from k-SAT to Subset-Sum on dense
instances, proving that Bellman's 1962 pseudo-polynomial $O^{*}(T)$-time
algorithm for Subset-Sum on $n$ numbers and target $T$ cannot be improved to
time $T^{1-\varepsilon}\cdot 2^{o(n)}$ for any $\varepsilon&gt;0$, unless the
Strong Exponential Time Hypothesis (SETH) fails. This is one of the strongest
known connections between any two of the core problems of fine-grained
complexity.
  As a corollary, we prove a &quot;Direct-OR&quot; theorem for Subset-Sum under SETH,
offering a new tool for proving conditional lower bounds: It is now possible to
assume that deciding whether one out of $N$ given instances of Subset-Sum is a
YES instance requires time $(N T)^{1-o(1)}$. As an application of this
corollary, we prove a tight SETH-based lower bound for the classical Bicriteria
s,t-Path problem, which is extensively studied in Operations Research. We
separate its complexity from that of Subset-Sum: On graphs with $m$ edges and
edge lengths bounded by $L$, we show that the $O(Lm)$ pseudo-polynomial time
algorithm by Joksch from 1966 cannot be improved to $\tilde{O}(L+m)$, in
contrast to a recent improvement for Subset Sum (Bringmann, SODA 2017).
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04546</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04548</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Gap Between Strict-Saddles and True Convexity: An Omega(log d)
  Lower Bound for Eigenvector Approximation</dc:title>
 <dc:creator>Simchowitz, Max</dc:creator>
 <dc:creator>Alaoui, Ahmed El</dc:creator>
 <dc:creator>Recht, Benjamin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We prove a \emph{query complexity} lower bound on rank-one principal
component analysis (PCA). We consider an oracle model where, given a symmetric
matrix $M \in \mathbb{R}^{d \times d}$, an algorithm is allowed to make $T$
\emph{exact} queries of the form $w^{(i)} = Mv^{(i)}$ for $i \in
\{1,\dots,T\}$, where $v^{(i)}$ is drawn from a distribution which depends
arbitrarily on the past queries and measurements $\{v^{(j)},w^{(j)}\}_{1 \le j
\le i-1}$. We show that for a small constant $\epsilon$, any adaptive,
randomized algorithm which can find a unit vector $\widehat{v}$ for which
$\widehat{v}^{\top}M\widehat{v} \ge (1-\epsilon)\|M\|$, with even small
probability, must make $T = \Omega(\log d)$ queries. In addition to settling a
widely-held folk conjecture, this bound demonstrates a fundamental gap between
convex optimization and &quot;strict-saddle&quot; non-convex optimization of which PCA is
a canonical example: in the former, first-order methods can have dimension-free
iteration complexity, whereas in PCA, the iteration complexity of
gradient-based methods must necessarily grow with the dimension. Our argument
proceeds via a reduction to estimating the rank-one spike in a deformed Wigner
model. We establish lower bounds for this model by developing a &quot;truncated&quot;
analogue of the $\chi^2$ Bayes-risk lower bound of Chen et al.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04548</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04550</identifier>
 <datestamp>2017-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributional Modeling on a Diet: One-shot Word Learning from Text Only</dc:title>
 <dc:creator>Wang, Su</dc:creator>
 <dc:creator>Roller, Stephen</dc:creator>
 <dc:creator>Erk, Katrin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We test whether distributional models can do one-shot learning of
definitional properties from text only. Using Bayesian models, we find that
first learning overarching structure in the known data, regularities in textual
contexts and in properties, helps one-shot learning, and that individual
context items can be highly informative. Our experiments show that our model
can learn properties from a single exposure when given an informative
utterance.
</dc:description>
 <dc:description>Comment: The 8th International Joint Conference on Natural Language Processing
  (IJCNLP 2017)</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-10-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04550</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04555</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pseudo-Separation for Assessment of Structural Vulnerability of a
  Network</dc:title>
 <dc:creator>Kuhnle, Alan</dc:creator>
 <dc:creator>Pan, Tianyi</dc:creator>
 <dc:creator>Crawford, Victoria G.</dc:creator>
 <dc:creator>Alim, Md Abdul</dc:creator>
 <dc:creator>Thai, My T.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Based upon the idea that network functionality is impaired if two nodes in a
network are sufficiently separated in terms of a given metric, we introduce two
combinatorial \emph{pseudocut} problems generalizing the classical min-cut and
multi-cut problems. We expect the pseudocut problems will find broad relevance
to the study of network reliability. We comprehensively analyze the
computational complexity of the pseudocut problems and provide three
approximation algorithms for these problems.
  Motivated by applications in communication networks with strict
Quality-of-Service (QoS) requirements, we demonstrate the utility of the
pseudocut problems by proposing a targeted vulnerability assessment for the
structure of communication networks using QoS metrics; we perform experimental
evaluations of our proposed approximation algorithms in this context.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04555</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04558</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Verifying Safety of Functional Programs with Rosette/Unbound</dc:title>
 <dc:creator>Mordvinov, Dmitry</dc:creator>
 <dc:creator>Fedyukovich, Grigory</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The goal of unbounded program verification is to discover an inductive
invariant that safely over-approximates all possible program behaviors.
Functional languages featuring higher order and recursive functions become more
popular due to the domain-specific needs of big data analytics, web, and
security. We present Rosette/Unbound, the first program verifier for Racket
exploiting the automated constrained Horn solver on its backend. One of the key
features of Rosette/Unbound is the ability to synchronize recursive
computations over the same inputs allowing to verify programs that iterate over
unbounded data streams multiple times. Rosette/Unbound is successfully
evaluated on a set of non-trivial recursive and higher order functional
programs.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04560</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>User-transparent Distributed TensorFlow</dc:title>
 <dc:creator>Vishnu, Abhinav</dc:creator>
 <dc:creator>Manzano, Joseph</dc:creator>
 <dc:creator>Siegel, Charles</dc:creator>
 <dc:creator>Daily, Jeff</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Deep Learning (DL) algorithms have become the {\em de facto} choice for data
analysis. Several DL implementations -- primarily limited to a single compute
node -- such as Caffe, TensorFlow, Theano and Torch have become readily
available. Distributed DL implementations capable of execution on large scale
systems are becoming important to address the computational needs of large data
produced by scientific simulations and experiments. Yet, the adoption of
distributed DL implementations faces significant impediments: 1) most
implementations require DL analysts to modify their code significantly -- which
is a show-stopper, 2) several distributed DL implementations are geared towards
cloud computing systems -- which is inadequate for execution on massively
parallel systems such as supercomputers.
  This work addresses each of these problems. We provide a distributed memory
DL implementation by incorporating required changes in the TensorFlow runtime
itself. This dramatically reduces the entry barrier for using a distributed
TensorFlow implementation. We use Message Passing Interface (MPI) -- which
provides performance portability, especially since MPI specific changes are
abstracted from users. Lastly -- and arguably most importantly -- we make our
implementation available for broader use, under the umbrella of Machine
Learning Toolkit for Extreme Scale (MaTEx) at {\texttt
http://hpc.pnl.gov/matex}. We refer to our implementation as MaTEx-TensorFlow.
</dc:description>
 <dc:description>Comment: 9 pages, 8 figures</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04560</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04561</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Contour Trees in the Analysis and Visualization of Radio Astronomy
  Data Cubes</dc:title>
 <dc:creator>Rosen, Paul</dc:creator>
 <dc:creator>Wang, Bei</dc:creator>
 <dc:creator>Seth, Anil</dc:creator>
 <dc:creator>Mills, Betsy</dc:creator>
 <dc:creator>Ginsburg, Adam</dc:creator>
 <dc:creator>Kamenetzky, Julia</dc:creator>
 <dc:creator>Kern, Jeff</dc:creator>
 <dc:creator>Johnson, Chris R.</dc:creator>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  The current generation of radio and millimeter telescopes, particularly the
Atacama Large Millimeter Array (ALMA), offers enormous advances in observing
capabilities. While these advances represent an unprecedented opportunity to
advance scientific understanding, the increased complexity in the spatial and
spectral structure of even a single spectral line is hard to interpret. The
complexity present in current ALMA data cubes therefore challenges not only the
existing tools for fundamental analysis of these datasets, but also users'
ability to explore and visualize their data. We have performed a feasibility
study for applying forms of topological data analysis and visualization never
before tested by the ALMA community. Through contour tree-based data analysis,
we seek to improve upon existing data cube analysis and visualization
workflows, in the forms of improved accuracy and speed in extracting features.
In this paper, we review our design process in building effective analysis and
visualization capabilities for the astrophysicist users. We summarize effective
design practices, in particular, we identify domain-specific needs of
simplicity, integrability and reproducibility, in order to best target and
service the large astrophysics community.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04561</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04565</identifier>
 <datestamp>2017-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Paraphrase Identification of Questions with Noisy Pretraining</dc:title>
 <dc:creator>Tomar, Gaurav Singh</dc:creator>
 <dc:creator>Duque, Thyago</dc:creator>
 <dc:creator>T&#xe4;ckstr&#xf6;m, Oscar</dc:creator>
 <dc:creator>Uszkoreit, Jakob</dc:creator>
 <dc:creator>Das, Dipanjan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a solution to the problem of paraphrase identification of
questions. We focus on a recent dataset of question pairs annotated with binary
paraphrase labels and show that a variant of the decomposable attention model
(Parikh et al., 2016) results in accurate performance on this task, while being
far simpler than many competing neural architectures. Furthermore, when the
model is pretrained on a noisy dataset of automatically collected question
paraphrases, it obtains the best reported performance on the dataset.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04565</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04566</identifier>
 <datestamp>2017-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Formation Control of Nonlonolomic Mobile Robots by Bounded
  Feedback in the Presence of Obstacles</dc:title>
 <dc:creator>Nguyen, Thang</dc:creator>
 <dc:creator>La, Hung M.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The problem of distributed formation control of nonholonomic mobile robots is
addressed in this paper, in which the robots are designed to track a formation.
Collision avoidance among agents is guaranteed using a control law based on a
repulsive force. In an uncertain environment where obstacles exist, the
construction of repulsive force and rotational direction enables agents to
avoid and pass the obstacles. The control inputs of each robot are designed to
be bounded. Numerical simulations with different formations are implemented to
demonstrate the efficacy of the proposed scheme.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-05-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04566</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04567</identifier>
 <datestamp>2017-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asynchronous Parallel Empirical Variance Guided Algorithms for the
  Thresholding Bandit Problem</dc:title>
 <dc:creator>Zhong, Jie</dc:creator>
 <dc:creator>Huang, Yijun</dc:creator>
 <dc:creator>Liu, Ji</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper considers the multi-armed thresholding bandit problem --
identifying all arms whose expected rewards are above a predefined threshold
via as few pulls (or rounds) as possible -- proposed by Locatelli et al. [2016]
recently. Although the proposed algorithm in Locatelli et al. [2016] achieves
the optimal round complexity in a certain sense, there still remain unsolved
issues. This paper proposes an asynchronous parallel thresholding algorithm and
its parameter-free version to improve the efficiency and the applicability. On
one hand, the proposed two algorithms use the empirical variance to guide the
pull decision at each round, and significantly improve the round complexity of
the &quot;optimal&quot; algorithm when all arms have bounded high order moments. The
proposed algorithms can be proven to be optimal. On the other hand, most bandit
algorithms assume that the reward can be observed immediately after the pull or
the next decision would not be made before all rewards are observed. Our
proposed asynchronous parallel algorithms allow making the choice of the next
pull with unobserved rewards from earlier pulls, which avoids such an
unrealistic assumption and significantly improves the identification process.
Our theoretical analysis justifies the effectiveness and the efficiency of
proposed asynchronous parallel algorithms.
</dc:description>
 <dc:description>Comment: added lower bound</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04567</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04572</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Task-Oriented Query Reformulation with Reinforcement Learning</dc:title>
 <dc:creator>Nogueira, Rodrigo</dc:creator>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Search engines play an important role in our everyday lives by assisting us
in finding the information we need. When we input a complex query, however,
results are often far from satisfactory. In this work, we introduce a query
reformulation system based on a neural network that rewrites a query to
maximize the number of relevant documents returned. We train this neural
network with reinforcement learning. The actions correspond to selecting terms
to build a reformulated query, and the reward is the document recall. We
evaluate our approach on three datasets against strong baselines and show a
relative improvement of 5-20% in terms of recall. Furthermore, we present a
simple method to estimate a conservative upper-bound performance of a model in
a particular environment and verify that there is still large room for
improvements.
</dc:description>
 <dc:description>Comment: EMNLP 2017</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:date>2017-09-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04572</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04573</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RaPro: A Novel 5G Rapid Prototyping System Architecture</dc:title>
 <dc:creator>Yang, Xi</dc:creator>
 <dc:creator>Huang, Zhichao</dc:creator>
 <dc:creator>Han, Bin</dc:creator>
 <dc:creator>Zhang, Senjie</dc:creator>
 <dc:creator>Wen, Chao-Kai</dc:creator>
 <dc:creator>Gao, Feifei</dc:creator>
 <dc:creator>Jin, Shi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We propose a novel fifth-generation (5G) rapid prototyping (RaPro) system
architecture by combining FPGA-privileged modules from a software defined radio
(or FPGA-coprocessor) and high-level programming language for advanced
algorithms from multi-core general purpose processors. The proposed system
architecture exhibits excellent flexibility and scalability in the development
of a 5G prototyping system. As a proof of concept, a multi-user full-dimension
multiple-input and multiple-output system is established based on the proposed
architecture. Experimental results demonstrate the superiority of the proposed
architecture in large-scale antenna and wideband communication systems.
</dc:description>
 <dc:description>Comment: accepted by IEEE Wireless Communication Letters</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04573</dc:identifier>
 <dc:identifier>doi:10.1109/LWC.2017.2692780</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04574</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Securing a UAV Using Individual Characteristics From an EEG Signal</dc:title>
 <dc:creator>Singandhupe, Ashutosh</dc:creator>
 <dc:creator>La, Hung Manh</dc:creator>
 <dc:creator>Feil-Seifer, David</dc:creator>
 <dc:creator>Huang, Pei</dc:creator>
 <dc:creator>Guo, Linke</dc:creator>
 <dc:creator>Li, Ming</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Unmanned aerial vehicles (UAVs) have gained much attention in recent years
for both commercial and military applications. The progress in this field has
gained much popularity and the research has encompassed various fields of
scientific domain. Cyber securing a UAV communication has been one of the
active research field since the attack on Predator UAV video stream hijacking
in 2009. Since UAVs rely heavily on on-board autopilot to function, it is
important to develop an autopilot system that is robust to possible cyber
attacks. In this work, we present a biometric system to encrypt the UAV
communication by generating a key which is derived from Beta component of the
EEG signal of a user. We have developed a safety mechanism that would be
activated in case the communication of the UAV from the ground control station
gets attacked. This system has been validated on a commercial UAV under
malicious attack conditions during which we implement a procedure where the UAV
return safely to a &quot;home&quot; position.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04574</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04576</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NEXT: A Neural Network Framework for Next POI Recommendation</dc:title>
 <dc:creator>Zhang, Zhiqian</dc:creator>
 <dc:creator>Li, Chenliang</dc:creator>
 <dc:creator>Wu, Zhiyong</dc:creator>
 <dc:creator>Sun, Aixin</dc:creator>
 <dc:creator>Ye, Dengpan</dc:creator>
 <dc:creator>Luo, Xiangyang</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  The task of next POI recommendation has been studied extensively in recent
years. However, developing an unified recommendation framework to incorporate
multiple factors associated with both POIs and users remains challenging,
because of the heterogeneity nature of these information. Further, effective
mechanisms to handle cold-start and endow the system with interpretability are
also difficult topics. Inspired by the recent success of neural networks in
many areas, in this paper, we present a simple but effective neural network
framework for next POI recommendation, named NEXT. NEXT is an unified framework
to learn the hidden intent regarding user's next move, by incorporating
different factors in an unified manner. Specifically, in NEXT, we incorporate
meta-data information and two kinds of temporal contexts (i.e., time interval
and visit time). To leverage sequential relations and geographical influence,
we propose to adopt DeepWalk, a network representation learning technique, to
encode such knowledge. We evaluate the effectiveness of NEXT against
state-of-the-art alternatives and neural networks based solutions. Experimental
results over three publicly available datasets demonstrate that NEXT
significantly outperforms baselines in real-time next POI recommendation.
Further experiments demonstrate the superiority of NEXT in handling cold-start.
More importantly, we show that NEXT provides meaningful explanation of the
dimensions in hidden intent space.
</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04576</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04579</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating Quality of Chatbots and Intelligent Conversational Agents</dc:title>
 <dc:creator>Radziwill, Nicole M.</dc:creator>
 <dc:creator>Benton, Morgan C.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Chatbots are one class of intelligent, conversational software agents
activated by natural language input (which can be in the form of text, voice,
or both). They provide conversational output in response, and if commanded, can
sometimes also execute tasks. Although chatbot technologies have existed since
the 1960s and have influenced user interface development in games since the
early 1980s, chatbots are now easier to train and implement. This is due to
plentiful open source code, widely available development platforms, and
implementation options via Software as a Service (SaaS). In addition to
enhancing customer experiences and supporting learning, chatbots can also be
used to engineer social harm - that is, to spread rumors and misinformation, or
attack people for posting their thoughts and opinions online. This paper
presents a literature review of quality issues and attributes as they relate to
the contemporary issue of chatbot development and implementation. Finally,
quality assessment approaches are reviewed, and a quality assessment method
based on these attributes and the Analytic Hierarchy Process (AHP) is proposed
and examined.
</dc:description>
 <dc:description>Comment: Software Quality Professional, June 2017</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04579</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04584</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance of Energy Harvesting Receivers with Power Optimization</dc:title>
 <dc:creator>Ni, Zhengwei</dc:creator>
 <dc:creator>Motani, Mehul</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The difficulty of modeling energy consumption in communication systems leads
to challenges in energy harvesting (EH) systems, in which nodes scavenge energy
from their environment. An EH receiver must harvest enough energy for
demodulating and decoding. The energy required depends upon factors, like code
rate and signal-to-noise ratio, which can be adjusted dynamically. We consider
a receiver which harvests energy from ambient sources and the transmitter,
meaning the received signal is used for both EH and information decoding.
Assuming a generalized function for energy consumption, we maximize the total
number of information bits decoded, under both average and peak power
constraints at the transmitter, by carefully optimizing the power used for EH,
power used for information transmission, fraction of time for EH, and code
rate. For transmission over a single block, we find there exist problem
parameters for which either maximizing power for information transmission or
maximizing power for EH is optimal. In the general case, the optimal solution
is a tradeoff of the two. For transmission over multiple blocks, we give an
upper bound on performance and give sufficient and necessary conditions to
achieve this bound. Finally, we give some numerical results to illustrate our
results and analysis.
</dc:description>
 <dc:description>Comment: 28 pages</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04584</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04585</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Path Planning and Replanning for Mobile Robots using RRT*</dc:title>
 <dc:creator>Connell, Devin</dc:creator>
 <dc:creator>La, Hung Manh</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  It is necessary for a mobile robot to be able to efficiently plan a path from
its starting, or current, location to a desired goal location. This is a
trivial task when the environment is static. However, the operational
environment of the robot is rarely static, and it often has many moving
obstacles. The robot may encounter one, or many, of these unknown and
unpredictable moving obstacles. The robot will need to decide how to proceed
when one of these obstacles is obstructing it's path. A method of dynamic
replanning using RRT* is presented. The robot will modify it's current plan
when an unknown random moving obstacle obstructs the path. Various experimental
results show the effectiveness of the proposed method.
</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04585</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04587</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning for Photoacoustic Tomography from Sparse Data</dc:title>
 <dc:creator>Antholzer, Stephan</dc:creator>
 <dc:creator>Haltmeier, Markus</dc:creator>
 <dc:creator>Schwab, Johannes</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The development of fast and accurate image reconstruction algorithms is a
central aspect of computed tomography. In this paper we investigate this issue
for the sparse data problem in photoacoustic tomography (PAT). We develop a
direct and highly efficient reconstruction algorithm based on deep learning. In
our approach image reconstruction is performed with a deep convolutional neural
network (CNN), whose weights are adjusted prior to the actual image
reconstruction based on a set of training data. The proposed reconstruction
approach can be interpreted as a network that uses the PAT filtered
backprojection algorithm for the first layer, followed by the U-net
architecture for the remaining layers. Actual image reconstruction with deep
learning consists in one evaluation of the trained network. The numerical
complexity of evaluating the trained network is smaller than that of iterative
reconstruction algorithms, which require repeatedly solving the forward and
adjoint problems. At the same time, our numerical results demonstrate that the
proposed deep learning approach reconstructs images with a quality comparable
to (or even outperforming) state of the art iterative approaches for PAT from
sparse data.
</dc:description>
 <dc:description>Comment: 20 pages, 7 figures</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:date>2017-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04587</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04588</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data aggregation routing protocols in wireless sensor networks: a
  taxonomy</dc:title>
 <dc:creator>Ardakani, Saeid Pourroostaei</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Routing in Wireless Sensor Network (WSN) aims to interconnect sensor nodes
via single or multi-hop paths. The routes are established to forward data
packets from sensor nodes to the sink. Establishing a single path to report
each data packet results in increasing energy consumption in WSN, hence, data
aggregation routing is used to combine data packets and consequently reduce the
number of transmissions. This reduces the routing overhead by eliminating
redundant and meaningless data. There are two models for data aggregation
routing in WSN: mobile agent and client/server. This paper describes data
aggregation routing and classifies then the routing protocols according to the
network architecture and routing models. The key issues of the data aggregation
routing models (client/server and mobile agent) are highlighted and discussed.
</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04588</dc:identifier>
 <dc:identifier>doi:10.5121/ijcnc.2017.9207</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04595</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Non-Causal CPU-State Information for Energy-Efficient Mobile
  Cooperative Computing</dc:title>
 <dc:creator>You, Changsheng</dc:creator>
 <dc:creator>Huang, Kaibin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Scavenging the idling computation resources at the enormous number of mobile
devices can provide a powerful platform for local mobile cloud computing. The
vision can be realized by peer-to-peer cooperative computing between edge
devices, referred to as co-computing. This paper considers a co-computing
system where a user offloads computation of input-data to a helper. The helper
controls the offloading process for the objective of minimizing the user's
energy consumption based on a predicted helper's CPU-idling profile that
specifies the amount of available computation resource for co-computing.
Consider the scenario that the user has one-shot input-data arrival and the
helper buffers offloaded bits. The problem for energy-efficient co-computing is
formulated as two sub-problems: the slave problem corresponding to adaptive
offloading and the master one to data partitioning. Given a fixed offloaded
data size, the adaptive offloading aims at minimizing the energy consumption
for offloading by controlling the offloading rate under the deadline and buffer
constraints. By deriving the necessary and sufficient conditions for the
optimal solution, we characterize the structure of the optimal policies and
propose algorithms for computing the policies. Furthermore, we show that the
problem of optimal data partitioning for offloading and local computing at the
user is convex, admitting a simple solution using the sub-gradient method.
Last, the developed design approach for co-computing is extended to the
scenario of bursty data arrivals at the user accounting for data causality
constraints. Simulation results verify the effectiveness of the proposed
algorithms.
</dc:description>
 <dc:description>Comment: Submitted to possible journal</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:date>2017-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04595</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04599</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A novel approach for fast mining frequent itemsets use N-list structure
  based on MapReduce</dc:title>
 <dc:creator>Al-Hamodi, Arkan A. G.</dc:creator>
 <dc:creator>Lu, Songfeng</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>68Wxx, 68P05</dc:subject>
 <dc:description>  Frequent Pattern Mining is a one field of the most significant topics in data
mining. In recent years, many algorithms have been proposed for mining frequent
itemsets. A new algorithm has been presented for mining frequent itemsets based
on N-list data structure called Prepost algorithm. The Prepost algorithm is
enhanced by implementing compact PPC-tree with the general tree. Prepost
algorithm can only find a frequent itemsets with required (pre-order and
post-order) for each node. In this chapter, we improved prepost algorithm based
on Hadoop platform (HPrepost), proposed using the Mapreduce programming model.
The main goals of proposed method are efficient mining frequent itemsets
requiring less running time and memory usage. We have conduct experiments for
the proposed scheme to compare with another algorithms. With dense datasets,
which have a large average length of transactions, HPrepost is more effective
than frequent itemsets algorithms in terms of execution time and memory usage
for all min-sup. Generally, our algorithm outperforms algorithms in terms of
runtime and memory usage with small thresholds and large datasets.
</dc:description>
 <dc:description>Comment: 11 pages, 10 figures</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04599</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04600</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Randomized detection and detection capacity of multidetector networks</dc:title>
 <dc:creator>Ganesan, Ghurumuruhan</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study the following detection problem. There are $n$
detectors randomly placed in the unit square $S =
\left[-\frac{1}{2},\frac{1}{2}\right]^2$ assigned to detect the presence of a
source located at the origin. Time is divided into slots of unit length and
$D_i(t) \in \{0,1\}$ represents the (random) decision of the $i^{\rm th}$
detector in time slot $t$. The location of the source is unknown to the
detectors and the goal is to design schemes that use the decisions
$\{D_i(t)\}_{i,t}$ and detect the presence of the source in as short time as
possible.
  We first determine the minimum achievable detection time $T_{cap}$ and show
the existence of \emph{randomized} detection schemes that have detection times
arbitrarily close to $T_{cap}$ for almost all configuration of detectors,
provided the number of detectors $n$ is sufficiently large. We call such
schemes as \emph{capacity achieving} and completely characterize all capacity
achieving detection schemes.
</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04600</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04601</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MUSE: Modularizing Unsupervised Sense Embeddings</dc:title>
 <dc:creator>Lee, Guang-He</dc:creator>
 <dc:creator>Chen, Yun-Nung</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper proposes to address the word sense ambiguity issue in an
unsupervised manner, where word sense representations are learned along a word
sense selection mechanism given contexts. Prior work about learning multi-sense
embeddings suffered from either ambiguity of different-level embeddings or
inefficient sense selection. The proposed modular framework, MUSE, implements
flexible modules to optimize distinct mechanisms, achieving the first purely
sense-level representation learning system with linear-time sense selection. We
leverage reinforcement learning to enable joint training on the proposed
modules, and introduce various exploration techniques on sense selection for
better robustness. The experiments on benchmark data show that the proposed
approach achieves the state-of-the-art performance on synonym selection as well
as on contextual word similarities in terms of MaxSimC.
</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04601</dc:identifier>
 <dc:identifier>Proceedings of the 2017 Conference on Empirical Methods in Natural
  Language Processing, pages 327-337</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04607</identifier>
 <datestamp>2017-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Massive MU-MIMO-OFDM Downlink with One-Bit DACs and Linear Precoding</dc:title>
 <dc:creator>Jacobsson, Sven</dc:creator>
 <dc:creator>Durisi, Giuseppe</dc:creator>
 <dc:creator>Coldrey, Mikael</dc:creator>
 <dc:creator>Studer, Christoph</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Massive multiuser (MU) multiple-input multiple- output (MIMO) is foreseen to
be a key technology in future wireless communication systems. In this paper, we
analyze the downlink performance of an orthogonal frequency division
multiplexing (OFDM)-based massive MU-MIMO system in which the base station (BS)
is equipped with 1-bit digital-to-analog converters (DACs). Using Bussgang's
theorem, we characterize the performance achievable with linear precoders (such
as maximal-ratio transmission and zero forcing) in terms of bit error rate
(BER). Our analysis accounts for the possibility of oversampling the
time-domain transmit signal before the DACs. We further develop a lower bound
on the information-theoretic sum-rate throughput achievable with Gaussian
inputs.
  Our results suggest that the performance achievable with 1-bit DACs in a
massive MU-MIMO-OFDM downlink are satisfactory provided that the number of BS
antennas is sufficiently large.
</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:date>2017-09-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04610</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A learning-based approach for automatic image and video colorization</dc:title>
 <dc:creator>Gupta, Raj Kumar</dc:creator>
 <dc:creator>Chia, Alex Yong-Sang</dc:creator>
 <dc:creator>Rajan, Deepu</dc:creator>
 <dc:creator>Zhiyong, Huang</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we present a color transfer algorithm to colorize a broad
range of gray images without any user intervention. The algorithm uses a
machine learning-based approach to automatically colorize grayscale images. The
algorithm uses the superpixel representation of the reference color images to
learn the relationship between different image features and their corresponding
color values. We use this learned information to predict the color value of
each grayscale image superpixel. As compared to processing individual image
pixels, our use of superpixels helps us to achieve a much higher degree of
spatial consistency as well as speeds up the colorization process. The
predicted color values of the gray-scale image superpixels are used to provide
a 'micro-scribble' at the centroid of the superpixels. These color scribbles
are refined by using a voting based approach. To generate the final
colorization result, we use an optimization-based approach to smoothly spread
the color scribble across all pixels within a superpixel. Experimental results
on a broad range of images and the comparison with existing state-of-the-art
colorization methods demonstrate the greater effectiveness of the proposed
algorithm.
</dc:description>
 <dc:description>Comment: Computer Graphics International - 2012</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04610</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04611</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Transceiver Design Based on Interference Alignment for Multi-User
  Multi-Cell MIMO Networks with Channel Uncertainty</dc:title>
 <dc:creator>Xie, Xianzhong</dc:creator>
 <dc:creator>Yang, Helin</dc:creator>
 <dc:creator>Vasilakos, Athanasios V.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>H.4.3</dc:subject>
 <dc:subject>H.2.3</dc:subject>
 <dc:description>  In this paper, we firstly exploit the inter-user interference (IUI) and
inter-cell interference (ICI) as useful references to develop a robust
transceiver design based on interference alignment for a downlink multi-user
multi-cell multiple-input multiple-output (MIMO) interference network under
channel estimation error. At transmitters, we propose a two-tier transmit
beamforming strategy, we first achieve the inner beamforming direction and
allocated power by minimizing the interference leakage as well as maximizing
the system energy efficiency, respectively. Then, for the outer beamformer
design, we develop an efficient conjugate gradient Grassmann manifold subspace
tracking algorithm to minimize the distances between the subspace spanned by
interference and the interference subspace in the time varying channel. At
receivers, we propose a practical interference alignment based on fast and
robust fast data projection method (FDPM) subspace tracking algorithm, to
achieve the receive beamformer under channel uncertainty. Numerical results
show that our proposed robust transceiver design achieves better performance
compared with some existing methods in terms of the sum rate and the energy
efficiency.
</dc:description>
 <dc:description>Comment: 12 pages, 8 figures</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04611</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04613</identifier>
 <datestamp>2017-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integrating Scene Text and Visual Appearance for Fine-Grained Image
  Classification</dc:title>
 <dc:creator>Bai, Xiang</dc:creator>
 <dc:creator>Yang, Mingkun</dc:creator>
 <dc:creator>Lyu, Pengyuan</dc:creator>
 <dc:creator>Xu, Yongchao</dc:creator>
 <dc:creator>Luo, Jiebo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Text in natural images contains rich semantics that are often highly relevant
to objects or scene. In this paper, we focus on the problem of fully exploiting
scene text for visual understanding. The main idea is combining word
representations and deep visual features into a globally trainable deep
convolutional neural network. First, the recognized words are obtained by a
scene text reading system. Then, we combine the word embedding of the
recognized words and the deep visual features into a single representation,
which is optimized by a convolutional neural network for fine-grained image
classification. In our framework, the attention mechanism is adopted to reveal
the relevance between each recognized word and the given image, which further
enhances the recognition performance. We have performed experiments on two
datasets: Con-Text dataset and Drink Bottle dataset, that are proposed for
fine-grained classification of business places and drink bottles, respectively.
The experimental results consistently demonstrate that the proposed method
combining textual and visual cues significantly outperforms classification with
only visual representations. Moreover, we have shown that the learned
representation improves the retrieval performance on the drink bottle images by
a large margin, making it potentially useful in product search.
</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:date>2017-05-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04613</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04615</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FMtree: A fast locating algorithm of FM-indexes for genomic data</dc:title>
 <dc:creator>Cheng, Haoyu</dc:creator>
 <dc:creator>Wu, Ming</dc:creator>
 <dc:creator>Xu, Yun</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Motivation: As a fundamental task in bioinformatics, searching for massive
short patterns over a long text is widely accelerated by various compressed
full-text indexes. These indexes are able to provide similar searching
functionalities to classical indexes, e.g., suffix trees and suffix arrays,
while requiring less space. For genomic data, a well-known family of compressed
full-text index, called FM-indexes, presents unmatched performance in practice.
One major drawback of FM-indexes is that their locating operations, which
report all occurrence positions of patterns in a given text, are particularly
slow, especially for the patterns with many occurrences.
  Results: In this paper, we introduce a novel locating algorithm, FMtree, to
fast retrieve all occurrence positions of any pattern via FM-indexes. When
searching for a pattern over a given text, FMtree organizes the search space of
the locating operation into a conceptual quadtree. As a result, multiple
occurrence positions of this pattern can be retrieved simultaneously by
traversing the quadtree. Compared with the existing locating algorithms, our
tree-based algorithm reduces large numbers of redundant operations and presents
better data locality. Experimental results show that FMtree is usually one
order of magnitude faster than the state-of-the-art algorithms, and still
memory-efficient.
</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04615</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04618</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Advances in Detection and Error Correction for Coherent Optical
  Communications: Regular, Irregular, and Spatially Coupled LDPC Code Designs</dc:title>
 <dc:creator>Schmalen, Laurent</dc:creator>
 <dc:creator>Brink, Stephan ten</dc:creator>
 <dc:creator>Leven, Andreas</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this chapter, we show how the use of differential coding and the presence
of phase slips in the transmission channel affect the total achievable
information rates and capacity of a system. By means of the commonly used QPSK
modulation, we show that the use of differential coding does not decrease the
total amount of reliably conveyable information over the channel. It is a
common misconception that the use of differential coding introduces an
unavoidable differential loss. This perceived differential loss is rather a
consequence of simplified differential detection and decoding at the receiver.
Afterwards, we show how capacity-approaching coding schemes based on LDPC and
spatially coupled LDPC codes can be constructed by combining iterative
demodulation and decoding. For this, we first show how to modify the
differential decoder to account for phase slips and then how to use this
modified differential decoder to construct good LDPC codes. This construction
method can serve as a blueprint to construct good and practical LDPC codes for
other applications with iterative detection, such as higher order modulation
formats with non-square constellations, multi-dimensional optimized modulation
formats, turbo equalization to mitigate ISI (e.g., due to nonlinearities) and
many more. Finally, we introduce the class of spatially coupled (SC)-LDPC
codes, which are a generalization of LDPC codes with some outstanding
properties and which can be decoded with a very simple windowed decoder. We
show that the universal behavior of spatially coupled codes makes them an ideal
candidate for iterative differential demodulation/detection and decoding.
</dc:description>
 <dc:description>Comment: &quot;Enabling Technologies for High Spectral-efficiency Coherent Optical
  Communication Networks&quot; edited by X. Zhou and C. Xie, John Wiley &amp; Sons,
  Inc., April 2016</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04618</dc:identifier>
 <dc:identifier>doi:10.1002/9781119078289</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04620</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Geometry of Concurrent Interaction: Handling Multiple Ports by Way
  of Multiple Tokens (Long Version)</dc:title>
 <dc:creator>Lago, Ugo Dal</dc:creator>
 <dc:creator>Tanaka, Ryo</dc:creator>
 <dc:creator>Yoshimizu, Akira</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We introduce a geometry of interaction model for Mazza's multiport
interaction combinators, a graph-theoretic formalism which is able to
faithfully capture concurrent computation as embodied by process algebras like
the $\pi$-calculus. The introduced model is based on token machines in which
not one but multiple tokens are allowed to traverse the underlying net at the
same time. We prove soundness and adequacy of the introduced model. The former
is proved as a simulation result between the token machines one obtains along
any reduction sequence. The latter is obtained by a fine analysis of
convergence, both in nets and in token machines.
</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04620</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04640</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A fast ILP-based Heuristic for the robust design of Body Wireless Sensor
  Networks</dc:title>
 <dc:creator>D'Andreagiovanni, Fabio</dc:creator>
 <dc:creator>Nardin, Antonella</dc:creator>
 <dc:creator>Natalizio, Enrico</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We consider the problem of optimally designing a body wireless sensor
network, while taking into account the uncertainty of data generation of
biosensors. Since the related min-max robustness Integer Linear Programming
(ILP) problem can be difficult to solve even for state-of-the-art commercial
optimization solvers, we propose an original heuristic for its solution. The
heuristic combines deterministic and probabilistic variable fixing strategies,
guided by the information coming from strengthened linear relaxations of the
ILP robust model, and includes a very large neighborhood search for reparation
and improvement of generated solutions, formulated as an ILP problem solved
exactly. Computational tests on realistic instances show that our heuristic
finds solutions of much higher quality than a state-of-the-art solver and than
an effective benchmark heuristic.
</dc:description>
 <dc:description>Comment: This is the authors' final version of the paper published in G.
  Squillero and K. Sim (Eds.): EvoApplications 2017, Part I, LNCS 10199, pp.
  1-17, 2017. DOI: 10.1007/978-3-319-55849-3\_16. The final publication is
  available at Springer via http://dx.doi.org/10.1007/978-3-319-55849-3_16</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04640</dc:identifier>
 <dc:identifier>EvoApplications 2017, Springer LNCS 10199 (2017) 1-17</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-55849-3_16</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04641</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capacity of the Gaussian Two-Pair Two-Way Relay Channel to Within 1/2
  Bit</dc:title>
 <dc:creator>Yuan, Xiaojun</dc:creator>
 <dc:creator>Xin, Haiyang</dc:creator>
 <dc:creator>Liew, Soung-Chang</dc:creator>
 <dc:creator>Li, Yong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies the transceiver design of the Gaussian two-pair two-way
relay channel (TWRC), where two pairs of users exchange information through a
common relay in a pairwise manner. Our main contribution is to show that the
capacity of the Gaussian two-pair TWRC is achievable to within 1/2 bit for
arbitrary channel conditions. In the proof, we develop a hybrid coding scheme
involving Gaussian random coding, nested lattice coding, superposition coding,
and network-coded decoding. Further, we present a message-reassembling strategy
to decouple the coding design for the user-to-relay and relay-to-user links, so
as to provide flexibility to fully exploit the channel randomness. Finally,
judicious power allocation at the relay is necessary to approach the channel
capacity under various channel conditions.
</dc:description>
 <dc:description>Comment: 28 pages, 5 figures, journal</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04647</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effectful Applicative Bisimilarity: Monads, Relators, and Howe's Method
  (Long Version)</dc:title>
 <dc:creator>Lago, Ugo Dal</dc:creator>
 <dc:creator>Gavazzo, Francesco</dc:creator>
 <dc:creator>Levy, Paul Blain</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We study Abramsky's applicative bisimilarity abstractly, in the context of
call-by-value $\lambda$-calculi with algebraic effects. We first of all endow a
computational $\lambda$-calculus with a monadic operational semantics. We then
show how the theory of relators provides precisely what is needed to generalise
applicative bisimilarity to such a calculus, and to single out those monads and
relators for which applicative bisimilarity is a congruence, thus a sound
methodology for program equivalence. This is done by studying Howe's method in
the abstract.
</dc:description>
 <dc:description>Comment: 30 pages</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04647</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04650</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Big Universe, Big Data: Machine Learning and Image Analysis for
  Astronomy</dc:title>
 <dc:creator>Kremer, Jan</dc:creator>
 <dc:creator>Stensbo-Smidt, Kristoffer</dc:creator>
 <dc:creator>Gieseke, Fabian</dc:creator>
 <dc:creator>Pedersen, Kim Steenstrup</dc:creator>
 <dc:creator>Igel, Christian</dc:creator>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Astrophysics and cosmology are rich with data. The advent of wide-area
digital cameras on large aperture telescopes has led to ever more ambitious
surveys of the sky. Data volumes of entire surveys a decade ago can now be
acquired in a single night and real-time analysis is often desired. Thus,
modern astronomy requires big data know-how, in particular it demands highly
efficient machine learning and image analysis algorithms. But scalability is
not the only challenge: Astronomy applications touch several current machine
learning research questions, such as learning from biased data and dealing with
label and measurement noise. We argue that this makes astronomy a great domain
for computer science research, as it pushes the boundaries of data analysis. In
the following, we will present this exciting application area for data
scientists. We will focus on exemplary results, discuss main challenges, and
highlight some recent methodological advancements in machine learning and image
analysis triggered by astronomical applications.
</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04650</dc:identifier>
 <dc:identifier>IEEE Intelligent Systems, vol. 32, no. , pp. 16-22, Mar.-Apr. 2017</dc:identifier>
 <dc:identifier>doi:10.1109/MIS.2017.40</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04651</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Reactor: A Sample-Efficient Actor-Critic Architecture</dc:title>
 <dc:creator>Gruslys, Audrunas</dc:creator>
 <dc:creator>Azar, Mohammad Gheshlaghi</dc:creator>
 <dc:creator>Bellemare, Marc G.</dc:creator>
 <dc:creator>Munos, Remi</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this work we present a new reinforcement learning agent, called Reactor
(for Retrace-actor), based on an off-policy multi-step return actor-critic
architecture. The agent uses a deep recurrent neural network for function
approximation. The network outputs a target policy {\pi} (the actor), an
action-value Q-function (the critic) evaluating the current policy {\pi}, and
an estimated behavioral policy {\hat \mu} which we use for off-policy
correction. The agent maintains a memory buffer filled with past experiences.
The critic is trained by the multi-step off-policy Retrace algorithm and the
actor is trained by a novel {\beta}-leave-one-out policy gradient estimate
(which uses both the off-policy corrected return and the estimated Q-function).
The Reactor is sample-efficient thanks to the use of memory replay, and
numerical efficient since it uses multi-step returns. Also both acting and
learning can be parallelized. We evaluated our algorithm on 57 Atari 2600 games
and demonstrate that it achieves state-of-the-art performance.
</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04651</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04652</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Output Consensus of High-Order Multi-Agent Systems with Embedded
  Technique</dc:title>
 <dc:creator>Tang, Yutao</dc:creator>
 <dc:creator>Deng, Zhenhua</dc:creator>
 <dc:creator>Hong, Yiguang</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, we study an optimal output consensus problem for a multi-agent
network with agents in the form of multi-input multi-output minimum-phase
dynamics. Optimal output consensus can be taken as an extended version of the
existing output consensus problem for higher-order agents with an optimization
requirement, where the output variables of agents are driven to achieve a
consensus on the optimal solution of a global cost function. To solve this
problem, we first construct an optimal signal generator, and then propose an
embedded control scheme by embedding the generator in the feedback loop. We
give two kinds of algorithms based on different available information along
with both state feedback and output feedback, and prove that these algorithms
with the embedded technique can guarantee the solvability of the problem for
high-order multi-agent systems under standard assumptions.
</dc:description>
 <dc:description>Comment: 24 page, 5 figures</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04652</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04656</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Negative Cycle Separation in Wireless Network Design</dc:title>
 <dc:creator>D'Andreagiovanni, Fabio</dc:creator>
 <dc:creator>Mannino, Carlo</dc:creator>
 <dc:creator>Sassano, Antonio</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The Wireless Network Design Problem (WND) consists in choosing values of
radio-electrical parameters of transmitters of a wireless network, to maximize
network coverage. We present a pure 0-1 Linear Programming formulation for the
WND that may contain an exponential number of constraints. Violated
inequalities of this formulation are hard to separate both theoretically and in
practice. However, a relevant subset of such inequalities can be separated more
efficiently in practice and can be used to strengthen classical MILP
formulations for the WND. Preliminary computational experience confirms the
effectiveness of our new technique both in terms of quality of solutions found
and provided bounds.
</dc:description>
 <dc:description>Comment: This is the authors' final version of the paper published in Pahl J.,
  Reiners T., Voss S. (eds), Network Optimization - INOC 2011. Lecture Notes in
  Computer Science, vol 6701, pp. 51-56. Springer, Berlin, Heidelberg, 2011,
  DOI: 10.1007/978-3-642-21527-8_7. The final publication is available at
  Springer via http://dx.doi.org/10.1007/978-3-642-21527-8_7</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04656</dc:identifier>
 <dc:identifier>Network Optimization - INOC 2011, In: Pahl J., Reiners T., Voss S.
  (eds). Lecture Notes in Computer Science, vol 6701, pp. 51-56. Springer,
  Berlin, Heidelberg, 2011</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-642-21527-8_7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04657</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Time Dimension of Science: Connecting the Past to the Future</dc:title>
 <dc:creator>Yin, Yian</dc:creator>
 <dc:creator>Wang, Dashun</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  A central question in science of science concerns how time affects citations.
Despite the long-standing interests and its broad impact, we lack systematic
answers to this simple yet fundamental question. By reviewing and classifying
prior studies for the past 50 years, we find a significant lack of consensus in
the literature, primarily due to the coexistence of retrospective and
prospective approaches to measuring citation age distributions. These two
approaches have been pursued in parallel, lacking any known connections between
the two. Here we developed a new theoretical framework that not only allows us
to connect the two approaches through precise mathematical relationships, it
also helps us reconcile the interplay between temporal decay of citations and
the growth of science, helping us uncover new functional forms characterizing
citation age distributions. We find retrospective distribution follows a
lognormal distribution with exponential cutoff, while prospective distribution
is governed by the interplay between a lognormal distribution and the growth in
the number of references. Most interestingly, the two approaches can be
connected once rescaled by the growth of publications and citations. We further
validate our framework using both large-scale citation datasets and analytical
models capturing citation dynamics. Together this paper presents a
comprehensive analysis of the time dimension of science, representing a new
empirical and theoretical basis for all future studies in this area.
</dc:description>
 <dc:description>Comment: To appear in Journal of Informetrics</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04657</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04663</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Autonomous Robotic System using Non-Destructive Evaluation methods for
  Bridge Deck Inspection</dc:title>
 <dc:creator>Le, Tuan</dc:creator>
 <dc:creator>Gibb, Spencer</dc:creator>
 <dc:creator>La, Hung Manh</dc:creator>
 <dc:creator>Falk, Logan</dc:creator>
 <dc:creator>Berendsen, Tony</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Bridge condition assessment is important to maintain the quality of highway
roads for public transport. Bridge deterioration with time is inevitable due to
aging material, environmental wear and in some cases, inadequate maintenance.
Non-destructive evaluation (NDE) methods are preferred for condition assessment
for bridges, concrete buildings, and other civil structures. Some examples of
NDE methods are ground penetrating radar (GPR), acoustic emission, and
electrical resistivity (ER). NDE methods provide the ability to inspect a
structure without causing any damage to the structure in the process. In
addition, NDE methods typically cost less than other methods, since they do not
require inspection sites to be evacuated prior to inspection, which greatly
reduces the cost of safety related issues during the inspection process. In
this paper, an autonomous robotic system equipped with three different NDE
sensors is presented. The system employs GPR, ER, and a camera for data
collection. The system is capable of performing real-time, cost-effective
bridge deck inspection, and is comprised of a mechanical robot design and
machine learning and pattern recognition methods for automated steel rebar
picking to provide realtime condition maps of the corrosive deck environments.
</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04663</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04664</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Spatial Concept and Lexical Acquisition with Simultaneous
  Localization and Mapping</dc:title>
 <dc:creator>Taniguchi, Akira</dc:creator>
 <dc:creator>Hagiwara, Yoshinobu</dc:creator>
 <dc:creator>Taniguchi, Tadahiro</dc:creator>
 <dc:creator>Inamura, Tetsunari</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this paper, we propose an online learning algorithm based on a
Rao-Blackwellized particle filter for spatial concept acquisition and mapping.
We have proposed a nonparametric Bayesian spatial concept acquisition model
(SpCoA). We propose a novel method (SpCoSLAM) integrating SpCoA and FastSLAM in
the theoretical framework of the Bayesian generative model. The proposed method
can simultaneously learn place categories and lexicons while incrementally
generating an environmental map. Furthermore, the proposed method has scene
image features and a language model added to SpCoA. In the experiments, we
tested online learning of spatial concepts and environmental maps in a novel
environment of which the robot did not have a map. Then, we evaluated the
results of online learning of spatial concepts and lexical acquisition. The
experimental results demonstrated that the robot was able to more accurately
learn the relationships between words and the place in the environmental map
incrementally by using the proposed method.
</dc:description>
 <dc:description>Comment: Preprint submitted to 2017 IEEE/RSJ International Conference on
  Intelligent Robots and Systems. Received March 1, 2017</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04664</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04671</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal Action Localization by Structured Maximal Sums</dc:title>
 <dc:creator>Yuan, Zehuan</dc:creator>
 <dc:creator>Stroud, Jonathan C.</dc:creator>
 <dc:creator>Lu, Tong</dc:creator>
 <dc:creator>Deng, Jia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We address the problem of temporal action localization in videos. We pose
action localization as a structured prediction over arbitrary-length temporal
windows, where each window is scored as the sum of frame-wise classification
scores. Additionally, our model classifies the start, middle, and end of each
action as separate components, allowing our system to explicitly model each
action's temporal evolution and take advantage of informative temporal
dependencies present in this structure. In this framework, we localize actions
by searching for the structured maximal sum, a problem for which we develop a
novel, provably-efficient algorithmic solution. The frame-wise classification
scores are computed using features from a deep Convolutional Neural Network
(CNN), which are trained end-to-end to directly optimize for a novel structured
objective. We evaluate our system on the THUMOS 14 action detection benchmark
and achieve competitive performance.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2017</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04671</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04672</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Potential Field Controller for Use on Aerial Robots</dc:title>
 <dc:creator>Woods, Alexander C.</dc:creator>
 <dc:creator>La, Hung M.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Unmanned Aerial Vehicles (UAV), commonly known as drones, have many potential
uses in real world applications. Drones require advanced planning and
navigation algorithms to enable them to safely move through and interact with
the world around them. This paper presents an extended potential field
controller (ePFC) which enables an aerial robot, or drone, to safely track a
dynamic target location while simultaneously avoiding any obstacles in its
path. The ePFC outperforms a traditional potential field controller (PFC) with
smoother tracking paths and shorter settling times. The proposed ePFC's
stability is evaluated by Lyapunov approach, and its performance is simulated
in a Matlab environment. Finally, the controller is implemented on an
experimental platform in a laboratory environment which demonstrates the
effectiveness of the controller.
</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04672</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04675</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph Convolutional Encoders for Syntax-aware Neural Machine Translation</dc:title>
 <dc:creator>Bastings, Joost</dc:creator>
 <dc:creator>Titov, Ivan</dc:creator>
 <dc:creator>Aziz, Wilker</dc:creator>
 <dc:creator>Marcheggiani, Diego</dc:creator>
 <dc:creator>Sima'an, Khalil</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a simple and effective approach to incorporating syntactic
structure into neural attention-based encoder-decoder models for machine
translation. We rely on graph-convolutional networks (GCNs), a recent class of
neural networks developed for modeling graph-structured data. Our GCNs use
predicted syntactic dependency trees of source sentences to produce
representations of words (i.e. hidden states of the encoder) that are sensitive
to their syntactic neighborhoods. GCNs take word representations as input and
produce word representations as output, so they can easily be incorporated as
layers into standard encoders (e.g., on top of bidirectional RNNs or
convolutional neural networks). We evaluate their effectiveness with
English-German and English-Czech translation experiments for different types of
encoders and observe substantial improvements over their syntax-agnostic
versions in all the considered setups.
</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04675</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04677</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kinematically Redundant Octahedral Motion Platform for Virtual Reality
  Simulations</dc:title>
 <dc:creator>Nawratil, Georg</dc:creator>
 <dc:creator>Rasoulzadeh, Arvin</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We propose a novel design of a parallel manipulator of Stewart Gough type for
virtual reality application of single individuals; i.e. an omni-directional
treadmill is mounted on the motion platform in order to improve VR immersion by
giving feedback to the human body. For this purpose we modify the well-known
octahedral manipulator in a way that it has one degree of kinematical
redundancy; namely an equiform reconfigurability of the base. The instantaneous
kinematics and singularities of this mechanism are studied, where especially
&quot;unavoidable singularities&quot; are characterized. These are poses of the motion
platform, which can only be realized by singular configurations of the
mechanism despite its kinematic redundancy.
</dc:description>
 <dc:description>Comment: 13 pages, 6 figures</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04677</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04681</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automaton model of protein: dynamics of conformational and functional
  states</dc:title>
 <dc:creator>Khrennikov, Andrei</dc:creator>
 <dc:creator>Yurova, Ekaterina</dc:creator>
 <dc:subject>Quantitative Biology - Biomolecules</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  In this conceptual paper we propose to explore the analogy between
ontic/epistemic description of quantum phenomena and interrelation between
dynamics of conformational and functional states of proteins. Another new idea
is to apply theory of automata to model the latter dynamics. In our model
protein's behavior is modeled with the aid of two dynamical systems, ontic and
epistemic, which describe evolution of conformational and functional states of
proteins, respectively. The epistemic automaton is constructed from the ontic
automaton on the basis of functional (observational) equivalence relation on
the space of ontic states. This reminds a few approaches to emergent quantum
mechanics in which a quantum (epistemic) state is treated as representing a
class of prequantum (ontic) states. This approach does not match to the
standard {\it protein structure-function paradigm.} However, it is perfect for
modeling of behavior of intrinsically disordered proteins. Mathematically space
of protein's ontic states (conformational states) is modeled with the aid of
$p$-adic numbers or more general ultrametric spaces encoding the internal
hierarchical structure of proteins. Connection with theory of $p$-adic
dynamical systems is briefly discussed.
</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04681</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04683</identifier>
 <datestamp>2017-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RACE: Large-scale ReAding Comprehension Dataset From Examinations</dc:title>
 <dc:creator>Lai, Guokun</dc:creator>
 <dc:creator>Xie, Qizhe</dc:creator>
 <dc:creator>Liu, Hanxiao</dc:creator>
 <dc:creator>Yang, Yiming</dc:creator>
 <dc:creator>Hovy, Eduard</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present RACE, a new dataset for benchmark evaluation of methods in the
reading comprehension task. Collected from the English exams for middle and
high school Chinese students in the age range between 12 to 18, RACE consists
of near 28,000 passages and near 100,000 questions generated by human experts
(English instructors), and covers a variety of topics which are carefully
designed for evaluating the students' ability in understanding and reasoning.
In particular, the proportion of questions that requires reasoning is much
larger in RACE than that in other benchmark datasets for reading comprehension,
and there is a significant gap between the performance of the state-of-the-art
models (43%) and the ceiling human performance (95%). We hope this new dataset
can serve as a valuable resource for research and evaluation in machine
comprehension. The dataset is freely available at
http://www.cs.cmu.edu/~glai1/data/race/ and the code is available at
https://github.com/qizhex/RACE_AR_baselines.
</dc:description>
 <dc:description>Comment: EMNLP 2017</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:date>2017-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04683</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04684</identifier>
 <datestamp>2017-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generic LSH Families for the Angular Distance Based on
  Johnson-Lindenstrauss Projections and Feature Hashing LSH</dc:title>
 <dc:creator>Argerich, Luis</dc:creator>
 <dc:creator>Golmar, Natalia</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  In this paper we propose the creation of generic LSH families for the angular
distance based on Johnson-Lindenstrauss projections. We show that feature
hashing is a valid J-L projection and propose two new LSH families based on
feature hashing. These new LSH families are tested on both synthetic and real
datasets with very good results and a considerable performance improvement over
other LSH families. While the theoretical analysis is done for the angular
distance, these families can also be used in practice for the euclidean
distance with excellent results [2]. Our tests using real datasets show that
the proposed LSH functions work well for the euclidean distance.
</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04684</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04688</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine Learning and the Future of Realism</dc:title>
 <dc:creator>Hooker, Giles</dc:creator>
 <dc:creator>Hooker, Cliff</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The preceding three decades have seen the emergence, rise, and proliferation
of machine learning (ML). From half-recognised beginnings in perceptrons,
neural nets, and decision trees, algorithms that extract correlations (that is,
patterns) from a set of data points have broken free from their origin in
computational cognition to embrace all forms of problem solving, from voice
recognition to medical diagnosis to automated scientific research and
driverless cars, and it is now widely opined that the real industrial
revolution lies less in mobile phone and similar than in the maturation and
universal application of ML. Among the consequences just might be the triumph
of anti-realism over realism.
</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04688</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04689</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Video Fill In the Blank using LR/RL LSTMs with Spatial-Temporal
  Attentions</dc:title>
 <dc:creator>Mazaheri, Amir</dc:creator>
 <dc:creator>Zhang, Dong</dc:creator>
 <dc:creator>Shah, Mubarak</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Given a video and a description sentence with one missing word (we call it
the &quot;source sentence&quot;), Video-Fill-In-the-Blank (VFIB) problem is to find the
missing word automatically. The contextual information of the sentence, as well
as visual cues from the video, are important to infer the missing word
accurately. Since the source sentence is broken into two fragments: the
sentence's left fragment (before the blank) and the sentence's right fragment
(after the blank), traditional Recurrent Neural Networks cannot encode this
structure accurately because of many possible variations of the missing word in
terms of the location and type of the word in the source sentence. For example,
a missing word can be the first word or be in the middle of the sentence and it
can be a verb or an adjective. In this paper, we propose a framework to tackle
the textual encoding: Two separate LSTMs (the LR and RL LSTMs) are employed to
encode the left and right sentence fragments and a novel structure is
introduced to combine each fragment with an &quot;external memory&quot; corresponding the
opposite fragments. For the visual encoding, end-to-end spatial and temporal
attention models are employed to select discriminative visual representations
to find the missing word. In the experiments, we demonstrate the superior
performance of the proposed method on challenging VFIB problem. Furthermore, we
introduce an extended and more generalized version of VFIB, which is not
limited to a single blank. Our experiments indicate the generalization
capability of our method in dealing with such more realistic scenarios.
</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04689</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04697</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comprehensive Review of Smart Wheelchairs: Past, Present and Future</dc:title>
 <dc:creator>Leaman, Jesse</dc:creator>
 <dc:creator>La, Hung M.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  A smart wheelchair (SW) is a power wheelchair (PW) to which computers,
sensors, and assistive technology are attached. In the past decade, there has
been little effort to provide a systematic review of SW research. This paper
aims to provide a complete state-of-the-art overview of SW research trends. We
expect that the information gathered in this study will enhance awareness of
the status of contemporary PW as well as SW technology, and increase the
functional mobility of people who use PWs. We systematically present the
international SW research effort, starting with an introduction to power
wheelchairs and the communities they serve. Then we discuss in detail the SW
and associated technological innovations with an emphasis on the most
researched areas, generating the most interest for future research and
development. We conclude with our vision for the future of SW research and how
to best serve people with all types of disabilities.
</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04697</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04698</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Network Coding Schemes for Satellite Communications</dc:title>
 <dc:creator>Gharsellaoui, Ala Eddine</dc:creator>
 <dc:creator>Ghanem, Samah A. M.</dc:creator>
 <dc:creator>Tarchi, Daniele</dc:creator>
 <dc:creator>Vanelli-Coralli, Alessandro</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose two novel physical layer aware adaptive network
coding and coded modulation schemes for time variant channels. The proposed
schemes have been applied to different satellite communications scenarios with
different Round Trip Times (RTT). Compared to adaptive network coding, and
classical non-adaptive network coding schemes for time variant channels, as
benchmarks, the proposed schemes demonstrate that adaptation of packet
transmission based on the channel variation and corresponding erasures allows
for significant gains in terms of throughput, delay and energy efficiency. We
shed light on the trade-off between energy efficiency and delay-throughput
gains, demonstrating that conservative adaptive approaches that favors less
transmission under high erasures, might cause higher delay and less throughput
gains in comparison to non-conservative approaches that favor more transmission
to account for high erasures.
</dc:description>
 <dc:description>Comment: IEEE Advanced Satellite Multimedia Systems Conference and the 14th
  Signal Processing for Space Communications Workshop (ASMS/SPSC), 2016</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04698</dc:identifier>
 <dc:identifier>doi:10.1109/ASMS-SPSC.2016.7601546</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04706</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trigger for the SoLid Reactor Antineutrino Experiment</dc:title>
 <dc:creator>Arnold, Lukas On</dc:creator>
 <dc:creator>collaboration, for the SoLid</dc:creator>
 <dc:subject>Physics - Instrumentation and Detectors</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>High Energy Physics - Experiment</dc:subject>
 <dc:description>  SoLid, located at SCK-CEN in Mol, Belgium, is a reactor antineutrino
experiment at a very short baseline of 5.5 -- 10m aiming at the search for
sterile neutrinos and for high precision measurement of the neutrino energy
spectrum of Uranium-235. It uses a novel approach using Lithium-6 sheets and
PVT cubes as scintillators for tagging the Inverse Beta-Decay products (neutron
and positron). Being located overground and close to the BR2 research reactor,
the experiment faces a large amount of backgrounds. Efficient real-time
background and noise rejection is essential in order to increase the
signal-background ratio for precise oscillation measurement and decrease data
production to a rate which can be handled by the online software. Therefore, a
reliable distinction between the neutrons and background signals is crucial.
This can be performed online with a dedicated firmware trigger. A peak counting
algorithm and an algorithm measuring time over threshold have been identified
as performing well both in terms of efficiency and fake rate, and have been
implemented onto FPGA.
</dc:description>
 <dc:description>Comment: Poster presented at NuPhys2016 (London, 12-14 December 2016). 8
  pages, LaTeX, 6 png figures, 1 pdf figure</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04706</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04707</identifier>
 <datestamp>2017-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structure and Randomness of Continuous-Time Discrete-Event Processes</dc:title>
 <dc:creator>Marzen, S. E.</dc:creator>
 <dc:creator>Crutchfield, J. P.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:description>  Loosely speaking, the Shannon entropy rate is used to gauge a stochastic
process' intrinsic randomness; the statistical complexity gives the cost of
predicting the process. We calculate, for the first time, the entropy rate and
statistical complexity of stochastic processes generated by finite unifilar
hidden semi-Markov models---memoryful, state-dependent versions of renewal
processes. Calculating these quantities requires introducing novel mathematical
objects ({\epsilon}-machines of hidden semi-Markov processes) and new
information-theoretic methods to stochastic processes.
</dc:description>
 <dc:description>Comment: 10 pages, 2 figures;
  http://csc.ucdavis.edu/~cmg/compmech/pubs/ctdep.htm</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04707</dc:identifier>
 <dc:identifier>doi:10.1007/s10955-017-1859-y</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04709</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantization Design and Channel Estimation for Massive MIMO Systems with
  One-Bit ADCs</dc:title>
 <dc:creator>Wang, Feiyu</dc:creator>
 <dc:creator>Fang, Jun</dc:creator>
 <dc:creator>Li, Hongbin</dc:creator>
 <dc:creator>Li, Shaoqian</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the problem of channel estimation for uplink multiuser massive
MIMO systems, where, in order to significantly reduce the hardware cost and
power consumption, one-bit analog-to-digital converters (ADCs) are used at the
base station (BS) to quantize the received signal. Channel estimation for
one-bit massive MIMO systems is challenging due to the severe distortion caused
by the coarse quantization. It was shown in previous studies that an extremely
long training sequence is required to attain an acceptable performance. In this
paper, we study the problem of optimal one-bit quantization design for channel
estimation in one-bit massive MIMO systems. Our analysis reveals that, if the
quantization thresholds are optimally devised, using one-bit ADCs can achieve
an estimation error close to (with an increase by a factor of $\pi/2$) that of
an ideal estimator which has access to the unquantized data. The optimal
quantization thresholds, however, are dependent on the unknown channel
parameters. To cope with this difficulty, we propose an adaptive quantization
(AQ) approach in which the thresholds are adaptively adjusted in a way such
that the thresholds converge to the optimal thresholds, and a random
quantization (RQ) scheme which randomly generate a set of nonidentical
thresholds based on some statistical prior knowledge of the channel. Simulation
results show that, our proposed AQ and RQ schemes, owing to their wisely
devised thresholds, present a significant performance improvement over the
conventional fixed quantization scheme that uses a fixed (typically zero)
threshold, and meanwhile achieve a substantial training overhead reduction for
channel estimation. In particular, even with a moderate number of pilot symbols
(about 5 times the number of users), the AQ scheme can provide an achievable
rate close to that of the perfect channel state information (CSI) case.
</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04712</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learn-Memorize-Recall-Reduce A Robotic Cloud Computing Paradigm</dc:title>
 <dc:creator>Liu, Shaoshan</dc:creator>
 <dc:creator>Ding, Bolin</dc:creator>
 <dc:creator>Tang, Jie</dc:creator>
 <dc:creator>Sun, Dawei</dc:creator>
 <dc:creator>Zhang, Zhe</dc:creator>
 <dc:creator>Tsai, Grace</dc:creator>
 <dc:creator>Gaudiot, Jean-Luc</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The rise of robotic applications has led to the generation of a huge volume
of unstructured data, whereas the current cloud infrastructure was designed to
process limited amounts of structured data. To address this problem, we propose
a learn-memorize-recall-reduce paradigm for robotic cloud computing. The
learning stage converts incoming unstructured data into structured data; the
memorization stage provides effective storage for the massive amount of data;
the recall stage provides efficient means to retrieve the raw data; while the
reduction stage provides means to make sense of this massive amount of
unstructured data with limited computing resources.
</dc:description>
 <dc:description>Comment: 6 pages, 7 figures</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04712</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04718</identifier>
 <datestamp>2017-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning Based Regression and Multi-class Models for Acute Oral
  Toxicity Prediction with Automatic Chemical Feature Extraction</dc:title>
 <dc:creator>Xu, Youjun</dc:creator>
 <dc:creator>Pei, Jianfeng</dc:creator>
 <dc:creator>Lai, Luhua</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  For quantitative structure-property relationship (QSPR) studies in
chemoinformatics, it is important to get interpretable relationship between
chemical properties and chemical features. However, the predictive power and
interpretability of QSPR models are usually two different objectives that are
difficult to achieve simultaneously. A deep learning architecture using
molecular graph encoding convolutional neural networks (MGE-CNN) provided a
universal strategy to construct interpretable QSPR models with high predictive
power. Instead of using application-specific preset molecular descriptors or
fingerprints, the models can be resolved using raw and pertinent features
without manual intervention or selection. In this study, we developed acute
oral toxicity (AOT) models of compounds using the MGE-CNN architecture as a
case study. Three types of high-level predictive models: regression model
(deepAOT-R), multi-classification model (deepAOT-C) and multi-task model
(deepAOT-CR) for AOT evaluation were constructed. These models highly
outperformed previously reported models. For the two external datasets
containing 1673 (test set I) and 375 (test set II) compounds, the R2 and mean
absolute error (MAE) of deepAOT-R on the test set I were 0.864 and 0.195, and
the prediction accuracy of deepAOT-C was 95.5% and 96.3% on the test set I and
II, respectively. The two external prediction accuracy of deepAOT-CR is 95.0%
and 94.1%, while the R2 and MAE are 0.861 and 0.204 for test set I,
respectively.
</dc:description>
 <dc:description>Comment: 36 pages, 4 figures</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:date>2017-05-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04719</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FML-based Prediction Agent and Its Application to Game of Go</dc:title>
 <dc:creator>Lee, Chang-Shing</dc:creator>
 <dc:creator>Wang, Mei-Hui</dc:creator>
 <dc:creator>Kao, Chia-Hsiu</dc:creator>
 <dc:creator>Yang, Sheng-Chi</dc:creator>
 <dc:creator>Nojima, Yusuke</dc:creator>
 <dc:creator>Saga, Ryosuke</dc:creator>
 <dc:creator>Shuo, Nan</dc:creator>
 <dc:creator>Kubota, Naoyuki</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper, we present a robotic prediction agent including a darkforest
Go engine, a fuzzy markup language (FML) assessment engine, an FML-based
decision support engine, and a robot engine for game of Go application. The
knowledge base and rule base of FML assessment engine are constructed by
referring the information from the darkforest Go engine located in NUTN and
OPU, for example, the number of MCTS simulations and winning rate prediction.
The proposed robotic prediction agent first retrieves the database of Go
competition website, and then the FML assessment engine infers the winning
possibility based on the information generated by darkforest Go engine. The
FML-based decision support engine computes the winning possibility based on the
partial game situation inferred by FML assessment engine. Finally, the robot
engine combines with the human-friendly robot partner PALRO, produced by
Fujisoft incorporated, to report the game situation to human Go players.
Experimental results show that the FML-based prediction agent can work
effectively.
</dc:description>
 <dc:description>Comment: 6 pages, 12 figures, Joint 17th World Congress of International Fuzzy
  Systems Association and 9th International Conference on Soft Computing and
  Intelligent Systems (IFSA-SCIS 2017), Otsu, Japan, Jun. 27-30, 2017</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04719</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04720</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Norm Change: An Evolutionary Game-Theoretic Approach
  (Extended Version)</dc:title>
 <dc:creator>De, Soham</dc:creator>
 <dc:creator>Nau, Dana S.</dc:creator>
 <dc:creator>Gelfand, Michele J.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Human societies around the world interact with each other by developing and
maintaining social norms, and it is critically important to understand how such
norms emerge and change. In this work, we define an evolutionary game-theoretic
model to study how norms change in a society, based on the idea that different
strength of norms in societies translate to different game-theoretic
interaction structures and incentives. We use this model to study, both
analytically and with extensive agent-based simulations, the evolutionary
relationships of the need for coordination in a society (which is related to
its norm strength) with two key aspects of norm change: cultural inertia
(whether or how quickly the population responds when faced with conditions that
make a norm change desirable), and exploration rate (the willingness of agents
to try out new strategies). Our results show that a high need for coordination
leads to both high cultural inertia and a low exploration rate, while a low
need for coordination leads to low cultural inertia and high exploration rate.
This is the first work, to our knowledge, on understanding the evolutionary
causal relationships among these factors.
</dc:description>
 <dc:description>Comment: In 2017 International Conference on Autonomous Agents &amp; Multiagent
  Systems (AAMAS)</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04720</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04722</identifier>
 <datestamp>2017-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounded Distributed Flocking Control of Nonholonomic Mobile Robots</dc:title>
 <dc:creator>Nguyen, Thang</dc:creator>
 <dc:creator>La, Hung</dc:creator>
 <dc:creator>Azimi, Vahid</dc:creator>
 <dc:creator>Han, Thanh-Trung</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  There have been numerous studies on the problem of flocking control for
multiagent systems whose simplified models are presented in terms of point-mass
elements. Meanwhile, full dynamic models pose some challenging problems in
addressing the flocking control problem of mobile robots due to their
nonholonomic dynamic properties. Taking practical constraints into
consideration, we propose a novel approach to distributed flocking control of
nonholonomic mobile robots by bounded feedback. The flocking control objectives
consist of velocity consensus, collision avoidance, and cohesion maintenance
among mobile robots. A flocking control protocol which is based on the
information of neighbor mobile robots is constructed. The theoretical analysis
is conducted with the help of a Lyapunov-like function and graph theory.
Simulation results are shown to demonstrate the efficacy of the proposed
distributed flocking control scheme.
</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:date>2017-05-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04722</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04723</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Models for Attitude and Actions Prediction</dc:title>
 <dc:creator>Mahmud, Jalal</dc:creator>
 <dc:creator>Fei, Geli</dc:creator>
 <dc:creator>Xu, Anbang</dc:creator>
 <dc:creator>Pal, Aditya</dc:creator>
 <dc:creator>Zhou, Michelle</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this paper, we present computational models to predict Twitter users'
attitude towards a specific brand through their personal and social
characteristics. We also predict their likelihood to take different actions
based on their attitudes. In order to operationalize our research on users'
attitude and actions, we collected ground-truth data through surveys of Twitter
users. We have conducted experiments using two real world datasets to validate
the effectiveness of our attitude and action prediction framework. Finally, we
show how our models can be integrated with a visual analytics system for
customer intervention.
</dc:description>
 <dc:description>Comment: This is an extended version of a previously published IUI 2016 paper
  from same authors. http://dl.acm.org/citation.cfm?id=2856800</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04723</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04725</identifier>
 <datestamp>2017-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Angle-Domain Doppler Pre-Compensation for High-Mobility OFDM Uplink with
  a Massive ULA</dc:title>
 <dc:creator>Guo, Wei</dc:creator>
 <dc:creator>Zhang, Weile</dc:creator>
 <dc:creator>Mu, Pengcheng</dc:creator>
 <dc:creator>Gao, Feifei</dc:creator>
 <dc:creator>Yao, Bobin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose a Doppler pre-compensation scheme for high-mobility
orthogonal frequency division multiplexing (OFDM) uplink, where a high-speed
terminal transmits signals to the base station (BS). Considering that the
time-varying multipath channel consists of multiple Doppler frequency offsets
(DFOs) with different angle of departures (AoDs), we propose to perform DFO
pre-compensation at the transmitter with a large-scale uniform linear array
(ULA). The transmitted signal passes through a beamforming network with
high-spatial resolution to produce multiple parallel branches. Each branch
transmits signal towards one direction thus it is affected by one dominant DFO
when passing over the time-varying channel. Therefore, we can compensate the
DFO for each branch at the transmitter previously. Theoretical analysis for the
Doppler spread of the equivalent uplink channel is also conducted. It is found
that when the number of transmit antennas is sufficiently large, the
time-variation of channel can be efficiently suppressed. Therefore, the
performance will not degrade significantly if applying the conventional
time-invariant channel estimation and equalization methods at the receiver.
Simulation results are provided to verify the proposed scheme.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1701.03221</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04725</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04738</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SilkMoth: An Efficient Method for Finding Related Sets with Maximum
  Matching Constraints</dc:title>
 <dc:creator>Deng, Dong</dc:creator>
 <dc:creator>Kim, Albert</dc:creator>
 <dc:creator>Madden, Samuel</dc:creator>
 <dc:creator>Stonebraker, Michael</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Determining if two sets are related - that is, if they have similar values or
if one set contains the other - is an important problem with many applications
in data cleaning, data integration, and information retrieval. A particularly
popular metric that has been proposed is to measure the relatedness of two sets
by treating the elements as vertices of a bipartite graph and calculating the
score of the maximum matching pairing between elements. Compared to other
metrics which require exact matchings between elements, this metric uses a
similarity function to compare elements between the two sets, making it robust
to small dissimilarities in elements and more useful for real-world, dirty
data. Unfortunately, the metric suffers from expensive computational cost,
taking O(n^3) time, where n is the number of elements in sets, for each
set-to-set comparison. Thus for applications which try to search for all
pairings of related sets in a brute-force manner, the runtime becomes
unacceptably large.
  To address this challenge, we developed SilkMoth, a system capable of rapidly
discovering related set pairs in collections of sets. Internally, SilkMoth
creates a signature for each set, with the property that any other set which is
related must match the signature. SilkMoth then uses these signatures to prune
the search space, so only sets which match the signatures are left as
candidates. Finally, SilkMoth applies the maximum matching metric on remaining
candidates to verify which of these candidates are truly related sets. Thus, a
contribution of this paper is the characterization of the space of signatures
which enable this property. We show that selecting the optimal signature in
this space is NP-complete, and based on insights from the characterization of
the space, we propose two novel filters which help to prune the candidates
further before verification.
</dc:description>
 <dc:description>Comment: VLDB 2017</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04738</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04739</identifier>
 <datestamp>2017-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The network structure of visited locations according to geotagged social
  media photos</dc:title>
 <dc:creator>Junker, Christian</dc:creator>
 <dc:creator>Akbar, Zaenal</dc:creator>
 <dc:creator>Cuquet, Mart&#xed;</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Businesses, tourism attractions, public transportation hubs and other points
of interest are not isolated but part of a collaborative system. Making such
collaborative network surface is not always an easy task. The existence of
data-rich environments can assist in the reconstruction of collaborative
networks. They shed light into how their members operate and reveal a potential
for value creation via collaborative approaches. Social media data are an
example of a means to accomplish this task. In this paper, we reconstruct a
network of tourist locations using fine-grained data from Flickr, an online
community for photo sharing. We have used a publicly available set of Flickr
data provided by Yahoo! Labs. To analyse the complex structure of tourism
systems, we have reconstructed a network of visited locations in Europe,
resulting in around 180,000 vertices and over 32 million edges. An analysis of
the resulting network properties reveals its complex structure.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04739</dc:identifier>
 <dc:identifier>PRO-VE 2017: Collaboration in a Data-Rich World, pp. 276-283
  (2017)</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-65151-4_26</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04743</identifier>
 <datestamp>2017-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards String-to-Tree Neural Machine Translation</dc:title>
 <dc:creator>Aharoni, Roee</dc:creator>
 <dc:creator>Goldberg, Yoav</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a simple method to incorporate syntactic information about the
target language in a neural machine translation system by translating into
linearized, lexicalized constituency trees. An experiment on the WMT16
German-English news translation task resulted in an improved BLEU score when
compared to a syntax-agnostic NMT baseline trained on the same dataset. An
analysis of the translations from the syntax-aware system shows that it
performs more reordering during translation in comparison to the baseline. A
small-scale human evaluation also showed an advantage to the syntax-aware
system.
</dc:description>
 <dc:description>Comment: Accepted as a short paper in ACL 2017</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:date>2017-05-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04743</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04747</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dependent Cartesian Closed Categories</dc:title>
 <dc:creator>Yamada, Norihiro</dc:creator>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We present a generalization of cartesian closed categories (CCCs) for
dependent types, called dependent cartesian closed categories (DCCCs), which
also provides a reformulation of categories with families (CwFs), an abstract
semantics for Martin-L\&quot;{o}f type theory (MLTT) which is very close to the
syntax. Thus, DCCCs accomplish mathematical elegance as well as a direct
interpretation of the syntax. Moreover, they capture the categorical
counterpart of the generalization of the simply-typed lambda-calculus (STLC) to
MLTT in syntax, and give a systematic perspective on the relation between
categorical semantics for these type theories. Furthermore, we construct a term
model from the syntax, establishing the completeness of our interpretation of
MLTT in DCCCs.
</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04747</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04749</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AnchorNet: A Weakly Supervised Network to Learn Geometry-sensitive
  Features For Semantic Matching</dc:title>
 <dc:creator>Novotny, David</dc:creator>
 <dc:creator>Larlus, Diane</dc:creator>
 <dc:creator>Vedaldi, Andrea</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Despite significant progress of deep learning in recent years,
state-of-the-art semantic matching methods still rely on legacy features such
as SIFT or HoG. We argue that the strong invariance properties that are key to
the success of recent deep architectures on the classification task make them
unfit for dense correspondence tasks, unless a large amount of supervision is
used. In this work, we propose a deep network, termed AnchorNet, that produces
image representations that are well-suited for semantic matching. It relies on
a set of filters whose response is geometrically consistent across different
object instances, even in the presence of strong intra-class, scale, or
viewpoint variations. Trained only with weak image-level labels, the final
representation successfully captures information about the object structure and
improves results of state-of-the-art semantic matching methods such as the
deformable spatial pyramid or the proposal flow methods. We show positive
results on the cross-instance matching task where different instances of the
same object category are matched as well as on a new cross-category semantic
matching task aligning pairs of instances each from a different object class.
</dc:description>
 <dc:description>Comment: Proceedings of the IEEE Conference on Computer Vision and Pattern
  Recognition. 2017</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04749</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04759</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Component-Based Simplex Architecture for High-Assurance Cyber-Physical
  Systems</dc:title>
 <dc:creator>Phan, Dung</dc:creator>
 <dc:creator>Yang, Junxing</dc:creator>
 <dc:creator>Clark, Matthew</dc:creator>
 <dc:creator>Grosu, Radu</dc:creator>
 <dc:creator>Schierman, John D.</dc:creator>
 <dc:creator>Smolka, Scott A.</dc:creator>
 <dc:creator>Stoller, Scott D.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We present Component-Based Simplex Architecture (CBSA), a new framework for
assuring the runtime safety of component-based cyber-physical systems (CPSs).
CBSA integrates Assume-Guarantee (A-G) reasoning with the core principles of
the Simplex control architecture to allow component-based CPSs to run advanced,
uncertified controllers while still providing runtime assurance that A-G
contracts and global properties are satisfied. In CBSA, multiple Simplex
instances, which can be composed in a nested, serial or parallel manner,
coordinate to assure system-wide properties. Combining A-G reasoning and the
Simplex architecture is a challenging problem that yields significant benefits.
By utilizing A-G contracts, we are able to compositionally determine the
switching logic for CBSAs, thereby alleviating the state explosion encountered
by other approaches. Another benefit is that we can use A-G proof rules to
decompose the proof of system-wide safety assurance into sub-proofs
corresponding to the component-based structure of the system architecture. We
also introduce the notion of coordinated switching between Simplex instances, a
key component of our compositional approach to reasoning about CBSA switching
logic. We illustrate our framework with a component-based control system for a
ground rover. We formally prove that the CBSA for this system guarantees energy
safety (the rover never runs out of power), and collision freedom (the rover
never collides with a stationary obstacle). We also consider a CBSA for the
rover that guarantees mission completion: all target destinations visited
within a prescribed amount of time.
</dc:description>
 <dc:description>Comment: Extended version of a paper to be presented at ACSD 2017, 12 pages, 3
  figures, 1 appendix</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04759</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04760</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>In-Datacenter Performance Analysis of a Tensor Processing Unit</dc:title>
 <dc:creator>Jouppi, Norman P.</dc:creator>
 <dc:creator>Young, Cliff</dc:creator>
 <dc:creator>Patil, Nishant</dc:creator>
 <dc:creator>Patterson, David</dc:creator>
 <dc:creator>Agrawal, Gaurav</dc:creator>
 <dc:creator>Bajwa, Raminder</dc:creator>
 <dc:creator>Bates, Sarah</dc:creator>
 <dc:creator>Bhatia, Suresh</dc:creator>
 <dc:creator>Boden, Nan</dc:creator>
 <dc:creator>Borchers, Al</dc:creator>
 <dc:creator>Boyle, Rick</dc:creator>
 <dc:creator>Cantin, Pierre-luc</dc:creator>
 <dc:creator>Chao, Clifford</dc:creator>
 <dc:creator>Clark, Chris</dc:creator>
 <dc:creator>Coriell, Jeremy</dc:creator>
 <dc:creator>Daley, Mike</dc:creator>
 <dc:creator>Dau, Matt</dc:creator>
 <dc:creator>Dean, Jeffrey</dc:creator>
 <dc:creator>Gelb, Ben</dc:creator>
 <dc:creator>Ghaemmaghami, Tara Vazir</dc:creator>
 <dc:creator>Gottipati, Rajendra</dc:creator>
 <dc:creator>Gulland, William</dc:creator>
 <dc:creator>Hagmann, Robert</dc:creator>
 <dc:creator>Ho, C. Richard</dc:creator>
 <dc:creator>Hogberg, Doug</dc:creator>
 <dc:creator>Hu, John</dc:creator>
 <dc:creator>Hundt, Robert</dc:creator>
 <dc:creator>Hurt, Dan</dc:creator>
 <dc:creator>Ibarz, Julian</dc:creator>
 <dc:creator>Jaffey, Aaron</dc:creator>
 <dc:creator>Jaworski, Alek</dc:creator>
 <dc:creator>Kaplan, Alexander</dc:creator>
 <dc:creator>Khaitan, Harshit</dc:creator>
 <dc:creator>Koch, Andy</dc:creator>
 <dc:creator>Kumar, Naveen</dc:creator>
 <dc:creator>Lacy, Steve</dc:creator>
 <dc:creator>Laudon, James</dc:creator>
 <dc:creator>Law, James</dc:creator>
 <dc:creator>Le, Diemthu</dc:creator>
 <dc:creator>Leary, Chris</dc:creator>
 <dc:creator>Liu, Zhuyuan</dc:creator>
 <dc:creator>Lucke, Kyle</dc:creator>
 <dc:creator>Lundin, Alan</dc:creator>
 <dc:creator>MacKean, Gordon</dc:creator>
 <dc:creator>Maggiore, Adriana</dc:creator>
 <dc:creator>Mahony, Maire</dc:creator>
 <dc:creator>Miller, Kieran</dc:creator>
 <dc:creator>Nagarajan, Rahul</dc:creator>
 <dc:creator>Narayanaswami, Ravi</dc:creator>
 <dc:creator>Ni, Ray</dc:creator>
 <dc:creator>Nix, Kathy</dc:creator>
 <dc:creator>Norrie, Thomas</dc:creator>
 <dc:creator>Omernick, Mark</dc:creator>
 <dc:creator>Penukonda, Narayana</dc:creator>
 <dc:creator>Phelps, Andy</dc:creator>
 <dc:creator>Ross, Jonathan</dc:creator>
 <dc:creator>Ross, Matt</dc:creator>
 <dc:creator>Salek, Amir</dc:creator>
 <dc:creator>Samadiani, Emad</dc:creator>
 <dc:creator>Severn, Chris</dc:creator>
 <dc:creator>Sizikov, Gregory</dc:creator>
 <dc:creator>Snelham, Matthew</dc:creator>
 <dc:creator>Souter, Jed</dc:creator>
 <dc:creator>Steinberg, Dan</dc:creator>
 <dc:creator>Swing, Andy</dc:creator>
 <dc:creator>Tan, Mercedes</dc:creator>
 <dc:creator>Thorson, Gregory</dc:creator>
 <dc:creator>Tian, Bo</dc:creator>
 <dc:creator>Toma, Horia</dc:creator>
 <dc:creator>Tuttle, Erick</dc:creator>
 <dc:creator>Vasudevan, Vijay</dc:creator>
 <dc:creator>Walter, Richard</dc:creator>
 <dc:creator>Wang, Walter</dc:creator>
 <dc:creator>Wilcox, Eric</dc:creator>
 <dc:creator>Yoon, Doe Hyun</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Many architects believe that major improvements in cost-energy-performance
must now come from domain-specific hardware. This paper evaluates a custom
ASIC---called a Tensor Processing Unit (TPU)---deployed in datacenters since
2015 that accelerates the inference phase of neural networks (NN). The heart of
the TPU is a 65,536 8-bit MAC matrix multiply unit that offers a peak
throughput of 92 TeraOps/second (TOPS) and a large (28 MiB) software-managed
on-chip memory. The TPU's deterministic execution model is a better match to
the 99th-percentile response-time requirement of our NN applications than are
the time-varying optimizations of CPUs and GPUs (caches, out-of-order
execution, multithreading, multiprocessing, prefetching, ...) that help average
throughput more than guaranteed latency. The lack of such features helps
explain why, despite having myriad MACs and a big memory, the TPU is relatively
small and low power. We compare the TPU to a server-class Intel Haswell CPU and
an Nvidia K80 GPU, which are contemporaries deployed in the same datacenters.
Our workload, written in the high-level TensorFlow framework, uses production
NN applications (MLPs, CNNs, and LSTMs) that represent 95% of our datacenters'
NN inference demand. Despite low utilization for some applications, the TPU is
on average about 15X - 30X faster than its contemporary GPU or CPU, with
TOPS/Watt about 30X - 80X higher. Moreover, using the GPU's GDDR5 memory in the
TPU would triple achieved TOPS and raise TOPS/Watt to nearly 70X the GPU and
200X the CPU.
</dc:description>
 <dc:description>Comment: 17 pages, 11 figures, 8 tables. To appear at the 44th International
  Symposium on Computer Architecture (ISCA), Toronto, Canada, June 24-28, 2017</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04760</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04761</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Effective Bug Triage with Towards Effective Bug Triage with
  Software Data Reduction Techniques</dc:title>
 <dc:creator>Xuan, Jifeng</dc:creator>
 <dc:creator>Jiang, He</dc:creator>
 <dc:creator>Hu, Yan</dc:creator>
 <dc:creator>Ren, Zhilei</dc:creator>
 <dc:creator>Zou, Weiqin</dc:creator>
 <dc:creator>Luo, Zhongxuan</dc:creator>
 <dc:creator>Wu, Xindong</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Software companies spend over 45 percent of cost in dealing with software
bugs. An inevitable step of fixing bugs is bug triage, which aims to correctly
assign a developer to a new bug. To decrease the time cost in manual work, text
classification techniques are applied to conduct automatic bug triage. In this
paper, we address the problem of data reduction for bug triage, i.e., how to
reduce the scale and improve the quality of bug data. We combine instance
selection with feature selection to simultaneously reduce data scale on the bug
dimension and the word dimension. To determine the order of applying instance
selection and feature selection, we extract attributes from historical bug data
sets and build a predictive model for a new bug data set. We empirically
investigate the performance of data reduction on totally 600,000 bug reports of
two large open source projects, namely Eclipse and Mozilla. The results show
that our data reduction can effectively reduce the data scale and improve the
accuracy of bug triage. Our work provides an approach to leveraging techniques
on data processing to form reduced and high-quality bug data in software
development and maintenance.
</dc:description>
 <dc:description>Comment: 17 pages, 7 figures</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04761</dc:identifier>
 <dc:identifier>IEEE Transactions on Knowledge and Data Engineering, 2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04764</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Developer Prioritization in Bug Repositories</dc:title>
 <dc:creator>Xuan, Jifeng</dc:creator>
 <dc:creator>Jiang, He</dc:creator>
 <dc:creator>Ren, Zhilei</dc:creator>
 <dc:creator>Zou, Weiqin</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Developers build all the software artifacts in development. Existing work has
studied the social behavior in software repositories. In one of the most
important software repositories, a bug repository, developers create and update
bug reports to support software development and maintenance. However, no prior
work has considered the priorities of developers in bug repositories. In this
paper, we address the problem of the developer prioritization, which aims to
rank the contributions of developers. We mainly explore two aspects, namely
modeling the developer prioritization in a bug repository and assisting
predictive tasks with our model. First, we model how to assign the priorities
of developers based on a social network technique. Three problems are
investigated, including the developer rankings in products, the evolution over
time, and the tolerance of noisy comments. Second, we consider leveraging the
developer prioritization to improve three predicted tasks in bug repositories,
i.e., bug triage, severity identification, and reopened bug prediction. We
empirically investigate the performance of our model and its applications in
bug repositories of Eclipse and Mozilla. The results indicate that the
developer prioritization can provide the knowledge of developer priorities to
assist software tasks, especially the task of bug triage.
</dc:description>
 <dc:description>Comment: 11 pages, 8 figures, Proceedings of 34th International Conference on
  Software Engineering (ICSE 2012), 2012</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04764</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04766</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Debt-Prone Bugs: Technical Debt in Software Maintenance</dc:title>
 <dc:creator>Xuan, Jifeng</dc:creator>
 <dc:creator>Hu, Yan</dc:creator>
 <dc:creator>Jiang, He</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Fixing bugs is an important phase in software development and maintenance. In
practice, the process of bug fixing may conflict with the release schedule.
Such confliction leads to a trade-off between software quality and release
schedule, which is known as the technical debt metaphor. In this article, we
propose the concept of debt-prone bugs to model the technical debt in software
maintenance. We identify three types of debt-prone bugs, namely tag bugs,
reopened bugs, and duplicate bugs. A case study on Mozilla is conducted to
examine the impact of debt-prone bugs in software products. We investigate the
correlation between debt-prone bugs and the product quality. For a product
under development, we build prediction models based on historical products to
predict the time cost of fixing bugs. The result shows that identifying
debt-prone bugs can assist in monitoring and improving software quality.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures, International Journal of Advancements in
  Computing Technology, 2012</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04766</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04768</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving the Large Scale Next Release Problem with a Backbone Based
  Multilevel Algorithm</dc:title>
 <dc:creator>Xuan, Jifeng</dc:creator>
 <dc:creator>Jiang, He</dc:creator>
 <dc:creator>Ren, Zhilei</dc:creator>
 <dc:creator>Luo, Zhongxuan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The Next Release Problem (NRP) aims to optimize customer profits and
requirements selection for the software releases. The research on the NRP is
restricted by the growing scale of requirements. In this paper, we propose a
Backbone based Multilevel Algorithm (BMA) to address the large scale NRP. In
contrast to direct solving approaches, BMA employs multilevel reductions to
downgrade the problem scale and multilevel refinements to construct the final
optimal set of customers. In both reductions and refinements, the backbone is
built to fix the common part of the optimal customers. Since it is intractable
to extract the backbone in practice, the approximate backbone is employed for
the instance reduction while the soft backbone is proposed to augment the
backbone application. In the experiments, to cope with the lack of open large
requirements databases, we propose a method to extract instances from open bug
repositories. Experimental results on 15 classic instances and 24 realistic
instances demonstrate that BMA can achieve better solutions on the large scale
NRP instances than direct solving approaches. Our work provides a reduction
approach for solving large scale problems in search based requirements
engineering.
</dc:description>
 <dc:description>Comment: 18 pages, 7 figures</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04768</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04769</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Bug Triage using Semi-Supervised Text Classification</dc:title>
 <dc:creator>Xuan, Jifeng</dc:creator>
 <dc:creator>Jiang, He</dc:creator>
 <dc:creator>Ren, Zhilei</dc:creator>
 <dc:creator>Yan, Jun</dc:creator>
 <dc:creator>Luo, Zhongxuan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In this paper, we propose a semi-supervised text classification approach for
bug triage to avoid the deficiency of labeled bug reports in existing
supervised approaches. This new approach combines naive Bayes classifier and
expectation-maximization to take advantage of both labeled and unlabeled bug
reports. This approach trains a classifier with a fraction of labeled bug
reports. Then the approach iteratively labels numerous unlabeled bug reports
and trains a new classifier with labels of all the bug reports. We also employ
a weighted recommendation list to boost the performance by imposing the weights
of multiple developers in training the classifier. Experimental results on bug
reports of Eclipse show that our new approach outperforms existing supervised
approaches in terms of classification accuracy.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure, Proceedings of 22nd International Conference on
  Software Engineering and Knowledge Engineering (SEKE 2010), 2010</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04769</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04772</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Random Walk Based Algorithm for Structural Test Case Generation</dc:title>
 <dc:creator>Xuan, Jifeng</dc:creator>
 <dc:creator>Jiang, He</dc:creator>
 <dc:creator>Ren, Zhilei</dc:creator>
 <dc:creator>Hu, Yan</dc:creator>
 <dc:creator>Luo, Zhongxuan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Structural testing is a significant and expensive process in software
development. By converting test data generation into an optimization problem,
search-based software testing is one of the key technologies of automated test
case generation. Motivated by the success of random walk in solving the
satisfiability problem (SAT), we proposed a random walk based algorithm
(WalkTest) to solve structural test case generation problem. WalkTest provides
a framework, which iteratively calls random walk operator to search the optimal
solutions. In order to improve search efficiency, we sorted the test goals with
the costs of solutions completely instead of traditional dependence analysis
from control flow graph. Experimental results on the condition-decision
coverage demonstrated that WalkTest achieves better performance than existing
algorithms (random test and tabu search) in terms of running time and coverage
rate.
</dc:description>
 <dc:description>Comment: 6 pages, 3 pages, Proceedings of 2nd International Conference on
  Software Engineering and Data Mining (SEDM 2010), 2010</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04772</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04773</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate Backbone Based Multilevel Algorithm for Next Release Problem</dc:title>
 <dc:creator>Jiang, He</dc:creator>
 <dc:creator>Xuan, Jifeng</dc:creator>
 <dc:creator>Ren, Zhilei</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The next release problem (NRP) aims to effectively select software
requirements in order to acquire maximum customer profits. As an NP-hard
problem in software requirement engineering, NRP lacks efficient approximate
algorithms for large scale instances. The backbone is a new tool for tackling
large scale NP-hard problems in recent years. In this paper, we employ the
backbone to design high performance approximate algorithms for large scale NRP
instances. Firstly we show that it is NP-hard to obtain the backbone of NRP.
Then, we illustrate by fitness landscape analysis that the backbone can be well
approximated by the shared common parts of local optimal solutions. Therefore,
we propose an approximate backbone based multilevel algorithm (ABMA) to solve
large scale NRP instances. This algorithm iteratively explores the search
spaces by multilevel reductions and refinements. Experimental results
demonstrate that ABMA outperforms existing algorithms on large instances in
terms of solution quality and running time.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures, Proceedings of 12th Annual Conference on Genetic
  and Evolutionary Computation. (GECCO 2010), 2010</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04773</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04775</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximating the Backbone in the Weighted Maximum Satisfiability
  Problem</dc:title>
 <dc:creator>Jiang, He</dc:creator>
 <dc:creator>Xuan, Jifeng</dc:creator>
 <dc:creator>Hu, Yan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The weighted Maximum Satisfiability problem (weighted MAX-SAT) is a NP-hard
problem with numerous applications arising in artificial intelligence. As an
efficient tool for heuristic design, the backbone has been applied to
heuristics design for many NP-hard problems. In this paper, we investigated the
computational complexity for retrieving the backbone in weighted MAX-SAT and
developed a new algorithm for solving this problem. We showed that it is
intractable to retrieve the full backbone under the assumption that . Moreover,
it is intractable to retrieve a fixed fraction of the backbone as well. And
then we presented a backbone guided local search (BGLS) with Walksat operator
for weighted MAX-SAT. BGLS consists of two phases: the first phase samples the
backbone information from local optima and the backbone phase conducts local
search under the guideline of backbone. Extensive experimental results on the
benchmark showed that BGLS outperforms the existing heuristics in both solution
quality and runtime.
</dc:description>
 <dc:description>Comment: 14 pages, 1 figure, Proceedings of Advances in Knowledge Discovery
  and Data Mining 2008 (PAKDD 2008), 2008</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04775</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04777</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Hybrid ACO Algorithm for the Next Release Problem</dc:title>
 <dc:creator>Jiang, He</dc:creator>
 <dc:creator>Zhang, Jingyuan</dc:creator>
 <dc:creator>Xuan, Jifeng</dc:creator>
 <dc:creator>Ren, Zhilei</dc:creator>
 <dc:creator>Hu, Yan</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this paper, we propose a Hybrid Ant Colony Optimization algorithm (HACO)
for Next Release Problem (NRP). NRP, a NP-hard problem in requirement
engineering, is to balance customer requests, resource constraints, and
requirement dependencies by requirement selection. Inspired by the successes of
Ant Colony Optimization algorithms (ACO) for solving NP-hard problems, we
design our HACO to approximately solve NRP. Similar to traditional ACO
algorithms, multiple artificial ants are employed to construct new solutions.
During the solution construction phase, both pheromone trails and neighborhood
information will be taken to determine the choices of every ant. In addition, a
local search (first found hill climbing) is incorporated into HACO to improve
the solution quality. Extensively wide experiments on typical NRP test
instances show that HACO outperforms the existing algorithms (GRASP and
simulated annealing) in terms of both solution uality and running time.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures, Proceedings of 2nd International Conference on
  Software Engineering and Data Mining (SEDM 2010), 2010</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04777</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04782</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Security Monitoring Framework For Virtualization Based HEP
  Infrastructures</dc:title>
 <dc:creator>Ramirez, A. Gomez</dc:creator>
 <dc:creator>Pedreira, M. Martinez</dc:creator>
 <dc:creator>Grigoras, C.</dc:creator>
 <dc:creator>Betev, L.</dc:creator>
 <dc:creator>Lara, C.</dc:creator>
 <dc:creator>Collaboration, U. Kebschull for the ALICE</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>High Energy Physics - Experiment</dc:subject>
 <dc:description>  High Energy Physics (HEP) distributed computing infrastructures require
automatic tools to monitor, analyze and react to potential security incidents.
These tools should collect and inspect data such as resource consumption, logs
and sequence of system calls for detecting anomalies that indicate the presence
of a malicious agent. They should also be able to perform automated reactions
to attacks without administrator intervention. We describe a novel framework
that accomplishes these requirements, with a proof of concept implementation
for the ALICE experiment at CERN. We show how we achieve a fully virtualized
environment that improves the security by isolating services and Jobs without a
significant performance impact. We also describe a collected dataset for
Machine Learning based Intrusion Prevention and Detection Systems on Grid
computing. This dataset is composed of resource consumption measurements (such
as CPU, RAM and network traffic), logfiles from operating system services, and
system call data collected from production Jobs running in an ALICE Grid test
site and a big set of malware. This malware was collected from security
research sites. Based on this dataset, we will proceed to develop Machine
Learning algorithms able to detect malicious Jobs.
</dc:description>
 <dc:description>Comment: Proceedings of the 22nd International Conference on Computing in High
  Energy and Nuclear Physics, CHEP 2016, 10-14 October 2016, San Francisco.
  Submitted to Journal of Physics: Conference Series (JPCS)</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04782</dc:identifier>
 <dc:identifier>doi:10.1088/1742-6596/898/10/102004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04785</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Cryptographic Substitution Box Design Using Travelling
  Salesman Problem and Chaos</dc:title>
 <dc:creator>Ahmad, Musheer</dc:creator>
 <dc:creator>Mittal, Nikhil</dc:creator>
 <dc:creator>Garg, Prerit</dc:creator>
 <dc:creator>Khan, Manaff Mahtab</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Symmetric encryption has been a standout amongst the most reliable option by
which security is accomplished. In modern block symmetric ciphers, the
substitution-boxes have been playing a critical role of nonlinear components
that drives the actual security of ciphers. In this paper, the travelling
salesman problem and piecewise linear chaotic map are explored to synthesize an
efficient configuration of 8x8 substitution-box. The proposed anticipated
design has the consistency which is justified by the standard performance
indexes. The statistical results manifest that the prospective substitution-box
is cryptographically more impressive as compared to some recent investigations.
</dc:description>
 <dc:description>Comment: 06 pages</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04785</dc:identifier>
 <dc:identifier>Perspectives in Science 8 2016</dc:identifier>
 <dc:identifier>doi:10.1016/j.pisc.2016.06.001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04789</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy Efficient Adaptive Network Coding Schemes for Satellite
  Communications</dc:title>
 <dc:creator>Gharsellaoui, Ala Eddine</dc:creator>
 <dc:creator>Ghanem, Samah A. M.</dc:creator>
 <dc:creator>Tarchi, Daniele</dc:creator>
 <dc:creator>Coralli, Alessandro Vanelli</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose novel energy efficient adaptive network coding and
modulation schemes for time variant channels. We evaluate such schemes under a
realistic channel model for open area environments and Geostationary Earth
Orbit (GEO) satellites. Compared to non-adaptive network coding and adaptive
rate efficient network-coded schemes for time variant channels, we show that
our proposed schemes, through physical layer awareness can be designed to
transmit only if a target quality of service (QoS) is achieved. As a result,
such schemes can provide remarkable energy savings.
</dc:description>
 <dc:description>Comment: Lecture Notes of the Institute for Computer Sciences, Social
  Informatics and Telecommunications Engineering, 24 March 2017</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04789</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-53850-1_20</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04790</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network Coding Channel Virtualization Schemes for Satellite Multicast
  Communications</dc:title>
 <dc:creator>Ghanem, Samah A. M.</dc:creator>
 <dc:creator>Gharsellaoui, Ala Eddine</dc:creator>
 <dc:creator>Tarchi, Daniele</dc:creator>
 <dc:creator>Vanelli-Coralli, Alessandro</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose two novel schemes to solve the problem of finding a
quasi-optimal number of coded packets to multicast to a set of independent
wireless receivers suffering different channel conditions. In particular, we
propose two network channel virtualization schemes that allow for representing
the set of intended receivers in a multicast group to be virtualized as one
receiver. Such approach allows for a transmission scheme not only adapted to
per-receiver channel variation over time, but to the network-virtualized
channel representing all receivers in the multicast group. The first scheme
capitalizes on a maximum erasure criterion introduced via the creation of a
virtual worst per receiver per slot reference channel of the network. The
second scheme capitalizes on a maximum completion time criterion by the use of
the worst performing receiver channel as a virtual reference to the network. We
apply such schemes to a GEO satellite scenario. We demonstrate the benefits of
the proposed schemes comparing them to a per-receiver point-to-point adaptive
strategy.
</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04790</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04792</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Locating Power Flow Solution Space Boundaries: A Numerical Polynomial
  Homotopy Approach</dc:title>
 <dc:creator>Chandra, Souvik</dc:creator>
 <dc:creator>Mehta, Dhagash</dc:creator>
 <dc:creator>Chakrabortty, Aranya</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:description>  The solution space of any set of power flow equations may contain different
number of real-valued solutions. The boundaries that separate these regions are
referred to as power flow solution space boundaries. Knowledge of these
boundaries is important as they provide a measure for voltage stability.
Traditionally, continuation based methods have been employed to compute these
boundaries on the basis of initial guesses for the solution. However, with
rapid growth of renewable energy sources these boundaries will be increasingly
affected by variable parameters such as penetration levels, locations of the
renewable sources, and voltage set-points, making it difficult to generate an
initial guess that can guarantee all feasible solutions for the power flow
problem. In this paper we solve this problem by applying a numerical polynomial
homotopy based continuation method. The proposed method guarantees to find all
solution boundaries within a given parameter space up to a chosen level of
discretization, independent of any initial guess. Power system operators can
use this computational tool conveniently to plan the penetration levels of
renewable sources at different buses. We illustrate the proposed method through
simulations on 3-bus and 10-bus power system examples with renewable
generation.
</dc:description>
 <dc:description>Comment: 9 pages, 5 figures</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04792</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04793</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Harvesting Multiple Views for Marker-less 3D Human Pose Annotations</dc:title>
 <dc:creator>Pavlakos, Georgios</dc:creator>
 <dc:creator>Zhou, Xiaowei</dc:creator>
 <dc:creator>Derpanis, Konstantinos G.</dc:creator>
 <dc:creator>Daniilidis, Kostas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent advances with Convolutional Networks (ConvNets) have shifted the
bottleneck for many computer vision tasks to annotated data collection. In this
paper, we present a geometry-driven approach to automatically collect
annotations for human pose prediction tasks. Starting from a generic ConvNet
for 2D human pose, and assuming a multi-view setup, we describe an automatic
way to collect accurate 3D human pose annotations. We capitalize on constraints
offered by the 3D geometry of the camera setup and the 3D structure of the
human body to probabilistically combine per view 2D ConvNet predictions into a
globally optimal 3D pose. This 3D pose is used as the basis for harvesting
annotations. The benefit of the annotations produced automatically with our
approach is demonstrated in two challenging settings: (i) fine-tuning a generic
ConvNet-based 2D pose predictor to capture the discriminative aspects of a
subject's appearance (i.e.,&quot;personalization&quot;), and (ii) training a ConvNet from
scratch for single view 3D human pose prediction without leveraging 3D pose
groundtruth. The proposed multi-view pose estimator achieves state-of-the-art
results on standard benchmarks, demonstrating the effectiveness of our method
in exploiting the available multi-view information.
</dc:description>
 <dc:description>Comment: CVPR 2017 Camera Ready</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04793</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04794</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Outward Influence and Cascade Size Estimation in Billion-scale Networks</dc:title>
 <dc:creator>Nguyen, Hung T.</dc:creator>
 <dc:creator>Nguyen, Tri P.</dc:creator>
 <dc:creator>Vu, Tam</dc:creator>
 <dc:creator>Dinh, Thang N.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Estimating cascade size and nodes' influence is a fundamental task in social,
technological, and biological networks. Yet this task is extremely challenging
due to the sheer size and the structural heterogeneity of networks. We
investigate a new influence measure, termed outward influence (OI), defined as
the (expected) number of nodes that a subset of nodes $S$ will activate,
excluding the nodes in S. Thus, OI equals, the de facto standard measure,
influence spread of S minus |S|. OI is not only more informative for nodes with
small influence, but also, critical in designing new effective sampling and
statistical estimation methods.
  Based on OI, we propose SIEA/SOIEA, novel methods to estimate influence
spread/outward influence at scale and with rigorous theoretical guarantees. The
proposed methods are built on two novel components 1) IICP an important
sampling method for outward influence, and 2) RSA, a robust mean estimation
method that minimize the number of samples through analyzing variance and range
of random variables. Compared to the state-of-the art for influence estimation,
SIEA is $\Omega(\log^4 n)$ times faster in theory and up to several orders of
magnitude faster in practice. For the first time, influence of nodes in the
networks of billions of edges can be estimated with high accuracy within a few
minutes. Our comprehensive experiments on real-world networks also give
evidence against the popular practice of using a fixed number, e.g. 10K or 20K,
of samples to compute the &quot;ground truth&quot; for influence spread.
</dc:description>
 <dc:description>Comment: 16 pages, SIGMETRICS 2017</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04794</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04795</identifier>
 <datestamp>2017-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Root Mean Square Error of Neural Spike Train Sequence Matching with
  Optogenetics</dc:title>
 <dc:creator>Noel, Adam</dc:creator>
 <dc:creator>Makrakis, Dimitrios</dc:creator>
 <dc:creator>Eckford, Andrew W.</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Physics - Biological Physics</dc:subject>
 <dc:description>  Optogenetics is an emerging field of neuroscience where neurons are
genetically modified to express light-sensitive receptors that enable external
control over when the neurons fire. Given the prominence of neuronal signaling
within the brain and throughout the body, optogenetics has significant
potential to improve the understanding of the nervous system and to develop
treatments for neurological diseases. This paper uses a simple optogenetic
model to compare the timing distortion between a randomly-generated target
spike sequence and an externally-stimulated neuron spike sequence. The
distortion is measured by filtering each sequence and finding the root mean
square error between the two filter outputs. The expected distortion is derived
in closed form when the target sequence generation rate is sufficiently low.
Derivations are verified via simulations.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures. Will be presented at IEEE Global Communications
  Conference (IEEE GLOBECOM 2017) in December 2017</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:date>2017-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04795</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04797</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Setting Up Pepper For Autonomous Navigation And Personalized Interaction
  With Users</dc:title>
 <dc:creator>Perera, Vittorio</dc:creator>
 <dc:creator>Pereira, Tiago</dc:creator>
 <dc:creator>Connell, Jonathan</dc:creator>
 <dc:creator>Veloso, Manuela</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this paper we present our work with the Pepper robot, a service robot from
SoftBank Robotics. We had two main goals in this work: improving the autonomy
of this robot by increasing its awareness of the environment; and enhance the
robot ability to interact with its users. To achieve this goals, we used ROS, a
modern open-source framework for developing robotics software, to provide
Pepper with state of the art localization and navigation capabilities.
Furthermore, we contribute an architecture for effective human interaction
based on cloud services. Our architecture improves Pepper speech recognition
capabilities by connecting it to the IBM Bluemix Speech Recognition service and
enable the robot to recognize its user via an in-house face recognition
web-service. We show examples of our successful integration of ROS and IBM
services with Pepper's own software. As a result, we were able to make Pepper
move autonomously in a environment with humans and obstacles. We were also able
to have Pepper execute spoken commands from known users as well as newly
introduced users that were enrolled in the robot list of trusted users via a
multi-modal interface.
</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04797</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04798</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uncovering Architectural Design Decisions</dc:title>
 <dc:creator>Shahbazian, Arman</dc:creator>
 <dc:creator>Lee, Youn Kyu</dc:creator>
 <dc:creator>Le, Duc</dc:creator>
 <dc:creator>Medvidovic, Nenad</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Over the past three decades, considerable effort has been devoted to the
study of software architecture. A major portion of this effort has focused on
the originally proposed view of four &quot;C&quot;s---components, connectors,
configurations, and constraints---that are the building blocks of a system's
architecture. Despite being simple and appealing, this view has proven to be
incomplete and has required further elaboration. To that end, researchers have
more recently tried to approach architectures from another important
perspective---that of design decisions that yield a system's architecture.
These more recent efforts have lacked a precise understanding of several key
questions, however: (1) What is an architectural design decision (definition)?
(2) How can architectural design decisions be found in existing systems
(identification)? (3) What system decisions are and are not architectural
(classification)? (4) How are architectural design decisions manifested in the
code (reification)? (5) How can important architectural decisions be preserved
and/or changed as desired (evolution)? This paper presents a technique targeted
at answering these questions by analyzing information that is readily available
about software systems. We applied our technique on over 100 different versions
of two widely adopted open- source systems, and found that it can accurately
uncover the architectural design decisions embodied in the systems.
</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04799</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random Walk Sampling for Big Data over Networks</dc:title>
 <dc:creator>Basirian, Saeed</dc:creator>
 <dc:creator>Jung, Alexander</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  It has been shown recently that graph signals with small total variation can
be accurately recovered from only few samples if the sampling set satisfies a
certain condition, referred to as the network nullspace property. Based on this
recovery condition, we propose a sampling strategy for smooth graph signals
based on random walks. Numerical experiments demonstrate the effectiveness of
this approach for graph signals obtained from a synthetic random graph model as
well as a real-world dataset.
</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04799</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04800</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-parametric Impedance based Stability and Controller Bandwidth
  Extraction from Impedance Measurements of HVDC-connected Wind Farms</dc:title>
 <dc:creator>Amin, Mohammad</dc:creator>
 <dc:creator>Molinas, Marta</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Impedance measurements have been widely used with the Nyquist plot to
estimate the stability of interconnected power systems. Being a black-box
method for equivalent and aggregated impedance estimation, its use for the
identification of sub-components bandwidth is not a straightforward task. This
paper proposes a simple method that will enable to identify the specific part
of the equivalent impedance (e.g. controller's bandwidth) that has major impact
on the stability of the system. For doing that, the paper analyses the
stability of an interconnected system of wind farms and high voltage dc (HVDC)
transmission system. The impedance frequency responses of the wind farms and
HVDC system from the ac collection point are measured and it is shown by the
method proposed in this paper, which controller has major impact in the
observed oscillation. A mitigation technique is proposed based on re-tuning of
the critical controller bandwidth of the interconnected converters. The method
suggested can reveal the internal controllers' dynamics of the wind farm from
the measured impedance combined with an analytical expression of the impedance
and a transfer function identity when no information about the controllers is
provided by the vendors due to confidentiality and industry secrecy.
</dc:description>
 <dc:description>Comment: This paper has been submitted to IEEE JESTPE for review on 28th
  January, 2017</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04802</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design and implementation of lighting control system using battery-less
  wireless human detection sensor networks</dc:title>
 <dc:creator>Yu, Tao</dc:creator>
 <dc:creator>Kuki, Yusuke</dc:creator>
 <dc:creator>Matsushita, Gento</dc:creator>
 <dc:creator>Maehara, Daiki</dc:creator>
 <dc:creator>Sampei, Seiichi</dc:creator>
 <dc:creator>Sakaguchi, Kei</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Artificial lighting is responsible for a large portion of total energy
consumption and has great potential for energy saving. This paper designs an
LED light control algorithm based on users' localization using multiple
battery-less binary human detection sensors. The proposed lighting control
system focuses on reducing office lighting energy consumption and satisfying
users' illumination requirement. Most current lighting control systems use
infrared human detection sensors, but the poor detection probability,
especially for a static user, makes it difficult to realize comfortable and
effective lighting control. To improve the detection probability of each
sensor, we proposed to locate sensors as close to each user as possible by
using a battery-less wireless sensor network, in which all sensors can be
placed freely in the space with high energy stability. We also proposed to use
a multi-sensor-based user localization algorithm to capture user's position
more accurately and realize fine lighting control which works even with static
users. The system is actually implemented in an indoor office environment in a
pilot project. A verification experiment is conducted by measuring the
practical illumination and power consumption. The performance agrees with
design expectations. It shows that the proposed LED lighting control system
reduces the energy consumption significantly, 57% compared to the batch control
scheme, and satisfies user's illumination requirement with 100% probability.
</dc:description>
 <dc:description>Comment: This paper is submitted to IEICE Transactions on Communications</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04802</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04805</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Replicator Equation: Applications Revisited</dc:title>
 <dc:creator>Dulecha, Tinsae G.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The replicator equation is a simple model of evolution that leads to stable
form of Nash Equilibrium, Evolutionary Stable Strategy (ESS). It has been
studied in connection with Evolutionary Game Theory and was originally
developed for symmetric games. Beyond its first emphasis in biological use,
evolutionary game theory has been expanded well beyond in social studies for
behavioral analysis, in machine learning, computer vision and others. Its
several applications in the fields of machine learning and computer vision has
drawn my attention which is the reason to write this extended abstract
</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04805</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04810</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Experimental Platform for In-Vessel Multi-Chemical Molecular
  Communications</dc:title>
 <dc:creator>Farsad, Nariman</dc:creator>
 <dc:creator>Pan, David</dc:creator>
 <dc:creator>Goldsmith, Andrea</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This work presents a new multi-chemical experimental platform for molecular
communication where the transmitter can release different chemicals. This
platform is designed to be inexpensive and accessible, and it can be expanded
to simulate different environments including the cardiovascular system and
complex network of pipes in industrial complexes and city infrastructures. To
demonstrate the capabilities of the platform, we implement a time-slotted
binary communication system where a bit-0 is represented by an acid pulse, a
bit-1 by a base pulse, and information is carried via pH signals. The channel
model for this system, which is nonlinear and has long memories, is unknown.
Therefore, we devise novel detection algorithms that use techniques from
machine learning and deep learning to train a maximum-likelihood detector.
Using these algorithms the bit error rate improves by an order of magnitude
relative to the approach used in previous works. Moreover, our system achieves
a data rate that is an order of magnitude higher than any of the previous
molecular communication platforms.
</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04810</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04813</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wireless Communication using Unmanned Aerial Vehicles (UAVs): Optimal
  Transport Theory for Hover Time Optimization</dc:title>
 <dc:creator>Mozaffari, Mohammad</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:creator>Bennis, Mehdi</dc:creator>
 <dc:creator>Debbah, Merouane</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, the effective use of flight-time constrained unmanned aerial
vehicles (UAVs) as flying base stations that can provide wireless service to
ground users is investigated. In particular, a novel framework for optimizing
the performance of such UAV-based wireless systems in terms of the average
number of bits (data service) transmitted to users as well as UAVs' hover
duration (i.e. flight time) is proposed. In the considered model, UAVs hover
over a given geographical area to serve ground users that are distributed
within the area based on an arbitrary spatial distribution function. In this
case, two practical scenarios are considered. In the first scenario, based on
the maximum possible hover times of UAVs, the average data service delivered to
the users under a fair resource allocation scheme is maximized by finding the
optimal cell partitions associated to the UAVs. Using the mathematical
framework of optimal transport theory, a gradient-based algorithm is proposed
for optimally partitioning the geographical area based on the users'
distribution, hover times, and locations of the UAVs. In the second scenario,
given the load requirements of ground users, the minimum average hover time
that the UAVs need for completely servicing their ground users is derived. To
this end, first, an optimal bandwidth allocation scheme for serving the users
is proposed. Then, given this optimal bandwidth allocation, the optimal cell
partitions associated with the UAVs are derived by exploiting the optimal
transport theory. Results show that our proposed cell partitioning approach
leads to a significantly higher fairness among the users compared to the
classical weighted Voronoi diagram. In addition, our results reveal an inherent
tradeoff between the hover time of UAVs and bandwidth efficiency while serving
the ground users.
</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04813</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04815</identifier>
 <datestamp>2017-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Transceiver Design for Bidirectional Full-Duplex MIMO OFDM
  Systems</dc:title>
 <dc:creator>Taghizadeh, Omid</dc:creator>
 <dc:creator>Radhakrishnan, Vimal</dc:creator>
 <dc:creator>Cirik, Ali Cagatay</dc:creator>
 <dc:creator>Mathar, Rudolf</dc:creator>
 <dc:creator>Lampe, Lutz</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we address the linear precoding and decoding design problem for
a bidirectional orthogonal frequencydivision multiplexing (OFDM) communication
system, between two multiple-input multiple-output (MIMO) full-duplex (FD)
nodes. The effects of hardware distortion, leading to the residual
self-interference and inter-carrier leakage, as well as the channel state
information (CSI) error are taken into account. In the first step, the
operation of an FD MIMO OFDM transceiver is modeled, relying on the results of
the available related system measurements. As a result, the explicit impact of
hardware inaccuracies on the residual self-interference and inter-carrier
leakage is formulated in relation to the intended transmit/received signal.
Afterwards, linear precoding and decoding designs are proposed to enhance the
system performance following minimummean- squared-error (MMSE) and sum rate
maximization strategies, assuming the availability of perfect or erroneous CSI.
The proposed designs are based on the application of alternating optimization
over the system parameters, leading to a necessary convergence. Numerical
results show that a significant gain is obtained as the transceiver inaccuracy
increases, compared to the approaches where the impact of nonlinear hardware
distortions, leading to inter-carrier leakage, is ignored.
</dc:description>
 <dc:description>Comment: Submitted to IEEE for publication</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:date>2017-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04815</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04816</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conditions for the equivalence between IQC and graph separation
  stability results</dc:title>
 <dc:creator>Carrasco, Joaquin</dc:creator>
 <dc:creator>Seiler, Peter</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper provides a link between time-domain and frequency-domain stability
results in the literature. Specifically, we focus on the comparison between
stability results for a feedback interconnection of two nonlinear systems
stated in terms of frequency-domain conditions. While the Integral Quadratic
Constrain (IQC) theorem can cope with them via a homotopy argument for the
Lurye problem, graph separation results require the transformation of the
frequency-domain conditions into truncated time-domain conditions. To date,
much of the literature focuses on &quot;hard&quot; factorizations of the multiplier,
considering only one of the two frequency-domain conditions. Here it is shown
that a symmetric, &quot;doubly-hard&quot; factorization is required to convert both
frequency-domain conditions into truncated time-domain conditions. By using the
appropriate factorization, a novel comparison between the results obtained by
IQC and separation theories is then provided. As a result, we identify under
what conditions the IQC theorem may provide some advantage.
</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04816</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04825</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CT Image Reconstruction in a Low Dimensional Manifold</dc:title>
 <dc:creator>Cong, Wenxiang</dc:creator>
 <dc:creator>Wang, Ge</dc:creator>
 <dc:creator>Yang, Qingsong</dc:creator>
 <dc:creator>Hsieh, Jiang</dc:creator>
 <dc:creator>Li, Jia</dc:creator>
 <dc:creator>Lai, Rongjie</dc:creator>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Regularization methods are commonly used in X-ray CT image reconstruction.
Different regularization methods reflect the characterization of different
prior knowledge of images. In a recent work, a new regularization method called
a low-dimensional manifold model (LDMM) is investigated to characterize the
low-dimensional patch manifold structure of natural images, where the manifold
dimensionality characterizes structural information of an image. In this paper,
we propose a CT image reconstruction method based on the prior knowledge of the
low-dimensional manifold of CT image. Using the clinical raw projection data
from GE clinic, we conduct comparisons for the CT image reconstruction among
the proposed method, the simultaneous algebraic reconstruction technique (SART)
with the total variation (TV) regularization, and the filtered back projection
(FBP) method. Results show that the proposed method can successfully recover
structural details of an imaging object, and achieve higher spatial and
contrast resolution of the reconstructed image than counterparts of FBP and
SART with TV.
</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04825</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04828</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Versatile Robust Clustering of Ad Hoc Cognitive Radio Network</dc:title>
 <dc:creator>Li, Di</dc:creator>
 <dc:creator>Fang, Erwin</dc:creator>
 <dc:creator>Gross, James</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Cluster structure in cognitive radio networks facilitates cooperative
spectrum sensing, routing and other functionalities. The unlicensed channels,
which are available for every member of a group of cognitive radio users,
consolidate the group into a cluster, and the availability of unlicensed
channels decides the robustness of that cluster against the licensed users'
influence. This paper analyses the problem that how to form robust clusters in
cognitive radio network, so that more cognitive radio users can get benefits
from cluster structure even when the primary users' operation are intense. We
provide a formal description of robust clustering problem, prove it to be
NP-hard and propose a centralized solution, besides, a distributed solution is
proposed to suit the dynamics in the ad hoc cognitive radio network. Congestion
game model is adopted to analyze the process of cluster formation, which not
only contributes designing the distributed clustering scheme directly, but also
provides the guarantee of convergence into Nash Equilibrium and convergence
speed. Our proposed clustering solution is versatile to fulfill some other
requirements such as faster convergence and cluster size control. The proposed
distributed clustering scheme outperforms the related work in terms of cluster
robustness, convergence speed and overhead. The extensive simulation supports
our claims.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04828</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04830</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nearly Tight Bounds for Sandpile Transience on the Grid</dc:title>
 <dc:creator>Durfee, David</dc:creator>
 <dc:creator>Fahrbach, Matthew</dc:creator>
 <dc:creator>Gao, Yu</dc:creator>
 <dc:creator>Xiao, Tao</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We use techniques from the theory of electrical networks to give nearly tight
bounds for the transience class of the Abelian sandpile model on the
two-dimensional grid up to polylogarithmic factors. The Abelian sandpile model
is a discrete process on graphs that is intimately related to the phenomenon of
self-organized criticality. In this process, vertices receive grains of sand,
and once the number of grains exceeds their degree, they topple by sending
grains to their neighbors. The transience class of a model is the maximum
number of grains that can be added to the system before it necessarily reaches
its steady-state behavior or, equivalently, a recurrent state. Through a more
refined and global analysis of electrical potentials and random walks, we give
an $O(n^4\log^4{n})$ upper bound and an $\Omega(n^4)$ lower bound for the
transience class of the $n \times n$ grid. Our methods naturally extend to
$n^d$-sized $d$-dimensional grids to give $O(n^{3d - 2}\log^{d+2}{n})$ upper
bounds and $\Omega(n^{3d -2})$ lower bounds.
</dc:description>
 <dc:description>Comment: 36 pages, 4 figures</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04830</dc:identifier>
 <dc:identifier>Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on
  Discrete Algorithms (SODA 2018)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04846</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PerspectivesX: A Proposed Tool to Scaffold Collaborative Learning
  Activities within MOOCs</dc:title>
 <dc:creator>Bakharia, Aneesha</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  In this work-in-progress paper, we introduce the PerspectivesX tool which
aims to scaffold collaborative learning activities within MOOCs. The
PerspectivesX tool has been designed to promote learner knowledge construction
and curation for a range of multi-perspective elaboration techniques (e.g.,
SWOT analysis and Six Thinking Hats). The PerspectivesX tool is designed to
store learner submissions in a searchable knowledge base which is able to be
persisted across course re-runs and promotes the use of natural language
processing techniques to allow course moderators to provide scalable feedback.
In this paper we outline the design principles that structured collaborative
learning tools need to adhere to, design a prototype tool (PerspectivesX) and
evaluate whether MOOC platform extension frameworks are able to support the
implementation of the tool.
</dc:description>
 <dc:description>Comment: Accepted as a Work In Progress paper at EMOOC 2017</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04846</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04848</identifier>
 <datestamp>2017-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Power of Waiting for More than One Response in Minimizing the
  Age-of-Information</dc:title>
 <dc:creator>Sang, Yu</dc:creator>
 <dc:creator>Li, Bin</dc:creator>
 <dc:creator>Ji, Bo</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The Age-of-Information (AoI) has recently been proposed as an important
metric for investigating the timeliness performance in information-update
systems. Prior studies on AoI optimization often consider a Push model, which
is concerned about when and how to &quot;push&quot; (i.e., generate and transmit) the
updated information to the user. In stark contrast, in this paper we introduce
a new Pull model, which is more relevant for certain applications (such as the
real-time stock quotes service), where a user sends requests to the servers to
proactively &quot;pull&quot; the information of interest. Moreover, we propose to employ
request replication to reduce the AoI. Interestingly, we find that under this
new Pull model, replication schemes capture a novel tradeoff between different
levels of information freshness and different response times across the
servers, which can be exploited to minimize the expected AoI at the user's
side. Specifically, assuming Poisson updating process at the servers and
exponentially distributed response time, we derive a closedform formula for
computing the expected AoI and obtain the optimal number of responses to wait
for to minimize the expected AoI. Finally, we conduct numerical simulations to
elucidate our theoretical results. Our findings show that waiting for more than
one response can significantly reduce the AoI in most scenarios.
</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:date>2017-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04848</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04849</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stationary Distribution of a Generalized LRU-MRU Content Cache</dc:title>
 <dc:creator>Kesidis, George</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Many different caching mechanisms have been previously proposed, exploring
different insertion and eviction policies and their performance individually
and as part of caching networks. We obtain a novel closed-form stationary
invariant distribution for a generalization of LRU and MRU caching nodes under
a reference Markov model. Numerical comparisons are made with an &quot;Incremental
Rank Progress&quot; (IRP a.k.a. CLIMB) and random eviction (a.k.a. random
replacement) methods under a steady-state Zipf popularity distribution. The
range of cache hit probabilities is smaller under MRU and larger under IRP
compared to LRU. We conclude with the invariant distribution for a special case
of a random-eviction caching tree-network and associated discussion.
</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04849</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04852</identifier>
 <datestamp>2017-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Downwash-Aware Trajectory Planning for Large Quadrotor Teams</dc:title>
 <dc:creator>Preiss, James A.</dc:creator>
 <dc:creator>H&#xf6;nig, Wolfgang</dc:creator>
 <dc:creator>Ayanian, Nora</dc:creator>
 <dc:creator>Sukhatme, Gaurav S.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We describe a method for formation-change trajectory planning for large
quadrotor teams in obstacle-rich environments. Our method decomposes the
planning problem into two stages: a discrete planner operating on a graph
representation of the workspace, and a continuous refinement that converts the
non-smooth graph plan into a set of C^k-continuous trajectories, locally
optimizing an integral-squared-derivative cost. We account for the downwash
effect, allowing safe flight in dense formations. We demonstrate the
computational efficiency in simulation with up to 200 robots and the physical
plausibility with an experiment with 32 nano-quadrotors. Our approach can
compute safe and smooth trajectories for hundreds of quadrotors in dense
environments with obstacles in a few minutes.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:date>2017-07-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04852</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04853</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differential Evolution and Bayesian Optimisation for Hyper-Parameter
  Selection in Mixed-Signal Neuromorphic Circuits Applied to UAV Obstacle
  Avoidance</dc:title>
 <dc:creator>Salt, Llewyn</dc:creator>
 <dc:creator>Howard, David</dc:creator>
 <dc:creator>Indiveri, Giacomo</dc:creator>
 <dc:creator>Sandamirskaya, Yulia</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The Lobula Giant Movement Detector (LGMD) is a an identified neuron of the
locust that detects looming objects and triggers its escape responses.
Understanding the neural principles and networks that lead to these fast and
robust responses can lead to the design of efficient facilitate obstacle
avoidance strategies in robotic applications. Here we present a neuromorphic
spiking neural network model of the LGMD driven by the output of a neuromorphic
Dynamic Vision Sensor (DVS), which has been optimised to produce robust and
reliable responses in the face of the constraints and variability of its mixed
signal analogue-digital circuits. As this LGMD model has many parameters, we
use the Differential Evolution (DE) algorithm to optimise its parameter space.
We also investigate the use of Self-Adaptive Differential Evolution (SADE)
which has been shown to ameliorate the difficulties of finding appropriate
input parameters for DE. We explore the use of two biological mechanisms:
synaptic plasticity and membrane adaptivity in the LGMD. We apply DE and SADE
to find parameters best suited for an obstacle avoidance system on an unmanned
aerial vehicle (UAV), and show how it outperforms state-of-the-art Bayesian
optimisation used for comparison.
</dc:description>
 <dc:description>Comment: Submitted to TNNLS</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04853</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04855</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fooling intersections of low-weight halfspaces</dc:title>
 <dc:creator>Servedio, Rocco A.</dc:creator>
 <dc:creator>Tan, Li-Yang</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  A weight-$t$ halfspace is a Boolean function $f(x)=$sign$(w_1 x_1 + \cdots +
w_n x_n - \theta)$ where each $w_i$ is an integer in $\{-t,\dots,t\}.$ We give
an explicit pseudorandom generator that $\delta$-fools any intersection of $k$
weight-$t$ halfspaces with seed length poly$(\log n, \log k,t,1/\delta)$. In
particular, our result gives an explicit PRG that fools any intersection of any
quasipoly$(n)$ number of halfspaces of any poly$\log(n)$ weight to any
$1/$poly$\log(n)$ accuracy using seed length poly$\log(n).$ Prior to this work
no explicit PRG with non-trivial seed length was known even for fooling
intersections of $n$ weight-1 halfspaces to constant accuracy.
  The analysis of our PRG fuses techniques from two different lines of work on
unconditional pseudorandomness for different kinds of Boolean functions. We
extend the approach of Harsha, Klivans and Meka \cite{HKM12} for fooling
intersections of regular halfspaces, and combine this approach with results of
Bazzi \cite{Bazzi:07} and Razborov \cite{Razborov:09} on bounded independence
fooling CNF formulas. Our analysis introduces new coupling-based ingredients
into the standard Lindeberg method for establishing quantitative central limit
theorems and associated pseudorandomness results.
</dc:description>
 <dc:description>Comment: 27 pages</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04855</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04856</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Neural Architecture for Generating Natural Language Descriptions from
  Source Code Changes</dc:title>
 <dc:creator>Loyola, Pablo</dc:creator>
 <dc:creator>Marrese-Taylor, Edison</dc:creator>
 <dc:creator>Matsuo, Yutaka</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We propose a model to automatically describe changes introduced in the source
code of a program using natural language. Our method receives as input a set of
code commits, which contains both the modifications and message introduced by
an user. These two modalities are used to train an encoder-decoder
architecture. We evaluated our approach on twelve real world open source
projects from four different programming languages. Quantitative and
qualitative results showed that the proposed approach can generate feasible and
semantically sound descriptions not only in standard in-project settings, but
also in a cross-project setting.
</dc:description>
 <dc:description>Comment: Accepted at ACL 2017</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04856</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04857</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Capacity Requirement for Arbitrary End-to-End Deadline and
  Reliability Guarantees in Multi-hop Networks</dc:title>
 <dc:creator>Deng, Han</dc:creator>
 <dc:creator>Hou, I-Hong</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  It has been shown that it is impossible to achieve both stringent end-to-end
deadline and reliability guarantees in a large network without having complete
information of all future packet arrivals. In order to maintain desirable
performance in the presence of uncertainty of future packet arrivals, common
practice is to add redundancy by increasing link capacities. This paper studies
the amount of capacity needed to provide stringent performance guarantees. We
propose a low-complexity online algorithm and prove that it only requires a
small amount of redundancy to guarantee both end-to-end deadline and
reliability. Further, we show that in large networks with very high reliability
requirements, the redundancy needed by our policy is at most twice as large as
a theoretical lower bound. Also, for practical implementation, we propose a
fully distributed protocol based on the previous centralized policy. Without
adding redundancy, we further propose a low-complexity order-optimal online
policy for the network. Simulation results also show that our policy achieves
much better performance than other state-of-the-art policies.
</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04857</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04859</identifier>
 <datestamp>2017-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Character-level Compositionality with Visual Features</dc:title>
 <dc:creator>Liu, Frederick</dc:creator>
 <dc:creator>Lu, Han</dc:creator>
 <dc:creator>Lo, Chieh</dc:creator>
 <dc:creator>Neubig, Graham</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Previous work has modeled the compositionality of words by creating
character-level models of meaning, reducing problems of sparsity for rare
words. However, in many writing systems compositionality has an effect even on
the character-level: the meaning of a character is derived by the sum of its
parts. In this paper, we model this effect by creating embeddings for
characters based on their visual characteristics, creating an image for the
character and running it through a convolutional neural network to produce a
visual character embedding. Experiments on a text classification task
demonstrate that such model allows for better processing of instances with rare
characters in languages such as Chinese, Japanese, and Korean. Additionally,
qualitative analyses demonstrate that our proposed model learns to focus on the
parts of characters that carry semantic content, resulting in embeddings that
are coherent in visual space.
</dc:description>
 <dc:description>Comment: Accepted to ACL 2017</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:date>2017-05-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04859</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04860</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Caching Policy Optimization for D2D Communications by Learning User
  Preference</dc:title>
 <dc:creator>Chen, Binqiang</dc:creator>
 <dc:creator>Yang, Chenyang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Cache-enabled device-to-device (D2D) communications can boost network
throughput. By pre-downloading contents to local caches of users, the content
requested by a user can be transmitted via D2D links by other users in
proximity. Prior works optimize the caching policy at users with the knowledge
of content popularity, defined as the probability distribution of request for
every file in a library from by all users. However, content popularity can not
reflect the interest of each individual user and thus popularity-based caching
policy may not fully capture the performance gain introduced by caching. In
this paper, we optimize caching policy for cache-enabled D2D by learning user
preference, defined as the conditional probability distribution of a user's
request for a file given that the user sends a request. We first formulate an
optimization problem with given user preference to maximize the offloading
probability, which is proved as NP-hard, and then provide a greedy algorithm to
find the solution. In order to predict the preference of each individual user,
we model the user request behavior by probabilistic latent semantic analysis
(pLSA), and then apply expectation maximization (EM) algorithm to estimate the
model parameters. Simulation results show that the user preference can be
learnt quickly. Compared to the popularity-based caching policy, the offloading
gain achieved by the proposed policy can be remarkably improved even with
predicted user preference.
</dc:description>
 <dc:description>Comment: Accepted by VTC Spring 2017</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04860</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04861</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
  Applications</dc:title>
 <dc:creator>Howard, Andrew G.</dc:creator>
 <dc:creator>Zhu, Menglong</dc:creator>
 <dc:creator>Chen, Bo</dc:creator>
 <dc:creator>Kalenichenko, Dmitry</dc:creator>
 <dc:creator>Wang, Weijun</dc:creator>
 <dc:creator>Weyand, Tobias</dc:creator>
 <dc:creator>Andreetto, Marco</dc:creator>
 <dc:creator>Adam, Hartwig</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a class of efficient models called MobileNets for mobile and
embedded vision applications. MobileNets are based on a streamlined
architecture that uses depth-wise separable convolutions to build light weight
deep neural networks. We introduce two simple global hyper-parameters that
efficiently trade off between latency and accuracy. These hyper-parameters
allow the model builder to choose the right sized model for their application
based on the constraints of the problem. We present extensive experiments on
resource and accuracy tradeoffs and show strong performance compared to other
popular models on ImageNet classification. We then demonstrate the
effectiveness of MobileNets across a wide range of applications and use cases
including object detection, finegrain classification, face attributes and large
scale geo-localization.
</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04861</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04865</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gang of GANs: Generative Adversarial Networks with Maximum Margin
  Ranking</dc:title>
 <dc:creator>Juefei-Xu, Felix</dc:creator>
 <dc:creator>Boddeti, Vishnu Naresh</dc:creator>
 <dc:creator>Savvides, Marios</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Traditional generative adversarial networks (GAN) and many of its variants
are trained by minimizing the KL or JS-divergence loss that measures how close
the generated data distribution is from the true data distribution. A recent
advance called the WGAN based on Wasserstein distance can improve on the KL and
JS-divergence based GANs, and alleviate the gradient vanishing, instability,
and mode collapse issues that are common in the GAN training. In this work, we
aim at improving on the WGAN by first generalizing its discriminator loss to a
margin-based one, which leads to a better discriminator, and in turn a better
generator, and then carrying out a progressive training paradigm involving
multiple GANs to contribute to the maximum margin ranking loss so that the GAN
at later stages will improve upon early stages. We call this method Gang of
GANs (GoGAN). We have shown theoretically that the proposed GoGAN can reduce
the gap between the true data distribution and the generated data distribution
by at least half in an optimally trained WGAN. We have also proposed a new way
of measuring GAN quality which is based on image completion tasks. We have
evaluated our method on four visual datasets: CelebA, LSUN Bedroom, CIFAR-10,
and 50K-SSFF, and have seen both visual and quantitative improvement over
baseline WGAN.
</dc:description>
 <dc:description>Comment: 16 pages. 11 figures</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04865</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04866</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effective Warm Start for the Online Actor-Critic Reinforcement Learning
  based mHealth Intervention</dc:title>
 <dc:creator>Zhu, Feiyun</dc:creator>
 <dc:creator>Liao, Peng</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Online reinforcement learning (RL) is increasingly popular for the
personalized mobile health (mHealth) intervention. It is able to personalize
the type and dose of interventions according to user's ongoing statuses and
changing needs. However, at the beginning of online learning, there are usually
too few samples to support the RL updating, which leads to poor performances. A
delay in good performance of the online learning algorithms can be especially
detrimental in the mHealth, where users tend to quickly disengage with the
mHealth app. To address this problem, we propose a new online RL methodology
that focuses on an effective warm start. The main idea is to make full use of
the data accumulated and the decision rule achieved in a former study. As a
result, we can greatly enrich the data size at the beginning of online learning
in our method. Such case accelerates the online learning process for new users
to achieve good performances not only at the beginning of online learning but
also through the whole online learning process. Besides, we use the decision
rules achieved in a previous study to initialize the parameter in our online RL
model for new users. It provides a good initialization for the proposed online
RL algorithm. Experiment results show that promising improvements have been
achieved by our method compared with the state-of-the-art method.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04866</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04872</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Categorical Liveness Checking by Corecursive Algebras</dc:title>
 <dc:creator>Urabe, Natsuki</dc:creator>
 <dc:creator>Hara, Masaki</dc:creator>
 <dc:creator>Hasuo, Ichiro</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Final coalgebras as &quot;categorical greatest fixed points&quot; play a central role
in the theory of coalgebras. Somewhat analogously, most proof methods studied
therein have focused on greatest fixed-point properties like safety and
bisimilarity. Here we make a step towards categorical proof methods for least
fixed-point properties over dynamical systems modeled as coalgebras.
Concretely, we seek a categorical axiomatization of well-known proof methods
for liveness, namely ranking functions (in nondeterministic settings) and
ranking supermartingales (in probabilistic ones). We find an answer in a
suitable combination of coalgebraic simulation (studied previously by the
authors) and corecursive algebra as a classifier for (non-)well-foundedness.
</dc:description>
 <dc:description>Comment: 28 pages</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04872</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04877</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Least square ellipsoid fitting using iterative orthogonal
  transformations</dc:title>
 <dc:creator>Reza, Amit</dc:creator>
 <dc:creator>Sengupta, Anand S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We describe a generalised method for ellipsoid fitting against a minimum set
of data points. The proposed method is numerically stable and applies to a wide
range of ellipsoidal shapes, including highly elongated and arbitrarily
oriented ellipsoids. This new method also provides for the retrieval of
rotational angle and length of semi-axes of the fitted ellipsoids accurately.
We demonstrate the efficacy of this algorithm on simulated data sets and also
indicate its potential use in gravitational wave data analysis.
</dc:description>
 <dc:description>Comment: Submitted to Applied Mathematics and Computation (Elsevier)</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-05-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04877</dc:identifier>
 <dc:identifier>doi:10.1016/j.amc.2017.07.025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04879</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Sport Tournament Scheduling by Genetic Algorithm with Swapping Method</dc:title>
 <dc:creator>Rutjanisarakul, Tinnaluk</dc:creator>
 <dc:creator>Jiarasuksakun, Thiradet</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  A sport tournament problem is considered the Traveling Tournament Problem
(TTP). One interesting type is the mirrored Traveling Tournament Problem
(mTTP). The objective of the problem is to minimize either the total number of
traveling or the total distances of traveling or both. This research aims to
find an optimized solution of the mirrored Traveling Tournament Problem with
minimum total number of traveling. The solutions consisting of traveling and
scheduling tables are solved by using genetic algorithm (GA) with swapping
method. The number of traveling of all teams from obtained solutions are close
to the lower bound theory of number of traveling. Moreover, this algorithm
generates better solutions than known results for most cases.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04879</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04882</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monoidal computer III: A coalgebraic view of computability and
  complexity</dc:title>
 <dc:creator>Pavlovic, Dusko</dc:creator>
 <dc:creator>Yahia, Muzamil</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>03D10, 03D15, 18D10, 68Q05, 68Q15</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.3</dc:subject>
 <dc:description>  Monoidal computer is a categorical model of intensional computation, where
many different programs correspond to the same input-output behavior. The
upshot of yet another model of computation is that a categorical formalism
should provide a much needed high level language for theory of computation,
flexible enough to allow abstracting away the low level implementation details
when they are irrelevant, or taking them into account when they are genuinely
needed. A salient feature of the approach through monoidal categories is the
formal graphical language of string diagrams, which supports visual reasoning
about programs and computations.
  In the present paper, we provide a coalgebraic characterization of monoidal
computer. It turns out that the availability of interpreters and specializers,
that make a monoidal category into a monoidal computer, is equivalent with the
existence of a *universal state space*, that carries a weakly final state
machine for any pair of input and output types. Being able to program state
machines in monoidal computers allows us to represent Turing machines, to
capture their execution, count their steps, as well as, e.g., the memory cells
that they use. The coalgebraic view of monoidal computer thus provides a
convenient diagrammatic language for studying computability and complexity.
</dc:description>
 <dc:description>Comment: 29 pages, 20 figures</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04882</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04886</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-View Image Generation from a Single-View</dc:title>
 <dc:creator>Zhao, Bo</dc:creator>
 <dc:creator>Wu, Xiao</dc:creator>
 <dc:creator>Cheng, Zhi-Qi</dc:creator>
 <dc:creator>Liu, Hao</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  This paper addresses a challenging problem -- how to generate multi-view
cloth images from only a single view input. To generate realistic-looking
images with different views from the input, we propose a new image generation
model termed VariGANs that combines the strengths of the variational inference
and the Generative Adversarial Networks (GANs). Our proposed VariGANs model
generates the target image in a coarse-to-fine manner instead of a single pass
which suffers from severe artifacts. It first performs variational inference to
model global appearance of the object (e.g., shape and color) and produce a
coarse image with a different view. Conditioned on the generated low resolution
images, it then proceeds to perform adversarial learning to fill details and
generate images of consistent details with the input. Extensive experiments
conducted on two clothing datasets, MVC and DeepFashion, have demonstrated that
images of a novel view generated by our model are more plausible than those
generated by existing approaches, in terms of more consistent global appearance
as well as richer and sharper details.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04886</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04888</identifier>
 <datestamp>2017-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Envy-free Matchings with Lower Quotas</dc:title>
 <dc:creator>Yokoi, Yu</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>91B68, 52B40</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:description>  While every instance of the Hospitals/Residents problem admits a stable
matching, the problem with lower quotas (HR-LQ) has instances with no stable
matching. For such an instance, we expect the existence of an envy-free
matching, which is a relaxation of a stable matching preserving a kind of
fairness property. In this paper, we investigate the existence of an envy-free
matching in several settings, in which hospitals have lower quotas and not all
doctor-hospital pairs are acceptable. We first show that, for an HR-LQ
instance, we can efficiently decide the existence of an envy-free matching.
Then, we consider envy-freeness in the Classified Stable Matching model due to
Huang (2010), i.e., each hospital has lower and upper quotas on subsets of
doctors. We show that, for this model, deciding the existence of an envy-free
matching is NP-hard in general, but solvable in polynomial time if quotas are
paramodular.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-09-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04888</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04900</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Input Reconstruction Approach for Command Following in Linear MIMO
  Systems</dc:title>
 <dc:creator>Chavan, Roshan A.</dc:creator>
 <dc:creator>Kadam, Sujay D.</dc:creator>
 <dc:creator>Rajiv, Abhijith</dc:creator>
 <dc:creator>Palanthandalam-Madapusi, Harish J.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The idea of posing a command following or tracking control problem as an
input reconstruction problem is explored in the paper. For a class of square
MIMO systems with known dynamics, by pretending that reference commands are
actual outputs of the system, input reconstruction methods can be used to
determine control action that will result in a system following desired
reference commands. A feedback controller which is a combination of an unbiased
state estimator and an input reconstructor that ensures unbiased tracking of
reference commands is proposed. Simulations and real-time implementation are
presented to demonstrate utility of the proposed idea. Conditions under which
proposed controller may be used for non-square systems are also discussed.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04900</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04904</identifier>
 <datestamp>2017-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capacity-Achieving Input Distributions in Nondispersive Optical Fibers</dc:title>
 <dc:creator>Fahs, Jihad</dc:creator>
 <dc:creator>Tchamkerten, Aslan</dc:creator>
 <dc:creator>Yousefi, Mansoor I.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates the discrete-time per-sample model of the
zero-dispersion optical fiber. It is shown that the capacity-achieving input
distribution is unique, has (continuous) uniform phase and discrete amplitude
with a finite number of mass points. The optimality of this multi-ring input
holds when the channel is subject to general input cost constraints that
include peak power constraint and a joint average and peak power constraint.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04904</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04905</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A contract-based method to specify stimulus-response requirements</dc:title>
 <dc:creator>Naumchev, Alexandr</dc:creator>
 <dc:creator>Mazzara, Manuel</dc:creator>
 <dc:creator>Meyer, Bertrand</dc:creator>
 <dc:creator>Bruel, Jean-Michel</dc:creator>
 <dc:creator>Galinier, Florian</dc:creator>
 <dc:creator>Ebersold, Sophie</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  A number of formal methods exist for capturing stimulus-response requirements
in a declarative form. Someone yet needs to translate the resulting declarative
statements into imperative programs. The present article describes a method for
specification and verification of stimulus-response requirements in the form of
imperative program routines with conditionals and assertions. A program prover
then checks a candidate program directly against the stated requirements. The
article illustrates the approach by applying it to an ASM model of the Landing
Gear System, a widely used realistic example proposed for evaluating
specification and verification techniques.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04905</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04912</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pseudorehearsal in actor-critic agents</dc:title>
 <dc:creator>Vladimir, Marochko</dc:creator>
 <dc:creator>Johard, Leonard</dc:creator>
 <dc:creator>Mazzara, Manuel</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Catastrophic forgetting has a serious impact in reinforcement learning, as
the data distribution is generally sparse and non-stationary over time. The
purpose of this study is to investigate whether pseudorehearsal can increase
performance of an actor-critic agent with neural-network based policy selection
and function approximation in a pole balancing task and compare different
pseudorehearsal approaches. We expect that pseudorehearsal assists learning
even in such very simple problems, given proper initialization of the rehearsal
parameters.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04912</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04920</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Joint Entity Disambiguation with Local Neural Attention</dc:title>
 <dc:creator>Ganea, Octavian-Eugen</dc:creator>
 <dc:creator>Hofmann, Thomas</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We propose a novel deep learning model for joint document-level entity
disambiguation, which leverages learned neural representations. Key components
are entity embeddings, a neural attention mechanism over local context windows,
and a differentiable joint inference stage for disambiguation. Our approach
thereby combines benefits of deep learning with more traditional approaches
such as graphical models and probabilistic mention-entity maps. Extensive
experiments show that we are able to obtain competitive or state-of-the-art
accuracy at moderate computational costs.
</dc:description>
 <dc:description>Comment: Conference on Empirical Methods in Natural Language Processing
  (EMNLP) 2017 long paper</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04920</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04929</identifier>
 <datestamp>2017-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimized LTE Data Transmission Procedures for IoT: Device Side Energy
  Consumption Analysis</dc:title>
 <dc:creator>Andres-Maldonado, Pilar</dc:creator>
 <dc:creator>Ameigeiras, Pablo</dc:creator>
 <dc:creator>Prados-Garzon, Jonathan</dc:creator>
 <dc:creator>Ramos-Munoz, Juan J.</dc:creator>
 <dc:creator>Lopez-Soler, Juan M.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The efficient deployment of Internet of Things (IoT) over cellular networks,
such as Long Term Evolution (LTE) or the next generation 5G, entails several
challenges. For massive IoT, reducing the energy consumption on the device side
becomes essential. One of the main characteristics of massive IoT is small data
transmissions. To improve the support of them, the 3GPP has included two novel
optimizations in LTE: one of them based on the Control Plane (CP), and the
other on the User Plane (UP). In this paper, we analyze the average energy
consumption per data packet using these two optimizations compared to
conventional LTE Service Request procedure. We propose an analytical model to
calculate the energy consumption for each procedure based on a Markov chain. In
the considered scenario, for large and small Inter-Arrival Times (IATs), the
results of the three procedures are similar. While for medium IATs CP reduces
the energy consumption per packet up to 87% due to its connection release
optimization.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04929</dc:identifier>
 <dc:identifier>doi:10.1109/ICCW.2017.7962714</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04932</identifier>
 <datestamp>2017-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Relaxation: partial differential equations for optimizing deep
  neural networks</dc:title>
 <dc:creator>Chaudhari, Pratik</dc:creator>
 <dc:creator>Oberman, Adam</dc:creator>
 <dc:creator>Osher, Stanley</dc:creator>
 <dc:creator>Soatto, Stefano</dc:creator>
 <dc:creator>Carlier, Guillaume</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper we establish a connection between non-convex optimization
methods for training deep neural networks and nonlinear partial differential
equations (PDEs). Relaxation techniques arising in statistical physics which
have already been used successfully in this context are reinterpreted as
solutions of a viscous Hamilton-Jacobi PDE. Using a stochastic control
interpretation allows we prove that the modified algorithm performs better in
expectation that stochastic gradient descent. Well-known PDE regularity results
allow us to analyze the geometry of the relaxed energy landscape, confirming
empirical evidence. The PDE is derived from a stochastic homogenization
problem, which arises in the implementation of the algorithm. The algorithms
scale well in practice and can effectively tackle the high dimensionality of
modern neural networks.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04932</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04937</identifier>
 <datestamp>2017-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Certificate Transparency with Enhancements and Short Proofs</dc:title>
 <dc:creator>Singh, Abhishek</dc:creator>
 <dc:creator>Sengupta, Binanda</dc:creator>
 <dc:creator>Ruj, Sushmita</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Browsers can detect malicious websites that are provisioned with forged or
fake TLS/SSL certificates. However, they are not so good at detecting malicious
websites if they are provisioned with mistakenly issued certificates or
certificates that have been issued by a compromised certificate authority.
Google proposed certificate transparency which is an open framework to monitor
and audit certificates in real time. Thereafter, a few other certificate
transparency schemes have been proposed which can even handle revocation. All
currently known constructions use Merkle hash trees and have proof size
logarithmic in the number of certificates/domain owners.
  We present a new certificate transparency scheme with short (constant size)
proofs. Our construction makes use of dynamic bilinear-map accumulators. The
scheme has many desirable properties like efficient revocation, low
verification cost and update costs comparable to the existing schemes. We
provide proofs of security and evaluate the performance of our scheme.
</dc:description>
 <dc:description>Comment: A preliminary version of the paper was published in ACISP 2017</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-07-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04937</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04946</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Covert Communication in Wireless Relay Networks</dc:title>
 <dc:creator>Hu, Jinsong</dc:creator>
 <dc:creator>Yan, Shihao</dc:creator>
 <dc:creator>Zhou, Xiangyun</dc:creator>
 <dc:creator>Shu, Feng</dc:creator>
 <dc:creator>Wang, Jiangzhou</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Covert communication aims to shield the very existence of wireless
transmissions in order to guarantee a strong security in wireless networks. In
this work, for the first time we examine the possibility and achievable
performance of covert communication in one-way relay networks. Specifically,
the relay opportunistically transmits its own information to the destination
covertly on top of forwarding the source's message, while the source tries to
detect this covert transmission to discover the illegitimate usage of the
recourse (e.g., power, spectrum) allocated only for the purpose of forwarding
source's information. The necessary condition that the relay can transmit
covertly without being detected is identified and the source's detection limit
is derived in terms of the false alarm and miss detection rates. Our analysis
indicates that boosting the forwarding ability of the relay (e.g., increasing
its maximum transmit power) also increases its capacity to perform the covert
communication in terms of achieving a higher effective covert rate subject to
some specific requirement on the source's detection performance.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04946</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04947</identifier>
 <datestamp>2017-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Space-Optimal Majority in Population Protocols</dc:title>
 <dc:creator>Alistarh, Dan</dc:creator>
 <dc:creator>Aspnes, James</dc:creator>
 <dc:creator>Gelashvili, Rati</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Population protocols are a model of distributed computing, in which $n$
agents with limited local state interact randomly, and cooperate to
collectively compute global predicates. An extensive series of papers, across
different communities, has examined the computability and complexity
characteristics of this model. Majority, or consensus, is a central task, in
which agents need to collectively reach a decision as to which one of two
states $A$ or $B$ had a higher initial count. Two complexity metrics are
important: the time that a protocol requires to stabilize to an output
decision, and the state space size that each agent requires.
  It is known that majority requires $\Omega(\log \log n)$ states per agent to
allow for poly-logarithmic time stabilization, and that $O(\log^2 n)$ states
are sufficient. Thus, there is an exponential gap between the upper and lower
bounds.
  We address this question. We provide a new lower bound of $\Omega(\log n)$
states for any protocol which stabilizes in $O( n^{1-c} )$ time, for any $c &gt;
0$ constant. This result is conditional on basic monotonicity and output
assumptions, satisfied by all known protocols. Technically, it represents a
significant departure from previous lower bounds. Instead of relying on dense
configurations, we introduce a new surgery technique to construct executions
which contradict the correctness of algorithms that stabilize too fast.
Subsequently, our lower bound applies to general initial configurations.
  We give an algorithm for majority which uses $O(\log n)$ states, and
stabilizes in $O(\log^2 n)$ time. Central to the algorithm is a new leaderless
phase clock, which allows nodes to synchronize in phases of $\Theta(n \log{n})$
consecutive interactions using $O(\log n)$ states per node. We also employ our
phase clock to build a leader election algorithm with $O(\log n )$ states,
which stabilizes in $O(\log^2 n)$ time.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04952</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AMTnet: Action-Micro-Tube Regression by End-to-end Trainable Deep
  Architecture</dc:title>
 <dc:creator>Saha, Suman</dc:creator>
 <dc:creator>Singh, Gurkirt</dc:creator>
 <dc:creator>Cuzzolin, Fabio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Dominant approaches to action detection can only provide sub-optimal
solutions to the problem, as they rely on seeking frame-level detections, to
later compose them into &quot;action tubes&quot; in a post-processing step. With this
paper we radically depart from current practice, and take a first step towards
the design and implementation of a deep network architecture able to classify
and regress whole video subsets, so providing a truly optimal solution of the
action detection problem. In this work, in particular, we propose a novel deep
net framework able to regress and classify 3D region proposals spanning two
successive video frames, whose core is an evolution of classical region
proposal networks (RPNs). As such, our 3D-RPN net is able to effectively encode
the temporal aspect of actions by purely exploiting appearance, as opposed to
methods which heavily rely on expensive flow maps. The proposed model is
end-to-end trainable and can be jointly optimised for action localisation and
classification in a single step. At test time the network predicts
&quot;micro-tubes&quot; encompassing two successive frames, which are linked up into
complete action tubes via a new algorithm which exploits the temporal encoding
learned by the network and cuts computation time by 50%. Promising results on
the J-HMDB-21 and UCF-101 action detection datasets show that our model does
outperform the state-of-the-art when relying purely on appearance.
</dc:description>
 <dc:description>Comment: Update to version in ICCV 2017 proceedings</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04952</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04959</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Introspection: Accelerating Neural Network Training By Learning Weight
  Evolution</dc:title>
 <dc:creator>Sinha, Abhishek</dc:creator>
 <dc:creator>Sarkar, Mausoom</dc:creator>
 <dc:creator>Mukherjee, Aahitagni</dc:creator>
 <dc:creator>Krishnamurthy, Balaji</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Neural Networks are function approximators that have achieved
state-of-the-art accuracy in numerous machine learning tasks. In spite of their
great success in terms of accuracy, their large training time makes it
difficult to use them for various tasks. In this paper, we explore the idea of
learning weight evolution pattern from a simple network for accelerating
training of novel neural networks. We use a neural network to learn the
training pattern from MNIST classification and utilize it to accelerate
training of neural networks used for CIFAR-10 and ImageNet classification. Our
method has a low memory footprint and is computationally efficient. This method
can also be used with other optimizers to give faster convergence. The results
indicate a general trend in the weight evolution during training of neural
networks.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04959</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04960</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial and Clean Data Are Not Twins</dc:title>
 <dc:creator>Gong, Zhitao</dc:creator>
 <dc:creator>Wang, Wenlu</dc:creator>
 <dc:creator>Ku, Wei-Shinn</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Adversarial attack has cast a shadow on the massive success of deep neural
networks. Despite being almost visually identical to the clean data, the
adversarial images can fool deep neural networks into wrong predictions with
very high confidence. In this paper, however, we show that we can build a
simple binary classifier separating the adversarial apart from the clean data
with accuracy over 99%. We also empirically show that the binary classifier is
robust to a second-round adversarial attack. In other words, it is difficult to
disguise adversarial samples to bypass the binary classifier. Further more, we
empirically investigate the generalization limitation which lingers on all
current defensive methods, including the binary classifier approach. And we
hypothesize that this is the result of intrinsic property of adversarial
crafting algorithms.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04960</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04962</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Hybrid Matrix Factorisation for Data Integration</dc:title>
 <dc:creator>Brouwer, Thomas</dc:creator>
 <dc:creator>Li&#xf3;, Pietro</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce a novel Bayesian hybrid matrix factorisation model (HMF) for
data integration, based on combining multiple matrix factorisation methods,
that can be used for in- and out-of-matrix prediction of missing values. The
model is very general and can be used to integrate many datasets across
different entity types, including repeated experiments, similarity matrices,
and very sparse datasets. We apply our method on two biological applications,
and extensively compare it to state-of-the-art machine learning and matrix
factorisation models. For in-matrix predictions on drug sensitivity datasets we
obtain consistently better performances than existing methods. This is
especially the case when we increase the sparsity of the datasets. Furthermore,
we perform out-of-matrix predictions on methylation and gene expression
datasets, and obtain the best results on two of the three datasets, especially
when the predictivity of datasets is high.
</dc:description>
 <dc:description>Comment: Proceedings of the 20th International Conference on Artificial
  Intelligence and Statistics (AISTATS 2017)</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04962</dc:identifier>
 <dc:identifier>PMLR 54:557-566, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04964</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Combinatorics of Weighted Vector Compositions</dc:title>
 <dc:creator>Eger, Steffen</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  A vector composition of a vector $\mathbf{\ell}$ is a matrix $\mathbf{A}$
whose rows sum to $\mathbf{\ell}$. We define a weighted vector composition as a
vector composition in which the column values of $\mathbf{A}$ may appear in
different colors. We study vector compositions from different viewpoints: (1)
We show how they are related to sums of random vectors and (2) how they allow
to derive formulas for partial derivatives of composite functions. (3) We study
congruence properties of the number of weighted vector compositions, for fixed
and arbitrary number of parts, many of which are analogous to those of ordinary
binomial coefficients and related quantities. Via the Central Limit Theorem and
their multivariate generating functions, (4) we also investigate the asymptotic
behavior of several special cases of numbers of weighted vector compositions.
Finally, (5) we conjecture an extension of a primality criterion due to Mann
and Shanks in the context of weighted vector compositions.
</dc:description>
 <dc:description>Comment: Submitted; some minor modifications and extensions</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04964</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04966</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Larger is Better: The Effect of Learning Rates Enjoyed by Stochastic
  Optimization with Progressive Variance Reduction</dc:title>
 <dc:creator>Shang, Fanhua</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we propose a simple variant of the original stochastic
variance reduction gradient (SVRG), where hereafter we refer to as the variance
reduced stochastic gradient descent (VR-SGD). Different from the choices of the
snapshot point and starting point in SVRG and its proximal variant, Prox-SVRG,
the two vectors of each epoch in VR-SGD are set to the average and last iterate
of the previous epoch, respectively. This setting allows us to use much larger
learning rates or step sizes than SVRG, e.g., 3/(7L) for VR-SGD vs 1/(10L) for
SVRG, and also makes our convergence analysis more challenging. In fact, a
larger learning rate enjoyed by VR-SGD means that the variance of its
stochastic gradient estimator asymptotically approaches zero more rapidly.
Unlike common stochastic methods such as SVRG and proximal stochastic methods
such as Prox-SVRG, we design two different update rules for smooth and
non-smooth objective functions, respectively. In other words, VR-SGD can tackle
non-smooth and/or non-strongly convex problems directly without using any
reduction techniques such as quadratic regularizers. Moreover, we analyze the
convergence properties of VR-SGD for strongly convex problems, which show that
VR-SGD attains a linear convergence rate. We also provide the convergence
guarantees of VR-SGD for non-strongly convex problems. Experimental results
show that the performance of VR-SGD is significantly better than its
counterparts, SVRG and Prox-SVRG, and it is also much better than the best
known stochastic method, Katyusha.
</dc:description>
 <dc:description>Comment: 36 pages, 10 figures. The simple variant of SVRG is much better than
  the best-known stochastic method, Katyusha</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04966</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04969</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On weighted configuration logics</dc:title>
 <dc:creator>Paraponiari, Paulina</dc:creator>
 <dc:creator>Rahonis, George</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We introduce and investigate a weighted propositional configuration logic
over a commutative semiring. Our logic, which is proved to be sound and
complete, is intended to serve as a specification language for software
architectures with quantitative features. We extend the weighted configuration
logic to its first-order level and succeed in describing architecture styles
equipped with quantitative characteristics. We provide interesting examples of
weighted architecture styles. Surprisingly, we can construct a formula, in our
logic, which describes a classical problem of a different nature than that of
software architectures.
</dc:description>
 <dc:description>Comment: 37 pages, 2 figures</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04969</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04977</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic programs for inferring the goals of autonomous agents</dc:title>
 <dc:creator>Cusumano-Towner, Marco F.</dc:creator>
 <dc:creator>Radul, Alexey</dc:creator>
 <dc:creator>Wingate, David</dc:creator>
 <dc:creator>Mansinghka, Vikash K.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Intelligent systems sometimes need to infer the probable goals of people,
cars, and robots, based on partial observations of their motion. This paper
introduces a class of probabilistic programs for formulating and solving these
problems. The formulation uses randomized path planning algorithms as the basis
for probabilistic models of the process by which autonomous agents plan to
achieve their goals. Because these path planning algorithms do not have
tractable likelihood functions, new inference algorithms are needed. This paper
proposes two Monte Carlo techniques for these &quot;likelihood-free&quot; models, one of
which can use likelihood estimates from neural networks to accelerate
inference. The paper demonstrates efficacy on three simple examples, each using
under 50 lines of probabilistic code.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04977</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04979</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Urban Data Streams and Machine Learning: A Case of Swiss Real Estate
  Market</dc:title>
 <dc:creator>Moosavi, Vahid</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Quantitative Finance - General Finance</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  In this paper, we show how using publicly available data streams and machine
learning algorithms one can develop practical data driven services with no
input from domain experts as a form of prior knowledge. We report the initial
steps toward development of a real estate portal in Switzerland. Based on
continuous web crawling of publicly available real estate advertisements and
using building data from Open Street Map, we developed a system, where we
roughly estimate the rental and sale price indexes of 1.7 million buildings
across the country. In addition to these rough estimates, we developed a web
based API for accurate automated valuation of rental prices of individual
properties and spatial sensitivity analysis of rental market. We tested several
established function approximation methods against the test data to check the
quality of the rental price estimations and based on our experiments, Random
Forest gives very reasonable results with the median absolute relative error of
6.57 percent, which is comparable with the state of the art in the industry. We
argue that while recently there have been successful cases of real estate
portals, which are based on Big Data, majority of the existing solutions are
expensive, limited to certain users and mostly with non-transparent underlying
systems. As an alternative we discuss, how using the crawled data sets and
other open data sets provided from different institutes it is easily possible
to develop data driven services for spatial and temporal sensitivity analysis
in the real estate market to be used for different stakeholders. We believe
that this kind of digital literacy can disrupt many other existing business
concepts across many domains.
</dc:description>
 <dc:date>2017-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04979</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04982</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Designing a Web-based interactive audio library automation system for
  visually-impaired people and evaluation of its usability</dc:title>
 <dc:creator>Tufekci, Aslihan</dc:creator>
 <dc:creator>Balaman, Yahya</dc:creator>
 <dc:creator>Kose, Utku</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The aim of this study is to introduce an application that enables information
sharing and communication between visually-impaired individuals and
able-bodied. For the purposes of the study, web-based audio library automation
was designed and the usability of the system was analyzed regarding the
volunteers who record audio books and the visually-impaired individuals. The
visually-impaired individuals who took part in the test procedures in order to
make a general evaluation of the system reported that the system was
theoretically necessary and successful. As for the usability aspect, positive
comments were received regarding the automation system developed. The authors
believe that the current study is likely to be an alternative reference source
for the related literature and further research studies to be conducted in the
field.
</dc:description>
 <dc:description>Comment: 22 pages, 9 figures, 7 tables</dc:description>
 <dc:date>2017-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04982</dc:identifier>
 <dc:identifier>Journal of Multidisciplinary Developments, 1(1), 2016, 38-59</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04985</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The application of the competency-based approach to assess the training
  and employment adequacy problem</dc:title>
 <dc:creator>Haddouchane, Zineb Ait</dc:creator>
 <dc:creator>Bakkali, Soumia</dc:creator>
 <dc:creator>Ajana, Souad</dc:creator>
 <dc:creator>Gassemi, Karim</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  This review paper fits in the context of the adequate matching of training to
employment, which is one of the main challenges that universities around the
world strive to meet. In higher education, the revision of curricula
necessitates a return to the skills required by the labor market to train
skilled labors.
  In this research, we started with the presentation of the conceptual
framework. Then we quoted different currents that discussed the problematic of
the job training match from various perspectives. We proceeded to choose some
studies that have attempted to remedy this problem by adopting the
competency-based approach that involves the referential line. This approach has
as a main characteristic the attainment of the match between training and
employment. Therefore, it is a relevant solution for this problem. We
scrutinized the selected studies, presenting their objectives, methodologies
and results, and we provided our own analysis. Then, we focused on the Moroccan
context through observations and studies already conducted. And finally, we
introduced the problematic of our future project.
</dc:description>
 <dc:description>Comment: 18 pages, 2 figures, 1 table</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04985</dc:identifier>
 <dc:identifier>Volume 5, N{\deg} 1, March 2017, International Journal of
  Education (IJE)</dc:identifier>
 <dc:identifier>doi:10.5121/ije.2017.5101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04988</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Augmented Coaching Ecosystem for Non-obtrusive Adaptive Personalized
  Elderly Care on the Basis of Cloud-Fog-Dew Computing Paradigm</dc:title>
 <dc:creator>Gordienko, Yu.</dc:creator>
 <dc:creator>Stirenko, S.</dc:creator>
 <dc:creator>Alienin, O.</dc:creator>
 <dc:creator>Skala, K.</dc:creator>
 <dc:creator>Soyat, Z.</dc:creator>
 <dc:creator>Rojbi, A.</dc:creator>
 <dc:creator>Benito, J. R. L&#xf3;pez</dc:creator>
 <dc:creator>Gonz&#xe1;lez, E. Artetxe</dc:creator>
 <dc:creator>Lushchyk, U.</dc:creator>
 <dc:creator>Sajn, L.</dc:creator>
 <dc:creator>Coto, A. Llorente</dc:creator>
 <dc:creator>Jervan, G.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The concept of the augmented coaching ecosystem for non-obtrusive adaptive
personalized elderly care is proposed on the basis of the integration of new
and available ICT approaches. They include the multimodal user interface
(MMUI), augmented reality (AR), machine learning (ML), Internet of Things
(IoT), and machine-to-machine (M2M) interactions. The ecosystem is based on the
Cloud-Fog-Dew computing paradigm services, providing a full symbiosis by
integrating the whole range from low-level sensors up to high-level services
using integration efficiency inherent in synergistic use of applied
technologies. Inside of this ecosystem, all of them are encapsulated in the
following network layers: Dew, Fog, and Cloud computing layer. Instead of the
&quot;spaghetti connections&quot;, &quot;mosaic of buttons&quot;, &quot;puzzles of output data&quot;, etc.,
the proposed ecosystem provides the strict division in the following dataflow
channels: consumer interaction channel, machine interaction channel, and
caregiver interaction channel. This concept allows to decrease the physical,
cognitive, and mental load on elderly care stakeholders by decreasing the
secondary human-to-human (H2H), human-to-machine (H2M), and machine-to-human
(M2H) interactions in favor of M2M interactions and distributed Dew Computing
services environment. It allows to apply this non-obtrusive augmented reality
ecosystem for effective personalized elderly care to preserve their physical,
cognitive, mental and social well-being.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures, 40th International Convention on Information and
  Communication Technology, Electronics and Microelectronics (MIPRO) Opatija,
  Croatia (2017)</dc:description>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04988</dc:identifier>
 <dc:identifier>Proceedings of MIPRO 2017 40th Jubilee International Convention
  (Opatija, Croatia) 387-392, ISBN 978-953-233-093-9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04989</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Excitable behaviors</dc:title>
 <dc:creator>Sepulchre, Rodolphe</dc:creator>
 <dc:creator>Drion, Guillaume</dc:creator>
 <dc:creator>Franci, Alessio</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This chapter revisits the concept of excitability, a basic system property of
neurons. The focus is on excitable systems regarded as behaviors rather than
dynamical systems. By this we mean open systems modulated by specific
interconnection properties rather than closed systems classified by their
parameter ranges. Modeling, analysis, and synthesis questions can be formulated
in the classical language of circuit theory. The input-output characterization
of excitability is in terms of the local sensitivity of the current-voltage
relationship. It suggests the formulation of novel questions for non-linear
system theory, inspired by questions from experimental neurophysiology.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04989</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04997</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multimodal Prediction and Personalization of Photo Edits with Deep
  Generative Models</dc:title>
 <dc:creator>Saeedi, Ardavan</dc:creator>
 <dc:creator>Hoffman, Matthew D.</dc:creator>
 <dc:creator>DiVerdi, Stephen J.</dc:creator>
 <dc:creator>Ghandeharioun, Asma</dc:creator>
 <dc:creator>Johnson, Matthew J.</dc:creator>
 <dc:creator>Adams, Ryan P.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Professional-grade software applications are powerful but
complicated$-$expert users can achieve impressive results, but novices often
struggle to complete even basic tasks. Photo editing is a prime example: after
loading a photo, the user is confronted with an array of cryptic sliders like
&quot;clarity&quot;, &quot;temp&quot;, and &quot;highlights&quot;. An automatically generated suggestion
could help, but there is no single &quot;correct&quot; edit for a given image$-$different
experts may make very different aesthetic decisions when faced with the same
image, and a single expert may make different choices depending on the intended
use of the image (or on a whim). We therefore want a system that can propose
multiple diverse, high-quality edits while also learning from and adapting to a
user's aesthetic preferences. In this work, we develop a statistical model that
meets these objectives. Our model builds on recent advances in neural network
generative modeling and scalable inference, and uses hierarchical structure to
learn editing patterns across many diverse users. Empirically, we find that our
model outperforms other approaches on this challenging multimodal prediction
task.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04998</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interval Arithmetic and Interval-Aware Operators for Genetic Programming</dc:title>
 <dc:creator>Dick, Grant</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Symbolic regression via genetic programming is a flexible approach to machine
learning that does not require up-front specification of model structure.
However, traditional approaches to symbolic regression require the use of
protected operators, which can lead to perverse model characteristics and poor
generalisation. In this paper, we revisit interval arithmetic as one possible
solution to allow genetic programming to perform regression using unprotected
operators. Using standard benchmarks, we show that using interval arithmetic
within model evaluation does not prevent invalid solutions from entering the
population, meaning that search performance remains compromised. We extend the
basic interval arithmetic concept with `safe' search operators that integrate
interval information into their process, thereby greatly reducing the number of
invalid solutions produced during search. The resulting algorithms are able to
more effectively identify good models that generalise well to unseen data. We
conclude with an analysis of the sensitivity of interval arithmetic-based
operators with respect to the accuracy of the supplied input feature intervals.
</dc:description>
 <dc:description>Comment: Extended version of: Grant Dick. 2017. Revisiting Interval Arithmetic
  for Regression Problems in Genetic Programming. In Proceedings of the 2017
  Annual Conference on Genetic and Evolutionary Computation. ACM. To appear 8
  pages, 10 figures</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.04998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05003</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Strong Determinacy of Countable Stochastic Games</dc:title>
 <dc:creator>Kiefer, Stefan</dc:creator>
 <dc:creator>Mayr, Richard</dc:creator>
 <dc:creator>Shirmohammadi, Mahsa</dc:creator>
 <dc:creator>Wojtczak, Dominik</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>91A15</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  We study 2-player turn-based perfect-information stochastic games with
countably infinite state space. The players aim at maximizing/minimizing the
probability of a given event (i.e., measurable set of infinite plays), such as
reachability, B\&quot;uchi, omega-regular or more general objectives.
  These games are known to be weakly determined, i.e., they have value.
However, strong determinacy of threshold objectives (given by an event and a
threshold $c \in [0,1]$) was open in many cases: is it always the case that the
maximizer or the minimizer has a winning strategy, i.e., one that enforces,
against all strategies of the other player, that the objective is satisfied
with probability $\ge c$ (resp. $&lt; c$)?
  We show that almost-sure objectives (where $c=1$) are strongly determined.
This vastly generalizes a previous result on finite games with almost-sure tail
objectives. On the other hand we show that $\ge 1/2$ (co-)B\&quot;uchi objectives
are not strongly determined, not even if the game is finitely branching.
  Moreover, for almost-sure reachability and almost-sure B\&quot;uchi objectives in
finitely branching games, we strengthen strong determinacy by showing that one
of the players must have a memoryless deterministic (MD) winning strategy.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05003</dc:identifier>
 <dc:identifier>LICS 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05004</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CUP: Comprehensive User-Space Protection for C/C++</dc:title>
 <dc:creator>Burow, Nathan</dc:creator>
 <dc:creator>McKee, Derrick</dc:creator>
 <dc:creator>Carr, Scott A.</dc:creator>
 <dc:creator>Payer, Mathias</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Memory corruption vulnerabilities in C/C++ applications enable attackers to
execute code, change data, and leak information. Current memory sanitizers do
no provide comprehensive coverage of a program's data. In particular, existing
tools focus primarily on heap allocations with limited support for stack
allocations and globals. Additionally, existing tools focus on the main
executable with limited support for system libraries. Further, they suffer from
both false positives and false negatives.
  We present Comprehensive User-Space Protection for C/C++, CUP, an LLVM
sanitizer that provides complete spatial and probabilistic temporal memory
safety for C/C++ program on 64-bit architectures (with a prototype
implementation for x86_64). CUP uses a hybrid metadata scheme that supports all
program data including globals, heap, or stack and maintains the ABI. Compared
to existing approaches with the NIST Juliet test suite, CUP reduces false
negatives by 10x (0.1%) compared to the state of the art LLVM sanitizers, and
produces no false positives. CUP instruments all user-space code, including
libc and other system libraries, removing them from the trusted code base.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05007</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low Complexity Coefficient Selection Algorithms for Compute-and-Forward</dc:title>
 <dc:creator>Huang, Qinhui</dc:creator>
 <dc:creator>Burr, Alister</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Compute-and-Forward (C&amp;F) has been proposed as an efficient strategy to
reduce the backhaul load for the distributed antenna systems. Finding the
optimal coefficients in C&amp;F has commonly been treated as a shortest vector
problem (SVP), which is N-P hard. The point of our work and of Sahraei's recent
work is that the C&amp;F coefficient problem can be much simpler. Due to the
special structure of C&amp;F, some low polynomial complexity optimal algorithms
have recently been developed. However these methods can be applied to real
valued channels and integer based lattices only. In this paper, we consider the
complex valued channel with complex integer based lattices. For the first time,
we propose a low polynomial complexity algorithm to find the optimal solution
for the complex scenario. Then we propose a simple linear search algorithm
which is conceptually suboptimal, however numerical results show that the
performance degradation is negligible compared to the optimal method. Both
algorithms are suitable for lattices over any algebraic integers, and
significantly outperform the lattice reduction algorithm. The complexity of
both algorithms are investigated both theoretically and numerically. The
results show that our proposed algorithms achieve better performance-complexity
trade-offs compared to the existing algorithms.
</dc:description>
 <dc:description>Comment: 10 pages, 10 figures</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05008</identifier>
 <datestamp>2017-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Initial steps towards assessing the usability of a verification tool</dc:title>
 <dc:creator>Khazeev, Mansur</dc:creator>
 <dc:creator>Rivera, Victor</dc:creator>
 <dc:creator>Mazzara, Manuel</dc:creator>
 <dc:creator>Johard, Leonard</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In this paper we report the experience of using AutoProof to statically
verify a small object oriented program. We identified the problems that emerged
by this activity and we classified them according to their nature. In
particular, we distinguish between tool-related and methodology-related issues,
and propose necessary changes to simplify both tool and method.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-06-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05012</identifier>
 <datestamp>2017-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial Opinion Dynamics and the Effects of Two Types of Mixing</dc:title>
 <dc:creator>Baumgaertner, Bert O.</dc:creator>
 <dc:creator>Tyson, Rebecca C.</dc:creator>
 <dc:creator>Krone, Stephen M.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Spatially-situated opinions that can be held with different degrees of
conviction lead to spatio-temporal patterns such as clustering (homophily),
polarization, and deadlock. Our goal is to understand how sensitive these
patterns are to changes in the local nature of interactions. We introduce two
different mixing mechanisms: spatial relocation and non-local interaction
(&quot;telephoning&quot;). Interestingly, the mechanisms that create deadlock in the
spatial model have the opposite affect when there is a sufficient amount of
telephoning: not only is polarization and deadlock broken up, but consensus is
hastened. The effects of mixing by relocation are even more pronounced. Further
insight into these dynamics is obtained for selected parameter regimes via
comparison to the mean-field differential equations.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05016</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CNN Feature boosted SeqSLAM for Real-Time Loop Closure Detection</dc:title>
 <dc:creator>Bai, Dongdong</dc:creator>
 <dc:creator>Wang, Chaoqun</dc:creator>
 <dc:creator>Zhang, Bo</dc:creator>
 <dc:creator>Yi, Xiaodong</dc:creator>
 <dc:creator>Yang, Xuejun</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Loop closure detection (LCD) is an indispensable part of simultaneous
localization and mapping systems (SLAM); it enables robots to produce a
consistent map by recognizing previously visited places. When robots operate
over extended periods, robustness to viewpoint and condition changes as well as
satisfactory real-time performance become essential requirements for a
practical LCD system.
  This paper presents an approach to directly utilize the outputs at the
intermediate layer of a pre-trained convolutional neural network (CNN) as image
descriptors. The matching location is determined by matching the image
sequences through a method called SeqCNNSLAM. The utility of SeqCNNSLAM is
comprehensively evaluated in terms of viewpoint and condition invariance.
Experiments show that SeqCNNSLAM outperforms state-of-the-art LCD systems, such
as SeqSLAM and Change Removal, in most cases. To allow for the real-time
performance of SeqCNNSLAM, an acceleration method, A-SeqCNNSLAM, is
established. This method exploits the location relationship between the
matching images of adjacent images to reduce the matching range of the current
image. Results demonstrate that acceleration of 4-6 is achieved with minimal
accuracy degradation, and the method's runtime satisfies the real-time demand.
To extend the applicability of A-SeqCNNSLAM to new environments, a method
called O-SeqCNNSLAM is established for the online adjustment of the parameters
of A-SeqCNNSLAM.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05017</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Morpheo: Traceable Machine Learning on Hidden data</dc:title>
 <dc:creator>Galtier, Mathieu</dc:creator>
 <dc:creator>Marini, Camille</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Morpheo is a transparent and secure machine learning platform collecting and
analysing large datasets. It aims at building state-of-the art prediction
models in various fields where data are sensitive. Indeed, it offers strong
privacy of data and algorithm, by preventing anyone to read the data, apart
from the owner and the chosen algorithms. Computations in Morpheo are
orchestrated by a blockchain infrastructure, thus offering total traceability
of operations. Morpheo aims at building an attractive economic ecosystem around
data prediction by channelling crypto-money from prediction requests to useful
data and algorithms providers. Morpheo is designed to handle multiple data
sources in a transfer learning approach in order to mutualize knowledge
acquired from large datasets for applications with smaller but similar
datasets.
</dc:description>
 <dc:description>Comment: whitepaper, 9 pages, 6 figures</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05020</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-end 3D face reconstruction with deep neural networks</dc:title>
 <dc:creator>Dou, Pengfei</dc:creator>
 <dc:creator>Shah, Shishir K.</dc:creator>
 <dc:creator>Kakadiaris, Ioannis A.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Monocular 3D facial shape reconstruction from a single 2D facial image has
been an active research area due to its wide applications. Inspired by the
success of deep neural networks (DNN), we propose a DNN-based approach for
End-to-End 3D FAce Reconstruction (UH-E2FAR) from a single 2D image. Different
from recent works that reconstruct and refine the 3D face in an iterative
manner using both an RGB image and an initial 3D facial shape rendering, our
DNN model is end-to-end, and thus the complicated 3D rendering process can be
avoided. Moreover, we integrate in the DNN architecture two components, namely
a multi-task loss function and a fusion convolutional neural network (CNN) to
improve facial expression reconstruction. With the multi-task loss function, 3D
face reconstruction is divided into neutral 3D facial shape reconstruction and
expressive 3D facial shape reconstruction. The neutral 3D facial shape is
class-specific. Therefore, higher layer features are useful. In comparison, the
expressive 3D facial shape favors lower or intermediate layer features. With
the fusion-CNN, features from different intermediate layers are fused and
transformed for predicting the 3D expressive facial shape. Through extensive
experiments, we demonstrate the superiority of our end-to-end framework in
improving the accuracy of 3D face reconstruction.
</dc:description>
 <dc:description>Comment: Accepted to CVPR17</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05021</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Communication for Distributed Gradient Descent</dc:title>
 <dc:creator>Aji, Alham Fikri</dc:creator>
 <dc:creator>Heafield, Kenneth</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We make distributed stochastic gradient descent faster by exchanging sparse
updates instead of dense updates. Gradient updates are positively skewed as
most updates are near zero, so we map the 99% smallest updates (by absolute
value) to zero then exchange sparse matrices. This method can be combined with
quantization to further improve the compression. We explore different
configurations and apply them to neural machine translation and MNIST image
classification tasks. Most configurations work on MNIST, whereas different
configurations reduce convergence rate on the more complex translation task.
Our experiments show that we can achieve up to 49% speed up on MNIST and 22% on
NMT without damaging the final accuracy or BLEU.
</dc:description>
 <dc:description>Comment: EMNLP 2017</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05027</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Multi-Unit Mechanisms with Private Demands</dc:title>
 <dc:creator>Devanur, Nikhil R.</dc:creator>
 <dc:creator>Haghpanah, Nima</dc:creator>
 <dc:creator>Psomas, Christos-Alexandros</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In the multi-unit pricing problem, multiple units of a single item are for
sale. A buyer's valuation for $n$ units of the item is $v \min \{ n, d\} $,
where the per unit valuation $v$ and the capacity $d$ are private information
of the buyer. We consider this problem in the Bayesian setting, where the pair
$(v,d)$ is drawn jointly from a given probability distribution. In the
\emph{unlimited supply} setting, the optimal (revenue maximizing) mechanism is
a pricing problem, i.e., it is a menu of lotteries. In this paper we show that
under a natural regularity condition on the probability distributions, which we
call \emph{decreasing marginal revenue}, the optimal pricing is in fact
\emph{deterministic}. It is a price curve, offering $i$ units of the item for a
price of $p_i$, for every integer $i$. Further, we show that the revenue as a
function of the prices $p_i$ is a \emph{concave} function, which implies that
the optimum price curve can be found in polynomial time. This gives a rare
example of a natural multi-parameter setting where we can show such a clean
characterization of the optimal mechanism. We also give a more detailed
characterization of the optimal prices for the case where there are only two
possible demands.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05041</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast multi-output relevance vector regression</dc:title>
 <dc:creator>Ha, Youngmin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper aims to decrease the time complexity of multi-output relevance
vector regression from O(VM^3) to O(V^3+M^3), where V is the number of output
dimensions, M is the number of basis functions, and V&lt;M. The experimental
results demonstrate that the proposed method is more competitive than the
existing method, with regard to computation time. MATLAB codes are available at
http://www.mathworks.com/matlabcentral/fileexchange/49131.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05044</identifier>
 <datestamp>2017-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Study on Performance and Power Efficiency of Dense Non-Volatile Caches
  in Multi-Core Systems</dc:title>
 <dc:creator>Jadidi, Amin</dc:creator>
 <dc:creator>Arjomand, Mohammad</dc:creator>
 <dc:creator>Kandemir, Mahmut T.</dc:creator>
 <dc:creator>Das, Chita R.</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  In this paper, we present a novel cache design based on Multi-Level Cell
Spin-Transfer Torque RAM (MLC STTRAM) that can dynamically adapt the set
capacity and associativity to use efficiently the full potential of MLC STTRAM.
We exploit the asymmetric nature of the MLC storage scheme to build cache lines
featuring heterogeneous performances, that is, half of the cache lines are
read-friendly, while the other is write-friendly. Furthermore, we propose to
opportunistically deactivate ways in underutilized sets to convert MLC to
Single-Level Cell (SLC) mode, which features overall better performance and
lifetime. Our ultimate goal is to build a cache architecture that combines the
capacity advantages of MLC and performance/energy advantages of SLC. Our
experiments show an improvement of 43% in total numbers of conflict misses, 27%
in memory access latency, 12% in system performance, and 26% in LLC access
energy, with a slight degradation in cache lifetime (about 7%) compared to an
SLC cache.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05044</dc:identifier>
 <dc:identifier>doi:10.1145/3078505.3078547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05051</identifier>
 <datestamp>2017-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Google's Cloud Vision API Is Not Robust To Noise</dc:title>
 <dc:creator>Hosseini, Hossein</dc:creator>
 <dc:creator>Xiao, Baicen</dc:creator>
 <dc:creator>Poovendran, Radha</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Google has recently introduced the Cloud Vision API for image analysis.
According to the demonstration website, the API &quot;quickly classifies images into
thousands of categories, detects individual objects and faces within images,
and finds and reads printed words contained within images.&quot; It can be also used
to &quot;detect different types of inappropriate content from adult to violent
content.&quot;
  In this paper, we evaluate the robustness of Google Cloud Vision API to input
perturbation. In particular, we show that by adding sufficient noise to the
image, the API generates completely different outputs for the noisy image,
while a human observer would perceive its original content. We show that the
attack is consistently successful, by performing extensive experiments on
different image types, including natural images, images containing faces and
images with texts. For instance, using images from ImageNet dataset, we found
that adding an average of 14.25% impulse noise is enough to deceive the API.
Our findings indicate the vulnerability of the API in adversarial environments.
For example, an adversary can bypass an image filtering system by adding noise
to inappropriate images. We then show that when a noise filter is applied on
input images, the API generates mostly the same outputs for restored images as
for original images. This observation suggests that cloud vision API can
readily benefit from noise filtering, without the need for updating image
analysis algorithms.
</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:date>2017-07-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05051</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05084</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conceptual Frameworks for Building Online Citizen Science Projects</dc:title>
 <dc:creator>Yadav, Poonam</dc:creator>
 <dc:creator>Darlington, John</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>K.4.3</dc:subject>
 <dc:description>  In recent years, citizen science has grown in popularity due to a number of
reasons, including the emphasis on informal learning and creativity potential
associated with these initiatives. Citizen science projects address research
questions from various domains, ranging from Ecology to Astronomy. Due to the
advancement of communication technologies, which makes outreach and engagement
of wider communities easier, scientists are keen to turn their own research
into citizen science projects. However, the development, deployment and
management of these projects remains challenging. One of the most important
challenges is building the project itself. There is no single tool or
framework, which guides the step-by-step development of the project, since
every project has specific characteristics, such as geographical constraints or
volunteers' mode of participation. Therefore, in this article, we present a
series of conceptual frameworks for categorisation, decision and deployment,
which guide a citizen science project creator in every step of creating a new
project starting from the research question to project deployment. The
frameworks are designed with consideration to the properties of already
existing citizen science projects and could be easily extended to include other
dimensions, which are not currently perceived.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05084</dc:identifier>
 <dc:identifier>Human Computation (2016) 3:1:213-223 ISSN: 2330-8001, DOI:
  10.15346/hc.v3i1.12</dc:identifier>
 <dc:identifier>doi:10.15346/hc.v3i1.12</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05090</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communication Modalities for Supervised Teleoperation in Highly
  Dexterous Tasks - Does one size fit all?</dc:title>
 <dc:creator>Zhou, Tian</dc:creator>
 <dc:creator>Cabrera, Maria E.</dc:creator>
 <dc:creator>Wachs, Juan P.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This study tries to explain the connection between communication modalities
and levels of supervision in teleoperation during a dexterous task, like
surgery. This concept is applied to two surgical related tasks: incision and
peg transfer. It was found that as the complexity of the task escalates, the
combination linking human supervision with a more expressive modality shows
better performance than other combinations of modalities and control. More
specifically, in the peg transfer task, the combination of speech modality and
action level supervision achieves shorter task completion time (77.1 +- 3.4 s)
with fewer mistakes (0.20 +- 0.17 pegs dropped).
</dc:description>
 <dc:description>Comment: Previously published online at 2nd Workshop on the Role of Human
  Sensormotor Control in Surgical Robotics at 2015 IEEE/RSJ International
  Conference on Intelligent Robots and Systems (IROS), Hamburg, Germany</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05090</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05091</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FEUP at SemEval-2017 Task 5: Predicting Sentiment Polarity and Intensity
  with Financial Word Embeddings</dc:title>
 <dc:creator>Saleiro, Pedro</dc:creator>
 <dc:creator>Rodrigues, Eduarda Mendes</dc:creator>
 <dc:creator>Soares, Carlos</dc:creator>
 <dc:creator>Oliveira, Eug&#xe9;nio</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  This paper presents the approach developed at the Faculty of Engineering of
University of Porto, to participate in SemEval 2017, Task 5: Fine-grained
Sentiment Analysis on Financial Microblogs and News. The task consisted in
predicting a real continuous variable from -1.0 to +1.0 representing the
polarity and intensity of sentiment concerning companies/stocks mentioned in
short texts. We modeled the task as a regression analysis problem and combined
traditional techniques such as pre-processing short texts, bag-of-words
representations and lexical-based features with enhanced financial specific
bag-of-embeddings. We used an external collection of tweets and news headlines
mentioning companies/stocks from S\&amp;P 500 to create financial word embeddings
which are able to capture domain-specific syntactic and semantic similarities.
The resulting approach obtained a cosine similarity score of 0.69 in sub-task
5.1 - Microblogs and 0.68 in sub-task 5.2 - News Headlines.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05112</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Making data center computations fast, but not so furious</dc:title>
 <dc:creator>Porto, Daniel</dc:creator>
 <dc:creator>Loff, Jo&#xe3;o</dc:creator>
 <dc:creator>Duarte, Rui</dc:creator>
 <dc:creator>Ceze, Luis</dc:creator>
 <dc:creator>Rodrigues, Rodrigo</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We propose an aggressive computational sprinting variant for data center
environments. While most of previous work on computational sprinting focuses on
maximizing the sprinting process while ensuring non-faulty conditions, we take
advantage of the existing replication in data centers to push the system beyond
its safety limits. In this paper we outline this vision, we survey existing
techniques for achieving it, and we present some design ideas for future work
in this area.
</dc:description>
 <dc:description>Comment: The 7th Workshop on Multi-core and Rack Scale Systems - MARS'17</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05112</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05119</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring Sparsity in Recurrent Neural Networks</dc:title>
 <dc:creator>Narang, Sharan</dc:creator>
 <dc:creator>Elsen, Erich</dc:creator>
 <dc:creator>Diamos, Gregory</dc:creator>
 <dc:creator>Sengupta, Shubho</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recurrent Neural Networks (RNN) are widely used to solve a variety of
problems and as the quantity of data and the amount of available compute have
increased, so have model sizes. The number of parameters in recent
state-of-the-art networks makes them hard to deploy, especially on mobile
phones and embedded devices. The challenge is due to both the size of the model
and the time it takes to evaluate it. In order to deploy these RNNs
efficiently, we propose a technique to reduce the parameters of a network by
pruning weights during the initial training of the network. At the end of
training, the parameters of the network are sparse while accuracy is still
close to the original dense neural network. The network size is reduced by 8x
and the time required to train the model remains constant. Additionally, we can
prune a larger dense network to achieve better than baseline performance while
still reducing the total number of parameters significantly. Pruning RNNs
reduces the size of the model and can also help achieve significant inference
time speed-up using sparse matrix multiply. Benchmarks show that using our
technique model size can be reduced by 90% and speed-up is around 2x to 7x.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2017</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05119</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05120</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Does robustness imply tractability? A lower bound for planted clique in
  the semi-random model</dc:title>
 <dc:creator>Steinhardt, Jacob</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We consider a robust analog of the planted clique problem. In this analog, a
set $S$ of vertices is chosen and all edges in $S$ are included; then, edges
between $S$ and the rest of the graph are included with probability
$\frac{1}{2}$, while edges not touching $S$ are allowed to vary arbitrarily.
For this semi-random model, we show that the information-theoretic threshold
for recovery is $\tilde{\Theta}(\sqrt{n})$, in sharp contrast to the classical
information-theoretic threshold of $\Theta(\log(n))$. This matches the
conjectured computational threshold for the classical planted clique problem,
and thus raises the intriguing possibility that, once we require robustness,
there is no computational-statistical gap for planted clique.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05120</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05122</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Gabor Filter Texture Analysis Approach for Histopathological Brain
  Tumor Subtype Discrimination</dc:title>
 <dc:creator>Al-Kadi, Omar S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Meningioma brain tumour discrimination is challenging as many histological
patterns are mixed between the different subtypes. In clinical practice,
dominant patterns are investigated for signs of specific meningioma pathology;
however the simple observation could result in inter- and intra-observer
variation due to the complexity of the histopathological patterns. Also
employing a computerised feature extraction approach applied at a single
resolution scale might not suffice in accurately delineating the mixture of
histopathological patterns. In this work we propose a novel multiresolution
feature extraction approach for characterising the textural properties of the
different pathological patterns (i.e. mainly cell nuclei shape, orientation and
spatial arrangement within the cytoplasm). The pattern textural properties are
characterised at various scales and orientations for an improved separability
between the different extracted features. The Gabor filter energy output of
each magnitude response was combined with four other fixed-resolution texture
signatures (2 model-based and 2 statistical-based) with and without cell nuclei
segmentation. The highest classification accuracy of 95% was reported when
combining the Gabor filters energy and the meningioma subimage fractal
signature as a feature vector without performing any prior cell nuceli
segmentation. This indicates that characterising the cell-nuclei
self-similarity properties via Gabor filters can assists in achieving an
improved meningioma subtype classification, which can assist in overcoming
variations in reported diagnosis.
</dc:description>
 <dc:description>Comment: 14 pages,4 figures, 2 tables</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05122</dc:identifier>
 <dc:identifier>ISESCO Journal of Science and Technology, vol. 12, no. 22, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05123</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resolution-Exact Planner for Thick Non-Crossing 2-Link Robots</dc:title>
 <dc:creator>Yap, Chee K.</dc:creator>
 <dc:creator>Luo, Zhongdi</dc:creator>
 <dc:creator>Hsu, Ching-Hsiang</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We consider the path planning problem for a 2-link robot amidst polygonal
obstacles. Our robot is parametrizable by the lengths $\ell_1, \ell_2&gt;0$ of its
two links, the thickness $\tau \ge 0$ of the links, and an angle $\kappa$ that
constrains the angle between the 2 links to be strictly greater than $\kappa$.
The case $\tau&gt;0$ and $\kappa \ge 0$ corresponds to &quot;thick non-crossing&quot;
robots. This results in a novel 4DOF configuration space ${\mathbb R}^2\times
({\mathbb T}\setminus\Delta(\kappa))$ where ${\mathbb T}$ is the torus and
$\Delta(\kappa)$ the diagonal band of width $\kappa$. We design a
resolution-exact planner for this robot using the framework of Soft Subdivision
Search (SSS). First, we provide an analysis of the space of forbidden angles,
leading to a soft predicate for classifying configuration boxes. We further
exploit the T/R splitting technique which was previously introduced for
self-crossing thin 2-link robots. Our open-source implementation in Core
Library achieves real-time performance for a suite of combinatorially
non-trivial obstacle sets. Experimentally, our algorithm is significantly
better than any of the state-of-art sampling algorithms we looked at, in timing
and in success rate.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05123</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05124</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The pebbling comonad in finite model theory</dc:title>
 <dc:creator>Abramsky, Samson</dc:creator>
 <dc:creator>Dawar, Anuj</dc:creator>
 <dc:creator>Wang, Pengming</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Pebble games are a powerful tool in the study of finite model theory,
constraint satisfaction and database theory. Monads and comonads are basic
notions of category theory which are widely used in semantics of computation
and in modern functional programming. We show that existential k-pebble games
have a natural comonadic formulation. Winning strategies for Duplicator in the
k-pebble game for structures A and B are equivalent to morphisms from A to B in
the coKleisli category for this comonad. This leads on to comonadic
characterisations of a number of central concepts in Finite Model Theory: -
Isomorphism in the co-Kleisli category characterises elementary equivalence in
the k-variable logic with counting quantifiers. - Symmetric games corresponding
to equivalence in full k-variable logic are also characterized. - The treewidth
of a structure A is characterised in terms of its coalgebra number: the least k
for which there is a coalgebra structure on A for the k-pebbling comonad. -
Co-Kleisli morphisms are used to characterize strong consistency, and to give
an account of a Cai-F\&quot;urer-Immerman construction. - The k-pebbling comonad is
also used to give semantics to a novel modal operator. These results lay the
basis for some new and promising connections between two areas within logic in
computer science which have largely been disjoint: (1) finite and algorithmic
model theory, and (2) semantics and categorical structures of computation.
</dc:description>
 <dc:description>Comment: To appear in LiCS 2017</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05124</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05125</identifier>
 <datestamp>2017-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Impact of Base Station Antenna Heights in Dense Cellular
  Networks</dc:title>
 <dc:creator>Ding, Ming</dc:creator>
 <dc:creator>Lopez-Perez, David</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we present a new and significant theoretical discovery. If the
absolute height difference between base station (BS) antenna and user equipment
(UE) antenna is larger than zero, then the network performance in terms of both
the coverage probability and the area spectral efficiency (ASE) will
continuously decrease toward zero as the BS density increases for ultra-dense
(UD) small cell networks (SCNs). Such findings are completely different from
the conclusions in existing works, both quantitatively and qualitatively. In
particular, this performance behavior has a tremendous impact on the deployment
of UD SCNs in the 5th-generation (5G) era. Network operators may invest large
amounts of money in deploying more network infrastructure to only obtain an
even less network capacity. Our study results reveal that one way to address
this issue is to lower the SCN BS antenna height to the UE antenna height.
However, this requires a revolutionized approach of BS architecture and
deployment, which is explored in this paper too.
</dc:description>
 <dc:description>Comment: To appear in IEEE TWC</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-09-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05132</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A hybrid CPU-GPU parallelization scheme of variable neighborhood search
  for inventory optimization problems</dc:title>
 <dc:creator>Antoniadis, Nikolaos</dc:creator>
 <dc:creator>Sifaleras, Angelo</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>68R99</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:description>  In this paper, we study various parallelization schemes for the Variable
Neighborhood Search (VNS) metaheuristic on a CPU-GPU system via OpenMP and
OpenACC. A hybrid parallel VNS method is applied to recent benchmark problem
instances for the multi-product dynamic lot sizing problem with product returns
and recovery, which appears in reverse logistics and is known to be NP-hard. We
report our findings regarding these parallelization approaches and present
promising computational results.
</dc:description>
 <dc:description>Comment: 8 pages, 1 figure</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05132</dc:identifier>
 <dc:identifier>Electronic Notes in Discrete Mathematics, Volume 58, April 2017,
  Pages 47-54, ISSN 1571-0653</dc:identifier>
 <dc:identifier>doi:10.1016/j.endm.2017.03.007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05134</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Linear Feature Space Transformations in Symbolic Regression</dc:title>
 <dc:creator>&#x17d;egklitz, Jan</dc:creator>
 <dc:creator>Po&#x161;&#xed;k, Petr</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We propose a new type of leaf node for use in Symbolic Regression (SR) that
performs linear combinations of feature variables (LCF). These nodes can be
handled in three different modes -- an unsynchronized mode, where all LCFs are
free to change on their own, a synchronized mode, where LCFs are sorted into
groups in which they are forced to be identical throughout the whole
individual, and a globally synchronized mode, which is similar to the previous
mode but the grouping is done across the whole population. We also present two
methods of evolving the weights of the LCFs -- a purely stochastic way via
mutation and a gradient-based way based on the backpropagation algorithm known
from neural networks -- and also a combination of both. We experimentally
evaluate all configurations of LCFs in Multi-Gene Genetic Programming (MGGP),
which was chosen as baseline, on a number of benchmarks. According to the
results, we identified two configurations which increase the performance of the
algorithm.
</dc:description>
 <dc:description>Comment: Changed the word &quot;affine&quot; to &quot;linear&quot; in title</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05134</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05135</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Does Neural Machine Translation Benefit from Larger Context?</dc:title>
 <dc:creator>Jean, Sebastien</dc:creator>
 <dc:creator>Lauly, Stanislas</dc:creator>
 <dc:creator>Firat, Orhan</dc:creator>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a neural machine translation architecture that models the
surrounding text in addition to the source sentence. These models lead to
better performance, both in terms of general translation quality and pronoun
prediction, when trained on small corpora, although this improvement largely
disappears when trained with a larger corpus. We also discover that
attention-based neural machine translation is well suited for pronoun
prediction and compares favorably with other approaches that were specifically
designed for this task.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05135</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05136</identifier>
 <datestamp>2017-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Causality/Repair Connection in Databases: Causality-Programs</dc:title>
 <dc:creator>Bertossi, Leopoldo</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this work, answer-set programs that specify repairs of databases are used
as a basis for solving computational and reasoning problems about causes for
query answers from databases.
</dc:description>
 <dc:description>Comment: To appear in Proc. SUM'17 as short paper, 7-pages</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-06-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05138</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Data Longevity for Enhancing the Lifetime of Flash-based
  Storage Class Memory</dc:title>
 <dc:creator>Choi, Wonil</dc:creator>
 <dc:creator>Arjomand, Mohammad</dc:creator>
 <dc:creator>Jung, Myoungsoo</dc:creator>
 <dc:creator>Kandemir, Mahmut</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Storage-class memory (SCM) combines the benefits of a solid-state memory,
such as high-performance and robustness, with the archival capabilities and low
cost of conventional hard-disk magnetic storage. Among candidate solid-state
nonvolatile memory technologies that could potentially be used to construct
SCM, flash memory is a well-established technology and have been widely used in
commercially available SCM incarnations. Flash-based SCM enables much better
tradeoffs between performance, space and power than disk-based systems.
However, write endurance is a significant challenge for a flash-based SCM (each
act of writing a bit may slightly damage a cell, so one flash cell can be
written 10^4--10^5 times, depending on the flash technology, before it becomes
unusable). This is a well-documented problem and has received a lot of
attention by manufactures that are using some combination of write reduction
and wear-leveling techniques for achieving longer lifetime. In an effort to
improve flash lifetime, first, by quantifying data longevity in an SCM, we show
that a majority of the data stored in a solid-state SCM do not require long
retention times provided by flash memory (i.e., up to 10 years in modern
devices); second, by exploiting retention time relaxation, we propose a novel
mechanism, called Dense-SLC (D-SLC), which enables us perform multiple writes
into a cell during each erase cycle for lifetime extension; and finally, we
discuss the required changes in the flash management software (FTL) in order to
use this characteristic for extending the lifetime of the solid-state part of
an SCM. Using an extensive simulation-based analysis of a flash-based SCM, we
demonstrate that D-SLC is able to significantly improve device lifetime
(between 5.1X and 8.6X) with no performance overhead and also very small
changes at the FTL software.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05138</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05143</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Emergence of Canalization and Evolvability in an Open-Ended,
  Interactive Evolutionary System</dc:title>
 <dc:creator>Huizinga, Joost</dc:creator>
 <dc:creator>Stanley, Kenneth O.</dc:creator>
 <dc:creator>Clune, Jeff</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Natural evolution has produced a tremendous diversity of functional
organisms. Many believe an essential component of this process was the
evolution of evolvability, whereby evolution speeds up its ability to innovate
by generating a more adaptive pool of offspring. One hypothesized mechanism for
evolvability is developmental canalization, wherein certain dimensions of
variation become more likely to be traversed and others are prevented from
being explored (e.g. offspring tend to have similarly sized legs, and mutations
affect the length of both legs, not each leg individually). While ubiquitous in
nature, canalization almost never evolves in computational simulations of
evolution. Not only does that deprive us of in silico models in which to study
the evolution of evolvability, but it also raises the question of which
conditions give rise to this form of evolvability. Answering this question
would shed light on why such evolvability emerged naturally and could
accelerate engineering efforts to harness evolution to solve important
engineering challenges. In this paper we reveal a unique system in which
canalization did emerge in computational evolution. We document that genomes
entrench certain dimensions of variation that were frequently explored during
their evolutionary history. The genetic representation of these organisms also
evolved to be highly modular and hierarchical, and we show that these
organizational properties correlate with increased fitness. Interestingly, the
type of computational evolutionary experiment that produced this evolvability
was very different from traditional digital evolution in that there was no
objective, suggesting that open-ended, divergent evolutionary processes may be
necessary for the evolution of evolvability.
</dc:description>
 <dc:description>Comment: SI can be found at: http://www.evolvingai.org/files/SI.zip</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05143</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05146</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Predicting Geolocation of Tweets using Convolutional Neural Networks</dc:title>
 <dc:creator>Huang, Binxuan</dc:creator>
 <dc:creator>Carley, Kathleen M.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In many Twitter studies, it is important to know where a tweet came from in
order to use the tweet content to study regional user behavior. However,
researchers using Twitter to understand user behavior often lack sufficient
geo-tagged data. Given the huge volume of Twitter data there is a need for
accurate automated geolocating solutions. Herein, we present a new method to
predict a Twitter user's location based on the information in a single tweet.
We integrate text and user profile meta-data into a single model using a
convolutional neural network. Our experiments demonstrate that our neural model
substantially outperforms baseline methods, achieving 52.8% accuracy and 92.1%
accuracy on city-level and country-level prediction respectively.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05146</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-60240-0_34</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05147</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>O$^2$TD: (Near)-Optimal Off-Policy TD Learning</dc:title>
 <dc:creator>Liu, Bo</dc:creator>
 <dc:creator>Lyu, Daoming</dc:creator>
 <dc:creator>Dong, Wen</dc:creator>
 <dc:creator>Biaz, Saad</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Temporal difference learning and Residual Gradient methods are the most
widely used temporal difference based learning algorithms; however, it has been
shown that none of their objective functions is optimal w.r.t approximating the
true value function $V$. Two novel algorithms are proposed to approximate the
true value function $V$. This paper makes the following contributions: (1) A
batch algorithm that can help find the approximate optimal off-policy
prediction of the true value function $V$. (2) A linear computational cost (per
step) near-optimal algorithm that can learn from a collection of off-policy
samples. (3) A new perspective of the emphatic temporal difference learning
which bridges the gap between off-policy optimality and off-policy stability.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05147</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05150</identifier>
 <datestamp>2017-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Century of Science: Globalization of Scientific Collaborations,
  Citations, and Innovations</dc:title>
 <dc:creator>Dong, Yuxiao</dc:creator>
 <dc:creator>Ma, Hao</dc:creator>
 <dc:creator>Shen, Zhihong</dc:creator>
 <dc:creator>Wang, Kuansan</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Progress in science has advanced the development of human society across
history, with dramatic revolutions shaped by information theory, genetic
cloning, and artificial intelligence, among the many scientific achievements
produced in the 20th century. However, the way that science advances itself is
much less well-understood. In this work, we study the evolution of scientific
development over the past century by presenting an anatomy of 89 million
digitalized papers published between 1900 and 2015. We find that science has
benefited from the shift from individual work to collaborative effort, with
over 90% of the world-leading innovations generated by collaborations in this
century, nearly four times higher than they were in the 1900s. We discover that
rather than the frequent myopic- and self-referencing that was common in the
early 20th century, modern scientists instead tend to look for literature
further back and farther around. Finally, we also observe the globalization of
scientific development from 1900 to 2015, including 25-fold and 7-fold
increases in international collaborations and citations, respectively, as well
as a dramatic decline in the dominant accumulation of citations by the US, the
UK, and Germany, from ~95% to ~50% over the same period. Our discoveries are
meant to serve as a starter for exploring the visionary ways in which science
has developed throughout the past century, generating insight into and an
impact upon the current scientific innovations and funding policies.
</dc:description>
 <dc:description>Comment: KDD'17: The 23rd ACM SIGKDD International Conference on Knowledge
  Discovery and Data Mining</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-10-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05150</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05155</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>VAE Learning via Stein Variational Gradient Descent</dc:title>
 <dc:creator>Pu, Yunchen</dc:creator>
 <dc:creator>Gan, Zhe</dc:creator>
 <dc:creator>Henao, Ricardo</dc:creator>
 <dc:creator>Li, Chunyuan</dc:creator>
 <dc:creator>Han, Shaobo</dc:creator>
 <dc:creator>Carin, Lawrence</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A new method for learning variational autoencoders (VAEs) is developed, based
on Stein variational gradient descent. A key advantage of this approach is that
one need not make parametric assumptions about the form of the encoder
distribution. Performance is further enhanced by integrating the proposed
encoder with importance sampling. Excellent performance is demonstrated across
multiple unsupervised and semi-supervised problems, including semi-supervised
analysis of the ImageNet data, demonstrating the scalability of the model to
large datasets.
</dc:description>
 <dc:description>Comment: Accepted to NIPS 2017</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05155</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05159</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Analysis of Slotted Secondary Transmission with Adaptive
  Modulation under Interweave Cognitive Radio Implementation</dc:title>
 <dc:creator>Wang, Wen-Jing</dc:creator>
 <dc:creator>Yang, Hong-Chuan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In cognitive radio communication, unlicensed secondary user (SU) can access
under-utilized spectrum of the licensed primary user (PU) opportunistically for
emerging wireless applications. With interweave implementation, SU has to
perform spectrum sensing on the target frequency band and waits for
transmission if PU occupies the channel. This waiting time results in extra
delay for secondary transmission. In this paper, the delay and throughput
performance of secondary packet transmission is evaluated with slotted
transmission protocol. We propose a discrete-time Markov model to characterize
secondary slotted transmission process. Close-form solution of collision
probability is obtained. We then carry out the queuing delay and throughput
analysis based on a two-dimensional-finite-state Markov chain for small-size
packet transmission. For large-size packets, the distribution function of
extended delivery time for secondary packet transmission is also derived.
Selected numerical results are presented to illustrate the mathematical
formulas and to validate our research results.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05162</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Disambiguation of French Discourse Connectives</dc:title>
 <dc:creator>Laali, Majid</dc:creator>
 <dc:creator>Kosseim, Leila</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Discourse connectives (e.g. however, because) are terms that can explicitly
convey a discourse relation within a text. While discourse connectives have
been shown to be an effective clue to automatically identify discourse
relations, they are not always used to convey such relations, thus they should
first be disambiguated between discourse-usage non-discourse-usage. In this
paper, we investigate the applicability of features proposed for the
disambiguation of English discourse connectives for French. Our results with
the French Discourse Treebank (FDTB) show that syntactic and lexical features
developed for English texts are as effective for French and allow the
disambiguation of French discourse connectives with an accuracy of 94.2%.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05162</dc:identifier>
 <dc:identifier>International Journal of Computational Linguistics and
  Applications, vol. 7, no. 1, 2016, pp. 11-30</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05165</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Video Object Segmentation using Supervoxel-Based Gerrymandering</dc:title>
 <dc:creator>Griffin, Brent A.</dc:creator>
 <dc:creator>Corso, Jason J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Pixels operate locally. Superpixels have some potential to collect
information across many pixels; supervoxels have more potential by implicitly
operating across time. In this paper, we explore this well established notion
thoroughly analyzing how supervoxels can be used in place of and in conjunction
with other means of aggregating information across space-time. Focusing on the
problem of strictly unsupervised video object segmentation, we devise a method
called supervoxel gerrymandering that links masks of foregroundness and
backgroundness via local and non-local consensus measures. We pose and answer a
series of critical questions about the ability of supervoxels to adequately
sway local voting; the questions regard type and scale of supervoxels as well
as local versus non-local consensus, and the questions are posed in a general
way so as to impact the broader knowledge of the use of supervoxels in video
understanding. We work with the DAVIS dataset and find that our analysis yields
an unsupervised method that outperforms all other known unsupervised methods
and even many supervised ones.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05165</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05169</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings 8th Workshop on Developments in Implicit Computational
  Complexity and 5th Workshop on Foundational and Practical Aspects of Resource
  Analysis</dc:title>
 <dc:creator>Bonfante, Guillaume</dc:creator>
 <dc:creator>Moser, Georg</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The DICE workshop explores the area of Implicit Computational Complexity
(ICC), which grew out from several proposals to use logic and formal methods to
provide languages for complexity-bounded computation (e.g. Ptime, Logspace
computation). It aims at studying the computational complexity of programs
without referring to external measuring conditions or a particular machine
model, but only by considering language restrictions or logical/computational
principles entailing complexity properties.
  The FOPARA workshop serves as a forum for presenting original research
results that are relevant to the analysis of resource (e.g. time, space,
energy) consumption by computer programs. The workshop aims to bring together
the researchers that work on foundational issues with the researchers that
focus more on practical results. Therefore, both theoretical and practical
contributions are encouraged. We also encourage papers that combine theory and
practice.
  Given the complementarity and the synergy between these two communities, and
following the successful experience of co-location of DICE-FOPARA 2015 in
London at ETAPS 2015, we hold these two workshops together at ETAPS 2017, which
takes place in Uppsala, Sweden. The provided proceedings collect the papers
accepted at the workshop.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05169</dc:identifier>
 <dc:identifier>EPTCS 248, 2017</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.248</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05174</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LibOPT: An Open-Source Platform for Fast Prototyping Soft Optimization
  Techniques</dc:title>
 <dc:creator>Papa, Joao Paulo</dc:creator>
 <dc:creator>Rosa, Gustavo Henrique</dc:creator>
 <dc:creator>Rodrigues, Douglas</dc:creator>
 <dc:creator>Yang, Xin-She</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Optimization techniques play an important role in several scientific and
real-world applications, thus becoming of great interest for the community. As
a consequence, a number of open-source libraries are available in the
literature, which ends up fostering the research and development of new
techniques and applications. In this work, we present a new library for the
implementation and fast prototyping of nature-inspired techniques called
LibOPT. Currently, the library implements 15 techniques and 112 benchmarking
functions, as well as it also supports 11 hypercomplex-based optimization
approaches, which makes it one of the first of its kind. We showed how one can
easily use and also implement new techniques in LibOPT under the C paradigm.
Examples are provided with samples of source-code using benchmarking functions.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05179</identifier>
 <datestamp>2017-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SearchQA: A New Q&amp;A Dataset Augmented with Context from a Search Engine</dc:title>
 <dc:creator>Dunn, Matthew</dc:creator>
 <dc:creator>Sagun, Levent</dc:creator>
 <dc:creator>Higgins, Mike</dc:creator>
 <dc:creator>Guney, V. Ugur</dc:creator>
 <dc:creator>Cirik, Volkan</dc:creator>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We publicly release a new large-scale dataset, called SearchQA, for machine
comprehension, or question-answering. Unlike recently released datasets, such
as DeepMind CNN/DailyMail and SQuAD, the proposed SearchQA was constructed to
reflect a full pipeline of general question-answering. That is, we start not
from an existing article and generate a question-answer pair, but start from an
existing question-answer pair, crawled from J! Archive, and augment it with
text snippets retrieved by Google. Following this approach, we built SearchQA,
which consists of more than 140k question-answer pairs with each pair having
49.6 snippets on average. Each question-answer-context tuple of the SearchQA
comes with additional meta-data such as the snippet's URL, which we believe
will be valuable resources for future research. We conduct human evaluation as
well as test two baseline methods, one simple word selection and the other deep
learning based, on the SearchQA. We show that there is a meaningful gap between
the human and machine performances. This suggests that the proposed dataset
could well serve as a benchmark for question-answering.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-06-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05181</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>&quot;Short-Dot&quot;: Computing Large Linear Transforms Distributedly Using Coded
  Short Dot Products</dc:title>
 <dc:creator>Dutta, Sanghamitra</dc:creator>
 <dc:creator>Cadambe, Viveck</dc:creator>
 <dc:creator>Grover, Pulkit</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Faced with saturation of Moore's law and increasing dimension of data, system
designers have increasingly resorted to parallel and distributed computing.
However, distributed computing is often bottle necked by a small fraction of
slow processors called &quot;stragglers&quot; that reduce the speed of computation
because the fusion node has to wait for all processors to finish. To combat the
effect of stragglers, recent literature introduces redundancy in computations
across processors, e.g.,~using repetition-based strategies or erasure codes.
The fusion node can exploit this redundancy by completing the computation using
outputs from only a subset of the processors, ignoring the stragglers. In this
paper, we propose a novel technique -- that we call &quot;Short-Dot&quot; -- to introduce
redundant computations in a coding theory inspired fashion, for computing
linear transforms of long vectors. Instead of computing long dot products as
required in the original linear transform, we construct a larger number of
redundant and short dot products that can be computed faster and more
efficiently at individual processors. In reference to comparable schemes that
introduce redundancy to tackle stragglers, Short-Dot reduces the cost of
computation, storage and communication since shorter portions are stored and
computed at each processor, and also shorter portions of the input is
communicated to each processor. We demonstrate through probabilistic analysis
as well as experiments that Short-Dot offers significant speed-up compared to
existing techniques. We also derive trade-offs between the length of the
dot-products and the resilience to stragglers (number of processors to wait
for), for any such strategy and compare it to that achieved by our strategy.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016, Barcelona, Spain</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05181</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05183</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Satellite Based Positioning Signal Acquisition at Higher Order Cycle
  Frequency</dc:title>
 <dc:creator>Wong, Pengda</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The acquisition of the signal from the satellite based positioning systems,
such as GPS, Galileo, and Compass, encounters challenges in the urban streets,
indoor. For improving the acquisition performance, the data accumulation is
usually performed to improve the signal-to-noise ratio which is defined on the
second order statistics. Different from the conventional approaches, the
acquisition based on higher order cyclostatistics is proposed. Using the
cyclostatistics, the estimation of the initial phase and Doppler shift of the
signal is presented respectively. Afterwards, a joint estimator is introduced.
The analysis in this paper is performed on GPS signal. Indeed, the proposed
estimation method can be straightforwardly extended to acquire the signal from
the other satellite positioning systems. The simulation and experiment results
demonstrate that the proposed signal acquisition scheme achieves the detection
probability of 0.9 at the CNR 28dBHz.
</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05183</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05186</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capacity of Cellular Wireless Network</dc:title>
 <dc:creator>Vaze, Rahul</dc:creator>
 <dc:creator>Iyer, Srikanth</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Earlier definitions of capacity for wireless networks, e.g., transport or
transmission capacity, for which exact theoretical results are known, are well
suited for ad hoc networks but are not directly applicable for cellular
wireless networks, where large-scale basestation (BS) coordination is not
possible, and retransmissions/ARQ under the SINR model is a universal feature.
  In this paper, cellular wireless networks, where both BS locations and mobile
user (MU) locations are distributed as independent Poisson point processes are
considered, and each MU connects to its nearest BS. With ARQ, under the SINR
model, the effective downlink rate of packet transmission is the reciprocal of
the expected delay (number of retransmissions needed till success), which we
use as our network capacity definition after scaling it with the BS density.
  Exact characterization of this natural capacity metric for cellular wireless
networks is derived. The capacity is shown to first increase polynomially with
the BS density in the low BS density regime and then scale inverse
exponentially with the increasing BS density. Two distinct upper bounds are
derived that are relevant for the low and the high BS density regimes. A single
power control strategy is shown to achieve the upper bounds in both the
regimes. This result is fundamentally different from the well known capacity
results for ad hoc networks, such as transport and transmission capacity that
scale as the square root of the (high) BS density. Our results show that the
strong temporal correlations of SINRs with PPP distributed BS locations is
limiting, and the realizable capacity in cellular wireless networks in high-BS
density regime is much smaller than previously thought. A byproduct of our
analysis shows that the capacity of the ALOHA strategy with retransmissions is
zero.
</dc:description>
 <dc:description>Comment: A shorter version to appear in WiOpt 2017</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05186</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05188</identifier>
 <datestamp>2017-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Self-Taught Learning for Weakly Supervised Object Localization</dc:title>
 <dc:creator>Jie, Zequn</dc:creator>
 <dc:creator>Wei, Yunchao</dc:creator>
 <dc:creator>Jin, Xiaojie</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:creator>Liu, Wei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Most existing weakly supervised localization (WSL) approaches learn detectors
by finding positive bounding boxes based on features learned with image-level
supervision. However, those features do not contain spatial location related
information and usually provide poor-quality positive samples for training a
detector. To overcome this issue, we propose a deep self-taught learning
approach, which makes the detector learn the object-level features reliable for
acquiring tight positive samples and afterwards re-train itself based on them.
Consequently, the detector progressively improves its detection ability and
localizes more informative positive samples. To implement such self-taught
learning, we propose a seed sample acquisition method via image-to-object
transferring and dense subgraph discovery to find reliable positive samples for
initializing the detector. An online supportive sample harvesting scheme is
further proposed to dynamically select the most confident tight positive
samples and train the detector in a mutual boosting way. To prevent the
detector from being trapped in poor optima due to overfitting, we propose a new
relative improvement of predicted CNN scores for guiding the self-taught
learning process. Extensive experiments on PASCAL 2007 and 2012 show that our
approach outperforms the state-of-the-arts, strongly validating its
effectiveness.
</dc:description>
 <dc:description>Comment: Accepted as spotlight paper by CVPR 2017</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-04-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05188</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05190</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Competitive Resource Allocation in HetNets: the Impact of Small-cell
  Spectrum Constraints and Investment Costs</dc:title>
 <dc:creator>Chen, Cheng</dc:creator>
 <dc:creator>Berry, Randall A.</dc:creator>
 <dc:creator>Honig, Michael L.</dc:creator>
 <dc:creator>Subramanian, Vijay G.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Heterogeneous wireless networks with small-cell deployments in licensed and
unlicensed spectrum bands are a promising approach for expanding wireless
connectivity and service. As a result, wireless service providers (SPs) are
adding small-cells to augment their existing macro-cell deployments. This added
flexibility complicates network management, in particular, service pricing and
spectrum allocations across macro- and small-cells. Further, these decisions
depend on the degree of competition among SPs. Restrictions on shared spectrum
access imposed by regulators, such as low power constraints that lead to
small-cell deployments, along with the investment cost needed to add small
cells to an existing network, also impact strategic decisions and market
efficiency. If the revenue generated by small-cells does not cover the
investment cost, then there will be no deployment even if it increases social
welfare. We study the implications of such spectrum constraints and investment
costs on resource allocation and pricing decisions by competitive SPs, along
with the associated social welfare. Our results show that while the optimal
resource allocation taking constraints and investment into account can be
uniquely determined, adding those features with strategic SPs can have a
substantial effect on the equilibrium market structure.
</dc:description>
 <dc:description>Comment: 15 pages, 8 figures. submitted to IEEE Transactions on Cognitive
  Communications and Networking</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05190</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05194</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Piece-wise Linear Models from Large Scale Data for Ad Click
  Prediction</dc:title>
 <dc:creator>Gai, Kun</dc:creator>
 <dc:creator>Zhu, Xiaoqiang</dc:creator>
 <dc:creator>Li, Han</dc:creator>
 <dc:creator>Liu, Kai</dc:creator>
 <dc:creator>Wang, Zhe</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  CTR prediction in real-world business is a difficult machine learning problem
with large scale nonlinear sparse data. In this paper, we introduce an
industrial strength solution with model named Large Scale Piece-wise Linear
Model (LS-PLM). We formulate the learning problem with $L_1$ and $L_{2,1}$
regularizers, leading to a non-convex and non-smooth optimization problem.
Then, we propose a novel algorithm to solve it efficiently, based on
directional derivatives and quasi-Newton method. In addition, we design a
distributed system which can run on hundreds of machines parallel and provides
us with the industrial scalability. LS-PLM model can capture nonlinear patterns
from massive sparse data, saving us from heavy feature engineering jobs. Since
2012, LS-PLM has become the main CTR prediction model in Alibaba's online
display advertising system, serving hundreds of millions users every day.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05194</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05199</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mutual Information, Relative Entropy and Estimation Error in
  Semi-martingale Channels</dc:title>
 <dc:creator>Jiao, Jiantao</dc:creator>
 <dc:creator>Venkat, Kartik</dc:creator>
 <dc:creator>Weissman, Tsachy</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Fundamental relations between information and estimation have been
established in the literature for the continuous-time Gaussian and Poisson
channels, in a long line of work starting from the classical representation
theorems by Duncan and Kabanov respectively. In this work, we demonstrate that
such relations hold for a much larger family of continuous-time channels. We
introduce the family of semi-martingale channels where the channel output is a
semi-martingale stochastic process, and the channel input modulates the
characteristics of the semi-martingale. For these channels, which includes as a
special case the continuous time Gaussian and Poisson models, we establish new
representations relating the mutual information between the channel input and
output to an optimal causal filtering loss, thereby unifying and considerably
extending results from the Gaussian and Poisson settings. Extensions to the
setting of mismatched estimation are also presented where the relative entropy
between the laws governing the output of the channel under two different input
distributions is equal to the cumulative difference between the estimation loss
incurred by using the mismatched and optimal causal filters respectively. The
main tool underlying these results is the Doob--Meyer decomposition of a class
of likelihood ratio sub-martingales. The results in this work can be viewed as
the continuous-time analogues of recent generalizations for relations between
information and estimation for discrete-time L\'evy channels.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05199</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05203</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ECG Signal Compression and Optimization in Remote Monitoring Networks</dc:title>
 <dc:creator>Wong, Pengda</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We proposed a practical ECG compression system which is beneficial for
tele-monitoring cardiovascular diseases. There are two steps in the compression
framework. First, we partition ECG signal into segments according to R- to
R-wave periods. The partition aims at achieving more stable statistical
features between segments of ECG signal which is beneficial for saving bit
rates. After the partition, we optimize the bit rate in the sense of minimizing
ECG reconstruction error under a constraint of consumed bits. From the
experiment results, the proposed compression scheme is able to reduce the
computation for updating codebook, and save channel capacity resources for
transmitting ECG signals.
</dc:description>
 <dc:description>Comment: 12 pages, 12 figures</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05204</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HPSLPred: An Ensemble Multi-label Classifier for Human Protein
  Subcellular Location Prediction with Imbalanced Source</dc:title>
 <dc:creator>Wan, Shixiang</dc:creator>
 <dc:creator>Zou, Quan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Predicting the subcellular localization of proteins is an important and
challenging problem. Traditional experimental approaches are often expensive
and time-consuming. Consequently, a growing number of research efforts employ a
series of machine learning approaches to predict the subcellular location of
proteins. There are two main challenges among the state-of-the-art prediction
methods. First, most of the existing techniques are designed to deal with
multi-class rather than multi-label classification, which ignores connections
between multiple labels. In reality, multiple locations of particular proteins
implies that there are vital and unique biological significances that deserve
special focus and cannot be ignored. Second, techniques for handling imbalanced
data in multi-label classification problems are necessary, but never employed.
For solving these two issues, we have developed an ensemble multi-label
classifier called HPSLPred, which can be applied for multi-label classification
with an imbalanced protein source. For convenience, a user-friendly webserver
has been established at http://server.malab.cn/HPSLPred.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05207</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithms for Pattern Containment in 0-1 Matrices</dc:title>
 <dc:creator>CrowdMath, P. A.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05D99</dc:subject>
 <dc:description>  We say a zero-one matrix $A$ avoids another zero-one matrix $P$ if no
submatrix of $A$ can be transformed to $P$ by changing some ones to zeros. A
fundamental problem is to study the extremal function $ex(n,P)$, the maximum
number of nonzero entries in an $n \times n$ zero-one matrix $A$ which avoids
$P$. To calculate exact values of $ex(n,P)$ for specific values of $n$, we need
containment algorithms which tell us whether a given $n \times n$ matrix $A$
contains a given pattern matrix $P$. In this paper, we present optimal
algorithms to determine when an $n \times n$ matrix $A$ contains a given
pattern $P$ when $P$ is a column of all ones, an identity matrix, a tuple
identity matrix, an $L$-shaped pattern, or a cross pattern. These algorithms
run in $\Theta(n^2)$ time, which is the lowest possible order a containment
algorithm can achieve. When $P$ is a rectangular all-ones matrix, we also
obtain an improved running time algorithm, albeit with a higher order.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05207</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05211</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Results on Pattern Avoidance Games</dc:title>
 <dc:creator>CrowdMath, P. A.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05D99</dc:subject>
 <dc:description>  A zero-one matrix $A$ contains another zero-one matrix $P$ if some submatrix
of $A$ can be transformed to $P$ by changing some ones to zeros. $A$ avoids $P$
if $A$ does not contain $P$. The Pattern Avoidance Game is played by two
players. Starting with an all-zero matrix, two players take turns changing
zeros to ones while keeping $A$ avoiding $P$. We study the strategies of this
game for some patterns $P$. We also study some generalizations of this game.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05215</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multisensory Omni-directional Long-term Place Recognition: Benchmark
  Dataset and Analysis</dc:title>
 <dc:creator>Mathur, Ashwin</dc:creator>
 <dc:creator>Han, Fei</dc:creator>
 <dc:creator>Zhang, Hao</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Recognizing a previously visited place, also known as place recognition (or
loop closure detection) is the key towards fully autonomous mobile robots and
self-driving vehicle navigation. Augmented with various Simultaneous
Localization and Mapping techniques (SLAM), loop closure detection allows for
incremental pose correction and can bolster efficient and accurate map
creation. However, repeated and similar scenes (perceptual aliasing) and long
term appearance changes (e.g. weather variations) are major challenges for
current place recognition algorithms. We introduce a new dataset Multisensory
Omnidirectional Long-term Place recognition (MOLP) comprising omnidirectional
intensity and disparity images. This dataset presents many of the challenges
faced by outdoor mobile robots and current place recognition algorithms. Using
MOLP dataset, we formulate the place recognition problem as a regularized
sparse convex optimization problem. We conclude that information extracted from
intensity image is superior to disparity image in isolating discriminative
features for successful long term place recognition. Furthermore, when these
discriminative features are extracted from an omnidirectional vision sensor, a
robust bidirectional loop closure detection approach is established, allowing
mobile robots to close the loop, regardless of the difference in the direction
when revisiting a place.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05220</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secret Key Generation from Correlated Sources and Secure Link</dc:title>
 <dc:creator>Cao, Daming</dc:creator>
 <dc:creator>Kang, Wei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study the problem of secret key generation from both
correlated sources and a secure channel. We obtain the optimal secret key rate
in this problem and show that the optimal scheme is to conduct secret key
generation and key distribution jointly, where every bit in the secret channel
will yield more than one bit of secret key rate. This joint scheme is better
than the separation-based scheme, where the secure channel is used for key
distribution, and as a result, every bit in the secure channel can only provide
one bit of secret key rate.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05220</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05223</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Know Your Master: Driver Profiling-based Anti-theft Method</dc:title>
 <dc:creator>Kwak, Byung Il</dc:creator>
 <dc:creator>Woo, JiYoung</dc:creator>
 <dc:creator>Kim, Huy Kang</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Although many anti-theft technologies are implemented, auto-theft is still
increasing. Also, security vulnerabilities of cars can be used for auto-theft
by neutralizing anti-theft system. This keyless auto-theft attack will be
increased as cars adopt computerized electronic devices more. To detect
auto-theft efficiently, we propose the driver verification method that analyzes
driving patterns using measurements from the sensor in the vehicle. In our
model, we add mechanical features of automotive parts that are excluded in
previous works, but can be differentiated by drivers' driving behaviors. We
design the model that uses significant features through feature selection to
reduce the time cost of feature processing and improve the detection
performance. Further, we enrich the feature set by deriving statistical
features such as mean, median, and standard deviation. This minimizes the
effect of fluctuation of feature values per driver and finally generates the
reliable model. We also analyze the effect of the size of sliding window on
performance to detect the time point when the detection becomes reliable and to
inform owners the theft event as soon as possible. We apply our model with real
driving and show the contribution of our work to the literature of driver
identification.
</dc:description>
 <dc:description>Comment: 8 pages, 11 figures, Accepted for PST 2016 : 14th International
  Conference on Privacy, Security and Trust</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05223</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05228</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sentiment analysis based on rhetorical structure theory: Learning deep
  neural networks from discourse trees</dc:title>
 <dc:creator>Kraus, Mathias</dc:creator>
 <dc:creator>Feuerriegel, Stefan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Prominent applications of sentiment analysis are countless, covering areas
such as marketing, customer service and communication. The conventional
bag-of-words approach for measuring sentiment merely counts term frequencies;
however, it neglects the position of the terms within the discourse. As a
remedy, we develop a discourse-aware method that builds upon the discourse
structure of documents. For this purpose, we utilize rhetorical structure
theory to label (sub-)clauses according to their hierarchical relationships and
then assign polarity scores to individual leaves. To learn from the resulting
rhetorical structure, we propose a tensor-based, tree-structured deep neural
network (named Discourse-LSTM) in order to process the complete discourse tree.
The underlying attention mechanism infers the salient passages of narrative
materials. In addition, we suggest two algorithms for data augmentation (node
reordering and artificial leaf insertion) that increase our training set and
reduce overfitting. Our benchmarks demonstrate the superior performance of our
approach. Moreover, the attention mechanism reveals the salient text passages
and thereby provides explanatory insights.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-10-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05228</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05231</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast 2-D Complex Gabor Filter with Kernel Decomposition</dc:title>
 <dc:creator>Um, Suhyuk</dc:creator>
 <dc:creator>Kim, Jaeyoon</dc:creator>
 <dc:creator>Min, Dongbo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  2-D complex Gabor filtering has found numerous applications in the fields of
computer vision and image processing. Especially, in some applications, it is
often needed to compute 2-D complex Gabor filter bank consisting of the 2-D
complex Gabor filtering outputs at multiple orientations and frequencies.
Although several approaches for fast 2-D complex Gabor filtering have been
proposed, they primarily focus on reducing the runtime of performing the 2-D
complex Gabor filtering once at specific orientation and frequency. To obtain
the 2-D complex Gabor filter bank output, existing methods are repeatedly
applied with respect to multiple orientations and frequencies. In this paper,
we propose a novel approach that efficiently computes the 2-D complex Gabor
filter bank by reducing the computational redundancy that arises when
performing the Gabor filtering at multiple orientations and frequencies. The
proposed method first decomposes the Gabor basis kernels to allow a fast
convolution with the Gaussian kernel in a separable manner. This enables
reducing the runtime of the 2-D complex Gabor filter bank by reusing
intermediate results of the 2-D complex Gabor filtering computed at a specific
orientation. Furthermore, we extend this idea into 2-D localized sliding
discrete Fourier transform (SDFT) using the Gaussian kernel in the DFT
computation, which lends a spatial localization ability as in the 2-D complex
Gabor filter. Experimental results demonstrate that our method runs faster than
state-of-the-arts methods for fast 2-D complex Gabor filtering, while
maintaining similar filtering quality.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05232</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the k-Means/Median Cost Function</dc:title>
 <dc:creator>Bhattacharya, Anup</dc:creator>
 <dc:creator>Jaiswal, Ragesh</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>I.5.3</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>F.2</dc:subject>
 <dc:description>  In this work, we study the $k$-means cost function. The (Euclidean) $k$-means
problem can be described as follows: given a dataset $X \subseteq \mathbb{R}^d$
and a positive integer $k$, find a set of $k$ centers $C \subseteq
\mathbb{R}^d$ such that $\Phi(C, X) \stackrel{def}{=} \sum_{x \in X} \min_{c
\in C} ||x - c||^2$ is minimized. Let $\Delta_k(X) \stackrel{def}{=} \min_{C
\subseteq \mathbb{R}^d} \Phi(C, X)$ denote the cost of the optimal $k$-means
solution. It is simple to observe that for any dataset $X$, $\Delta_k(X)$
decreases as $k$ increases. We try to understand this behaviour more precisely.
For any dataset $X \subseteq \mathbb{R}^d$, integer $k \geq 1$, and a small
precision parameter $\varepsilon &gt; 0$, let $\mathcal{L}_{X}^{k, \varepsilon}$
denote the smallest integer such that $\Delta_{\mathcal{L}_{X}^{k,
\varepsilon}}(X) \leq \varepsilon \cdot \Delta_{k}(X)$. We show upper and lower
bounds on this quantity. Our techniques generalize for the metric $k$-median
problem in arbitrary metrics and we give bounds in terms of the doubling
dimension of the metric. Finally, we observe that for any dataset $X$, we can
compute a set $S$ of size $O \left(\mathcal{L}_{X}^{k, \frac{\varepsilon}{c}}
\right)$ such that $\Delta_{S}(X) \leq \varepsilon \cdot \Delta_k(X)$ using the
$D^2$-sampling algorithm which is also known as the $k$-means++ seeding
procedure. In the previous statement, $c$ is some fixed constant. We also
discuss some applications of our bounds.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05233</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Faster Implementation of Online Run-Length Burrows-Wheeler Transform</dc:title>
 <dc:creator>Ohno, Tatsuya</dc:creator>
 <dc:creator>Takabatake, Yoshimasa</dc:creator>
 <dc:creator>I, Tomohiro</dc:creator>
 <dc:creator>Sakamoto, Hiroshi</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Run-length encoding Burrows-Wheeler Transformed strings, resulting in
Run-Length BWT (RLBWT), is a powerful tool for processing highly repetitive
strings. We propose a new algorithm for online RLBWT working in run-compressed
space, which runs in $O(n\lg r)$ time and $O(r\lg n)$ bits of space, where $n$
is the length of input string $S$ received so far and $r$ is the number of runs
in the BWT of the reversed $S$. We improve the state-of-the-art algorithm for
online RLBWT in terms of empirical construction time. Adopting the dynamic list
for maintaining a total order, we can replace rank queries in a dynamic wavelet
tree on a run-length compressed string by the direct comparison of labels in a
dynamic list. The empirical result for various benchmarks show the efficiency
of our algorithm, especially for highly repetitive strings.
</dc:description>
 <dc:description>Comment: In Proc. IWOCA2017</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-10-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05233</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05239</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Optical Flow Estimation in Rainy Scenes</dc:title>
 <dc:creator>Li, Ruoteng</dc:creator>
 <dc:creator>Tan, Robby T.</dc:creator>
 <dc:creator>Cheong, Loong-Fah</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Optical flow estimation in the rainy scenes is challenging due to background
degradation introduced by rain streaks and rain accumulation effects in the
scene. Rain accumulation effect refers to poor visibility of remote objects due
to the intense rainfall. Most existing optical flow methods are erroneous when
applied to rain sequences because the conventional brightness constancy
constraint (BCC) and gradient constancy constraint (GCC) generally break down
in this situation. Based on the observation that the RGB color channels receive
raindrop radiance equally, we introduce a residue channel as a new data
constraint to reduce the effect of rain streaks. To handle rain accumulation,
our method decomposes the image into a piecewise-smooth background layer and a
high-frequency detail layer. It also enforces the BCC on the background layer
only. Results on both synthetic dataset and real images show that our algorithm
outperforms existing methods on different types of rain sequences. To our
knowledge, this is the first optical flow method specifically dealing with
rain.
</dc:description>
 <dc:description>Comment: 9 pages, CVPR</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05239</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05240</identifier>
 <datestamp>2017-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Fusion With Cosparse Analysis Operator</dc:title>
 <dc:creator>Gao, Rui</dc:creator>
 <dc:creator>Vorobyov, Sergiy A.</dc:creator>
 <dc:creator>Zhao, Hong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The paper addresses the image fusion problem, where multiple images captured
with different focus distances are to be combined into a higher quality
all-in-focus image. Most current approaches for image fusion strongly rely on
the unrealistic noise-free assumption used during the image acquisition, and
then yield limited robustness in fusion processing. In our approach, we
formulate the multi-focus image fusion problem in terms of an analysis sparse
model, and simultaneously perform the restoration and fusion of multi-focus
images. Based on this model, we propose an analysis operator learning, and
define a novel fusion function to generate an all-in-focus image. Experimental
evaluations confirm the effectiveness of the proposed fusion approach both
visually and quantitatively, and show that our approach outperforms
state-of-the-art fusion methods.
</dc:description>
 <dc:description>Comment: 12 pages, 4 figures, 1 table, Submitted to IEEE Signal Processing
  Letters on December 2016</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05240</dc:identifier>
 <dc:identifier>doi:10.1109/LSP.2017.2696055</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05249</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hot or not? Forecasting cellular network hot spots using sector
  performance indicators</dc:title>
 <dc:creator>Serr&#xe0;, Joan</dc:creator>
 <dc:creator>Leontiadis, Ilias</dc:creator>
 <dc:creator>Karatzoglou, Alexandros</dc:creator>
 <dc:creator>Papagiannaki, Konstantina</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  To manage and maintain large-scale cellular networks, operators need to know
which sectors underperform at any given time. For this purpose, they use the
so-called hot spot score, which is the result of a combination of multiple
network measurements and reflects the instantaneous overall performance of
individual sectors. While operators have a good understanding of the current
performance of a network and its overall trend, forecasting the performance of
each sector over time is a challenging task, as it is affected by both regular
and non-regular events, triggered by human behavior and hardware failures. In
this paper, we study the spatio-temporal patterns of the hot spot score and
uncover its regularities. Based on our observations, we then explore the
possibility to use recent measurements' history to predict future hot spots. To
this end, we consider tree-based machine learning models, and study their
performance as a function of time, amount of past data, and prediction horizon.
Our results indicate that, compared to the best baseline, tree-based models can
deliver up to 14% better forecasts for regular hot spots and 153% better
forecasts for non-regular hot spots. The latter brings strong evidence that,
for moderate horizons, forecasts can be made even for sectors exhibiting
isolated, non-regular behavior. Overall, our work provides insight into the
dynamics of cellular sectors and their predictability. It also paves the way
for more proactive network operations with greater forecasting horizons.
</dc:description>
 <dc:description>Comment: Accepted for publication at ICDE 2017 - Industrial Track</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05250</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Tractable Approach to Dynamic Network Dimensioning Based on the
  Best-cell Configuration</dc:title>
 <dc:creator>Wu, Yanyan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Spatial distributions of other cell interference (OCIF) and interference to
own-cell power ratio (IOPR) with reference to the distance between a mobile and
its serving base station (BS) are modeled for the down-link reception of
cellular systems based on the best-cell configuration instead of the
nearest-cell configuration. This enables a more realistic evaluation of two
competing objectives in network dimensioning: coverage and rate capacity. More
outcomes useful for dynamic network dimensioning are also derived, including
maximum BS transmission power per cell size and the cell density required for
an adequate coverage of a given traffic density.
</dc:description>
 <dc:description>Comment: 7 pages; 10 figures; submitted to Globecom2017</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05250</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05254</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Grammar-Based Graph Compression</dc:title>
 <dc:creator>Maneth, Sebastian</dc:creator>
 <dc:creator>Peternek, Fabian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present a new graph compressor that works by recursively detecting
repeated substructures and representing them through grammar rules. We show
that for a large number of graphs the compressor obtains smaller
representations than other approaches. Specific queries such as reachability
between two nodes or regular path queries can be evaluated in linear time (or
quadratic times, respectively), over the grammar, thus allowing speed-ups
proportional to the compression ratio.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05254</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05255</identifier>
 <datestamp>2017-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Criticality as It Could Be: organizational invariance as self-organized
  criticality in embodied agents</dc:title>
 <dc:creator>Aguilera, Miguel</dc:creator>
 <dc:creator>Bedia, Manuel G.</dc:creator>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  This paper outlines a methodological approach for designing adaptive agents
driving themselves near points of criticality. Using a synthetic approach we
construct a conceptual model that, instead of specifying mechanistic
requirements to generate criticality, exploits the maintenance of an
organizational structure capable of reproducing critical behavior. Our approach
exploits the well-known principle of universality, which classifies critical
phenomena inside a few universality classes of systems independently of their
specific mechanisms or topologies. In particular, we implement an artificial
embodied agent controlled by a neural network maintaining a correlation
structure randomly sampled from a lattice Ising model at a critical point. We
evaluate the agent in two classical reinforcement learning scenarios: the
Mountain Car benchmark and the Acrobot double pendulum, finding that in both
cases the neural controller reaches a point of criticality, which coincides
with a transition point between two regimes of the agent's behaviour,
maximizing the mutual information between neurons and sensorimotor patterns.
Finally, we discuss the possible applications of this synthetic approach to the
comprehension of deeper principles connected to the pervasive presence of
criticality in biological and cognitive systems.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05255</dc:identifier>
 <dc:identifier>doi:10.7551/ecal_a_009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05259</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On PGZ decoding of alternant codes</dc:title>
 <dc:creator>Farr&#xe9;, R.</dc:creator>
 <dc:creator>Sayols, N.</dc:creator>
 <dc:creator>Xamb&#xf3;-Descamps, S.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this note we first review the classical Petterson-Gorenstein-Zierler
decoding algorithm for the class of alternant codes (which includes
Reed-Solomon, Bose-Chaudhuri-Hocquenghem and classical Goppa codes), then we
present an improvement of the method to find the number of errors and the
errorlocator polynomial, and finally we illustrate the procedure with several
examples. In two appendices we sketch the main features of the system we have
used for the computations.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05263</identifier>
 <datestamp>2017-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Specifying Graph Languages with Type Graphs</dc:title>
 <dc:creator>Corradini, Andrea</dc:creator>
 <dc:creator>K&#xf6;nig, Barbara</dc:creator>
 <dc:creator>Nolte, Dennis</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We investigate three formalisms to specify graph languages, i.e. sets of
graphs, based on type graphs. First, we are interested in (pure) type graphs,
where the corresponding language consists of all graphs that can be mapped
homomorphically to a given type graph. In this context, we also study languages
specified by restriction graphs and their relation to type graphs. Second, we
extend this basic approach to a type graph logic and, third, to type graphs
with annotations. We present decidability results and closure properties for
each of the formalisms.
</dc:description>
 <dc:description>Comment: (v2): -Fixed some typos -Added more references</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-04-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05263</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05267</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comment on &quot;Analysis of Video Image Sequences Using Point and Line
  Correspondences&quot;</dc:title>
 <dc:creator>K&#x142;opotek, Mieczys&#x142;aw A.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we would like to deny the results of Wang et al. raising two
fundamental claims:
  * A line does not contribute anything to recognition of motion parameters
from two images
  * Four traceable points are not sufficient to recover motion parameters from
two perspective
  To be constructive, however, we show that four traceable points are
sufficient to recover motion parameters from two frames under orthogonal
projection and that five points are sufficient to simplify the solution of the
two-frame problem under orthogonal projection to solving a linear equation
system.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05267</dc:identifier>
 <dc:identifier>preliminary version of: M.A. K{\l}opotek: A comment on &quot;Analysis
  of video image sequences using point and line correspondences&quot;. Pattern
  Recognition 28(1995)2, pp. 283-292</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05269</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Peer Truth Serum: Incentives for Crowdsourcing Measurements and Opinions</dc:title>
 <dc:creator>Faltings, Boi</dc:creator>
 <dc:creator>Jurca, Radu</dc:creator>
 <dc:creator>Radanovic, Goran</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Modern decision making tools are based on statistical analysis of abundant
data, which is often collected by querying multiple individuals. We consider
data collection through crowdsourcing, where independent and self-interested
agents, non-experts, report measurements, such as sensor readings, opinions,
such as product reviews, or answers to human intelligence tasks. Since the
accuracy of information is positively correlated with the effort invested in
obtaining it, self-interested agents tend to report low-quality data.
Therefore, there is a need for incentives that cover the cost of effort, while
discouraging random reports. We propose a novel incentive mechanism called Peer
Truth Serum that encourages truthful and accurate reporting, showing that it is
the unique mechanism to satisfy a combination of desirable properties.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05269</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05271</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-Scale Online Semantic Indexing of Biomedical Articles via an
  Ensemble of Multi-Label Classification Models</dc:title>
 <dc:creator>Papanikolaou, Yannis</dc:creator>
 <dc:creator>Tsoumakas, Grigorios</dc:creator>
 <dc:creator>Laliotis, Manos</dc:creator>
 <dc:creator>Markantonatos, Nikos</dc:creator>
 <dc:creator>Vlahavas, Ioannis</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Background: In this paper we present the approaches and methods employed in
order to deal with a large scale multi-label semantic indexing task of
biomedical papers. This work was mainly implemented within the context of the
BioASQ challenge of 2014. Methods: The main contribution of this work is a
multi-label ensemble method that incorporates a McNemar statistical
significance test in order to validate the combination of the constituent
machine learning algorithms. Some secondary contributions include a study on
the temporal aspects of the BioASQ corpus (observations apply also to the
BioASQ's super-set, the PubMed articles collection) and the proper adaptation
of the algorithms used to deal with this challenging classification task.
Results: The ensemble method we developed is compared to other approaches in
experimental scenarios with subsets of the BioASQ corpus giving positive
results. During the BioASQ 2014 challenge we obtained the first place during
the first batch and the third in the two following batches. Our success in the
BioASQ challenge proved that a fully automated machine-learning approach, which
does not implement any heuristics and rule-based approaches, can be highly
competitive and outperform other approaches in similar challenging contexts.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05271</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05272</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Global Grid catalogue for LHC Run3 and beyond</dc:title>
 <dc:creator>Pedreira, M Martinez</dc:creator>
 <dc:creator>Collaboration, C Grigoras for the ALICE</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The AliEn (ALICE Environment) file catalogue is a global unique namespace
providing mapping between a UNIX-like logical name structure and the
corresponding physical files distributed over 80 storage elements worldwide.
Powerful search tools and hierarchical metadata information are integral parts
of the system and are used by the Grid jobs as well as local users to store and
access all files on the Grid storage elements. The catalogue has been in
production since 2005 and over the past 11 years has grown to more than 2
billion logical file names. The backend is a set of distributed relational
databases, ensuring smooth growth and fast access. Due to the anticipated fast
future growth, we are looking for ways to enhance the performance and
scalability by simplifying the catalogue schema while keeping the functionality
intact. We investigated different backend solutions, such as distributed key
value stores, as replacement for the relational database. This contribution
covers the architectural changes in the system, together with the technology
evaluation, benchmark results and conclusions.
</dc:description>
 <dc:description>Comment: Proceedings of the 22nd International Conference on Computing in High
  Energy and Nuclear Physics, CHEP 2016, 10-14 October 2016, San Francisco.
  Submitted to Journal of Physics: Conference Series (JPCS)</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05272</dc:identifier>
 <dc:identifier>doi:10.1088/1742-6596/898/9/092006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05286</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Positive-instance driven dynamic programming for treewidth</dc:title>
 <dc:creator>Tamaki, Hisao</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Consider a dynamic programming scheme for a decision problem in which all
subproblems involved are also decision problems. An implementation of such a
scheme is {\em positive-instance driven} (PID), if it generates positive
subproblem instances, but not negative ones, building each on smaller positive
instances.
  We take the dynamic programming scheme due to Bouchitt\'{e} and Todinca for
treewidth computation, which is based on minimal separators and potential
maximal cliques, and design a variant (for the decision version of the problem)
with a natural PID implementation. The resulting algorithm performs extremely
well: it solves a number of standard benchmark instances for which the optimal
solutions have not previously been known. Incorporating a new heuristic
algorithm for detecting safe separators, it also solves all of the 100 public
instances posed by the exact treewidth track in PACE 2017, a competition on
algorithm implementation.
  We describe the algorithm, prove its correctness, and give a running time
bound in terms of the number of positive subproblem instances. We perform an
experimental analysis which supports the practical importance of such a bound.
</dc:description>
 <dc:description>Comment: A preliminary and abridged version appeared in ESA 2017</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2018-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05286</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05295</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Similarity from Natural Language and Ontology Analysis</dc:title>
 <dc:creator>Harispe, S&#xe9;bastien</dc:creator>
 <dc:creator>Ranwez, Sylvie</dc:creator>
 <dc:creator>Janaqi, Stefan</dc:creator>
 <dc:creator>Montmain, Jacky</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Artificial Intelligence federates numerous scientific fields in the aim of
developing machines able to assist human operators performing complex
treatments -- most of which demand high cognitive skills (e.g. learning or
decision processes). Central to this quest is to give machines the ability to
estimate the likeness or similarity between things in the way human beings
estimate the similarity between stimuli.
  In this context, this book focuses on semantic measures: approaches designed
for comparing semantic entities such as units of language, e.g. words,
sentences, or concepts and instances defined into knowledge bases. The aim of
these measures is to assess the similarity or relatedness of such semantic
entities by taking into account their semantics, i.e. their meaning --
intuitively, the words tea and coffee, which both refer to stimulating
beverage, will be estimated to be more semantically similar than the words
toffee (confection) and coffee, despite that the last pair has a higher
syntactic similarity. The two state-of-the-art approaches for estimating and
quantifying semantic similarities/relatedness of semantic entities are
presented in detail: the first one relies on corpora analysis and is based on
Natural Language Processing techniques and semantic models while the second is
based on more or less formal, computer-readable and workable forms of knowledge
such as semantic networks, thesaurus or ontologies. (...) Beyond a simple
inventory and categorization of existing measures, the aim of this monograph is
to convey novices as well as researchers of these domains towards a better
understanding of semantic similarity estimation and more generally semantic
measures.
</dc:description>
 <dc:description>Comment: preprint version of the book Semantic Similarity from Natural
  Language and Ontology Analysis (Synthesis Lectures on Human Language
  Technologies - Morgan &amp; Claypool publishers)</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05295</dc:identifier>
 <dc:identifier>doi:10.2200/S00639ED1V01Y201504HLT027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05296</identifier>
 <datestamp>2017-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coverage and Rate of Downlink Sequence Transmissions with Reliability
  Guarantees</dc:title>
 <dc:creator>Park, Jihong</dc:creator>
 <dc:creator>Popovski, Petar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Real-time distributed control is a promising application of 5G in which
communication links should satisfy certain reliability guarantees. In this
letter, we derive closed-form maximum average rate when a device (e.g.
industrial machine) downloads a sequence of n operational commands through
cellular connection, while guaranteeing a certain signal-to-interference ratio
(SIR) coverage for all n messages. The result is based on novel closed-form
n-successive SIR coverage bounds. The proposed bounds provide simple
approximations that are increasingly accurate in the high reliability region.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures, submitted to IEEE Wireless Communications Letters</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-06-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05296</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05303</identifier>
 <datestamp>2017-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Robot Routing Problem for Collecting Aggregate Stochastic Rewards</dc:title>
 <dc:creator>Dimitrova, Rayna</dc:creator>
 <dc:creator>Gavran, Ivan</dc:creator>
 <dc:creator>Majumdar, Rupak</dc:creator>
 <dc:creator>Prabhu, Vinayak S.</dc:creator>
 <dc:creator>Soudjani, Sadegh Esmaeil Zadeh</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We propose a new model for formalizing reward collection problems on graphs
with dynamically generated rewards which may appear and disappear based on a
stochastic model. The *robot routing problem* is modeled as a graph whose nodes
are stochastic processes generating potential rewards over discrete time. The
rewards are generated according to the stochastic process, but at each step, an
existing reward disappears with a given probability. The edges in the graph
encode the (unit-distance) paths between the rewards' locations. On visiting a
node, the robot collects the accumulated reward at the node at that time, but
traveling between the nodes takes time. The optimization question asks to
compute an optimal (or epsilon-optimal) path that maximizes the expected
collected rewards.
  We consider the finite and infinite-horizon robot routing problems. For
finite-horizon, the goal is to maximize the total expected reward, while for
infinite horizon we consider limit-average objectives. We study the
computational and strategy complexity of these problems, establish NP-lower
bounds and show that optimal strategies require memory in general. We also
provide an algorithm for computing epsilon-optimal infinite paths for arbitrary
epsilon &gt; 0.
</dc:description>
 <dc:description>Comment: 20 Pages. Full version of the CONCUR (28th International Conference
  on Concurrency Theory) 2017 paper</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05303</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05305</identifier>
 <datestamp>2017-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to Cooperate Locally to Improve Global Privacy in Social Networks?
  On Amplification of Privacy Preserving Data Aggregation</dc:title>
 <dc:creator>Grining, Krzysztof</dc:creator>
 <dc:creator>Klonowski, Marek</dc:creator>
 <dc:creator>Sulkowska, Ma&#x142;gorzata</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In many systems privacy of users depends on the number of participants
applying collectively some method to protect their security. Indeed, there are
numerous already classic results about revealing aggregated data from a set of
users. The conclusion is usually as follows: if you have enough friends to
&quot;aggregate&quot; the private data, you can safely reveal your private information.
  Apart from data aggregation, it has been noticed that in a wider context
privacy can be often reduced to being hidden in a crowd. Generally, the
problems is how to create such crowd. This task may be not easy in some
distributed systems, wherein gathering enough &quot;individuals&quot; is hard for
practical reasons.
  Such example are social networks (or similar systems), where users have only
a limited number of semi trusted contacts and their aim is to reveal some
aggregated data in a privacy preserving manner. This may be particularly
problematic in the presence of a strong adversary that can additionally corrupt
some users.
  We show two methods that allow to significantly amplify privacy with only
limited number of local operations and very moderate communication overhead.
Except theoretical analysis we show experimental results on topologies of
real-life social networks to demonstrate that our methods can significantly
amplify privacy of chosen aggregation protocols even facing a massive attack of
a powerful adversary.
  We believe however that our results can have much wider applications for
improving security of systems based on locally trusted relations.
</dc:description>
 <dc:description>Comment: Submitted to TrustCom2017</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-04-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05310</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Learning by Predicting Noise</dc:title>
 <dc:creator>Bojanowski, Piotr</dc:creator>
 <dc:creator>Joulin, Armand</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Convolutional neural networks provide visual features that perform remarkably
well in many computer vision applications. However, training these networks
requires significant amounts of supervision. This paper introduces a generic
framework to train deep networks, end-to-end, with no supervision. We propose
to fix a set of target representations, called Noise As Targets (NAT), and to
constrain the deep features to align to them. This domain agnostic approach
avoids the standard unsupervised learning issues of trivial solutions and
collapsing of features. Thanks to a stochastic batch reassignment strategy and
a separable square loss function, it scales to millions of images. The proposed
approach produces representations that perform on par with state-of-the-art
unsupervised methods on ImageNet and Pascal VOC.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05310</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05316</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Benchmarking OpenCL, OpenACC, OpenMP, and CUDA: programming
  productivity, performance, and energy consumption</dc:title>
 <dc:creator>Memeti, Suejb</dc:creator>
 <dc:creator>Li, Lu</dc:creator>
 <dc:creator>Pllana, Sabri</dc:creator>
 <dc:creator>Kolodziej, Joanna</dc:creator>
 <dc:creator>Kessler, Christoph</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Many modern parallel computing systems are heterogeneous at their node level.
Such nodes may comprise general purpose CPUs and accelerators (such as, GPU, or
Intel Xeon Phi) that provide high performance with suitable energy-consumption
characteristics. However, exploiting the available performance of heterogeneous
architectures may be challenging. There are various parallel programming
frameworks (such as, OpenMP, OpenCL, OpenACC, CUDA) and selecting the one that
is suitable for a target context is not straightforward.
  In this paper, we study empirically the characteristics of OpenMP, OpenACC,
OpenCL, and CUDA with respect to programming productivity, performance, and
energy. To evaluate the programming productivity we use our homegrown tool
CodeStat, which enables us to determine the percentage of code lines that was
required to parallelize the code using a specific framework. We use our tool
x-MeterPU to evaluate the energy consumption and the performance. Experiments
are conducted using the industry-standard SPEC benchmark suite and the Rodinia
benchmark suite for accelerated computing on heterogeneous systems that combine
Intel Xeon E5 Processors with a GPU accelerator or an Intel Xeon Phi
co-processor.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05320</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EPTL - A temporal logic for weakly consistent systems</dc:title>
 <dc:creator>Weber, Mathias</dc:creator>
 <dc:creator>Bieniusa, Annette</dc:creator>
 <dc:creator>Poetzsch-Heffter, Arnd</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The high availability and scalability of weakly-consistent systems attracts
system designers. Yet, writing correct application code for this type of
systems is difficult; even how to specify the intended behavior of such systems
is still an open question. There has not been established any standard method
to specify the intended dynamic behavior of a weakly consistent system. There
exist specifications of various consistency models for distributed and
concurrent systems; and the semantics of replicated datatypes like CRDTs have
been specified in axiomatic and operational models based on visibility
relations.
  In this paper, we present a temporal logic, EPTL, that is tailored to specify
properties of weakly consistent systems. In contrast to LTL and CTL, EPTL takes
into account that operations of weakly consistent systems are in many cases not
serializable and have to be treated respectively to capture the behavior. We
embed our temporal logic in Isabelle/HOL and can thereby leverage strong
semi-automatic proving capabilities.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05320</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05325</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anomaly detection and motif discovery in symbolic representations of
  time series</dc:title>
 <dc:creator>Guigou, Fabio</dc:creator>
 <dc:creator>Collet, Pierre</dc:creator>
 <dc:creator>Parrend, Pierre</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The advent of the Big Data hype and the consistent recollection of event logs
and real-time data from sensors, monitoring software and machine configuration
has generated a huge amount of time-varying data in about every sector of the
industry. Rule-based processing of such data has ceased to be relevant in many
scenarios where anomaly detection and pattern mining have to be entirely
accomplished by the machine. Since the early 2000s, the de-facto standard for
representing time series has been the Symbolic Aggregate approXimation (SAX).In
this document, we present a few algorithms using this representation for
anomaly detection and motif discovery, also known as pattern mining, in such
data. We propose a benchmark of anomaly detection algorithms using data from
Cloud monitoring software.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05325</dc:identifier>
 <dc:identifier>doi:10.13140/RG.2.2.20158.69447</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05334</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Low Complexity Detection for QAM Isomorphic Constellations</dc:title>
 <dc:creator>Kayhan, Farbod</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Despite of the known gap from the Shannon's capacity, several standards are
still employing QAM or star shape constellations, mainly due to the existing
low complexity detectors. In this paper, we investigate the low complexity
detection for a family of QAM isomorphic constellations. These constellations
are known to perform very close to the peak-power limited capacity,
outperforming the DVB-S2X standard constellations. The proposed strategy is to
first remap the received signals to the QAM constellation using the existing
isomorphism and then break the log likelihood ratio computations to two one
dimensional PAM constellations. Gains larger than 0.6 dB with respect to QAM
can be obtained over the peak power limited channels without any increase in
detection complexity. Our scheme also provides a systematic way to design
constellations with low complexity one dimensional detectors. Several open
problems are discussed at the end of the paper.
</dc:description>
 <dc:description>Comment: Submitted to IEEE GLOBECOM 2017</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05334</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05347</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Baselines and test data for cross-lingual inference</dc:title>
 <dc:creator>Agi&#x107;, &#x17d;eljko</dc:creator>
 <dc:creator>Schluter, Natalie</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Research in natural language inference is currently exclusive to English.
Here, we propose to advance toward multilingual evaluation. To that end, we
provide test data for four major languages. We experiment with a set of
baselines based on cross-lingual embeddings and machine translation. While our
best system scores an average accuracy of just over 75%, we focus largely on
enabling further research in multilingual inference.
</dc:description>
 <dc:description>Comment: Submitted for review at EMNLP 2017</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05349</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Domain Based Massive Access for Small Packets Traffic of Uplink
  Wireless Channel</dc:title>
 <dc:creator>Song, Qiang</dc:creator>
 <dc:creator>Xie, Ronggui</dc:creator>
 <dc:creator>Yin, Huarui</dc:creator>
 <dc:creator>Wei, Guo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The fifth generation (5G) communication scenarios such as the cellular
network and the emerging machine type communications will produce massive small
packets. To support massive connectivity and avoid signaling overhead caused by
the transmission of those small packets, this paper proposes a novel method to
improve the transmission efficiency for massive connections of wireless uplink
channel. The proposed method combines compressive sensing (CS) with power
domain NOMA jointly, especially neither the scheduling nor the centralized
power allocation is necessary in the method. Both the analysis and simulation
show that the method can support up to two or three times overloading.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures.submitted to globecom 2017</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05350</identifier>
 <datestamp>2017-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving the Performance of OTDOA based Positioning in NB-IoT Systems</dc:title>
 <dc:creator>Hu, Sha</dc:creator>
 <dc:creator>Berg, Axel</dc:creator>
 <dc:creator>Li, Xuhong</dc:creator>
 <dc:creator>Rusek, Fredrik</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we consider positioning with
observed-time-difference-of-arrival (OTDOA) for a device deployed in
long-term-evolution (LTE) based narrow-band Internet-of-things (NB-IoT)
systems. We propose an iterative expectation-maximization based successive
interference cancellation (EM-SIC) algorithm to jointly consider estimations of
residual frequency-offset (FO), fading-channel taps and time-of-arrival (ToA)
of the first arrival-path for each of the detected cells. In order to design a
low complexity ToA detector and also due to the limits of low-cost analog
circuits, we assume an NB-IoT device working at a low-sampling rate such as
1.92 MHz or lower. The proposed EM-SIC algorithm comprises two stages to detect
ToA, based on which OTDOA can be calculated. In a first stage, after running
the EM-SIC block a predefined number of iterations, a coarse ToA is estimated
for each of the detected cells. Then in a second stage, to improve the ToA
resolution, a low-pass filter is utilized to interpolate the correlations of
time-domain PRS signal evaluated at a low sampling-rate to a high sampling-rate
such as 30.72 MHz. To keep low-complexity, only the correlations inside a small
search window centered at the coarse ToA estimates are upsampled. Then, the
refined ToAs are estimated based on upsampled correlations. If at least three
cells are detected, with OTDOA and the locations of detected cell sites, the
position of the NB-IoT device can be estimated. We show through numerical
simulations that, the proposed EM-SIC based ToA detector is robust against
impairments introduced by inter-cell interference, fading-channel and residual
FO. Thus significant signal-to-noise (SNR) gains are obtained over traditional
ToA detectors that do not consider these impairments when positioning a device.
</dc:description>
 <dc:description>Comment: Accepted in GlobeCom 2017, 7 pages, 11 figures</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05356</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Negations in Information Processing: Learning from
  Replicating Human Behavior</dc:title>
 <dc:creator>Pr&#xf6;llochs, Nicolas</dc:creator>
 <dc:creator>Feuerriegel, Stefan</dc:creator>
 <dc:creator>Neumann, Dirk</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Information systems experience an ever-growing volume of unstructured data,
particularly in the form of textual materials. This represents a rich source of
information from which one can create value for people, organizations and
businesses. For instance, recommender systems can benefit from automatically
understanding preferences based on user reviews or social media. However, it is
difficult for computer programs to correctly infer meaning from narrative
content. One major challenge is negations that invert the interpretation of
words and sentences. As a remedy, this paper proposes a novel learning strategy
to detect negations: we apply reinforcement learning to find a policy that
replicates the human perception of negations based on an exogenous response,
such as a user rating for reviews. Our method yields several benefits, as it
eliminates the former need for expensive and subjective manual labeling in an
intermediate stage. Moreover, the inferred policy can be used to derive
statistical inferences and implications regarding how humans process and act on
negations.
</dc:description>
 <dc:description>Comment: 39 pages</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05356</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05357</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enabling an Anatomic View to Investigate Honeypot Systems: A Survey</dc:title>
 <dc:creator>Fan, Wenjun</dc:creator>
 <dc:creator>Du, Zhihui</dc:creator>
 <dc:creator>Fernandez, David</dc:creator>
 <dc:creator>Villagra, Victor A.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  A honeypot is a type of security facility deliberately created to be probed,
attacked and compromised. It is often used for protecting production systems by
detecting and deflecting unauthorized accesses. It is also useful for
investigating the behaviour of attackers, and in particular, unknown attacks.
For the past 17 years much effort has been invested in the research and
development of honeypot based techniques and tools and they have evolved to
become an increasingly powerful means of defending against the creations of the
blackhat community. In this paper, by studying multiple honeypot systems, the
two essential elements of honeypots - the decoy and the security program - are
captured and presented, together with two abstract organizational forms -
independent and cooperative - in which these two elements can be integrated. A
novel decoy and security program (D-P) based taxonomy is proposed, for the
purpose of investigating and classifying the various techniques involved in
honeypot systems. An extensive set of honeypot projects and research, which
cover the techniques applied in both independent and cooperative honeypots, is
surveyed under the taxonomy framework. Finally, the taxonomy is applied to a
wide set of tools and systems in order to demonstrate its validity and predict
the tendency of honeypot development.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05358</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Representing Sentences as Low-Rank Subspaces</dc:title>
 <dc:creator>Mu, Jiaqi</dc:creator>
 <dc:creator>Bhat, Suma</dc:creator>
 <dc:creator>Viswanath, Pramod</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Sentences are important semantic units of natural language. A generic,
distributional representation of sentences that can capture the latent
semantics is beneficial to multiple downstream applications. We observe a
simple geometry of sentences -- the word representations of a given sentence
(on average 10.23 words in all SemEval datasets with a standard deviation 4.84)
roughly lie in a low-rank subspace (roughly, rank 4). Motivated by this
observation, we represent a sentence by the low-rank subspace spanned by its
word vectors. Such an unsupervised representation is empirically validated via
semantic textual similarity tasks on 19 different datasets, where it
outperforms the sophisticated neural network models, including skip-thought
vectors, by 15% on average.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05358</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05365</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Application of Distributed Control Algorithms using VOLTTRON-based
  Software Platform</dc:title>
 <dc:creator>Luo, Jingwei</dc:creator>
 <dc:creator>Pourbabak, Hajir</dc:creator>
 <dc:creator>Su, Wencong</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper gives an insight into the applications of an open-source control
system platform named VOLTTRON. This platform was developed by the Pacific
Northwest National Laboratory. A brief introduction is given on the
functionality and key features of the platform. Potential applications in the
areas of building control and electric vehicle charging are stated, along with
an overview of existing projects. A comparison is also made between VOLTTRON
and other related software. An actual implementation case of VOLTTRON is then
presented in the case study. The demonstration uses the VOLTTRON platform as a
message bus. Decentralized generators and consumers are simulated by 16
single-board computers.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, The 8th International Renewable Energy Congress
  (IREC 2017)</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05365</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05367</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Improving the Capacity of Solving Large-scale Wireless Network Design
  Problems by Genetic Algorithms</dc:title>
 <dc:creator>D'Andreagiovanni, Fabio</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Over the last decade, wireless networks have experienced an impressive growth
and now play a main role in many telecommunications systems. As a consequence,
scarce radio resources, such as frequencies, became congested and the need for
effective and efficient assignment methods arose. In this work, we present a
Genetic Algorithm for solving large instances of the Power, Frequency and
Modulation Assignment Problem, arising in the design of wireless networks. To
our best knowledge, this is the first Genetic Algorithm that is proposed for
such problem. Compared to previous works, our approach allows a wider
exploration of the set of power solutions, while eliminating sources of
numerical problems. The performance of the algorithm is assessed by tests over
a set of large realistic instances of a Fixed WiMAX Network.
</dc:description>
 <dc:description>Comment: This is the authors' final version of the paper published in Di Chio
  C. et al. (Eds): EvoApplications 2011, LNCS 6625, pp. 11-20, 2011. The final
  publication is available at Springer via
  http://dx.doi.org/10.1007/978-3-642-20520-0_2</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05367</dc:identifier>
 <dc:identifier>Di Chio C. et al. (Eds), EvoApplications 2011, Springer LNCS vol.
  6625, pp. 11-20, 2011</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-642-20520-0_2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05368</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interactive Outlining of Pancreatic Cancer Liver Metastases in
  Ultrasound Images</dc:title>
 <dc:creator>Egger, Jan</dc:creator>
 <dc:creator>Schmalstieg, Dieter</dc:creator>
 <dc:creator>Chen, Xiaojun</dc:creator>
 <dc:creator>Zoller, Wolfram G.</dc:creator>
 <dc:creator>Hann, Alexander</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Ultrasound (US) is the most commonly used liver imaging modality worldwide.
Due to its low cost, it is increasingly used in the follow-up of cancer
patients with metastases localized in the liver. In this contribution, we
present the results of an interactive segmentation approach for liver
metastases in US acquisitions. A (semi-) automatic segmentation is still very
challenging because of the low image quality and the low contrast between the
metastasis and the surrounding liver tissue. Thus, the state of the art in
clinical practice is still manual measurement and outlining of the metastases
in the US images. We tackle the problem by providing an interactive
segmentation approach providing real-time feedback of the segmentation results.
The approach has been evaluated with typical US acquisitions from the clinical
routine, and the datasets consisted of pancreatic cancer metastases. Even for
difficult cases, satisfying segmentations results could be achieved because of
the interactive real-time behavior of the approach. In total, 40 clinical
images have been evaluated with our method by comparing the results against
manual ground truth segmentations. This evaluation yielded to an average Dice
Score of 85% and an average Hausdorff Distance of 13 pixels.
</dc:description>
 <dc:description>Comment: 15 pages, 16 figures, 2 tables, 58 references</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05368</dc:identifier>
 <dc:identifier>Sci. Rep. 7, 892, 2017</dc:identifier>
 <dc:identifier>doi:10.1038/s41598-017-00940-z</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05384</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Weighted Matching: Beating the $\frac{1}{2}$ Barrier</dc:title>
 <dc:creator>Zadimoghaddam, Morteza</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the problem of online weighted bipartite matching in which we want
to find a maximum weighted matching between two sets of entities, e.g. matching
impressions in online media to advertisers. Karp et al. designed the elegant
algorithm Ranking with competitive ratio $1-\frac{1}{e}$ for the unweighted
case. Without the commonly accepted Free Disposal assumption, it is easy to
show that no competitive ratio can be achieved in the weighted case. However,
under this assumption, it is not hard to show that algorithm Greedy is
$\frac{1}{2}$ competitive, and this is tight for deterministic algorithms.
After more than 25 years from the seminal work of Karp et al., it is still an
open question whether an online algorithm with competitive ratio better than
$\frac{1}{2}$ exists or not. We answer this question affirmatively by
presenting randomized algorithm $\mathsf{StochasticGreedy}$ with competitive
ratio greater than $0.501$. We also optimize this algorithm and propose
slightly changed algorithm $\mathsf{OptimizedStochasticGreedy}$ with
competitive ratio greater than $0.5018$.
  In light of the hardness result of Kapralov et al. that restricts beating the
$\frac{1}{2}$-competitive ratio for Monotone Submodular Welfare Maximization
problem, our result can be seen as an evidence that solving weighted matching
problem is strictly easier than submodular welfare maximization in online
settings.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05384</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05391</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic $N$-$k$ Failure-Identification for Power Systems</dc:title>
 <dc:creator>Sundar, Kaarthik</dc:creator>
 <dc:creator>Coffrin, Carleton</dc:creator>
 <dc:creator>Nagarajan, Harsha</dc:creator>
 <dc:creator>Bent, Russell</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper considers a probabilistic generalization of the $N$-$k$
failure-identification problem in power transmission networks, where the
probability of failure of each component in the network is known a priori and
the goal of the problem is to find a set of $k$ components that maximizes
disruption to the system loads weighted by the probability of simultaneous
failure of the $k$ components. The resulting problem is formulated as a bilevel
mixed-integer nonlinear program. Convex relaxations, linear approximations, and
heuristics are developed to obtain feasible solutions that are close to the
optimum. A general cutting-plane algorithm is proposed to solve the convex
relaxation and linear approximations of the $N$-$k$ problem. Extensive
numerical results corroborate the effectiveness of the proposed algorithms on
small-, medium-, and large-scale test instances; the test instances include the
IEEE 14-bus system, the IEEE single-area and three-area RTS96 systems, the IEEE
118-bus system, the WECC 240-bus test system, the 1354-bus PEGASE system, and
the 2383-bus Polish winter-peak test system.
</dc:description>
 <dc:description>Comment: 17 pages</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2018-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05391</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05392</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synergy of all-purpose static solver and temporal reasoning tools in
  dynamic integrated expert systems</dc:title>
 <dc:creator>Rybina, Galina</dc:creator>
 <dc:creator>Mozgachev, Alexey</dc:creator>
 <dc:creator>Demidov, Dmitry</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The paper discusses scientific and technological problems of dynamic
integrated expert systems development. Extensions of problem-oriented
methodology for dynamic integrated expert systems development are considered.
Attention is paid to the temporal knowledge representation and processing.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures</dc:description>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05392</dc:identifier>
 <dc:identifier>&quot;Informatsionno-izmeritelnye i upravlyayushchie sistemy&quot;
  (Information-measuring and Control Systems) no.8, vol.12, 2014. pp 27-33.
  ISSN 2070-0814</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05393</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mining Worse and Better Opinions. Unsupervised and Agnostic Aggregation
  of Online Reviews</dc:title>
 <dc:creator>Fazzolari, Michela</dc:creator>
 <dc:creator>Petrocchi, Marinella</dc:creator>
 <dc:creator>Tommasi, Alessandro</dc:creator>
 <dc:creator>Zavattari, Cesare</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  In this paper, we propose a novel approach for aggregating online reviews,
according to the opinions they express. Our methodology is unsupervised - due
to the fact that it does not rely on pre-labeled reviews - and it is agnostic -
since it does not make any assumption about the domain or the language of the
review content. We measure the adherence of a review content to the domain
terminology extracted from a review set. First, we demonstrate the
informativeness of the adherence metric with respect to the score associated
with a review. Then, we exploit the metric values to group reviews, according
to the opinions they express. Our experimental campaign has been carried out on
two large datasets collected from Booking and Amazon, respectively.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05393</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05396</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Study of Deep Learning Robustness Against Computation Failures</dc:title>
 <dc:creator>Vialatte, Jean-Charles</dc:creator>
 <dc:creator>Leduc-Primeau, Fran&#xe7;ois</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  For many types of integrated circuits, accepting larger failure rates in
computations can be used to improve energy efficiency. We study the performance
of faulty implementations of certain deep neural networks based on pessimistic
and optimistic models of the effect of hardware faults. After identifying the
impact of hyperparameters such as the number of layers on robustness, we study
the ability of the network to compensate for computational failures through an
increase of the network size. We show that some networks can achieve equivalent
performance under faulty implementations, and quantify the required increase in
computational complexity.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05396</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05397</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to exploit prior information in low-complexity models</dc:title>
 <dc:creator>Daei, Sajad</dc:creator>
 <dc:creator>Haddadi, Farzan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Compressed Sensing refers to extracting a low-dimensional structured signal
of interest from its incomplete random linear observations. A line of recent
work has studied that, with the extra prior information about the signal, one
can recover the signal with much fewer observations. For this purpose, the
general approach is to solve weighted convex function minimization problem. In
such settings, the convex function is chosen to promote the low-dimensional
structure and the optimal weights are so chosen to reduce the number of
measurements required for the optimization problem. In this paper, we consider
a generalized non-uniform model in which the structured signal falls into some
partitions, with entries of each partition having a definite probability to be
an element of the structure support. Given these probabilities and regarding
the recent developments in conic integral geometry, we provide a method to
choose the unique optimal weights for any general low-dimensional signal model.
This class of low-dimensional signal model includes many popular examples such
as $\ell_1$ analysis (entry-wise sparsity in an arbitrary redundant
dictionary), $\ell_{1,2}$ norm (block sparsity) and total variation semi-norm
(for piece-wise constant signals). We show through precise analysis and
simulations that the weighted convex optimization problem significantly
improves the regular convex optimization problem as we choose the unique
optimal weights.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05397</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05400</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Waveform Design for Wireless Power Transfer with Limited Feedback</dc:title>
 <dc:creator>Huang, Yang</dc:creator>
 <dc:creator>Clerckx, Bruno</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Waveform design is a key technique to jointly exploit a beamforming gain, the
channel frequency-selectivity and the rectifier nonlinearity, so as to enhance
the end-to-end power transfer efficiency of Wireless Power Transfer (WPT).
Those waveforms have been designed assuming perfect channel state information
at the transmitter. This paper proposes two waveform strategies relying on
limited feedback for multi-antenna multi-sine WPT over frequency-selective
channels. In the waveform selection strategy, the Energy Transmitter (ET)
transmits over multiple timeslots with every time a different waveform precoder
within a codebook, and the Energy Receiver (ER) reports the index of the
precoder in the codebook that leads to the largest harvested energy. In the
waveform refinement strategy, the ET sequentially transmits two waveforms in
each stage, and the ER reports one feedback bit indicating an increase/decrease
in the harvested energy during this stage. Based on multiple one-bit feedback,
the ET successively refines waveform precoders in a tree-structured codebook
over multiple stages. By employing the framework of the generalized Lloyd's
algorithm, novel algorithms are proposed for both strategies to optimize the
codebooks in both space and frequency domains. The proposed limited
feedback-based waveform strategies are shown to outperform a set of baselines,
achieving higher harvested energy.
</dc:description>
 <dc:description>Comment: Accepted to IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05405</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy Efficient Beamforming for Massive MIMO Public Channel</dc:title>
 <dc:creator>Zhang, Cheng</dc:creator>
 <dc:creator>Huang, Yongming</dc:creator>
 <dc:creator>Jing, Yindi</dc:creator>
 <dc:creator>Yang, Luxi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  For massive MIMO public channel with any sector size in either microwave or
millimeter wave (mmwave) band, this paper studies the beamforming design to
minimize the transmit power while guaranteeing the quality of service (QoS) for
randomly deployed users. First the ideal beampattern is derived via Parseval
Identity, based on which a beamforming design problem is formulated to minimize
the gap with the idea beampattern. The problem is transformable to a
multiconvex one and an iterative optimization algorithm is used to obtain the
full-digital beamformer. In addition, with the help of same beampattern
theorem, the power amplifier (PA) efficiency of the beamformer is improved with
unchanged beampattern. Finally, the practical hybrid implementation is obtained
that achieves the full-digital beamformer solution. Simulations verify the
advantages of the proposed scheme over existing ones.
</dc:description>
 <dc:description>Comment: Accepted by IEEE Transactions on Vehicular Technology</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05405</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05408</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wave-like Decoding of Tail-biting Spatially Coupled LDPC Codes Through
  Iterative Demapping</dc:title>
 <dc:creator>Cammerer, Sebastian</dc:creator>
 <dc:creator>Schmalen, Laurent</dc:creator>
 <dc:creator>Aref, Vahid</dc:creator>
 <dc:creator>Brink, Stephan ten</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  For finite coupling lengths, terminated spatially coupled low-density
parity-check (SC-LDPC) codes show a non-negligible rate-loss. In this paper, we
investigate if this rate loss can be mitigated by tail-biting SC-LDPC codes in
conjunction with iterative demapping of higher order modulation formats.
Therefore, we examine the BP threshold of different coupled and uncoupled
ensembles. A comparison between the decoding thresholds approximated by EXIT
charts and the density evolution results of the coupled and uncoupled ensemble
is given. We investigate the effect and potential of different labelings for
such a set-up using per-bit EXIT curves, and exemplify the method for a 16-QAM
system, e.g., using set partitioning labelings. A hybrid mapping is proposed,
where different sub-blocks use different labelings in order to further optimize
the decoding thresholds of tail-biting codes, while the computational
complexity overhead through iterative demapping remains small.
</dc:description>
 <dc:description>Comment: presentat at the International Symposium on Turbo Codes &amp; Iterative
  Information Processing (ISTC), Brest, Sept. 2016</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05408</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05409</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ranking to Learn: Feature Ranking and Selection via Eigenvector
  Centrality</dc:title>
 <dc:creator>Roffo, Giorgio</dc:creator>
 <dc:creator>Melzi, Simone</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In an era where accumulating data is easy and storing it inexpensive, feature
selection plays a central role in helping to reduce the high-dimensionality of
huge amounts of otherwise meaningless data. In this paper, we propose a
graph-based method for feature selection that ranks features by identifying the
most important ones into arbitrary set of cues. Mapping the problem on an
affinity graph-where features are the nodes-the solution is given by assessing
the importance of nodes through some indicators of centrality, in particular,
the Eigen-vector Centrality (EC). The gist of EC is to estimate the importance
of a feature as a function of the importance of its neighbors. Ranking central
nodes individuates candidate features, which turn out to be effective from a
classification point of view, as proved by a thoroughly experimental section.
Our approach has been tested on 7 diverse datasets from recent literature
(e.g., biological data and object recognition, among others), and compared
against filter, embedded and wrappers methods. The results are remarkable in
terms of accuracy, stability and low execution time.
</dc:description>
 <dc:description>Comment: Preprint version - Lecture Notes in Computer Science - Springer 2017</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05409</dc:identifier>
 <dc:identifier>New Frontiers in Mining Complex Patterns, Fifth International
  workshop, nfMCP2016. Lecture Notes in Computer Science - Springer</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05411</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Risk-limiting Load Restoration for Resilience Enhancement with
  Intermittent Energy Resources</dc:title>
 <dc:creator>Wang, Zhiwen</dc:creator>
 <dc:creator>Shen, Chen</dc:creator>
 <dc:creator>Xu, Yin</dc:creator>
 <dc:creator>Liu, Feng</dc:creator>
 <dc:creator>Wu, Xiangyu</dc:creator>
 <dc:creator>Liu, Chen-Ching</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Microgrids are resources that can be used to restore critical loads after a
natural disaster, enhancing resilience of a distribution network. To deal with
the stochastic nature of intermittent energy resources, such as wind turbines
(WTs) and photovoltaics (PVs), many methods rely on forecast information.
However, some microgrids may not be equipped with power forecasting tools. To
fill this gap, a risk-limiting strategy based on measurements is proposed.
Gaussian mixture model (GMM) is used to represent a prior joint probability
density function (PDF) of power outputs of WTs and PVs over multiple periods.
As time rolls forward, the distribution of WT/PV generation is updated based
the latest measurement data in a recursive manner. The updated distribution is
used as an input for the risk-limiting load restoration problem, enabling an
equivalent transformation of the original chance constrained problem into a
mixed integer linear programming (MILP). Simulation cases on a distribution
system with three microgrids demonstrate the effectiveness of the proposed
method. Results also indicate that networked microgrids have better uncertainty
management capabilities than stand-alone microgrids.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-09-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05411</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05415</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Empirical Analysis of NMT-Derived Interlingual Embeddings and their
  Use in Parallel Sentence Identification</dc:title>
 <dc:creator>Espa&#xf1;a-Bonet, Cristina</dc:creator>
 <dc:creator>Varga, &#xc1;d&#xe1;m Csaba</dc:creator>
 <dc:creator>Barr&#xf3;n-Cede&#xf1;o, Alberto</dc:creator>
 <dc:creator>van Genabith, Josef</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  End-to-end neural machine translation has overtaken statistical machine
translation in terms of translation quality for some language pairs, specially
those with large amounts of parallel data. Besides this palpable improvement,
neural networks provide several new properties. A single system can be trained
to translate between many languages at almost no additional cost other than
training time. Furthermore, internal representations learned by the network
serve as a new semantic representation of words -or sentences- which, unlike
standard word embeddings, are learned in an essentially bilingual or even
multilingual context. In view of these properties, the contribution of the
present work is two-fold. First, we systematically study the NMT context
vectors, i.e. output of the encoder, and their power as an interlingua
representation of a sentence. We assess their quality and effectiveness by
measuring similarities across translations, as well as semantically related and
semantically unrelated sentence pairs. Second, as extrinsic evaluation of the
first point, we identify parallel sentences in comparable corpora, obtaining an
F1=98.2% on data from a shared task when using only NMT context vectors. Using
context vectors jointly with similarity measures F1 reaches 98.9%.
</dc:description>
 <dc:description>Comment: 11 pages, 4 figures</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05415</dc:identifier>
 <dc:identifier>IEEE Journal of Selected Topics in Signal Processing, vol. 11, no.
  8, pp. 1340-1350, December 2017</dc:identifier>
 <dc:identifier>doi:10.1109/JSTSP.2017.2764273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05416</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Light Field Blind Motion Deblurring</dc:title>
 <dc:creator>Srinivasan, Pratul P.</dc:creator>
 <dc:creator>Ng, Ren</dc:creator>
 <dc:creator>Ramamoorthi, Ravi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We study the problem of deblurring light fields of general 3D scenes captured
under 3D camera motion and present both theoretical and practical
contributions. By analyzing the motion-blurred light field in the primal and
Fourier domains, we develop intuition into the effects of camera motion on the
light field, show the advantages of capturing a 4D light field instead of a
conventional 2D image for motion deblurring, and derive simple methods of
motion deblurring in certain cases. We then present an algorithm to blindly
deblur light fields of general scenes without any estimation of scene geometry,
and demonstrate that we can recover both the sharp light field and the 3D
camera motion path of real and synthetically-blurred light fields.
</dc:description>
 <dc:description>Comment: To be presented at CVPR 2017</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05416</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05420</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diagonal RNNs in Symbolic Music Modeling</dc:title>
 <dc:creator>Subakan, Y. Cem</dc:creator>
 <dc:creator>Smaragdis, Paris</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we propose a new Recurrent Neural Network (RNN) architecture.
The novelty is simple: We use diagonal recurrent matrices instead of full. This
results in better test likelihood and faster convergence compared to regular
full RNNs in most of our experiments. We show the benefits of using diagonal
recurrent matrices with popularly used LSTM and GRU architectures as well as
with the vanilla RNN architecture, on four standard symbolic music datasets.
</dc:description>
 <dc:description>Comment: Submitted to Waspaa 2017</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05426</identifier>
 <datestamp>2017-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Broad-Coverage Challenge Corpus for Sentence Understanding through
  Inference</dc:title>
 <dc:creator>Williams, Adina</dc:creator>
 <dc:creator>Nangia, Nikita</dc:creator>
 <dc:creator>Bowman, Samuel R.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper introduces the Multi-Genre Natural Language Inference (MultiNLI)
corpus, a dataset designed for use in the development and evaluation of machine
learning models for sentence understanding. In addition to being one of the
largest corpora available for the task of NLI, at 433k examples, this corpus
improves upon available resources in its coverage: it offers data from ten
distinct genres of written and spoken English--making it possible to evaluate
systems on nearly the full complexity of the language--and it offers an
explicit setting for the evaluation of cross-genre domain adaptation.
</dc:description>
 <dc:description>Comment: 12 pages, 2 figures, 7 tables. v2 corrects a misreported accuracy
  number for the CBOW model in the 'matched' setting. v3 adds a discussion of
  the difficulty of the corpus to the analysis section</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05426</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05430</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Degree-Bounded Steiner Network Design</dc:title>
 <dc:creator>Dahghani, Sina</dc:creator>
 <dc:creator>Ehsani, Soheil</dc:creator>
 <dc:creator>Hajiaghayi, MohammadTaghi</dc:creator>
 <dc:creator>Liaghat, Vahid</dc:creator>
 <dc:creator>Racke, Harald</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We initiate the study of degree-bounded network design problems in the online
setting. The degree-bounded Steiner tree problem { which asks for a subgraph
with minimum degree that connects a given set of vertices { is perhaps one of
the most representative problems in this class. This paper deals with its
well-studied generalization called the degree-bounded Steiner forest problem
where the connectivity demands are represented by vertex pairs that need to be
individually connected. In the classical online model, the input graph is given
online but the demand pairs arrive sequentially in online steps. The selected
subgraph starts off as the empty subgraph, but has to be augmented to satisfy
the new connectivity constraint in each online step. The goal is to be
competitive against an adversary that knows the input in advance. We design a
simple greedy-like algorithm that achieves a competitive ratio of O(log n)
where n is the number of vertices. We show that no (randomized) algorithm can
achieve a (multiplicative) competitive ratio o(log n); thus our result is
asymptotically tight. We further show strong hardness results for the group
Steiner tree and the edge-weighted variants of degree-bounded connectivity
problems. Fourer and Raghavachari resolved the online variant of degree-bounded
Steiner forest in their paper in SODA'92. Since then, the natural family of
degree-bounded network design problems has been extensively studied in the
literature resulting in the development of many interesting tools and numerous
papers on the topic. We hope that our approach in this paper, paves the way for
solving the online variants of the classical problems in this family of network
design problems.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05430</dc:identifier>
 <dc:identifier>In Proceedings of the Twenty-Seventh Annual ACM-SIAM Symposium on
  Discrete Algorithms (pp. 164-175)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05432</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reverse Engineering of Communications Networks: Evolution and Challenges</dc:title>
 <dc:creator>Teimouri, Mehdi</dc:creator>
 <dc:creator>Motlagh, Hamidreza Kakaei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Reverse engineering of a communications network is the process of identifying
the communications protocol used in the network. This problem arises in various
situations such as eavesdropping, intelligent jamming, cognitive radio, and
adaptive coding and modulation (ACM). According to the Open Systems
Interconnection (OSI) reference model, the first step in reverse engineering of
communications networks is recognition of physical layer which consists of
recognition of digital modulations and identification of physical layer
transmission techniques. The next step is recognition of data link layer
(consisting of frame synchronization, recognition of channel codes,
reconstruction of interleavers, reconstruction of scramblers, etc.) and also
recognition of network and transport layers. The final step in reverse
engineering of communications networks is recognition of upper layers which
essentially can be seen as identification of source encoders. The objective of
this paper is to provide a comprehensive overview on the current methods for
reverse engineering of communications networks. Furthermore, challenges and
open research issues in this field are introduced.
</dc:description>
 <dc:description>Comment: 18 pages, 9 figures</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05432</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05443</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximations from Anywhere and General Rough Sets</dc:title>
 <dc:creator>Mani, A.</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>03E75, 03E05, 03E72,</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>H.1.1</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:description>  Not all approximations arise from information systems. The problem of fitting
approximations, subjected to some rules (and related data), to information
systems in a rough scheme of things is known as the \emph{inverse problem}. The
inverse problem is more general than the duality (or abstract representation)
problems and was introduced by the present author in her earlier papers. From
the practical perspective, a few (as opposed to one) theoretical frameworks may
be suitable for formulating the problem itself. \emph{Granular operator spaces}
have been recently introduced and investigated by the present author in her
recent work in the context of antichain based and dialectical semantics for
general rough sets. The nature of the inverse problem is examined from
number-theoretic and combinatorial perspectives in a higher order variant of
granular operator spaces and some necessary conditions are proved. The results
and the novel approach would be useful in a number of unsupervised and semi
supervised learning contexts and algorithms.
</dc:description>
 <dc:description>Comment: 20 Pages. Scheduled to appear in IJCRS'2017 LNCS Proceedings,
  Springer</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05443</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05473</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HEPData: a repository for high energy physics data</dc:title>
 <dc:creator>Maguire, Eamonn</dc:creator>
 <dc:creator>Heinrich, Lukas</dc:creator>
 <dc:creator>Watt, Graeme</dc:creator>
 <dc:subject>High Energy Physics - Experiment</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>High Energy Physics - Phenomenology</dc:subject>
 <dc:description>  The Durham High Energy Physics Database (HEPData) has been built up over the
past four decades as a unique open-access repository for scattering data from
experimental particle physics papers. It comprises data points underlying
several thousand publications. Over the last two years, the HEPData software
has been completely rewritten using modern computing technologies as an overlay
on the Invenio v3 digital library framework. The software is open source with
the new site available at https://hepdata.net now replacing the previous site
at http://hepdata.cedar.ac.uk. In this write-up, we describe the development of
the new site and explain some of the advantages it offers over the previous
platform.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures. Submitted to the proceedings of the 22nd
  International Conference on Computing in High Energy and Nuclear Physics,
  CHEP 2016, 10-14 October 2016, San Francisco</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05473</dc:identifier>
 <dc:identifier>J. Phys.: Conf. Ser. 898 (2017) 102006</dc:identifier>
 <dc:identifier>doi:10.1088/1742-6596/898/10/102006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05476</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing Reformulated First Zagreb Index of Some Chemical Graphs as an
  Application of Generalized Hierarchical Product of Graphs</dc:title>
 <dc:creator>De, Nilanjan</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  The generalized hierarchical product of graphs was introduced by L.
Barri\'ere et al in 2009. In this paper, reformulated first Zagreb index of
generalized hierarchical product of two connected graphs and hence as a special
case cluster product of graphs are obtained. Finally using the derived results
the reformulated first Zagreb index of some chemically important graphs such as
square comb lattice, hexagonal chain, molecular graph of truncated cube, dimer
fullerene, zig-zag polyhex nanotube and dicentric dendrimers are computed.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05476</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05477</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Ideals and Co-Granular Rough Sets</dc:title>
 <dc:creator>Mani, A</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03G25, 03G10, 06F99, 08A70</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>H.1.1</dc:subject>
 <dc:description>  Lattice-theoretic ideals have been used to define and generate non granular
rough approximations over general approximation spaces over the last few years
by few authors. The goal of these studies, in relation based rough sets, have
been to obtain nice properties comparable to those of classical rough
approximations. In this research paper, these ideas are generalized in a severe
way by the present author and associated semantic features are investigated by
her. Granules are used in the construction of approximations in implicit ways
and so a concept of co-granularity is introduced. Knowledge interpretation
associable with the approaches is also investigated. This research will be of
relevance for a number of logico-algebraic approaches to rough sets that
proceed from point-wise definitions of approximations and also for using
alternative approximations in spatial mereological contexts involving actual
contact relations. The antichain based semantics invented in earlier papers by
the present author also applies to the contexts considered.
</dc:description>
 <dc:description>Comment: 20pages. Scheduled to appear in IJCRS'2017 Proceedings, LNCS,
  Springer</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05477</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05479</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feedback-Capacity of Degraded Gaussian Vector BC using Directed
  Information and Concave Envelopes</dc:title>
 <dc:creator>Ramachandran, Viswanathan</dc:creator>
 <dc:creator>Pillai, S. R. B.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  It is known that the capacity region of a two user physically degraded
discrete memoryless (DM) broadcast channel (BC) is not enlarged by feedback. An
identical result holds true for a physically degraded Gaussian BC, established
later using a variant of the Entropy Power Inequality (EPI). In this paper, we
extend the latter result to a physically degraded Gaussian Vector BC (PD-GVBC).
However, the extension is not EPI based, but employs a recent result on the
factorization of concave envelopes. While the existing concave envelope
factorization results do not hold in the presence of feedback, we show that
factorizing the corresponding directed information quantities suffice to attain
the feedback capacity region of a PD-GVBC. Our work demonstrates that
factorizing concave envelopes of directed information can handle situations
involving feedback. We further show that the capacity region of a discrete
memoryless reversely physically degraded BC is not enlarged by feedback.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05479</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05495</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Investigating Recurrence and Eligibility Traces in Deep Q-Networks</dc:title>
 <dc:creator>Harb, Jean</dc:creator>
 <dc:creator>Precup, Doina</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Eligibility traces in reinforcement learning are used as a bias-variance
trade-off and can often speed up training time by propagating knowledge back
over time-steps in a single update. We investigate the use of eligibility
traces in combination with recurrent networks in the Atari domain. We
illustrate the benefits of both recurrent nets and eligibility traces in some
Atari games, and highlight also the importance of the optimization used in the
training.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures, NIPS 2016 Deep Reinforcement Learning Workshop</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05495</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05499</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantifying instabilities in Financial Markets</dc:title>
 <dc:creator>Gon&#xe7;alves, Bruna Amin</dc:creator>
 <dc:creator>Carpi, Laura</dc:creator>
 <dc:creator>Rosso, Osvaldo A.</dc:creator>
 <dc:creator>Ravetti, Martin G.</dc:creator>
 <dc:creator>Atman, A. P. F</dc:creator>
 <dc:subject>Quantitative Finance - Statistical Finance</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Financial global crisis has devastating impacts to economies since early XX
century and continues to impose increasing collateral damages for governments,
enterprises, and society in general. Up to now, all efforts to obtain efficient
methods to predict these events have been disappointing. However, the quest for
a robust estimator of the degree of the market efficiency, or even, a crisis
predictor, is still one of the most studied subjects in the field. We present
here an original contribution that combines Information Theory with graph
concepts, to study the return rate series of 32 global trade markets.
Specifically, we propose a very simple quantifier that shows to be highly
correlated with global financial instability periods, being also a good
estimator of the market crisis risk and market resilience. We show that this
estimator displays striking results when applied to countries that played
central roles during the last major global market crisis. The simplicity and
effectiveness of our quantifier allow us to anticipate its use in a wide range
of disciplines.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05499</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05505</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Making Sense of Unstructured Text Data</dc:title>
 <dc:creator>Li, Lin</dc:creator>
 <dc:creator>Campbell, William M.</dc:creator>
 <dc:creator>Dagli, Cagri</dc:creator>
 <dc:creator>Campbell, Joseph P.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Many network analysis tasks in social sciences rely on pre-existing data
sources that were created with explicit relations or interactions between
entities under consideration. Examples include email logs, friends and
followers networks on social media, communication networks, etc. In these data,
it is relatively easy to identify who is connected to whom and how they are
connected. However, most of the data that we encounter on a daily basis are
unstructured free-text data, e.g., forums, online marketplaces, etc. It is
considerably more difficult to extract network data from unstructured text. In
this work, we present an end-to-end system for analyzing unstructured text data
and transforming the data into structured graphs that are directly applicable
to a downstream application. Specifically, we look at social media data and
attempt to predict the most indicative words from users' posts. The resulting
keywords can be used to construct a context+content network for downstream
processing such as graph-based analysis and learning. With that goal in mind,
we apply our methods to the application of cross-domain entity resolution. The
performance of the resulting system with automatic keywords shows improvement
over the system with user-annotated hashtags.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05505</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05511</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Posted Prices for Online Cloud Resource Allocation</dc:title>
 <dc:creator>Zhang, Zijun</dc:creator>
 <dc:creator>Li, Zongpeng</dc:creator>
 <dc:creator>Wu, Chuan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We study online resource allocation in a cloud computing platform, through a
posted pricing mechanism: The cloud provider publishes a unit price for each
resource type, which may vary over time; upon arrival at the cloud system, a
cloud user either takes the current prices, renting resources to execute its
job, or refuses the prices without running its job there. We design pricing
functions based on the current resource utilization ratios, in a wide array of
demand-supply relationships and resource occupation durations, and prove
worst-case competitive ratios of the pricing functions in terms of social
welfare. In the basic case of a single-type, non-recycled resource (i.e.,
allocated resources are not later released for reuse), we prove that our
pricing function design is optimal, in that any other pricing function can only
lead to a worse competitive ratio. Insights obtained from the basic cases are
then used to generalize the pricing functions to more realistic cloud systems
with multiple types of resources, where a job occupies allocated resources for
a number of time slots till completion, upon which time the resources are
returned back to the cloud resource pool.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05511</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05513</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>25 Tweets to Know You: A New Model to Predict Personality with Social
  Media</dc:title>
 <dc:creator>Arnoux, Pierre-Hadrien</dc:creator>
 <dc:creator>Xu, Anbang</dc:creator>
 <dc:creator>Boyette, Neil</dc:creator>
 <dc:creator>Mahmud, Jalal</dc:creator>
 <dc:creator>Akkiraju, Rama</dc:creator>
 <dc:creator>Sinha, Vibha</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Predicting personality is essential for social applications supporting
human-centered activities, yet prior modeling methods with users written text
require too much input data to be realistically used in the context of social
media. In this work, we aim to drastically reduce the data requirement for
personality modeling and develop a model that is applicable to most users on
Twitter. Our model integrates Word Embedding features with Gaussian Processes
regression. Based on the evaluation of over 1.3K users on Twitter, we find that
our model achieves comparable or better accuracy than state of the art
techniques with 8 times fewer data.
</dc:description>
 <dc:description>Comment: Accepted as a short paper at ICWSM 2017. Please cite the ICWSM
  version and not the ArXiv version</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05513</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05516</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph Model Selection via Random Walks</dc:title>
 <dc:creator>Li, Lin</dc:creator>
 <dc:creator>Campbell, William M.</dc:creator>
 <dc:creator>Caceres, Rajmonda S.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this paper, we present a novel approach based on the random walk process
for finding meaningful representations of a graph model. Our approach leverages
the transient behavior of many short random walks with novel initialization
mechanisms to generate model discriminative features. These features are able
to capture a more comprehensive structural signature of the underlying graph
model. The resulting representation is invariant to both node permutation and
the size of the graph, allowing direct comparison between large classes of
graphs. We test our approach on two challenging model selection problems: the
discrimination in the sparse regime of an Erd\&quot;{o}s-Renyi model from a
stochastic block model and the planted clique problem. Our representation
approach achieves performance that closely matches known theoretical limits in
addition to being computationally simple and scalable to large graphs.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05516</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05519</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computer Vision for Autonomous Vehicles: Problems, Datasets and
  State-of-the-Art</dc:title>
 <dc:creator>Janai, Joel</dc:creator>
 <dc:creator>G&#xfc;ney, Fatma</dc:creator>
 <dc:creator>Behl, Aseem</dc:creator>
 <dc:creator>Geiger, Andreas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Recent years have witnessed amazing progress in AI related fields such as
computer vision, machine learning and autonomous vehicles. As with any rapidly
growing field, however, it becomes increasingly difficult to stay up-to-date or
enter the field as a beginner. While several topic specific survey papers have
been written, to date no general survey on problems, datasets and methods in
computer vision for autonomous vehicles exists. This paper attempts to narrow
this gap by providing a state-of-the-art survey on this topic. Our survey
includes both the historically most relevant literature as well as the current
state-of-the-art on several specific topics, including recognition,
reconstruction, motion estimation, tracking, scene understanding and end-to-end
learning. Towards this goal, we first provide a taxonomy to classify each
approach and then analyze the performance of the state-of-the-art on several
challenging benchmarking datasets including KITTI, ISPRS, MOT and Cityscapes.
Besides, we discuss open problems and current research challenges. To ease
accessibility and accommodate missing references, we will also provide an
interactive platform which allows to navigate topics and methods, and provides
additional information and project links for each paper.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05519</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05521</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building Regular Registers with Rational Malicious Servers and Anonymous
  Clients -- Extended Version</dc:title>
 <dc:creator>Del Pozzo, Antonella</dc:creator>
 <dc:creator>Bonomi, Silvia</dc:creator>
 <dc:creator>Lazzeretti, Riccardo</dc:creator>
 <dc:creator>Baldoni, Roberto</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>68</dc:subject>
 <dc:description>  The paper addresses the problem of emulating a regular register in a
synchronous distributed system where clients invoking ${\sf read}()$ and ${\sf
write}()$ operations are anonymous while server processes maintaining the state
of the register may be compromised by rational adversaries (i.e., a server
might behave as \emph{rational malicious Byzantine} process). We first model
our problem as a Bayesian game between a client and a rational malicious server
where the equilibrium depends on the decisions of the malicious server (behave
correctly and not be detected by clients vs returning a wrong register value to
clients with the risk of being detected and then excluded by the computation).
We prove such equilibrium exists and finally we design a protocol implementing
the regular register that forces the rational malicious server to behave
correctly.
</dc:description>
 <dc:description>Comment: Extended version of paper accepted at 2017 International Symposium on
  Cyber Security Cryptography and Machine Learning (CSCML 2017)</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05521</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05522</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance of Optimal Data Shaping Codes</dc:title>
 <dc:creator>Liu, Yi</dc:creator>
 <dc:creator>Huang, Pengfei</dc:creator>
 <dc:creator>Siegel, Paul H.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Data shaping is a coding technique that has been proposed to increase the
lifetime of flash memory devices. Several data shaping codes have been
described in recent work, including endurance codes and direct shaping codes
for structured data. In this paper, we study information-theoretic properties
of a general class of data shaping codes and prove a separation theorem stating
that optimal data shaping can be achieved by the concatenation of optimal
lossless compression with optimal endurance coding. We also determine the
expansion factor that minimizes the total wear cost. Finally, we analyze the
performance of direct shaping codes and establish a condition for their
optimality.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05522</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05526</identifier>
 <datestamp>2017-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Reason: End-to-End Module Networks for Visual Question
  Answering</dc:title>
 <dc:creator>Hu, Ronghang</dc:creator>
 <dc:creator>Andreas, Jacob</dc:creator>
 <dc:creator>Rohrbach, Marcus</dc:creator>
 <dc:creator>Darrell, Trevor</dc:creator>
 <dc:creator>Saenko, Kate</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Natural language questions are inherently compositional, and many are most
easily answered by reasoning about their decomposition into modular
sub-problems. For example, to answer &quot;is there an equal number of balls and
boxes?&quot; we can look for balls, look for boxes, count them, and compare the
results. The recently proposed Neural Module Network (NMN) architecture
implements this approach to question answering by parsing questions into
linguistic substructures and assembling question-specific deep networks from
smaller modules that each solve one subtask. However, existing NMN
implementations rely on brittle off-the-shelf parsers, and are restricted to
the module configurations proposed by these parsers rather than learning them
from data. In this paper, we propose End-to-End Module Networks (N2NMNs), which
learn to reason by directly predicting instance-specific network layouts
without the aid of a parser. Our model learns to generate network structures
(by imitating expert demonstrations) while simultaneously learning network
parameters (using the downstream task loss). Experimental results on the new
CLEVR dataset targeted at compositional question answering show that N2NMNs
achieve an error reduction of nearly 50% relative to state-of-the-art
attentional approaches, while discovering interpretable network architectures
specialized for each question.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-09-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05526</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05528</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Fast Implementation of Singular Value Thresholding Algorithm using
  Recycling Rank Revealing Randomized Singular Value Decomposition</dc:title>
 <dc:creator>Li, Yaohang</dc:creator>
 <dc:creator>Yu, Wenjian</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  In this paper, we present a fast implementation of the Singular Value
Thresholding (SVT) algorithm for matrix completion. A rank-revealing randomized
singular value decomposition (R3SVD) algorithm is used to adaptively carry out
partial singular value decomposition (SVD) to fast approximate the SVT operator
given a desired, fixed precision. We extend the R3SVD algorithm to a recycling
rank revealing randomized singular value decomposition (R4SVD) algorithm by
reusing the left singular vectors obtained from the previous iteration as the
approximate basis in the current iteration, where the computational cost for
partial SVD at each SVT iteration is significantly reduced. A simulated
annealing style cooling mechanism is employed to adaptively adjust the low-rank
approximation precision threshold as SVT progresses. Our fast SVT
implementation is effective in both large and small matrices, which is
demonstrated in matrix completion applications including image recovery and
movie recommendation system.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05528</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05537</identifier>
 <datestamp>2017-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Signaling on the Continuous Spectrum of Nonlinear Optical fiber</dc:title>
 <dc:creator>Tavakkolnia, Iman</dc:creator>
 <dc:creator>Safari, Majid</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:description>  This paper studies different signaling techniques on the continuous spectrum
(CS) of nonlinear optical fiber defined by nonlinear Fourier transform. Three
different signaling techniques are proposed and analyzed based on the
statistics of the noise added to CS after propagation along the nonlinear
optical fiber. The proposed methods are compared in terms of error performance,
distance reach, and complexity. Furthermore, the effect of chromatic dispersion
on the data rate and noise in nonlinear spectral domain is investigated. It is
demonstrated that, for a given sequence of CS symbols, an optimal bandwidth (or
symbol rate) can be determined so that the temporal duration of the propagated
signal at the end of the fiber is minimized. In effect, the required guard
interval between the subsequently transmitted data packets in time is minimized
and the effective data rate is significantly enhanced. Moreover, by selecting
the proper signaling method and design criteria a reach distance of 7100 km is
reported by only singling on the CS at a rate of 9.6 Gbps.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-09-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05537</dc:identifier>
 <dc:identifier>Optics Express, vol. 25, issue 16, pages 18685-18702, July 2017</dc:identifier>
 <dc:identifier>doi:10.1364/OE.25.018685</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05539</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beating Atari with Natural Language Guided Reinforcement Learning</dc:title>
 <dc:creator>Kaplan, Russell</dc:creator>
 <dc:creator>Sauer, Christopher</dc:creator>
 <dc:creator>Sosa, Alexander</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We introduce the first deep reinforcement learning agent that learns to beat
Atari games with the aid of natural language instructions. The agent uses a
multimodal embedding between environment observations and natural language to
self-monitor progress through a list of English instructions, granting itself
reward for completing instructions in addition to increasing the game score.
Our agent significantly outperforms Deep Q-Networks (DQNs), Asynchronous
Advantage Actor-Critic (A3C) agents, and the best agents posted to OpenAI Gym
on what is often considered the hardest Atari 2600 environment: Montezuma's
Revenge.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05539</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05543</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coordinating Collaborative Chat in Massive Open Online Courses</dc:title>
 <dc:creator>Tomar, Gaurav Singh</dc:creator>
 <dc:creator>Sankaranarayanan, Sreecharan</dc:creator>
 <dc:creator>Wang, Xu</dc:creator>
 <dc:creator>Ros&#xe9;, Carolyn Penstein</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  An earlier study of a collaborative chat intervention in a Massive Open
Online Course (MOOC) identified negative effects on attrition stemming from a
requirement for students to be matched with exactly one partner prior to
beginning the activity. That study raised questions about how to orchestrate a
collaborative chat intervention in a MOOC context in order to provide the
benefit of synchronous social engagement without the coordination difficulties.
In this paper we present a careful analysis of an intervention designed to
overcome coordination difficulties by welcoming students into the chat on a
rolling basis as they arrive rather than requiring them to be matched with a
partner before beginning. The results suggest the most positive impact when
experiencing a chat with exactly one partner rather than more or less. A
qualitative analysis of the chat data reveals differential experiences between
these configurations that suggests a potential explanation for the effect and
raises questions for future research.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05543</dc:identifier>
 <dc:identifier>Proceedings of the International Conference of the Learning
  Sciences 2016, Volume 1, pp 607-614</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05544</identifier>
 <datestamp>2017-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A lower bound on the 2-adic complexity of Ding-Helleseth generalized
  cyclotomic sequences of period $p^n$</dc:title>
 <dc:creator>Sun, Yuhua</dc:creator>
 <dc:creator>Wang, Qiang</dc:creator>
 <dc:creator>Yan, Tongjiang</dc:creator>
 <dc:creator>Zhao, Chun'e</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Let $p$ be an odd prime, $n$ a positive integer and $g$ a primitive root of
$p^n$. Suppose
$D_i^{(p^n)}=\{g^{2s+i}|s=0,1,2,\cdots,\frac{(p-1)p^{n-1}}{2}\}$, $i=0,1$, is
the generalized cyclotomic classes with $Z_{p^n}^{\ast}=D_0\cup D_1$. In this
paper, we prove that Gauss periods based on $D_0$ and $D_1$ are both equal to 0
for $n\geq2$. As an application, we determine a lower bound on the 2-adic
complexity of a class of Ding-Helleseth generalized cyclotomic sequences of
period $p^n$. The result shows that the 2-adic complexity is at least
$p^n-p^{n-1}-1$, which is larger than $\frac{N+1}{2}$, where $N=p^n$ is the
period of the sequence.
</dc:description>
 <dc:description>Comment: 11</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-04-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05544</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05547</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ubergraphs: A Definition of a Recursive Hypergraph Structure</dc:title>
 <dc:creator>Joslyn, Cliff</dc:creator>
 <dc:creator>Nowak, Kathleen</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Partly in service of exploring the formal basis for Georgetown University's
AvesTerra database structure, we formalize a recursive hypergraph data
structure, which we call an ubergraph.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05548</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Annotating Object Instances with a Polygon-RNN</dc:title>
 <dc:creator>Castrejon, Lluis</dc:creator>
 <dc:creator>Kundu, Kaustav</dc:creator>
 <dc:creator>Urtasun, Raquel</dc:creator>
 <dc:creator>Fidler, Sanja</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose an approach for semi-automatic annotation of object instances.
While most current methods treat object segmentation as a pixel-labeling
problem, we here cast it as a polygon prediction task, mimicking how most
current datasets have been annotated. In particular, our approach takes as
input an image crop and sequentially produces vertices of the polygon outlining
the object. This allows a human annotator to interfere at any time and correct
a vertex if needed, producing as accurate segmentation as desired by the
annotator. We show that our approach speeds up the annotation process by a
factor of 4.7 across all classes in Cityscapes, while achieving 78.4% agreement
in IoU with original ground-truth, matching the typical agreement between human
annotators. For cars, our speed-up factor is 7.3 for an agreement of 82.2%. We
further show generalization capabilities of our approach to unseen datasets.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05548</dc:identifier>
 <dc:identifier>CVPR 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05550</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extractive Summarization: Limits, Compression, Generalized Model and
  Heuristics</dc:title>
 <dc:creator>Verma, Rakesh</dc:creator>
 <dc:creator>Lee, Daniel</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Due to its promise to alleviate information overload, text summarization has
attracted the attention of many researchers. However, it has remained a serious
challenge. Here, we first prove empirical limits on the recall (and F1-scores)
of extractive summarizers on the DUC datasets under ROUGE evaluation for both
the single-document and multi-document summarization tasks. Next we define the
concept of compressibility of a document and present a new model of
summarization, which generalizes existing models in the literature and
integrates several dimensions of the summarization, viz., abstractive versus
extractive, single versus multi-document, and syntactic versus semantic.
Finally, we examine some new and existing single-document summarization
algorithms in a single framework and compare with state of the art summarizers
on DUC data.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05550</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05551</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simulator for LLVM Bitcode</dc:title>
 <dc:creator>Ro&#x10d;kai, Petr</dc:creator>
 <dc:creator>Barnat, Ji&#x159;&#xed;</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In this paper, we introduce an interactive simulator for programs in the form
of LLVM bitcode. The main features of the simulator include precise control
over thread scheduling, automatic checkpoints and reverse stepping, support for
source-level information about functions and variables in C and C++ programs
and structured heap visualisation. Additionally, the simulator is compatible
with DiVM (DIVINE VM) hypercalls, which makes it possible to load, simulate and
analyse counterexamples from an existing model checker.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05551</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05554</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovering Evolutionary Stepping Stones through Behavior Domination</dc:title>
 <dc:creator>Meyerson, Elliot</dc:creator>
 <dc:creator>Miikkulainen, Risto</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Behavior domination is proposed as a tool for understanding and harnessing
the power of evolutionary systems to discover and exploit useful stepping
stones. Novelty search has shown promise in overcoming deception by collecting
diverse stepping stones, and several algorithms have been proposed that combine
novelty with a more traditional fitness measure to refocus search and help
novelty search scale to more complex domains. However, combinations of novelty
and fitness do not necessarily preserve the stepping stone discovery that
novelty search affords. In several existing methods, competition between
solutions can lead to an unintended loss of diversity. Behavior domination
defines a class of algorithms that avoid this problem, while inheriting
theoretical guarantees from multiobjective optimization. Several existing
algorithms are shown to be in this class, and a new algorithm is introduced
based on fast non-dominated sorting. Experimental results show that this
algorithm outperforms existing approaches in domains that contain useful
stepping stones, and its advantage is sustained with scale. The conclusion is
that behavior domination can help illuminate the complex dynamics of
behavior-driven search, and can thus lead to the design of more scalable and
robust algorithms.
</dc:description>
 <dc:description>Comment: To Appear in Proceedings of the Genetic and Evolutionary Computation
  Conference (GECCO 2017)</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05554</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05563</identifier>
 <datestamp>2017-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Impact of Antenna Height Difference on the Performance of Downlink
  Cellular Networks</dc:title>
 <dc:creator>Liu, Junyu</dc:creator>
 <dc:creator>Sheng, Min</dc:creator>
 <dc:creator>Wang, Kan</dc:creator>
 <dc:creator>Li, Jiandong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Capable of significantly reducing cell size and enhancing spatial reuse,
network densification is shown to be one of the most dominant approaches to
expand network capacity. Due to the scarcity of available spectrum resources,
nevertheless, the over-deployment of network infrastructures, e.g., cellular
base stations (BSs), would strengthen the inter-cell interference as well, thus
in turn deteriorating the system performance. On this account, we investigate
the performance of downlink cellular networks in terms of user coverage
probability (CP) and network spatial throughput (ST), aiming to shed light on
the limitation of network densification. Notably, it is shown that both CP and
ST would be degraded and even diminish to be zero when BS density is
sufficiently large, provided that practical antenna height difference (AHD)
between BSs and users is involved to characterize pathloss. Moreover, the
results also reveal that the increase of network ST is at the expense of the
degradation of CP. Therefore, to balance the tradeoff between user and network
performance, we further study the critical density, under which ST could be
maximized under the CP constraint. Through a special case study, it follows
that the critical density is inversely proportional to the square of AHD. The
results in this work could provide helpful guideline towards the application of
network densification in the next-generation wireless networks.
</dc:description>
 <dc:description>Comment: conference submission - Mar. 2017</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05563</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05564</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Illuminant Spectra-based Source Separation Using Flash Photography</dc:title>
 <dc:creator>Hui, Zhuo</dc:creator>
 <dc:creator>Sunkavalli, Kalyan</dc:creator>
 <dc:creator>Hadap, Sunil</dc:creator>
 <dc:creator>Sankaranarayanan, Aswin C.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Real-world lighting often consists of multiple illuminants with different
spectra. Separating and manipulating these illuminants in post-process is a
challenging problem that requires either significant manual input or calibrated
scene geometry and lighting. In this work, we leverage a flash/no-flash image
pair to analyze and edit scene illuminants based on their spectral differences.
We derive a novel physics-based relationship between color variations in the
observed flash/no-flash intensities and the spectra and surface shading
corresponding to individual scene illuminants. Our technique uses this
constraint to automatically separate an image into constituent images lit by
each illuminant. This separation can be used to support applications like white
balancing, lighting editing, and RGB photometric stereo, where we demonstrate
results that outperform state-of-the-art techniques on a wide range of images.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05565</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Introduction to Ultra Reliable and Low Latency Communications in 5G</dc:title>
 <dc:creator>Ji, Hyoungju</dc:creator>
 <dc:creator>Park, Sunho</dc:creator>
 <dc:creator>Yeo, Jeongho</dc:creator>
 <dc:creator>Kim, Younsun</dc:creator>
 <dc:creator>Lee, Juho</dc:creator>
 <dc:creator>Shim, Byonghyo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  New wave of the technology revolution, often referred to as the fourth
industrial revolution, is changing the way we live, work, and communicate with
each other. These days, we are witnessing the emergence of unprecedented
services and applications requiring lower latency, better reliability massive
connection density, and improved energy efficiency. In accordance with this
trend and change, international telecommunication union (ITU) defined three
representative service categories, viz., enhanced mobile broadband (eMBB),
massive machine-type communication (mMTC), and ultra-reliable and low latency
communication (uRLLC). Among three service categories, physical-layer design of
the uRLLC service is arguably the most challenging and problematic. This is
mainly because uRLLC should satisfy two conflicting requirements: low latency
and ultra-high reliability. In this article, we provide the state-of-the-art
overview of uRLLC communications with an emphasis on technical challenges and
solutions. We highlight key requirements of uRLLC service and then discuss the
physical-layer issues and enabling technologies including packet and frame
structure, multiplexing schemes, and reliability improvement techniques.
</dc:description>
 <dc:description>Comment: This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05565</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05566</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simultaneous Policy Learning and Latent State Inference for Imitating
  Driver Behavior</dc:title>
 <dc:creator>Morton, Jeremy</dc:creator>
 <dc:creator>Kochenderfer, Mykel J.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this work, we propose a method for learning driver models that account for
variables that cannot be observed directly. When trained on a synthetic
dataset, our models are able to learn encodings for vehicle trajectories that
distinguish between four distinct classes of driver behavior. Such encodings
are learned without any knowledge of the number of driver classes or any
objective that directly requires the models to learn encodings for each class.
We show that driving policies trained with knowledge of latent variables are
more effective than baseline methods at imitating the driver behavior that they
are trained to replicate. Furthermore, we demonstrate that the actions chosen
by our policy are heavily influenced by the latent variable settings that are
provided to them.
</dc:description>
 <dc:description>Comment: 7 pages, 6 figures, 2 tables</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05566</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05569</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Contexts and Constraints for Improved Geotagging of Human
  Trafficking Webpages</dc:title>
 <dc:creator>Kapoor, Rahul</dc:creator>
 <dc:creator>Kejriwal, Mayank</dc:creator>
 <dc:creator>Szekely, Pedro</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Extracting geographical tags from webpages is a well-motivated application in
many domains. In illicit domains with unusual language models, like human
trafficking, extracting geotags with both high precision and recall is a
challenging problem. In this paper, we describe a geotag extraction framework
in which context, constraints and the openly available Geonames knowledge base
work in tandem in an Integer Linear Programming (ILP) model to achieve good
performance. In preliminary empirical investigations, the framework improves
precision by 28.57% and F-measure by 36.9% on a difficult human trafficking
geotagging task compared to a machine learning-based baseline. The method is
already being integrated into an existing knowledge base construction system
widely used by US law enforcement agencies to combat human trafficking.
</dc:description>
 <dc:description>Comment: 6 pages, GeoRich 2017 workshop at ACM SIGMOD conference</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05569</dc:identifier>
 <dc:identifier>doi:10.1145/3080546.3080547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05571</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Role Relevance with Minimal Domain Expertise in a Financial
  Domain</dc:title>
 <dc:creator>Kejriwal, Mayank</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Word embeddings have made enormous inroads in recent years in a wide variety
of text mining applications. In this paper, we explore a word embedding-based
architecture for predicting the relevance of a role between two financial
entities within the context of natural language sentences. In this extended
abstract, we propose a pooled approach that uses a collection of sentences to
train word embeddings using the skip-gram word2vec architecture. We use the
word embeddings to obtain context vectors that are assigned one or more labels
based on manual annotations. We train a machine learning classifier using the
labeled context vectors, and use the trained classifier to predict contextual
role relevance on test data. Our approach serves as a good minimal-expertise
baseline for the task as it is simple and intuitive, uses open-source modules,
requires little feature crafting effort and performs well across roles.
</dc:description>
 <dc:description>Comment: DSMM 2017 workshop at ACM SIGMOD conference</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05571</dc:identifier>
 <dc:identifier>doi:10.1145/3077240.3077249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05572</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Answering Complex Questions Using Open Information Extraction</dc:title>
 <dc:creator>Khot, Tushar</dc:creator>
 <dc:creator>Sabharwal, Ashish</dc:creator>
 <dc:creator>Clark, Peter</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  While there has been substantial progress in factoid question-answering (QA),
answering complex questions remains challenging, typically requiring both a
large body of knowledge and inference techniques. Open Information Extraction
(Open IE) provides a way to generate semi-structured knowledge for QA, but to
date such knowledge has only been used to answer simple questions with
retrieval-based methods. We overcome this limitation by presenting a method for
reasoning with Open IE knowledge, allowing more complex questions to be
handled. Using a recently proposed support graph optimization framework for QA,
we develop a new inference model for Open IE, in particular one that can work
effectively with multiple short facts, noise, and the relational structure of
tuples. Our model significantly outperforms a state-of-the-art structured
solver on complex questions of varying difficulty, while also removing the
reliance on manually curated knowledge.
</dc:description>
 <dc:description>Comment: Accepted as short paper at ACL 2017</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05572</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05573</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proposal of Vital Data Analysis Platform using Wearable Sensor</dc:title>
 <dc:creator>Yamato, Yoji</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  In this paper, we propose a vital data analysis platform which resolves
existing problems to utilize vital data for real-time actions. Recently, IoT
technologies have been progressed but in the healthcare area, real-time actions
based on analyzed vital data are not considered sufficiently yet. The causes
are proper use of analyzing methods of stream / micro batch processing and
network cost. To resolve existing problems, we propose our vital data analysis
platform. Our platform collects vital data of Electrocardiograph and
acceleration using an example of wearable vital sensor and analyzes them to
extract posture, fatigue and relaxation in smart phones or cloud. Our platform
can show analyzed dangerous posture or fatigue level change. We implemented the
platform. And we are now preparing a field test.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures, 5th IIAE International Conference on Industrial
  Application Engineering 2017 (ICIAE2017), pp.138-143, Mar. 2017</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05573</dc:identifier>
 <dc:identifier>5th IIAE International Conference on Industrial Application
  Engineering 2017 (ICIAE2017), pp.138-143, Mar. 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05576</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>1D Modeling of Sensor Selection Problem for Weak Barrier Coverage and
  Gap Mending in Wireless Sensor Networks</dc:title>
 <dc:creator>Sadeghi, Hamed</dc:creator>
 <dc:creator>Soroushmehr, MohammadReza</dc:creator>
 <dc:creator>Valaee, Shahrokh</dc:creator>
 <dc:creator>Shirani, Shahram</dc:creator>
 <dc:creator>Samavi, Shadrokh</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, we first remodel the line coverage as a 1D discrete problem
with co-linear targets. Then, an order-based greedy algorithm, called OGA, is
proposed to solve the problem optimally. It will be shown that the existing
order in the 1D modeling, and especially the resulted Markov property of the
selected sensors can help design greedy algorithms such as OGA. These
algorithms demonstrate optimal/efficient performance and have lower complexity
compared to the state-of-the-art. Furthermore, it is demonstrated that the
conventional continuous line coverage problem can be converted to an equivalent
discrete problem and solved optimally by OGA. Next, we formulate the well-known
weak barrier coverage problem as an instance of the continuous line coverage
problem (i.e. a 1D problem) as opposed to the conventional 2D graph-based
models. We demonstrate that the equivalent discrete version of this problem can
be solved optimally and faster than the state-of-the-art methods using an
extended version of OGA, called K-OGA. Moreover, an efficient local algorithm,
called LOGM, is proposed to mend barrier gaps due to sensor failure. In the
case of m gaps, LOGM is proved to select at most 2m-1 sensors more than the
optimal while being local and implementable in distributed fashion. We
demonstrate the optimal/efficient performance of the proposed algorithms via
extensive simulations.
</dc:description>
 <dc:description>Comment: 10 Pages, 11 Figures</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05576</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05579</identifier>
 <datestamp>2017-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Large Self-Annotated Corpus for Sarcasm</dc:title>
 <dc:creator>Khodak, Mikhail</dc:creator>
 <dc:creator>Saunshi, Nikunj</dc:creator>
 <dc:creator>Vodrahalli, Kiran</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce the Self-Annotated Reddit Corpus (SARC), a large corpus for
sarcasm research and for training and evaluating systems for sarcasm detection.
The corpus has 1.3 million sarcastic statements -- 10 times more than any
previous dataset -- and many times more instances of non-sarcastic statements,
allowing for learning in regimes of both balanced and unbalanced labels. Each
statement is furthermore self-annotated -- sarcasm is labeled by the author and
not an independent annotator -- and provided with user, topic, and conversation
context. We evaluate the corpus for accuracy, compare it to previous related
corpora, and provide baselines for the task of sarcasm detection.
</dc:description>
 <dc:description>Comment: 5 pages, 2 Figures. In submission</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-10-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05579</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05585</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Sized-Type Inference and Complexity Analysis</dc:title>
 <dc:creator>Avanzini, Martin</dc:creator>
 <dc:creator>Lago, Ugo Dal</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>I.2.2</dc:subject>
 <dc:description>  This paper introduces a new methodology for the complexity analysis of
higher-order functional programs, which is based on three components: a
powerful type system for size analysis and a sound type inference procedure for
it, a ticking monadic transformation and a concrete tool for constraint
solving. Noticeably, the presented methodology can be fully automated, and is
able to analyse a series of examples which cannot be handled by most competitor
methodologies. This is possible due to various key ingredients, and in
particular an abstract index language and index polymorphism at higher ranks. A
prototype implementation is available.
</dc:description>
 <dc:description>Comment: In Proceedings DICE-FOPARA 2017, arXiv:1704.05169</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05585</dc:identifier>
 <dc:identifier>EPTCS 248, 2017, pp. 7-16</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.248.5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05586</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GUBS Upper Bound Solver (Extended Abstract)</dc:title>
 <dc:creator>Avanzini, Martin</dc:creator>
 <dc:creator>Schaper, Michael</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>F.4.0</dc:subject>
 <dc:description>  In this extended abstract we present the GUBS Upper Bound Solver. GUBS is a
dedicated constraint solver over the naturals for inequalities formed over
uninterpreted function symbols and standard arithmetic operations. GUBS now
forms the backbone of HoSA, a tool for analysing space and time complexity of
higher-order functional programs automatically. We give insights about the
implemen- tation and report different case studies.
</dc:description>
 <dc:description>Comment: In Proceedings DICE-FOPARA 2017, arXiv:1704.05169</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05586</dc:identifier>
 <dc:identifier>EPTCS 248, 2017, pp. 17-23</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.248.6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05587</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computability in the Lattice of Equivalence Relations</dc:title>
 <dc:creator>Moyen, Jean-Yves</dc:creator>
 <dc:creator>Simonsen, Jakob Grue</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We investigate computability in the lattice of equivalence relations on the
natural numbers. We mostly investigate whether the subsets of appropriately
defined subrecursive equivalence relations -for example the set of all
polynomial-time decidable equivalence relations- form sublattices of the
lattice.
</dc:description>
 <dc:description>Comment: In Proceedings DICE-FOPARA 2017, arXiv:1704.05169</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05587</dc:identifier>
 <dc:identifier>EPTCS 248, 2017, pp. 38-46</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.248.8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05588</identifier>
 <datestamp>2017-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Fly by Crashing</dc:title>
 <dc:creator>Gandhi, Dhiraj</dc:creator>
 <dc:creator>Pinto, Lerrel</dc:creator>
 <dc:creator>Gupta, Abhinav</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  How do you learn to navigate an Unmanned Aerial Vehicle (UAV) and avoid
obstacles? One approach is to use a small dataset collected by human experts:
however, high capacity learning algorithms tend to overfit when trained with
little data. An alternative is to use simulation. But the gap between
simulation and real world remains large especially for perception problems. The
reason most research avoids using large-scale real data is the fear of crashes!
In this paper, we propose to bite the bullet and collect a dataset of crashes
itself! We build a drone whose sole purpose is to crash into objects: it
samples naive trajectories and crashes into random objects. We crash our drone
11,500 times to create one of the biggest UAV crash dataset. This dataset
captures the different ways in which a UAV can crash. We use all this negative
flying data in conjunction with positive data sampled from the same
trajectories to learn a simple yet powerful policy for UAV navigation. We show
that this simple self-supervised model is quite effective in navigating the UAV
even in extremely cluttered environments with dynamic obstacles including
humans. For supplementary video see: https://youtu.be/u151hJaGKUo
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-04-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05588</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05589</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Loop Quasi-Invariant Chunk Motion by peeling with statement composition</dc:title>
 <dc:creator>Moyen, Jean-Yves</dc:creator>
 <dc:creator>Rubiano, Thomas</dc:creator>
 <dc:creator>Seiller, Thomas</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Several techniques for analysis and transformations are used in compilers.
Among them, the peeling of loops for hoisting quasi-invariants can be used to
optimize generated code, or simply ease developers' lives. In this paper, we
introduce a new concept of dependency analysis borrowed from the field of
Implicit Computational Complexity (ICC), allowing to work with composed
statements called Chunks to detect more quasi-invariants. Based on an
optimization idea given on a WHILE language, we provide a transformation method
- reusing ICC concepts and techniques - to compilers. This new analysis
computes an invariance degree for each statement or chunks of statements by
building a new kind of dependency graph, finds the maximum or worst dependency
graph for loops, and recognizes if an entire block is Quasi-Invariant or not.
This block could be an inner loop, and in that case the computational
complexity of the overall program can be decreased. We already implemented a
proof of concept on a toy C parser 1 analysing and transforming the AST
representation. In this paper, we introduce the theory around this concept and
present a prototype analysis pass implemented on LLVM. In a very near future,
we will implement the corresponding transformation and provide benchmarks
comparisons.
</dc:description>
 <dc:description>Comment: In Proceedings DICE-FOPARA 2017, arXiv:1704.05169</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05589</dc:identifier>
 <dc:identifier>EPTCS 248, 2017, pp. 47-59</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.248.9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05590</identifier>
 <datestamp>2017-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proactive Eavesdropping in Relaying Systems</dc:title>
 <dc:creator>Jiang, Xin</dc:creator>
 <dc:creator>Lin, Hai</dc:creator>
 <dc:creator>Zhong, Caijun</dc:creator>
 <dc:creator>Chen, Xiaoming</dc:creator>
 <dc:creator>Zhang, Zhaoyang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates the performance of a legitimate surveillance system,
where a legitimate monitor aims to eavesdrop on a dubious decode-and-forward
relaying communication link. In order to maximize the effective eavesdropping
rate, two strategies are proposed, where the legitimate monitor adaptively acts
as an eavesdropper, a jammer or a helper. In addition, the corresponding
optimal jamming beamformer and jamming power are presented. Numerical results
demonstrate that the proposed strategies attain better performance compared
with intuitive benchmark schemes. Moreover, it is revealed that the position of
the legitimate monitor plays an important role on the eavesdropping performance
for the two strategies.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05590</dc:identifier>
 <dc:identifier>doi:10.1109/LSP.2017.2696305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05591</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>OCRAPOSE II: An OCR-based indoor positioning system using mobile phone
  images</dc:title>
 <dc:creator>Sadeghi, Hamed</dc:creator>
 <dc:creator>Valaee, Shahrokh</dc:creator>
 <dc:creator>Shirani, Shahram</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper, we propose an OCR (optical character recognition)-based
localization system called OCRAPOSE II, which is applicable in a number of
indoor scenarios including office buildings, parkings, airports, grocery
stores, etc. In these scenarios, characters (i.e. texts or numbers) can be used
as suitable distinctive landmarks for localization. The proposed system takes
advantage of OCR to read these characters in the query still images and
provides a rough location estimate using a floor plan. Then, it finds depth and
angle-of-view of the query using the information provided by the OCR engine in
order to refine the location estimate. We derive novel formulas for the query
angle-of-view and depth estimation using image line segments and the OCR box
information. We demonstrate the applicability and effectiveness of the proposed
system through experiments in indoor scenarios. It is shown that our system
demonstrates better performance compared to the state-of-the-art benchmarks in
terms of location recognition rate and average localization error specially
under sparse database condition.
</dc:description>
 <dc:description>Comment: 14 pages, 22 Figures</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05591</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05592</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Testing Docker Performance for HPC Applications</dc:title>
 <dc:creator>Ermakov, Alexey</dc:creator>
 <dc:creator>Vasyukov, Alexey</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The main goal for this article is to compare performance penalties when using
KVM virtualization and Docker containers for creating isolated environments for
HPC applications. The article provides both data obtained using commonly
accepted synthetic tests (High Performance Linpack) and real life applications
(OpenFOAM). The article highlights the influence on resulting application
performance of major infrastructure configuration options: CPU type presented
to VM, networking connection type used.
</dc:description>
 <dc:description>Comment: 10 pages, 12 figures, 13 references</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05592</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05594</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DATeS: A Highly-Extensible Data Assimilation Testing Suite</dc:title>
 <dc:creator>Attia, Ahmed</dc:creator>
 <dc:creator>Sandu, Adrian</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  A flexible and highly-extensible data assimilation testing suite, named
DATeS, is described in this paper. DATeS aims to offer a unified testing
environment that allows researchers to compare different data assimilation
methodologies and understand their performance in various settings. The core of
DATeS is implemented in Python and takes advantage of its object-oriented
capabilities. The main components of the package (the numerical models, the
data assimilation algorithms, the linear algebra solvers, and the time
discretization routines) are independent of each other, which offers great
flexibility to configure data assimilation applications. DATeS can interface
easily with large third-party numerical models written in Fortran or in C, and
with a plethora of external solvers.
</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05594</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05596</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Insensitive Stochastic Gradient Twin Support Vector Machine for Large
  Scale Problems</dc:title>
 <dc:creator>Wang, Zhen</dc:creator>
 <dc:creator>Shao, Yuan-Hai</dc:creator>
 <dc:creator>Bai, Lan</dc:creator>
 <dc:creator>Liu, Li-Ming</dc:creator>
 <dc:creator>Deng, Nai-Yang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Stochastic gradient descent algorithm has been successfully applied on
support vector machines (called PEGASOS) for many classification problems. In
this paper, stochastic gradient descent algorithm is investigated to twin
support vector machines for classification. Compared with PEGASOS, the proposed
stochastic gradient twin support vector machines (SGTSVM) is insensitive on
stochastic sampling for stochastic gradient descent algorithm. In theory, we
prove the convergence of SGTSVM instead of almost sure convergence of PEGASOS.
For uniformly sampling, the approximation between SGTSVM and twin support
vector machines is also given, while PEGASOS only has an opportunity to obtain
an approximation of support vector machines. In addition, the nonlinear SGTSVM
is derived directly from its linear case. Experimental results on both
artificial datasets and large scale problems show the stable performance of
SGTSVM with a fast learning speed.
</dc:description>
 <dc:description>Comment: 31 pages, 31 figures</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05596</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05600</identifier>
 <datestamp>2017-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TrustShadow: Secure Execution of Unmodified Applications with ARM
  TrustZone</dc:title>
 <dc:creator>Guan, Le</dc:creator>
 <dc:creator>Liu, Peng</dc:creator>
 <dc:creator>Xing, Xinyu</dc:creator>
 <dc:creator>Ge, Xinyang</dc:creator>
 <dc:creator>Zhang, Shengzhi</dc:creator>
 <dc:creator>Yu, Meng</dc:creator>
 <dc:creator>Jaeger, Trent</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  The rapid evolution of Internet-of-Things (IoT) technologies has led to an
emerging need to make it smarter. A variety of applications now run
simultaneously on an ARM-based processor. For example, devices on the edge of
the Internet are provided with higher horsepower to be entrusted with storing,
processing and analyzing data collected from IoT devices. This significantly
improves efficiency and reduces the amount of data that needs to be transported
to the cloud for data processing, analysis and storage. However, commodity OSes
are prone to compromise. Once they are exploited, attackers can access the data
on these devices. Since the data stored and processed on the devices can be
sensitive, left untackled, this is particularly disconcerting.
  In this paper, we propose a new system, TrustShadow that shields legacy
applications from untrusted OSes. TrustShadow takes advantage of ARM TrustZone
technology and partitions resources into the secure and normal worlds. In the
secure world, TrustShadow constructs a trusted execution environment for
security-critical applications. This trusted environment is maintained by a
lightweight runtime system that coordinates the communication between
applications and the ordinary OS running in the normal world. The runtime
system does not provide system services itself. Rather, it forwards requests
for system services to the ordinary OS, and verifies the correctness of the
responses. To demonstrate the efficiency of this design, we prototyped
TrustShadow on a real chip board with ARM TrustZone support, and evaluated its
performance using both microbenchmarks and real-world applications. We showed
TrustShadow introduces only negligible overhead to real-world applications.
</dc:description>
 <dc:description>Comment: MobiSys 2017</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-06-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05600</dc:identifier>
 <dc:identifier>doi:10.1145/3081333.3081349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05611</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dependency resolution and semantic mining using Tree Adjoining Grammars
  for Tamil Language</dc:title>
 <dc:creator>Menon, Vijay Krishna</dc:creator>
 <dc:creator>Rajendran, S</dc:creator>
 <dc:creator>Anandkumar, M</dc:creator>
 <dc:creator>Soman, K P</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Tree adjoining grammars (TAGs) provide an ample tool to capture syntax of
many Indian languages. Tamil represents a special challenge to computational
formalisms as it has extensive agglutinative morphology and a comparatively
difficult argument structure. Modelling Tamil syntax and morphology using TAG
is an interesting problem which has not been in focus even though TAGs are over
4 decades old, since its inception. Our research with Tamil TAGs have shown us
that we can not only represent syntax of the language, but to an extent mine
out semantics through dependency resolution of the sentence. But in order to
demonstrate this phenomenal property, we need to parse Tamil language sentences
using TAGs we have built and through parsing obtain a derivation we could use
to resolve dependencies, thus proving the semantic property. We use an in-house
developed pseudo lexical TAG chart parser; algorithm given by Schabes and Joshi
(1988), for generating derivations of sentences. We do not use any statistics
to rank out ambiguous derivations but rather use all of them to understand the
mentioned semantic relation with in TAGs for Tamil. We shall also present a
brief parser analysis for the completeness of our discussions.
</dc:description>
 <dc:description>Comment: 9 pages. arXiv admin note: text overlap with arXiv:1604.01235</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05611</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05614</identifier>
 <datestamp>2017-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Receiver Design with Joint Coherent and Non-Coherent Processing</dc:title>
 <dc:creator>Liu, Wanchun</dc:creator>
 <dc:creator>Zhou, Xiangyun</dc:creator>
 <dc:creator>Durrani, Salman</dc:creator>
 <dc:creator>Popovski, Petar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose a novel splitting receiver, which involves joint
processing of coherently and non-coherently received signals. Using a passive
RF power splitter, the received signal at each receiver antenna is split into
two streams which are then processed by a conventional coherent detection (CD)
circuit and a power-detection (PD) circuit, respectively. The streams of the
signals from all the receiver antennas are then jointly used for information
detection. We show that the splitting receiver creates a three-dimensional
received signal space, due to the joint coherent and non-coherent processing.
We analyze the achievable rate of a splitting receiver, which shows that the
splitting receiver provides a rate gain of $3/2$ compared to either the
conventional (CD-based) coherent receiver or the PD-based non-coherent receiver
in the high SNR regime. We also analyze the symbol error rate (SER) for
practical modulation schemes, which shows that the splitting receiver achieves
asymptotic SER reduction by a factor of at least $\sqrt{M}-1$ for $M$-QAM
compared to either the conventional (CD-based) coherent receiver or the
PD-based non-coherent receiver.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05614</dc:identifier>
 <dc:identifier>IEEE Transactions on Communications, vol. 65, no. 8, pp.
  3479-3493, Aug. 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05617</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deduplication in a massive clinical note dataset</dc:title>
 <dc:creator>Shenoy, Sanjeev</dc:creator>
 <dc:creator>Kuo, Tsung-Ting</dc:creator>
 <dc:creator>Gabriel, Rodney</dc:creator>
 <dc:creator>McAuley, Julian</dc:creator>
 <dc:creator>Hsu, Chun-Nan</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Duplication, whether exact or partial, is a common issue in many datasets. In
clinical notes data, duplication (and near duplication) can arise for many
reasons, such as the pervasive use of templates, copy-pasting, or notes being
generated by automated procedures. A key challenge in removing such near
duplicates is the size of such datasets; our own dataset consists of more than
10 million notes. To detect and correct such duplicates requires algorithms
that both accurate and highly scalable. We describe a solution based on
Minhashing with Locality Sensitive Hashing. In this paper, we present the
theory behind this method and present a database-inspired approach to make the
method scalable. We also present a clustering technique using disjoint sets to
produce dense clusters, which speeds up our algorithm.
</dc:description>
 <dc:description>Comment: Extended from the Master project report of Sanjeev Shenoy, Department
  of Computer Science and Engineering, University of California, San Diego.
  June 2016</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05617</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05623</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximum Likelihood Detection for Cooperative Molecular Communication</dc:title>
 <dc:creator>Fang, Yuting</dc:creator>
 <dc:creator>Noel, Adam</dc:creator>
 <dc:creator>Yang, Nan</dc:creator>
 <dc:creator>Eckford, Andrew W.</dc:creator>
 <dc:creator>Kennedy, Rodney A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, symbol-by-symbol maximum likelihood (ML) detection is proposed
for a cooperative diffusion-based molecular communication (MC) system. In this
system, an fusion center (FC) chooses the transmitter's symbol that is more
likely, given the likelihood of the observations from multiple receivers (RXs).
We propose three different ML detection variants according to different
constraints on the information available to the FC, which enable us to
demonstrate trade-offs in their performance versus the information available.
The system error probability for one variant is derived in closed form.
Numerical and simulation results show that the ML detection variants provide
lower bounds on the error performance of the simpler cooperative variants and
demonstrate that majority rule detection has performance comparable to ML
detection when the reporting is noisy.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figurs. Submitted to IEEE ICC 2018. This work has been
  submitted to the IEEE for possible publication</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05623</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05624</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FSITM: A Feature Similarity Index For Tone-Mapped Images</dc:title>
 <dc:creator>Nafchi, Hossein Ziaei</dc:creator>
 <dc:creator>Shahkolaei, Atena</dc:creator>
 <dc:creator>Moghaddam, Reza Farrahi</dc:creator>
 <dc:creator>Cheriet, Mohamed</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, based on the local phase information of images, an objective
index, called the feature similarity index for tone-mapped images (FSITM), is
proposed. To evaluate a tone mapping operator (TMO), the proposed index
compares the locally weighted mean phase angle map of an original high dynamic
range (HDR) to that of its associated tone-mapped image calculated using the
output of the TMO method. In experiments on two standard databases, it is shown
that the proposed FSITM method outperforms the state-of-the-art index, the tone
mapped quality index (TMQI). In addition, a higher performance is obtained by
combining the FSITM and TMQI indices. The MATLAB source code of the proposed
metric(s) is available at
https://www.mathworks.com/matlabcentral/fileexchange/59814.
</dc:description>
 <dc:description>Comment: 4 Pages, 1 Figure, 1 Table</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05624</dc:identifier>
 <dc:identifier>IEEE Signal Processing Letters, vol. 22, no. 8, Aug 2015</dc:identifier>
 <dc:identifier>doi:10.1109/LSP.2014.2381458</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05626</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Perfect Half Space Games</dc:title>
 <dc:creator>Colcombet, Thomas</dc:creator>
 <dc:creator>Jurdzi&#x144;ski, Marcin</dc:creator>
 <dc:creator>Lazi&#x107;, Ranko</dc:creator>
 <dc:creator>Schmitz, Sylvain</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We introduce perfect half space games, in which the goal of Player 2 is to
make the sums of encountered multi-dimensional weights diverge in a direction
which is consistent with a chosen sequence of perfect half spaces (chosen
dynamically by Player 2). We establish that the bounding games of Jurdzi\'nski
et al. (ICALP 2015) can be reduced to perfect half space games, which in turn
can be translated to the lexicographic energy games of Colcombet and
Niwi\'nski, and are positionally determined in a strong sense (Player 2 can
play without knowing the current perfect half space). We finally show how
perfect half space games and bounding games can be employed to solve
multi-dimensional energy parity games in pseudo-polynomial time when both the
numbers of energy dimensions and of priorities are fixed, regardless of whether
the initial credit is given as part of the input or existentially quantified.
This also yields an optimal 2-EXPTIME complexity with given initial credit,
where the best known upper bound was non-elementary.
</dc:description>
 <dc:description>Comment: Accepted at LICS 2017</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05626</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05629</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ConvNet-Based Localization of Anatomical Structures in 3D Medical Images</dc:title>
 <dc:creator>de Vos, Bob D.</dc:creator>
 <dc:creator>Wolterink, Jelmer M.</dc:creator>
 <dc:creator>de Jong, Pim A.</dc:creator>
 <dc:creator>Leiner, Tim</dc:creator>
 <dc:creator>Viergever, Max A.</dc:creator>
 <dc:creator>I&#x161;gum, Ivana</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Localization of anatomical structures is a prerequisite for many tasks in
medical image analysis. We propose a method for automatic localization of one
or more anatomical structures in 3D medical images through detection of their
presence in 2D image slices using a convolutional neural network (ConvNet).
  A single ConvNet is trained to detect presence of the anatomical structure of
interest in axial, coronal, and sagittal slices extracted from a 3D image. To
allow the ConvNet to analyze slices of different sizes, spatial pyramid pooling
is applied. After detection, 3D bounding boxes are created by combining the
output of the ConvNet in all slices.
  In the experiments 200 chest CT, 100 cardiac CT angiography (CTA), and 100
abdomen CT scans were used. The heart, ascending aorta, aortic arch, and
descending aorta were localized in chest CT scans, the left cardiac ventricle
in cardiac CTA scans, and the liver in abdomen CT scans. Localization was
evaluated using the distances between automatically and manually defined
reference bounding box centroids and walls.
  The best results were achieved in localization of structures with clearly
defined boundaries (e.g. aortic arch) and the worst when the structure boundary
was not clearly visible (e.g. liver). The method was more robust and accurate
in localization multiple structures.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05629</dc:identifier>
 <dc:identifier>IEEE Transactions on Medical Imaging , vol.PP, no.99, pp.1-1
  (2017)</dc:identifier>
 <dc:identifier>doi:10.1109/TMI.2017.2673121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05641</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Technical Report on PLS-Completeness of Single-Swap for Unweighted
  Metric Facility Location and $K$-Means</dc:title>
 <dc:creator>Brauer, Sascha</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Recently, [Bra17] showed that the single-swap heuristic for weighted metric
uncapacitated facility location and $K$-Means is tightly PLS-complete. We build
upon this work and present a stronger reduction, which proves tight
PLS-completeness for the unweighted version of both problems.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1612.01752</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05643</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Skeleton Boxes: Solving skeleton based action detection with a single
  deep convolutional neural network</dc:title>
 <dc:creator>Li, Bo</dc:creator>
 <dc:creator>Chen, Huahui</dc:creator>
 <dc:creator>Chen, Yucheng</dc:creator>
 <dc:creator>Dai, Yuchao</dc:creator>
 <dc:creator>He, Mingyi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Action recognition from well-segmented 3D skeleton video has been intensively
studied. However, due to the difficulty in representing the 3D skeleton video
and the lack of training data, action detection from streaming 3D skeleton
video still lags far behind its recognition counterpart and image based object
detection. In this paper, we propose a novel approach for this problem, which
leverages both effective skeleton video encoding and deep regression based
object detection from images. Our framework consists of two parts:
skeleton-based video image mapping, which encodes a skeleton video to a color
image in a temporal preserving way, and an end-to-end trainable fast skeleton
action detector (Skeleton Boxes) based on image detection. Experimental results
on the latest and largest PKU-MMD benchmark dataset demonstrate that our method
outperforms the state-of-the-art methods with a large margin. We believe our
idea would inspire and benefit future research in this important area.
</dc:description>
 <dc:description>Comment: 4 pages,3 figures, icmew 2017</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05643</dc:identifier>
 <dc:identifier>icmew 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05645</identifier>
 <datestamp>2017-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Skeleton based action recognition using translation-scale invariant
  image mapping and multi-scale deep cnn</dc:title>
 <dc:creator>Li, Bo</dc:creator>
 <dc:creator>He, Mingyi</dc:creator>
 <dc:creator>Cheng, Xuelian</dc:creator>
 <dc:creator>Chen, Yucheng</dc:creator>
 <dc:creator>Dai, Yuchao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents an image classification based approach for skeleton-based
video action recognition problem. Firstly, A dataset independent
translation-scale invariant image mapping method is proposed, which transformes
the skeleton videos to colour images, named skeleton-images. Secondly, A
multi-scale deep convolutional neural network (CNN) architecture is proposed
which could be built and fine-tuned on the powerful pre-trained CNNs, e.g.,
AlexNet, VGGNet, ResNet etal.. Even though the skeleton-images are very
different from natural images, the fine-tune strategy still works well. At
last, we prove that our method could also work well on 2D skeleton video data.
We achieve the state-of-the-art results on the popular benchmard datasets e.g.
NTU RGB+D, UTD-MHAD, MSRC-12, and G3D. Especially on the largest and challenge
NTU RGB+D, UTD-MHAD, and MSRC-12 dataset, our method outperforms other methods
by a large margion, which proves the efficacy of the proposed method.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-06-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05645</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05646</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effects of the optimisation of the margin distribution on generalisation
  in deep architectures</dc:title>
 <dc:creator>Szymanski, Lech</dc:creator>
 <dc:creator>McCane, Brendan</dc:creator>
 <dc:creator>Gao, Wei</dc:creator>
 <dc:creator>Zhou, Zhi-Hua</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>68T05</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:description>  Despite being so vital to success of Support Vector Machines, the principle
of separating margin maximisation is not used in deep learning. We show that
minimisation of margin variance and not maximisation of the margin is more
suitable for improving generalisation in deep architectures. We propose the
Halfway loss function that minimises the Normalised Margin Variance (NMV) at
the output of a deep learning models and evaluate its performance against the
Softmax Cross-Entropy loss on the MNIST, smallNORB and CIFAR-10 datasets.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05646</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05647</identifier>
 <datestamp>2017-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Remote Document Encryption - encrypting data for e-passport holders</dc:title>
 <dc:creator>Verheul, Eric R.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We show how any party can encrypt data for an e-passport holder such that
only with physical possession of the e-passport decryption is possible. The
same is possible for electronic identity cards and driver licenses. We also
indicate possible applications. Dutch passports allow for 160 bit security,
theoretically giving sufficient security beyond the year 2079, exceeding
current good practice of 128 bit security. We also introduce the notion of RDE
Extraction PIN which effectively provides the same security as a regular PIN.
Our results ironically suggest that carrying a passport when traveling abroad
might violate export or import laws on strong cryptography.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-06-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05647</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05654</identifier>
 <datestamp>2017-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stabilization of slow-fast systems at fold points</dc:title>
 <dc:creator>Jardon-Kojakhmetov, H.</dc:creator>
 <dc:creator>Scherpen, Jacquelien M. A.</dc:creator>
 <dc:creator>del Puerto-Flores, D.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this document, we deal with the stabilization problem of slow-fast systems
(or singularly perturbed Ordinary Differential Equations) at a non-hyperbolic
point. The class of systems studied here have the following properties: 1) they
have one fast variable and an arbitrary number of slow variables, 2) they have
a non-hyperbolic singularity of the fold type at the origin. The presence of
the aforementioned singularity complicates the analysis and the controller
design of such systems. In particular, the classical theory of singular
perturbations cannot be used. We show a novel design process based on geometric
desingularization, which allows the stabilization of a fold point of singularly
perturbed control systems. Our results are exemplified on an electric circuit.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-04-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05654</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05660</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Alphabet-dependent Parallel Algorithm for Suffix Tree Construction for
  Pattern Searching</dc:title>
 <dc:creator>Kaniwa, Freeson</dc:creator>
 <dc:creator>Kuthadi, Venu Madhav</dc:creator>
 <dc:creator>Dinakenyane, Otlhapile</dc:creator>
 <dc:creator>Schroeder, Heiko</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Suffix trees have recently become very successful data structures in handling
large data sequences such as DNA or Protein sequences. Consequently parallel
architectures have become ubiquitous. We present a novel alphabet-dependent
parallel algorithm which attempts to take advantage of the perverseness of the
multicore architecture. Microsatellites are important for their biological
relevance hence our algorithm is based on time efficient construction for
identification of such. We experimentally achieved up to 15x speedup over the
sequential algorithm on different input sizes of biological sequences.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05660</dc:identifier>
 <dc:identifier>International Journal of Grid and Distributed Computing, Vol. 10,
  No. 1 (2017), pp.9-20</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05665</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CNN based music emotion classification</dc:title>
 <dc:creator>Liu, Xin</dc:creator>
 <dc:creator>Chen, Qingcai</dc:creator>
 <dc:creator>Wu, Xiangping</dc:creator>
 <dc:creator>Liu, Yan</dc:creator>
 <dc:creator>Liu, Yang</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Music emotion recognition (MER) is usually regarded as a multi-label tagging
task, and each segment of music can inspire specific emotion tags. Most
researchers extract acoustic features from music and explore the relations
between these features and their corresponding emotion tags. Considering the
inconsistency of emotions inspired by the same music segment for human beings,
seeking for the key acoustic features that really affect on emotions is really
a challenging task. In this paper, we propose a novel MER method by using deep
convolutional neural network (CNN) on the music spectrograms that contains both
the original time and frequency domain information. By the proposed method, no
additional effort on extracting specific features required, which is left to
the training procedure of the CNN model. Experiments are conducted on the
standard CAL500 and CAL500exp dataset. Results show that, for both datasets,
the proposed method outperforms state-of-the-art methods.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05665</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05674</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised object segmentation in video by efficient selection of
  highly probable positive features</dc:title>
 <dc:creator>Haller, Emanuela</dc:creator>
 <dc:creator>Leordeanu, Marius</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We address an essential problem in computer vision, that of unsupervised
object segmentation in video, where a main object of interest in a video
sequence should be automatically separated from its background. An efficient
solution to this task would enable large-scale video interpretation at a high
semantic level in the absence of the costly manually labeled ground truth. We
propose an efficient unsupervised method for generating foreground object
soft-segmentation masks based on automatic selection and learning from highly
probable positive features. We show that such features can be selected
efficiently by taking into consideration the spatio-temporal, appearance and
motion consistency of the object during the whole observed sequence. We also
emphasize the role of the contrasting properties between the foreground object
and its background. Our model is created in two stages: we start from pixel
level analysis, on top of which we add a regression model trained on a
descriptor that considers information over groups of pixels and is both
discriminative and invariant to many changes that the object undergoes
throughout the video. We also present theoretical properties of our
unsupervised learning method, that under some mild constraints is guaranteed to
learn a correct discriminative classifier even in the unsupervised case. Our
method achieves competitive and even state of the art results on the
challenging Youtube-Objects and SegTrack datasets, while being at least one
order of magnitude faster than the competition. We believe that the competitive
performance of our method in practice, along with its theoretical properties,
constitute an important step towards solving unsupervised discovery in video.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05674</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05676</identifier>
 <datestamp>2017-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CALF: Categorical Automata Learning Framework</dc:title>
 <dc:creator>van Heerdt, Gerco</dc:creator>
 <dc:creator>Sammartino, Matteo</dc:creator>
 <dc:creator>Silva, Alexandra</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:description>  Automata learning is a technique that has successfully been applied in
verification, with the automaton type varying depending on the application
domain. Adaptations of automata learning algorithms for increasingly complex
types of automata have to be developed from scratch because there was no
abstract theory offering guidelines. This makes it hard to devise such
algorithms, and it obscures their correctness proofs. We introduce a simple
category-theoretic formalism that provides an appropriately abstract foundation
for studying automata learning. Furthermore, our framework establishes formal
relations between algorithms for learning, testing, and minimization. We
illustrate its generality with two examples: deterministic and weighted
automata.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-06-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05676</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05678</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design of low-cost, compact and weather-proof whole sky imagers for
  high-dynamic-range captures</dc:title>
 <dc:creator>Dev, Soumyabrata</dc:creator>
 <dc:creator>Savoy, Florian M.</dc:creator>
 <dc:creator>Lee, Yee Hui</dc:creator>
 <dc:creator>Winkler, Stefan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Ground-based whole sky imagers are popular for monitoring cloud formations,
which is necessary for various applications. We present two new Wide Angle
High-Resolution Sky Imaging System (WAHRSIS) models, which were designed
especially to withstand the hot and humid climate of Singapore. The first uses
a fully sealed casing, whose interior temperature is regulated using a Peltier
cooler. The second features a double roof design with ventilation grids on the
sides, allowing the outside air to flow through the device. Measurements of
temperature inside these two devices show their ability to operate in Singapore
weather conditions. Unlike our original WAHRSIS model, neither uses a
mechanical sun blocker to prevent the direct sunlight from reaching the camera;
instead they rely on high-dynamic-range imaging (HDRI) techniques to reduce the
glare from the sun.
</dc:description>
 <dc:description>Comment: Published in Proc. IEEE International Geoscience and Remote Sensing
  Symposium (IGARSS), July 2015</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05678</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05682</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>m-Bonsai: a Practical Compact Dynamic Trie</dc:title>
 <dc:creator>Poyias, Andreas</dc:creator>
 <dc:creator>Puglisi, Simon J.</dc:creator>
 <dc:creator>Raman, Rajeev</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:subject>E.2</dc:subject>
 <dc:subject>E.4</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We consider the problem of implementing a space-efficient dynamic trie, with
an emphasis on good practical performance. For a trie with $n$ nodes with an
alphabet of size $\sigma$, the information-theoretic lower bound is $n \log
\sigma + O(n)$ bits. The Bonsai data structure is a compact trie proposed by
Darragh et al. (Softw., Pract. Exper. 23(3), 1993, p. 277-291). Its
disadvantages include the user having to specify an upper bound $M$ on the trie
size in advance (which cannot be changed easily after initalization), a space
usage of $M \log \sigma + O(M \log \log M)$ (which is asymptotically
non-optimal for smaller $\sigma$ or if $n \ll M$) and a lack of support for
deletions. It supports traversal and update operations in $O(1/\epsilon)$
expected time (based on assumptions about the behaviour of hash functions),
where $\epsilon = (M-n)/M$ and has excellent speed performance in practice. We
propose an alternative, m-Bonsai, that addresses the above problems, obtaining
a trie that uses $(1+\beta) n (\log \sigma + O(1))$ bits in expectation, and
supports traversal and update operations in $O(1/\beta)$ expected time and
$O(1/\beta^2)$ amortized expected time, for any user-specified parameter $\beta
&gt; 0$ (again based on assumptions about the behaviour of hash functions). We
give an implementation of m-Bonsai which uses considerably less memory and is
slightly faster than the original Bonsai.
</dc:description>
 <dc:description>Comment: Journal version of SPIRE 2015 paper by Poyias and Raman</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05682</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05684</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Distributed Scheduling Algorithm to Provide Quality-of-Service in
  Multihop Wireless Networks</dc:title>
 <dc:creator>S., Ashok Krishnan K.</dc:creator>
 <dc:creator>Sharma, Vinod</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Control of multihop Wireless networks in a distributed manner while providing
end-to-end delay requirements for different flows, is a challenging problem.
Using the notions of Draining Time and Discrete Review from the theory of fluid
limits of queues, an algorithm that meets delay requirements to various flows
in a network is constructed. The algorithm involves an optimization which is
implemented in a cyclic distributed manner across nodes by using the technique
of iterative gradient ascent, with minimal information exchange between nodes.
The algorithm uses time varying weights to give priority to flows. The
performance of the algorithm is studied in a network with interference modelled
by independent sets.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05684</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05692</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A multi-method simulation of a high-frequency bus line using AnyLogic</dc:title>
 <dc:creator>van der Spek, Thierry</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  In this work a mixed agent-based and discrete event simulation model is
developed for a high frequency bus route in the Netherlands. With this model,
different passenger growth scenarios can be easily evaluated. This simulation
model helps policy makers to predict changes that have to be made to bus routes
and planned travel times before problems occur. The model is validated using
several performance indicators, showing that under some model assumptions, it
can realistically simulate real-life situations. The simulation's workings are
illustrated by two use cases.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05692</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05693</identifier>
 <datestamp>2017-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Creation of Parameterized Avatars</dc:title>
 <dc:creator>Wolf, Lior</dc:creator>
 <dc:creator>Taigman, Yaniv</dc:creator>
 <dc:creator>Polyak, Adam</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study the problem of mapping an input image to a tied pair consisting of a
vector of parameters and an image that is created using a graphical engine from
the vector of parameters. The mapping's objective is to have the output image
as similar as possible to the input image. During training, no supervision is
given in the form of matching inputs and outputs.
  This learning problem extends two literature problems: unsupervised domain
adaptation and cross domain transfer. We define a generalization bound that is
based on discrepancy, and employ a GAN to implement a network solution that
corresponds to this bound. Experimentally, our method is shown to solve the
problem of automatically creating avatars.
</dc:description>
 <dc:description>Comment: v2 -- a change in the references due to a request from authors</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05693</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05698</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Segmentation of the Left Ventricle in Cardiac CT Angiography
  Using Convolutional Neural Network</dc:title>
 <dc:creator>Zreik, Majd</dc:creator>
 <dc:creator>Leiner, Tim</dc:creator>
 <dc:creator>de Vos, Bob D.</dc:creator>
 <dc:creator>van Hamersvelt, Robbert W.</dc:creator>
 <dc:creator>Viergever, Max A.</dc:creator>
 <dc:creator>Isgum, Ivana</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:description>  Accurate delineation of the left ventricle (LV) is an important step in
evaluation of cardiac function. In this paper, we present an automatic method
for segmentation of the LV in cardiac CT angiography (CCTA) scans. Segmentation
is performed in two stages. First, a bounding box around the LV is detected
using a combination of three convolutional neural networks (CNNs).
Subsequently, to obtain the segmentation of the LV, voxel classification is
performed within the defined bounding box using a CNN. The study included CCTA
scans of sixty patients, fifty scans were used to train the CNNs for the LV
localization, five scans were used to train LV segmentation and the remaining
five scans were used for testing the method. Automatic segmentation resulted in
the average Dice coefficient of 0.85 and mean absolute surface distance of 1.1
mm. The results demonstrate that automatic segmentation of the LV in CCTA scans
using voxel classification with convolutional neural networks is feasible.
</dc:description>
 <dc:description>Comment: This work has been published as: Zreik, M., Leiner, T., de Vos, B.
  D., van Hamersvelt, R. W., Viergever, M. A., I\v{s}gum, I. (2016, April).
  Automatic segmentation of the left ventricle in cardiac CT angiography using
  convolutional neural networks. In Biomedical Imaging (ISBI), 2016 IEEE 13th
  International Symposium on (pp. 40-43). IEEE</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05698</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05703</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Sphere-Packing Bounds with Polynomial Prefactors</dc:title>
 <dc:creator>Cheng, Hao-Chung</dc:creator>
 <dc:creator>Hsieh, Min-Hsiu</dc:creator>
 <dc:creator>Tomamichel, Marco</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study lower bounds on the optimal error probability in classical coding
over classical-quantum channels at rates below the capacity, commonly termed
quantum sphere-packing bounds. Winter and Dalai have derived such bounds for
classical-quantum channels; however, the exponents in their bounds only
coincide when the channel is classical. In this paper, we show that these two
exponents admit a variational representation and are related by the
Golden-Thompson inequality, reaffirming that Dalai's expression is stronger in
general classical-quantum channels. Second, we establish a sphere-packing bound
for classical-quantum channels, which significantly improves Dalai's prefactor
from the order of subexponential to polynomial. Furthermore, the gap between
the obtained error exponent for constant composition codes and the best known
classical random coding exponent vanishes in the order of $o(\log n / n)$,
indicating our sphere-packing bound is almost exact in the high rate regime.
Finally, for a special class of symmetric classical-quantum channels, we can
completely characterize its optimal error probability without the constant
composition code assumption. The main technical contributions are two converse
Hoeffding bounds for quantum hypothesis testing and the saddle-point properties
of error exponent functions.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05708</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Deep Learning Framework using Passive WiFi Sensing for Respiration
  Monitoring</dc:title>
 <dc:creator>Khan, U. M.</dc:creator>
 <dc:creator>Kabir, Z.</dc:creator>
 <dc:creator>Hassan, S. A.</dc:creator>
 <dc:creator>Ahmed, S. H.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper presents an end-to-end deep learning framework using passive WiFi
sensing to classify and estimate human respiration activity. A passive radar
test-bed is used with two channels where the first channel provides the
reference WiFi signal, whereas the other channel provides a surveillance signal
that contains reflections from the human target. Adaptive filtering is
performed to make the surveillance signal source-data invariant by eliminating
the echoes of the direct transmitted signal. We propose a novel convolutional
neural network to classify the complex time series data and determine if it
corresponds to a breathing activity, followed by a random forest estimator to
determine breathing rate. We collect an extensive dataset to train the learning
models and develop reference benchmarks for the future studies in the field.
Based on the results, we conclude that deep learning techniques coupled with
passive radars offer great potential for end-to-end human activity recognition.
</dc:description>
 <dc:description>Comment: 7 pages, 11 figures</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05708</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05709</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>$\beta$-expansion: A Theoretical Framework for Fast and Recursive
  Construction of Polar Codes</dc:title>
 <dc:creator>He, Gaoning</dc:creator>
 <dc:creator>Belfiore, Jean-Claude</dc:creator>
 <dc:creator>Liu, Xiaocheng</dc:creator>
 <dc:creator>Ge, Yiqun</dc:creator>
 <dc:creator>Zhang, Ran</dc:creator>
 <dc:creator>Land, Ingmar</dc:creator>
 <dc:creator>Chen, Ying</dc:creator>
 <dc:creator>Li, Rong</dc:creator>
 <dc:creator>Wang, Jun</dc:creator>
 <dc:creator>Yang, Ganghua</dc:creator>
 <dc:creator>Tong, Wen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work, we introduce $\beta$-expansion, a notion borrowed from number
theory, as a theoretical framework to study fast construction of polar codes
based on a recursive structure of universal partial order (UPO) and
polarization weight (PW) algorithm. We show that polar codes can be recursively
constructed from UPO by continuously solving several polynomial equations at
each recursive step. From these polynomial equations, we can extract an
interval for $\beta$, such that ranking the synthetic channels through a
closed-form $\beta$-expansion preserves the property of nested frozen sets,
which is a desired feature for low-complex construction. In an example of AWGN
channels, we show that this interval for $\beta$ converges to a constant close
to $1.1892 \approx 2^{1/4}$ when the code block-length trends to infinity. Both
asymptotic analysis and simulation results validate our theoretical claims.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05711</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>C-RAN with Hybrid RF/FSO Fronthaul Links: Joint Optimization of RF Time
  Allocation and Fronthaul Compression</dc:title>
 <dc:creator>Najafi, Marzieh</dc:creator>
 <dc:creator>Jamali, Vahid</dc:creator>
 <dc:creator>Ng, Derrick Wing Kwan</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers the uplink of a cloud radio access network (C-RAN)
comprised of several multi-antenna remote radio units (RUs) which send the data
that they received from multiple mobile users (MUs) to a central unit (CU) via
a wireless fronthaul link. One of the fundamental challenges in implementing
C-RAN is the huge data rate required for fronthauling. To address this issue,
we employ hybrid radio frequency (RF)/free space optical (FSO) systems for the
fronthaul links as they benefit from both the large data rates of FSO links and
the reliability of RF links. To efficiently exploit the fronthaul capacity, the
RUs employ vector quantization to jointly compress the signals received at
their antennas. Moreover, due to the limited available RF spectrum, we assume
that the RF multiple-access and fronthaul links employ the same RF resources.
Thereby, we propose an adaptive protocol which allocates transmission time to
the RF multiple-access and fronthaul links in a time division duplex (TDD)
manner and optimizes the quantization noise covariance matrix at each RU such
that the sum rate is maximized. Our simulation results reveal that a
considerable gain in terms of sum rate can be achieved by the proposed protocol
in comparison with benchmark schemes from the literature, especially when the
FSO links experience unfavorable atmospheric conditions.
</dc:description>
 <dc:description>Comment: This paper has been submitted to IEEE Global Communications
  Conference (GLOBECOM) 2017</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05711</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05712</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Universal Adversarial Perturbations Against Semantic Image Segmentation</dc:title>
 <dc:creator>Metzen, Jan Hendrik</dc:creator>
 <dc:creator>Kumar, Mummadi Chaithanya</dc:creator>
 <dc:creator>Brox, Thomas</dc:creator>
 <dc:creator>Fischer, Volker</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  While deep learning is remarkably successful on perceptual tasks, it was also
shown to be vulnerable to adversarial perturbations of the input. These
perturbations denote noise added to the input that was generated specifically
to fool the system while being quasi-imperceptible for humans. More severely,
there even exist universal perturbations that are input-agnostic but fool the
network on the majority of inputs. While recent work has focused on image
classification, this work proposes attacks against semantic image segmentation:
we present an approach for generating (universal) adversarial perturbations
that make the network yield a desired target segmentation as output. We show
empirically that there exist barely perceptible universal noise patterns which
result in nearly the same predicted segmentation for arbitrary inputs.
Furthermore, we also show the existence of universal noise which removes a
target class (e.g., all pedestrians) from the segmentation while leaving the
segmentation mostly unchanged otherwise.
</dc:description>
 <dc:description>Comment: Final version for ICCV including supplementary material</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05712</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05724</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The True Destination of EGO is Multi-local Optimization</dc:title>
 <dc:creator>Wessing, Simon</dc:creator>
 <dc:creator>Preuss, Mike</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Efficient global optimization is a popular algorithm for the optimization of
expensive multimodal black-box functions. One important reason for its
popularity is its theoretical foundation of global convergence. However, as the
budgets in expensive optimization are very small, the asymptotic properties
only play a minor role and the algorithm sometimes comes off badly in
experimental comparisons. Many alternative variants have therefore been
proposed over the years. In this work, we show experimentally that the
algorithm instead has its strength in a setting where multiple optima are to be
identified.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05724</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05730</identifier>
 <datestamp>2017-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Measuring Bias in Online Information</dc:title>
 <dc:creator>Pitoura, Evaggelia</dc:creator>
 <dc:creator>Tsaparas, Panayiotis</dc:creator>
 <dc:creator>Flouris, Giorgos</dc:creator>
 <dc:creator>Fundulaki, Irini</dc:creator>
 <dc:creator>Papadakos, Panagiotis</dc:creator>
 <dc:creator>Abiteboul, Serge</dc:creator>
 <dc:creator>Weikum, Gerhard</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Bias in online information has recently become a pressing issue, with search
engines, social networks and recommendation services being accused of
exhibiting some form of bias. In this vision paper, we make the case for a
systematic approach towards measuring bias. To this end, we discuss formal
measures for quantifying the various types of bias, we outline the system
components necessary for realizing them, and we highlight the related research
challenges and open problems.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-10-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05730</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05735</identifier>
 <datestamp>2017-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collaborative Filtering with Social Local Models</dc:title>
 <dc:creator>Zhao, Huan</dc:creator>
 <dc:creator>Yao, Quanming</dc:creator>
 <dc:creator>Kwok, James T.</dc:creator>
 <dc:creator>Lee, Dik Lun</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Matrix Factorization (MF) is a very popular method for recommendation
systems. It assumes that the underneath rating matrix is low-rank. However,
this assumption can be too restrictive to capture complex relationships and
interactions among users and items. Recently, Local LOw-Rank Matrix
Approximation (LLORMA) has been shown to be very successful in addressing this
issue. It just assumes the rating matrix is composed of a number of low-rank
submatrices constructed from subsets of similar users and items. Although
LLORMA outperforms MF, how to construct such submatrices remains a big problem.
Motivated by the availability of rich social connections in today's
recommendation systems, we propose a novel framework, i.e., Social LOcal
low-rank Matrix Approximation (SLOMA), to address this problem. To the best of
our knowledge, SLOMA is the first work to incorporate social connections into
the local low-rank framework. Furthermore, we enhance SLOMA by applying social
regularization to submatrices factorization, denoted as SLOMA++. Therefore, the
proposed model can benefit from both social recommendation and the local
low-rank assumption. Experimental results from two real-world datasets, Yelp
and Douban, demonstrate the superiority of the proposed models over LLORMA and
MF.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05735</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05737</identifier>
 <datestamp>2017-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Video Object Segmentation with Visual Memory</dc:title>
 <dc:creator>Tokmakov, Pavel</dc:creator>
 <dc:creator>Alahari, Karteek</dc:creator>
 <dc:creator>Schmid, Cordelia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper addresses the task of segmenting moving objects in unconstrained
videos. We introduce a novel two-stream neural network with an explicit memory
module to achieve this. The two streams of the network encode spatial and
temporal features in a video sequence respectively, while the memory module
captures the evolution of objects over time. The module to build a &quot;visual
memory&quot; in video, i.e., a joint representation of all the video frames, is
realized with a convolutional recurrent unit learned from a small number of
training video sequences. Given a video frame as input, our approach assigns
each pixel an object or background label based on the learned spatio-temporal
features as well as the &quot;visual memory&quot; specific to the video, acquired
automatically without any manually-annotated frames. The visual memory is
implemented with convolutional gated recurrent units, which allows to propagate
spatial information over time. We evaluate our method extensively on two
benchmarks, DAVIS and Freiburg-Berkeley motion segmentation datasets, and show
state-of-the-art results. For example, our approach outperforms the top method
on the DAVIS dataset by nearly 6%. We also provide an extensive ablative
analysis to investigate the influence of each component in the proposed
framework.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05737</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05739</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Long It Takes for an Ordinary Node with an Ordinary ID to Output?</dc:title>
 <dc:creator>Feuilloley, Laurent</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In the context of distributed synchronous computing, processors perform in
rounds, and the time-complexity of a distributed algorithm is classically
defined as the number of rounds before all computing nodes have output. Hence,
this complexity measure captures the running time of the slowest node(s). In
this paper, we are interested in the running time of the ordinary nodes, to be
compared with the running time of the slowest nodes. The node-averaged
time-complexity of a distributed algorithm on a given instance is defined as
the average, taken over every node of the instance, of the number of rounds
before that node output. We compare the node-averaged time-complexity with the
classical one in the standard LOCAL model for distributed network computing. We
show that there can be an exponential gap between the node-averaged
time-complexity and the classical time-complexity, as witnessed by, e.g.,
leader election. Our first main result is a positive one, stating that, in
fact, the two time-complexities behave the same for a large class of problems
on very sparse graphs. In particular, we show that, for LCL problems on cycles,
the node-averaged time complexity is of the same order of magnitude as the
slowest node time-complexity.
  In addition, in the LOCAL model, the time-complexity is computed as a worst
case over all possible identity assignments to the nodes of the network. In
this paper, we also investigate the ID-averaged time-complexity, when the
number of rounds is averaged over all possible identity assignments. Our second
main result is that the ID-averaged time-complexity is essentially the same as
the expected time-complexity of randomized algorithms (where the expectation is
taken over all possible random bits used by the nodes, and the number of rounds
is measured for the worst-case identity assignment).
  Finally, we study the node-averaged ID-averaged time-complexity.
</dc:description>
 <dc:description>Comment: (Submitted) Journal version</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05739</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05741</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Study of Anomaly Detection Based on Randomized Subspace Methods in IP
  Networks</dc:title>
 <dc:creator>Kaloorazi, M.</dc:creator>
 <dc:creator>de Lamare, R. C.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we propose novel randomized subspace methods to detect
anomalies in Internet Protocol networks. Given a data matrix containing
information about network traffic, the proposed approaches perform a
normal-plus-anomalous matrix decomposition aided by random subspace techniques
and subsequently detect traffic anomalies in the anomalous subspace using a
statistical test. Experimental results demonstrate improvement over the
traditional principal component analysis-based subspace methods in terms of
robustness to noise and detection rate.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05741</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05742</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Multi-task Learning for Text Classification</dc:title>
 <dc:creator>Liu, Pengfei</dc:creator>
 <dc:creator>Qiu, Xipeng</dc:creator>
 <dc:creator>Huang, Xuanjing</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Neural network models have shown their promising opportunities for multi-task
learning, which focus on learning the shared layers to extract the common and
task-invariant features. However, in most existing approaches, the extracted
shared features are prone to be contaminated by task-specific features or the
noise brought by other tasks. In this paper, we propose an adversarial
multi-task learning framework, alleviating the shared and private latent
feature spaces from interfering with each other. We conduct extensive
experiments on 16 different text classification tasks, which demonstrates the
benefits of our approach. Besides, we show that the shared knowledge learned by
our proposed model can be regarded as off-the-shelf knowledge and easily
transferred to new tasks. The datasets of all 16 tasks are publicly available
at \url{http://nlp.fudan.edu.cn/data/}
</dc:description>
 <dc:description>Comment: Accepted by ACL2017</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05742</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05746</identifier>
 <datestamp>2017-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vehicular Communications: A Physical Layer Perspective</dc:title>
 <dc:creator>Liang, Le</dc:creator>
 <dc:creator>Peng, Haixia</dc:creator>
 <dc:creator>Li, Geoffrey Ye</dc:creator>
 <dc:creator>Shen, Xuemin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Vehicular communications have attracted more and more attention recently from
both industry and academia due to its strong potential to enhance road safety,
improve traffic efficiency, and provide rich on-board information and
entertainment services. In this paper, we discuss fundamental physical layer
issues that enable efficient vehicular communications and present a
comprehensive overview of the state-of-the-art research. We first introduce
vehicular channel characteristics and modeling, which are the key underlying
features differentiating vehicular communications from other types of wireless
systems. We then present schemes to estimate the time-varying vehicular
channels and various modulation techniques to deal with high-mobility channels.
After reviewing resource allocation for vehicular communications, we discuss
the potential to enable vehicular communications over the millimeter wave
bands. Finally, we identify the challenges and opportunities associated with
vehicular communications.
</dc:description>
 <dc:description>Comment: 13pages, 4 figures. Accepted by IEEE Trans. Veh. Technol</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-09-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05746</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05753</identifier>
 <datestamp>2017-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Task Design Trade-offs in Crowdsourced Paraphrase
  Collection</dc:title>
 <dc:creator>Jiang, Youxuan</dc:creator>
 <dc:creator>Kummerfeld, Jonathan K.</dc:creator>
 <dc:creator>Lasecki, Walter S.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>H.5.0</dc:subject>
 <dc:description>  Linguistically diverse datasets are critical for training and evaluating
robust machine learning systems, but data collection is a costly process that
often requires experts. Crowdsourcing the process of paraphrase generation is
an effective means of expanding natural language datasets, but there has been
limited analysis of the trade-offs that arise when designing tasks. In this
paper, we present the first systematic study of the key factors in
crowdsourcing paraphrase collection. We consider variations in instructions,
incentives, data domains, and workflows. We manually analyzed paraphrases for
correctness, grammaticality, and linguistic diversity. Our observations provide
new insight into the trade-offs between accuracy and diversity in crowd
responses that arise as a result of task design, providing guidance for future
paraphrase generation procedures.
</dc:description>
 <dc:description>Comment: Published at ACL 2017</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-10-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05753</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05754</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A location-aware embedding technique for accurate landmark recognition</dc:title>
 <dc:creator>Magliani, Federico</dc:creator>
 <dc:creator>Bidgoli, Navid Mahmoudian</dc:creator>
 <dc:creator>Prati, Andrea</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The current state of the research in landmark recognition highlights the good
accuracy which can be achieved by embedding techniques, such as Fisher vector
and VLAD. All these techniques do not exploit spatial information, i.e.
consider all the features and the corresponding descriptors without embedding
their location in the image. This paper presents a new variant of the
well-known VLAD (Vector of Locally Aggregated Descriptors) embedding technique
which accounts, at a certain degree, for the location of features. The driving
motivation comes from the observation that, usually, the most interesting part
of an image (e.g., the landmark to be recognized) is almost at the center of
the image, while the features at the borders are irrelevant features which do
no depend on the landmark. The proposed variant, called locVLAD (location-aware
VLAD), computes the mean of the two global descriptors: the VLAD executed on
the entire original image, and the one computed on a cropped image which
removes a certain percentage of the image borders. This simple variant shows an
accuracy greater than the existing state-of-the-art approach. Experiments are
conducted on two public datasets (ZuBuD and Holidays) which are used both for
training and testing. Morever a more balanced version of ZuBuD is proposed.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures, ICDSC 2017</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05754</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05758</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rate-Distortion Theory of Finite Point Processes</dc:title>
 <dc:creator>Koliander, G&#xfc;nther</dc:creator>
 <dc:creator>Schuhmacher, Dominic</dc:creator>
 <dc:creator>Hlawatsch, Franz</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>94A34, 60G55</dc:subject>
 <dc:description>  We study the compression of data in the case where the useful information is
contained in a set rather than a vector, i.e., the ordering of the data points
is irrelevant and the number of data points is unknown. Our analysis is based
on rate-distortion theory and the theory of finite point processes. We
introduce fundamental information-theoretic concepts and quantities for point
processes and present general lower and upper bounds on the rate-distortion
function. To enable a comparison with the vector setting, we concretize our
bounds for point processes of fixed cardinality. In particular, we analyze a
fixed number of unordered data points with a Gaussian distribution and show
that we can significantly reduce the required rates compared to the best
possible compression strategy for Gaussian vectors. As an example of point
processes with variable cardinality, we study the best possible compression of
Poisson point processes. For the specific case of a Poisson point process with
uniform intensity on the unit square, our lower and upper bounds are separated
only by a small gap and thus provide a good characterization of the
rate-distortion function.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05758</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05761</identifier>
 <datestamp>2017-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximum Likelihood Estimation based on Random Subspace EDA: Application
  to Extrasolar Planet Detection</dc:title>
 <dc:creator>Liu, Bin</dc:creator>
 <dc:creator>Chen, Ke-Jia</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  This paper addresses maximum likelihood (ML) estimation based model fitting
in the context of extrasolar planet detection. This problem is featured by the
following properties: 1) the candidate models under consideration are highly
nonlinear; 2) the likelihood surface has a huge number of peaks; 3) the
parameter space ranges in size from a few to dozens of dimensions. These
properties make the ML search a very challenging problem, as it lacks any
analytical or gradient based searching solution to explore the parameter space.
A population based searching method, called estimation of distribution
algorithm (EDA), is adopted to explore the model parameter space starting from
a batch of random locations. EDA is featured by its ability to reveal and
utilize problem structures. This property is desirable for characterizing the
detections. However, it is well recognized that EDAs can not scale well to
large scale problems, as it consists of iterative random sampling and model
fitting procedures, which results in the well-known dilemma curse of
dimensionality. A novel mechanism to perform EDAs in interactive random
subspaces spanned by correlated variables is proposed and the hope is to
alleviate the curse of dimensionality for EDAs by performing the operations of
sampling and model fitting in lower dimensional subspaces. The effectiveness of
the proposed algorithm is verified via both benchmark numerical studies and
real data analysis.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures, conference</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-07-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05761</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05773</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Derivation of the Asymptotic Eigenvalue Distribution for Causal 2D-AR
  Models under Upscaling</dc:title>
 <dc:creator>V&#xe1;zquez-Pad&#xed;n, David</dc:creator>
 <dc:creator>P&#xe9;rez-Gonz&#xe1;lez, Fernando</dc:creator>
 <dc:creator>Comesa&#xf1;a-Alfaro, Pedro</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This technical report describes the derivation of the asymptotic eigenvalue
distribution for causal 2D-AR models under an upscaling scenario. Specifically,
it tackles the analytical derivation of the asymptotic eigenvalue distribution
of the sample autocorrelation matrix corresponding to genuine and upscaled
images. It also includes the pseudocode of the derived approaches for
resampling detection and resampling factor estimation that are based on this
analysis.
</dc:description>
 <dc:description>Comment: This technical report complements the work by David
  V\'azquez-Pad\'in, Fernando P\'erez-Gonz\'alez, and Pedro Comesa\~na-Alfaro,
  &quot;A random matrix approach to the forensic analysis of upscaled images,&quot;
  submitted to IEEE Transactions on Information Forensics and Security</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05773</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05775</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Occlusion Reasoning for Multi-Camera Multi-Target Detection</dc:title>
 <dc:creator>Baqu&#xe9;, Pierre</dc:creator>
 <dc:creator>Fleuret, Fran&#xe7;ois</dc:creator>
 <dc:creator>Fua, Pascal</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  People detection in single 2D images has improved greatly in recent years.
However, comparatively little of this progress has percolated into multi-camera
multi-people tracking algorithms, whose performance still degrades severely
when scenes become very crowded. In this work, we introduce a new architecture
that combines Convolutional Neural Nets and Conditional Random Fields to
explicitly model those ambiguities. One of its key ingredients are high-order
CRF terms that model potential occlusions and give our approach its robustness
even when many people are present. Our model is trained end-to-end and we show
that it outperforms several state-of-art algorithms on challenging scenes.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05775</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05776</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accurate Single Stage Detector Using Recurrent Rolling Convolution</dc:title>
 <dc:creator>Ren, Jimmy</dc:creator>
 <dc:creator>Chen, Xiaohao</dc:creator>
 <dc:creator>Liu, Jianbo</dc:creator>
 <dc:creator>Sun, Wenxiu</dc:creator>
 <dc:creator>Pang, Jiahao</dc:creator>
 <dc:creator>Yan, Qiong</dc:creator>
 <dc:creator>Tai, Yu-Wing</dc:creator>
 <dc:creator>Xu, Li</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Most of the recent successful methods in accurate object detection and
localization used some variants of R-CNN style two stage Convolutional Neural
Networks (CNN) where plausible regions were proposed in the first stage then
followed by a second stage for decision refinement. Despite the simplicity of
training and the efficiency in deployment, the single stage detection methods
have not been as competitive when evaluated in benchmarks consider mAP for high
IoU thresholds. In this paper, we proposed a novel single stage end-to-end
trainable object detection network to overcome this limitation. We achieved
this by introducing Recurrent Rolling Convolution (RRC) architecture over
multi-scale feature maps to construct object classifiers and bounding box
regressors which are &quot;deep in context&quot;. We evaluated our method in the
challenging KITTI dataset which measures methods under IoU threshold of 0.7. We
showed that with RRC, a single reduced VGG-16 based model already significantly
outperformed all the previously published results. At the time this paper was
written our models ranked the first in KITTI car detection (the hard level),
the first in cyclist detection and the second in pedestrian detection. These
results were not reached by the previous single stage methods. The code is
publicly available.
</dc:description>
 <dc:description>Comment: CVPR 2017</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05776</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05781</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Redefining Context Windows for Word Embedding Models: An Experimental
  Study</dc:title>
 <dc:creator>Lison, Pierre</dc:creator>
 <dc:creator>Kutuzov, Andrey</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Distributional semantic models learn vector representations of words through
the contexts they occur in. Although the choice of context (which often takes
the form of a sliding window) has a direct influence on the resulting
embeddings, the exact role of this model component is still not fully
understood. This paper presents a systematic analysis of context windows based
on a set of four distinct hyper-parameters. We train continuous Skip-Gram
models on two English-language corpora for various combinations of these
hyper-parameters, and evaluate them on both lexical similarity and analogy
tasks. Notable experimental results are the positive impact of cross-sentential
contexts and the surprisingly good performance of right-context windows.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05781</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05782</identifier>
 <datestamp>2017-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Positive Semidefiniteness and Positive Definiteness of a Linear
  Parametric Interval Matrix</dc:title>
 <dc:creator>Hlad&#xed;k, Milan</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  We consider a symmetric matrix, the entries of which depend linearly on some
parameters. The domains of the parameters are compact real intervals. We
investigate the problem of checking whether for each (or some) setting of the
parameters, the matrix is positive definite (or positive semidefinite). We
state a characterization in the form of equivalent conditions, and also propose
some computationally cheap sufficient\,/\,necessary conditions. Our results
extend the classical results on positive (semi-)definiteness of interval
matrices. They may be useful for checking convexity or non-convexity in global
optimization methods based on branch and bound framework and using interval
techniques.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05782</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05795</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sorting sums of binary decision summands</dc:title>
 <dc:creator>Gross, Torsten</dc:creator>
 <dc:creator>Bl&#xfc;thgen, Nils</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A sum where each of the $N$ summands can be independently chosen from two
choices yields $2^N$ possible summation outcomes. There is an
$\mathcal{O}(K^2)$-algorithm that finds the $K$ smallest/largest of these sums
by evading the enumeration of all sums.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05795</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05796</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network Dissection: Quantifying Interpretability of Deep Visual
  Representations</dc:title>
 <dc:creator>Bau, David</dc:creator>
 <dc:creator>Zhou, Bolei</dc:creator>
 <dc:creator>Khosla, Aditya</dc:creator>
 <dc:creator>Oliva, Aude</dc:creator>
 <dc:creator>Torralba, Antonio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:description>  We propose a general framework called Network Dissection for quantifying the
interpretability of latent representations of CNNs by evaluating the alignment
between individual hidden units and a set of semantic concepts. Given any CNN
model, the proposed method draws on a broad data set of visual concepts to
score the semantics of hidden units at each intermediate convolutional layer.
The units with semantics are given labels across a range of objects, parts,
scenes, textures, materials, and colors. We use the proposed method to test the
hypothesis that interpretability of units is equivalent to random linear
combinations of units, then we apply our method to compare the latent
representations of various networks when trained to solve different supervised
and self-supervised training tasks. We further analyze the effect of training
iterations, compare networks trained with different initializations, examine
the impact of network depth and width, and measure the effect of dropout and
batch normalization on the interpretability of deep visual representations. We
demonstrate that the proposed method can shed light on characteristics of CNN
models and training methods that go beyond measurements of their discriminative
power.
</dc:description>
 <dc:description>Comment: First two authors contributed equally. Oral presentation at CVPR 2017</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05796</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05798</identifier>
 <datestamp>2017-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A complete dichotomy for complex-valued Holant^c</dc:title>
 <dc:creator>Backens, Miriam</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Holant problems are a family of counting problems on graphs, parametrised by
sets of complex-valued functions of Boolean inputs. Holant^c denotes a
subfamily of those problems, where any function set considered must contain the
two unary functions pinning inputs to values 0 or 1. The complexity
classification of Holant problems usually takes the form of dichotomy theorems,
showing that for any set of functions in the family, the problem is either
#P-hard or it can be solved in polynomial time. Previous such results include a
dichotomy for real-valued Holant^c and one for Holant^c with complex symmetric
functions.
  Here, we derive a dichotomy theorem for Holant^c with complex-valued, not
necessarily symmetric functions. The tractable cases are the complex-valued
generalisations of the tractable cases of the real-valued Holant^c dichotomy.
The proof uses results from quantum information theory, particularly about
entanglement.
</dc:description>
 <dc:description>Comment: 18 pages; v2 fixes statement of main theorem and one of the lemmas</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-04-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05801</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gender Disparities in Science? Dropout, Productivity, Collaborations and
  Success of Male and Female Computer Scientists</dc:title>
 <dc:creator>Jadidi, Mohsen</dc:creator>
 <dc:creator>Karimi, Fariba</dc:creator>
 <dc:creator>Lietz, Haiko</dc:creator>
 <dc:creator>Wagner, Claudia</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Scientific collaborations shape ideas as well as innovations and are both the
substrate for, and the outcome of, academic careers. Recent studies show that
gender inequality is still present in many scientific practices ranging from
hiring to peer-review processes and grant applications. In this work, we
investigate gender-specific differences in collaboration patterns of more than
one million computer scientists over the course of 47 years. We explore how
these patterns change over years and career ages and how they impact scientific
success. Our results highlight that successful male and female scientists
reveal the same collaboration patterns: compared to scientists in the same
career age, they tend to collaborate with more colleagues than other
scientists, seek innovations as brokers and establish longer-lasting and more
repetitive collaborations. However, women are on average less likely to adapt
the collaboration patterns that are related with success, more likely to embed
into ego networks devoid of structural holes, and they exhibit stronger gender
homophily as well as a consistently higher dropout rate than men in all career
ages.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05801</dc:identifier>
 <dc:identifier>Advances in Complex Systems (2017)</dc:identifier>
 <dc:identifier>doi:10.1142/S0219525917500114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05808</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reliable Probabilistic Gossip over Large-Scale Random Topologies</dc:title>
 <dc:creator>Hu, Ruijing</dc:creator>
 <dc:creator>Jehl, Leander</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper studies reliability of probabilistic neighbor-aware gossip
algorithms over three well- known large-scale random topologies, namely
Bernoulli (or Erd\H{o}s-R\'enyi) graph, the random geometric graph, and the
scale-free graph. We propose a new and simple algorithm which ensures higher
reliability at lower message complexity than the three families of gossip
algorithms over every topology in our study. We also present a uniform approach
to model the reliability of probabilistic gossip algorithms in the different
random graphs, whose properties, in fact, are quite different. In our model a
forwarding probability is derived with consideration of parameters in gossip
algorithms and graph properties. Our simulations show that our model gives a
reasonable prediction of the trade-off between reliability and message
complexity for all probabilistic neighbor-aware gossip algorithms in various
random networks. Therefore, it allows to fine-tune the input parameters in the
gossip protocols to achieve a desirable reliability with tolerable message
complexity.
</dc:description>
 <dc:description>Comment: 18 pages, 3 figures, Journal</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05808</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05811</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Weighted Degree-Bounded Steiner Networks via Novel Online Mixed
  Packing/Covering</dc:title>
 <dc:creator>Dehghani, Sina</dc:creator>
 <dc:creator>Ehsani, Soheil</dc:creator>
 <dc:creator>Hajiaghayi, MohammadTaghi</dc:creator>
 <dc:creator>Liaghat, Vahid</dc:creator>
 <dc:creator>Racke, Harald</dc:creator>
 <dc:creator>Seddighin, Saeed</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We design the first online algorithm with poly-logarithmic competitive ratio
for the edge-weighted degree-bounded Steiner forest(EW-DB-SF) problem and its
generalized variant. We obtain our result by demonstrating a new generic
approach for solving mixed packing/covering integer programs in the online
paradigm. In EW-DB-SF we are given an edge-weighted graph with a degree bound
for every vertex. Given a root vertex in advance we receive a sequence of
terminal vertices in an online manner. Upon the arrival of a terminal we need
to augment our solution subgraph to connect the new terminal to the root. The
goal is to minimize the total weight of the solution while respecting the
degree bounds on the vertices. In the offline setting edge-weighted
degree-bounded Steiner tree (EW-DB-ST) and its many variations have been
extensively studied since early eighties. Unfortunately the recent advancements
in the online network design problems are inherently difficult to adapt for
degree-bounded problems. In contrast in this paper we obtain our result by
using structural properties of the optimal solution, and reducing the EW-DB-SF
problem to an exponential-size mixed packing/covering integer program in which
every variable appears only once in covering constraints. We then design a
generic integral algorithm for solving this restricted family of IPs. We
demonstrate a new technique for solving mixed packing/covering integer
programs. Define the covering frequency k of a program as the maximum number of
covering constraints in which a variable can participate. Let m denote the
number of packing constraints. We design an online deterministic integral
algorithm with competitive ratio of O(k log m) for the mixed packing/covering
integer programs. We believe this technique can be used as an interesting
alternative for the standard primal-dual techniques in solving online problems.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05811</dc:identifier>
 <dc:identifier>Dehghani, Sina, Soheil Ehsani, Mohammad Taghi Hajiaghayi, Vahid
  Liaghat, Harald Racke, and Saeed Seddighin. &quot;Online Weighted Degree-Bounded
  Steiner Networks via Novel Online Mixed Packing/Covering.&quot; ICALP 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05815</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Headphones on the wire</dc:title>
 <dc:creator>Louail, Thomas</dc:creator>
 <dc:creator>Barthelemy, Marc</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We analyze a dataset providing the complete information on the effective
plays of thousands of music listeners during several months. Our analysis
confirms a number of properties previously highlighted by research based on
interviews and questionnaires, but also uncover new statistical patterns, both
at the individual and collective levels. In particular, we show that
individuals follow common listening rhythms characterized by the same
fluctuations, alternating heavy and light listening periods, and can be
classified in four groups of similar sizes according to their temporal habits
--- 'early birds', 'working hours listeners', 'evening listeners' and 'night
owls'. We provide a detailed radioscopy of the listeners' interplay between
repeated listening and discovery of new content. We show that different genres
encourage different listening habits, from Classical or Jazz music with a more
balanced listening among different songs, to Hip Hop and Dance with a more
heterogeneous distribution of plays. Finally, we provide measures of how
distant people are from each other in terms of common songs. In particular, we
show that the number of songs $S$ a DJ should play to a random audience of size
$N$ such that everyone hears at least one song he/she currently listens to, is
of the form $S\sim N^\alpha$ where the exponent depends on the music genre and
is in the range $[0.5,0.8]$. More generally, our results show that the recent
access to virtually infinite catalogs of songs does not promote exploration for
novelty, but that most users favor repetition of the same songs.
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures + SI (13 pages and 13 Supplementary figures)</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05815</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05816</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analytical study of the &quot;master-worker&quot; framework scalability on
  multiprocessors with distributed memory</dc:title>
 <dc:creator>Sokolinsky, L. B.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The paper is devoted to an analytical study of the &quot;master-worker&quot; framework
scalability on multiprocessors with distributed memory. A new model of parallel
computations called BSF is proposed. The BSF model is based on BSP and SPMD
models. The scope of BSF model is the compute-intensive applications. The
architecture of BSF-computer is defined. The structure of BSF-program is
described. The Using this metric, the upper scalability bounds of BSF programs
on distributed memory multiprocessors are evaluated. The formulas for
estimating the parallel efficiency of BSF programs also proposed.
</dc:description>
 <dc:description>Comment: Submitted to &quot;Parallel computational technologies 2018&quot; (in Russian)</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-09-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05816</dc:identifier>
 <dc:language>ru</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05817</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learn to Model Motion from Blurry Footages</dc:title>
 <dc:creator>Li, Wenbin</dc:creator>
 <dc:creator>Chen, Da</dc:creator>
 <dc:creator>Lv, Zhihan</dc:creator>
 <dc:creator>Yan, Yan</dc:creator>
 <dc:creator>Cosker, Darren</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  It is difficult to recover the motion field from a real-world footage given a
mixture of camera shake and other photometric effects. In this paper we propose
a hybrid framework by interleaving a Convolutional Neural Network (CNN) and a
traditional optical flow energy. We first conduct a CNN architecture using a
novel learnable directional filtering layer. Such layer encodes the angle and
distance similarity matrix between blur and camera motion, which is able to
enhance the blur features of the camera-shake footages. The proposed CNNs are
then integrated into an iterative optical flow framework, which enable the
capability of modelling and solving both the blind deconvolution and the
optical flow estimation problems simultaneously. Our framework is trained
end-to-end on a synthetic dataset and yields competitive precision and
performance against the state-of-the-art approaches.
</dc:description>
 <dc:description>Comment: Preprint of our paper accepted by Pattern Recognition</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05817</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05831</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Generate Long-term Future via Hierarchical Prediction</dc:title>
 <dc:creator>Villegas, Ruben</dc:creator>
 <dc:creator>Yang, Jimei</dc:creator>
 <dc:creator>Zou, Yuliang</dc:creator>
 <dc:creator>Sohn, Sungryull</dc:creator>
 <dc:creator>Lin, Xunyu</dc:creator>
 <dc:creator>Lee, Honglak</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a hierarchical approach for making long-term predictions of future
frames. To avoid inherent compounding errors in recursive pixel-level
prediction, we propose to first estimate high-level structure in the input
frames, then predict how that structure evolves in the future, and finally by
observing a single frame from the past and the predicted high-level structure,
we construct the future frames without having to observe any of the pixel-level
predictions. Long-term video prediction is difficult to perform by recurrently
observing the predicted frames because the small errors in pixel space
exponentially amplify as predictions are made deeper into the future. Our
approach prevents pixel-level error propagation from happening by removing the
need to observe the predicted frames. Our model is built with a combination of
LSTM and analogy based encoder-decoder convolutional neural networks, which
independently predict the video structure and generate the future frames,
respectively. In experiments, our model is evaluated on the Human3.6M and Penn
Action datasets on the task of long-term pixel-level video prediction of humans
performing actions and demonstrate significantly better results than the
state-of-the-art.
</dc:description>
 <dc:description>Comment: International Conference on Machine Learning (ICML) 2017</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2018-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05831</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05832</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SkiMap: An Efficient Mapping Framework for Robot Navigation</dc:title>
 <dc:creator>De Gregorio, Daniele</dc:creator>
 <dc:creator>Di Stefano, Luigi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We present a novel mapping framework for robot navigation which features a
multi-level querying system capable to obtain rapidly representations as
diverse as a 3D voxel grid, a 2.5D height map and a 2D occupancy grid. These
are inherently embedded into a memory and time efficient core data structure
organized as a Tree of SkipLists. Compared to the well-known Octree
representation, our approach exhibits a better time efficiency, thanks to its
simple and highly parallelizable computational structure, and a similar memory
footprint when mapping large workspaces. Peculiarly within the realm of mapping
for robot navigation, our framework supports realtime erosion and
re-integration of measurements upon reception of optimized poses from the
sensor tracker, so as to improve continuously the accuracy of the map.
</dc:description>
 <dc:description>Comment: Accepted by International Conference on Robotics and Automation
  (ICRA) 2017. This is the submitted version. The final published version may
  be slightly different</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05832</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05836</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beating 1-1/e for Ordered Prophets</dc:title>
 <dc:creator>Abolhasani, Melika</dc:creator>
 <dc:creator>Ehsani, Soheil</dc:creator>
 <dc:creator>Esfandiari, Hosein</dc:creator>
 <dc:creator>Hajiaghayi, MohammadTaghi</dc:creator>
 <dc:creator>Kleinberg, Robert</dc:creator>
 <dc:creator>Lucier, Brendan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Hill and Kertz studied the prophet inequality on iid distributions [The
Annals of Probability 1982]. They proved a theoretical bound of $1-\frac{1}{e}$
on the approximation factor of their algorithm. They conjectured that the best
approximation factor for arbitrarily large n is $\frac{1}{1+1/e} \approx
0.731$. This conjecture remained open prior to this paper for over 30 years. In
this paper we present a threshold-based algorithm for the prophet inequality
with n iid distributions. Using a nontrivial and novel approach we show that
our algorithm is a 0.738-approximation algorithm. By beating the bound of
$\frac{1}{1+1/e}$, this refutes the conjecture of Hill and Kertz. Moreover, we
generalize our results to non-iid distributions and discuss its applications in
mechanism design.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05836</dc:identifier>
 <dc:identifier>doi:10.1145/3055399.3055479</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05838</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generative Face Completion</dc:title>
 <dc:creator>Li, Yijun</dc:creator>
 <dc:creator>Liu, Sifei</dc:creator>
 <dc:creator>Yang, Jimei</dc:creator>
 <dc:creator>Yang, Ming-Hsuan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose an effective face completion algorithm using a deep
generative model. Different from well-studied background completion, the face
completion task is more challenging as it often requires to generate
semantically new pixels for the missing key components (e.g., eyes and mouths)
that contain large appearance variations. Unlike existing nonparametric
algorithms that search for patches to synthesize, our algorithm directly
generates contents for missing regions based on a neural network. The model is
trained with a combination of a reconstruction loss, two adversarial losses and
a semantic parsing loss, which ensures pixel faithfulness and local-global
contents consistency. With extensive experimental results, we demonstrate
qualitatively and quantitatively that our model is able to deal with a large
area of missing pixels in arbitrary shapes and generate realistic face
completion results.
</dc:description>
 <dc:description>Comment: Accepted by CVPR 2017</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05838</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05841</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Magic Barrier Revisited: Accessing Natural Limitations of
  Recommender Assessment</dc:title>
 <dc:creator>Jasberg, Kevin</dc:creator>
 <dc:creator>Sizov, Sergej</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Recommender systems nowadays have many applications and are of great economic
benefit. Hence, it is imperative for success-oriented companies to compare
different of such systems and select the better one for their purposes. To this
end, various metrics of predictive accuracy are commonly used, such as the Root
Mean Square Error (RMSE), or precision and recall. All these metrics more or
less measure how well a recommender system can predict human behaviour.
  Unfortunately, human behaviour is always associated with some degree of
uncertainty, making the evaluation difficult, since it is not clear whether a
deviation is system-induced or just originates from the natural variability of
human decision making. At this point, some authors speculated that we may be
reaching some Magic Barrier where this variability prevents us from getting
much more accurate.
  In this article, we will extend the existing theory of the Magic Barrier into
a new probabilistic but a yet pragmatic model. In particular, we will use
methods from metrology and physics to develop easy-to-handle quantities for
computation to describe the Magic Barrier for different accuracy metrics and
provide suggestions for common application. This discussion is substantiated by
comprehensive experiments with real users and large-scale simulations on a
high-performance cluster.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05841</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05860</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Aggregation and visualization of spatial data with application to
  classification of land use and land cover</dc:title>
 <dc:creator>Miu, Mihal</dc:creator>
 <dc:creator>Zhang, Xiaokun</dc:creator>
 <dc:creator>Dewan, M. Ali Akber</dc:creator>
 <dc:creator>Wang, Junye</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Aggregation and visualization of geographical data are an important part of
environmental data mining, environmental modelling, and agricultural
management. However, it is difficult to aggregate geospatial data of the
various formats, such as maps, census and survey data. This paper presents a
framework named PlaniSphere, which can aggregate the various geospatial
datasets, and synthesizes raw data. We developed an algorithm in PlaniSphere to
aggregate remote sensing images with census data for classification and
visualization of land use and land cover (LULC). The results show that the
framework is able to classify geospatial data sets of LULC from multiple
formats. National census data sets can be used for calibration of remote
sensing LULC classifications. This provides a new approach for the
classification of remote sensing data. This approach proposed in this paper
should be useful for LULC classification in environmental spatial analysis.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05860</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05867</identifier>
 <datestamp>2017-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note on integrating products of linear forms over the unit simplex</dc:title>
 <dc:creator>Casale, Giuliano</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:description>  Integrating a product of linear forms over the unit simplex can be done in
polynomial time if the number of variables n is fixed (V. Baldoni et al.,
2011). In this note, we highlight that this problem is equivalent to obtaining
the normalizing constant of state probabilities for a popular class of Markov
processes used in queueing network theory. In light of this equivalence, we
survey existing computational algorithms developed in queueing theory that can
be used for exact integration. For example, under some regularity conditions,
queueing theory algorithms can exactly integrate a product of linear forms of
total degree N by solving N systems of linear equations.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-05-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05867</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05872</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A matrix generalization of a theorem of Fine</dc:title>
 <dc:creator>Rowland, Eric</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  In 1947 Nathan Fine gave a beautiful product for the number of binomial
coefficients $\binom{n}{m}$, for $m$ in the range $0 \leq m \leq n$, that are
not divisible by $p$. We give a matrix product that generalizes Fine's formula,
simultaneously counting binomial coefficients with $p$-adic valuation $\alpha$
for each $\alpha \geq 0$. For each $n$ this information is naturally encoded in
a polynomial generating function, and the sequence of these polynomials is
$p$-regular in the sense of Allouche and Shallit. We also give a further
generalization to multinomial coefficients.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05872</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05877</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast and Accurate Sparse Coding of Visual Stimuli with a Simple,
  Ultra-Low-Energy Spiking Architecture</dc:title>
 <dc:creator>Woods, Walt</dc:creator>
 <dc:creator>Teuscher, Christof</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Memristive crossbars have become a popular means for realizing unsupervised
and supervised learning techniques. Often, to preserve mathematical rigor, the
crossbar itself is separated from the neuron capacitors. In this work, we
sought to simplify the design, removing extraneous components to consume
significantly lower power at a minimal cost of accuracy. This work provides
derivations for the design of such a network, named the Simple Spiking Locally
Competitive Algorithm, or SSLCA, as well as CMOS designs and results on the
CIFAR and MNIST datasets. Compared to a non-spiking model which scored 33% on
CIFAR-10 with a single-layer classifier, this hardware scored 32% accuracy.
When used with a state-of-the-art deep learning classifier, the non-spiking
model achieved 82% and our simplified, spiking model achieved 80%, while
compressing the input data by 79%. Compared to a previously proposed spiking
model, our proposed hardware consumed 99% less energy to do the same work at 21
times the throughput. Accuracy held out with online learning to a write
variance of 3% and a read variance of 40%. The proposed architecture's
excellent accuracy and significantly lower energy usage demonstrate the utility
of our innovations. This work provides a means for extremely low-energy sparse
coding in mobile devices, such as cellular phones, or for very sparse coding as
is needed by self-driving cars or robotics that must integrate data from
multiple, high-resolution sensors.
</dc:description>
 <dc:description>Comment: 13 pages, 14 figures, submitted to IEEE Transactions on Neural
  Networks and Learning Systems</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05877</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05896</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Complexity of Tree Partitioning</dc:title>
 <dc:creator>An, Zhao</dc:creator>
 <dc:creator>Feng, Qilong</dc:creator>
 <dc:creator>Kanj, Iyad</dc:creator>
 <dc:creator>Xia, Ge</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Given a tree $T$ on $n$ vertices, and $k, b, s_1, \ldots, s_b \in N$, the
Tree Partitioning problem asks if at most $k$ edges can be removed from $T$ so
that the resulting components can be grouped into $b$ groups such that the
number of vertices in group $i$ is $s_i$, for $i =1, \ldots, b$. The case when
$s_1=\cdots =s_b =n/b$, referred to as the Balanced Tree Partitioning problem,
was shown to be NP-complete for trees of maximum degree at most 5, and the
complexity of the problem for trees of maximum degree 4 and 3 was posed as an
open question. The parameterized complexity of Balanced Tree Partitioning was
also posed as an open question in another work.
  In this paper, we answer both open questions negatively. We show that
Balanced Tree Partitioning (and hence, Tree Partitioning) is NP-complete for
trees of maximum degree 3, thus closing the door on the complexity of Balanced
Tree Partitioning, as the simple case when $T$ is a path is in P. In terms of
the parameterized complexity of the problems, we show that both Balanced Tree
Partitioning and Tree Partitioning are $W[1]$-complete. Finally, using a
compact representation of the solution space for an instance of the problem, we
present a dynamic programming algorithm for Tree Partitioning (and hence, for
Balanced Tree Partitioning) that runs in subexponential-time $2^{O(\sqrt{n})}$,
adding a natural problem to the list of problems that can be solved in
subexponential time.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05896</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05902</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On fast bounded locality sensitive hashing</dc:title>
 <dc:creator>Wygocki, Piotr</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  In this paper, we examine the hash functions expressed as scalar products,
i.e., $f(x)=&lt;v,x&gt;$, for some bounded random vector $v$. Such hash functions
have numerous applications, but often there is a need to optimize the choice of
the distribution of $v$. In the present work, we focus on so-called
anti-concentration bounds, i.e. the upper bounds of $\mathbb{P}\left[|&lt;v,x&gt;| &lt;
\alpha \right]$. In many applications, $v$ is a vector of independent random
variables with standard normal distribution. In such case, the distribution of
$&lt;v,x&gt;$ is also normal and it is easy to approximate $\mathbb{P}\left[|&lt;v,x&gt;| &lt;
\alpha \right]$. Here, we consider two bounded distributions in the context of
the anti-concentration bounds. Particularly, we analyze $v$ being a random
vector from the unit ball in $l_{\infty}$ and $v$ being a random vector from
the unit sphere in $l_{2}$. We show optimal up to a constant anti-concentration
measures for functions $f(x)=&lt;v,x&gt;$.
  As a consequence of our research, we obtain new best results for \newline
\textit{$c$-approximate nearest neighbors without false negatives} for $l_p$ in
high dimensional space for all $p\in[1,\infty]$, for
$c=\Omega(\max\{\sqrt{d},d^{1/p}\})$. These results improve over those
presented in [16]. Finally, our paper reports progress on answering the open
problem by Pagh~[17], who considered the nearest neighbor search without false
negatives for the Hamming distance.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05902</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05904</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Realizing an optimization approach inspired from Piagets theory on
  cognitive development</dc:title>
 <dc:creator>Kose, Utku</dc:creator>
 <dc:creator>Arslan, Ahmet</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The objective of this paper is to introduce an artificial intelligence based
optimization approach, which is inspired from Piagets theory on cognitive
development. The approach has been designed according to essential processes
that an individual may experience while learning something new or improving his
/ her knowledge. These processes are associated with the Piagets ideas on an
individuals cognitive development. The approach expressed in this paper is a
simple algorithm employing swarm intelligence oriented tasks in order to
overcome single-objective optimization problems. For evaluating effectiveness
of this early version of the algorithm, test operations have been done via some
benchmark functions. The obtained results show that the approach / algorithm
can be an alternative to the literature in terms of single-objective
optimization. The authors have suggested the name: Cognitive Development
Optimization Algorithm (CoDOA) for the related intelligent optimization
approach.
</dc:description>
 <dc:description>Comment: 8 pages, 1 figure, 2 tables</dc:description>
 <dc:date>2017-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05904</dc:identifier>
 <dc:identifier>Broad Research in Artificial Intelligence and Neuroscience,
  6(1-4), 2015, 15-22</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05905</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Coalition Formation Algorithm for Multi-Robot Task Allocation in
  Large-Scale Natural Disasters</dc:title>
 <dc:creator>Mouradian, Carla</dc:creator>
 <dc:creator>Sahoo, Jagruti</dc:creator>
 <dc:creator>Glitho, Roch H.</dc:creator>
 <dc:creator>Morrow, Monique J.</dc:creator>
 <dc:creator>Polakos, Paul A.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In large-scale natural disasters, humans are likely to fail when they attempt
to reach high-risk sites or act in search and rescue operations. Robots,
however, outdo their counterparts in surviving the hazards and handling the
search and rescue missions due to their multiple and diverse sensing and
actuation capabilities. The dynamic formation of optimal coalition of these
heterogeneous robots for cost efficiency is very challenging and research in
the area is gaining more and more attention. In this paper, we propose a novel
heuristic. Since the population of robots in large-scale disaster settings is
very large, we rely on Quantum Multi-Objective Particle Swarm Optimization
(QMOPSO). The problem is modeled as a multi-objective optimization problem.
Simulations with different test cases and metrics, and comparison with other
algorithms such as NSGA-II and SPEA-II are carried out. The experimental
results show that the proposed algorithm outperforms the existing algorithms
not only in terms of convergence but also in terms of diversity and processing
time.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05905</dc:identifier>
 <dc:identifier>doi:10.1109/IWCMC.2017.7986575</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05907</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-End Multi-View Networks for Text Classification</dc:title>
 <dc:creator>Guo, Hongyu</dc:creator>
 <dc:creator>Cherry, Colin</dc:creator>
 <dc:creator>Su, Jiang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We propose a multi-view network for text classification. Our method
automatically creates various views of its input text, each taking the form of
soft attention weights that distribute the classifier's focus among a set of
base features. For a bag-of-words representation, each view focuses on a
different subset of the text's words. Aggregating many such views results in a
more discriminative and robust representation. Through a novel architecture
that both stacks and concatenates views, we produce a network that emphasizes
both depth and width, allowing training to converge quickly. Using our
multi-view architecture, we establish new state-of-the-art accuracies on two
benchmark tasks.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05907</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05908</identifier>
 <datestamp>2017-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Interpretable Knowledge Transfer Model for Knowledge Base Completion</dc:title>
 <dc:creator>Xie, Qizhe</dc:creator>
 <dc:creator>Ma, Xuezhe</dc:creator>
 <dc:creator>Dai, Zihang</dc:creator>
 <dc:creator>Hovy, Eduard</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Knowledge bases are important resources for a variety of natural language
processing tasks but suffer from incompleteness. We propose a novel embedding
model, \emph{ITransF}, to perform knowledge base completion. Equipped with a
sparse attention mechanism, ITransF discovers hidden concepts of relations and
transfer statistical strength through the sharing of concepts. Moreover, the
learned associations between relations and concepts, which are represented by
sparse attention vectors, can be interpreted easily. We evaluate ITransF on two
benchmark datasets---WN18 and FB15k for knowledge base completion and obtains
improvements on both the mean rank and Hits@10 metrics, over all baselines that
do not use additional information.
</dc:description>
 <dc:description>Comment: Accepted by ACL 2017. Minor update</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-05-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05908</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05909</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proximal Nerve Complexes. A Computational Topology Approach</dc:title>
 <dc:creator>Peters, J. F.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>54E05, 68U05</dc:subject>
 <dc:description>  This article introduces a theory of proximal nerve complexes and nerve
spokes, restricted to the triangulation of finite regions in the Euclidean
plane. A nerve complex is a collection of filled triangles with a common
vertex, covering a finite region of the plane. Structures called $k$-spokes,
$k\geq 1$, are a natural extension of nerve complexes. A $k$-spoke is the union
of a collection of filled triangles that pairwise either have a common edge or
a common vertex. A consideration of the closeness of nerve complexes leads to a
proximal view of simplicial complexes. A practical application of proximal
nerve complexes is given, briefly, in terms of object shape geometry in digital
images.
</dc:description>
 <dc:description>Comment: 16 pages, 9 figures</dc:description>
 <dc:date>2017-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05909</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05911</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geant4 Maintainability Assessed with Respect to Software Engineering
  References</dc:title>
 <dc:creator>Ronchieri, Elisabetta</dc:creator>
 <dc:creator>Pia, Maria Grazia</dc:creator>
 <dc:creator>Basaglia, Tullio</dc:creator>
 <dc:creator>Canaparo, Marco</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.8</dc:subject>
 <dc:description>  We report a methodology developed to quantitatively assess the
maintainability of Geant4 with respect to software engineering references. The
level of maintainability is determined by combining a set of metrics values
whose references are documented in literature.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures, 4 tables, IEEE NSS/MIC 2016</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05911</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05915</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>User-driven Intelligent Interface on the Basis of Multimodal Augmented
  Reality and Brain-Computer Interaction for People with Functional
  Disabilities</dc:title>
 <dc:creator>Stirenko, S.</dc:creator>
 <dc:creator>Gordienko, Yu.</dc:creator>
 <dc:creator>Shemsedinov, T.</dc:creator>
 <dc:creator>Alienin, O.</dc:creator>
 <dc:creator>Kochura, Yu.</dc:creator>
 <dc:creator>Gordienko, N.</dc:creator>
 <dc:creator>Rojbi, A.</dc:creator>
 <dc:creator>Benito, J. R. L&#xf3;pez</dc:creator>
 <dc:creator>Gonz&#xe1;lez, E. Artetxe</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The analysis of the current integration attempts of some modes and use cases
of user-machine interaction is presented. The new concept of the user-driven
intelligent interface is proposed on the basis of multimodal augmented reality
and brain-computer interaction for various applications: in disabilities
studies, education, home care, health care, etc. The several use cases of
multimodal augmentation are presented. The perspectives of the better human
comprehension by the immediate feedback through neurophysical channels by means
of brain-computer interaction are outlined. It is shown that brain-computer
interface (BCI) technology provides new strategies to overcome limits of the
currently available user interfaces, especially for people with functional
disabilities. The results of the previous studies of the low end consumer and
open-source BCI-devices allow us to conclude that combination of machine
learning (ML), multimodal interactions (visual, sound, tactile) with BCI will
profit from the immediate feedback from the actual neurophysical reactions
classified by ML methods. In general, BCI in combination with other modes of AR
interaction can deliver much more information than these types of interaction
themselves. Even in the current state the combined AR-BCI interfaces could
provide the highly adaptable and personal services, especially for people with
functional disabilities.
</dc:description>
 <dc:description>Comment: 10 pages, 11 figures, 1 table, submitted to Future of Information and
  Communication Conference (FICC) 2018, 5-6 April 2018, Singapore</dc:description>
 <dc:date>2017-04-12</dc:date>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05915</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05916</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Piggybacking Codes for Network Coding: The High/Low SNR Regime</dc:title>
 <dc:creator>Ghanem, Samah A. M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We propose a piggybacking scheme for network coding where strong source
inputs piggyback the weaker ones, a scheme necessary and sufficient to achieve
the cut-set upper bound at high/low-snr regime, a new asymptotically optimal
operational regime for the multihop Amplify and Forward (AF) networks.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05916</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05920</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Application of Econometric Data Analysis Methods to Physics Software</dc:title>
 <dc:creator>Pia, Maria Grazia</dc:creator>
 <dc:creator>Ronchieri, Elisabetta</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  We report an investigation of data analysis methods derived from other
disciplines, which we applied to physics software systems. They concern the
analysis of inequality, trend analysis and the analysis of diversity. The
analysis of inequality exploits statistical methods originating from
econometrics; trend analysis is typical of economics and environmental
sciences; the analysis of diversity is based on concepts derived from ecology
and treats software as an ecosystem. To the best of our knowledge, this is an
innovative exploration, as we could not find track of previous use of these
methods in the experimental physics domains within the scope of the IEEE
Nuclear Science Symposium. We applied these methods in the context of Geant4
physics validation and Geant4 maintainability assessment.
</dc:description>
 <dc:description>Comment: 7 pages, 7 figures, IEEE NSS/MIC 2016</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05920</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05921</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Memcapacitive Devices in Logic and Crossbar Applications</dc:title>
 <dc:creator>Tran, Dat</dc:creator>
 <dc:creator>Teuscher, Christof</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Over the last decade, memristive devices have been widely adopted in
computing for various conventional and unconventional applications. While the
integration density, memory property, and nonlinear characteristics have many
benefits, reducing the energy consumption is limited by the resistive nature of
the devices. Memcapacitors would address that limitation while still having all
the benefits of memristors. Recent work has shown that with adjusted parameters
during the fabrication process, a metal-oxide device can indeed exhibit a
memcapacitive behavior. We introduce novel memcapacitive logic gates and
memcapacitive crossbar classifiers as a proof of concept that such applications
can outperform memristor-based architectures. The results illustrate that,
compared to memristive logic gates, our memcapacitive gates consume about 7x
less power. The memcapacitive crossbar classifier achieves similar
classification performance but reduces the power consumption by a factor of
about 1,500x for the MNIST dataset and a factor of about 1,000x for the
CIFAR-10 dataset compared to a memristive crossbar. Our simulation results
demonstrate that memcapacitive devices have great potential for both Boolean
logic and analog low-power applications.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05921</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05923</identifier>
 <datestamp>2017-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Model Order Reduction Algorithm for Estimating the Absorption Spectrum</dc:title>
 <dc:creator>Van Beeumen, Roel</dc:creator>
 <dc:creator>Williams-Young, David B.</dc:creator>
 <dc:creator>Kasper, Joseph M.</dc:creator>
 <dc:creator>Yang, Chao</dc:creator>
 <dc:creator>Ng, Esmond G.</dc:creator>
 <dc:creator>Li, Xiaosong</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Physics - Chemical Physics</dc:subject>
 <dc:description>  The ab initio description of the spectral interior of the absorption spectrum
poses both a theoretical and computational challenge for modern electronic
structure theory. Due to the often spectrally dense character of this domain in
the quantum propagator's eigenspectrum for medium-to-large sized systems,
traditional approaches based on the partial diagonalization of the propagator
often encounter oscillatory and stagnating convergence. Electronic structure
methods which solve the molecular response problem through the solution of
spectrally shifted linear systems, such as the complex polarization propagator,
offer an alternative approach which is agnostic to the underlying spectral
density or domain location. This generality comes at a seemingly high
computational cost associated with solving a large linear system for each
spectral shift in some discretization of the spectral domain of interest. We
present a novel, adaptive solution based on model order reduction techniques
via interpolation. Model order reduction reduces the computational complexity
of mathematical models and is ubiquitous in the simulation of dynamical
systems. The efficiency and effectiveness of the proposed algorithm in the ab
initio prediction of X-Ray absorption spectra is demonstrated using a test set
of challenging water clusters which are spectrally dense in the neighborhood of
the oxygen K-edge. Based on a single, user defined tolerance we automatically
determine the order of the reduced models and approximate the absorption
spectrum up to the given tolerance. We also illustrate that the automatically
determined model order increases logarithmically with the problem dimension,
compared to a linear increase of the number of eigenvalues within the energy
window. Furthermore, we observed that the computational cost of the proposed
algorithm only scales quadratically with respect to the problem dimension.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05923</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05928</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deciding some Maltsev conditions in finite idempotent algebras</dc:title>
 <dc:creator>Kazda, Alexandr</dc:creator>
 <dc:creator>Valeriote, Matt</dc:creator>
 <dc:subject>Mathematics - Rings and Algebras</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>08B05, 08A70</dc:subject>
 <dc:description>  In this paper we investigate the computational complexity of deciding if a
given finite algebraic structure satisfies a fixed (strong) Maltsev condition
$\Sigma$. Our goal in this paper is to show that $\Sigma$-testing can be
accomplished in polynomial time when the algebras tested are idempotent and the
Maltsev condition $\Sigma$ can be described using paths. Examples of such path
conditions are having a Maltsev term, having a majority operation, and having a
chain of J\'onsson (or Gumm) terms of fixed length.
</dc:description>
 <dc:description>Comment: 29 pages, 18 figures</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05929</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Equitable Colorings of $l$-Corona Products of Cubic Graphs</dc:title>
 <dc:creator>Furma&#x144;czyk, Hanna</dc:creator>
 <dc:creator>Kubale, Marek</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  A graph $G$ is equitably $k$-colorable if its vertices can be partitioned
into $k$ independent sets in such a way that the number of vertices in any two
sets differ by at most one. The smallest integer $k$ for which such a coloring
exists is known as the \emph{equitable chromatic number} of $G$ and it is
denoted by $\chi_{=}(G)$.
  In this paper the problem of determinig the value of equitable chromatic
number for multicoronas of cubic graphs $G \circ^l H$ is studied. The problem
of ordinary coloring of multicoronas of cubic graphs is solvable in polynomial
time. The complexity of equitable coloring problem is an open question for
these graphs. We provide some polynomially solvable cases of cubical
multicoronas and give simple linear time algorithms for equitable coloring of
such graphs which use at most $\chi_=(G \circ ^l H) + 1$ colors in the
remaining cases.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05929</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05936</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Global Stabilization of Triangular Systems with Time-Delayed Dynamic
  Input Perturbations</dc:title>
 <dc:creator>Krishnamurthy, Prashanth</dc:creator>
 <dc:creator>Khorrami, Farshad</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  A control design approach is developed for a general class of uncertain
strict-feedback-like nonlinear systems with dynamic uncertain input
nonlinearities with time delays. The system structure considered in this paper
includes a nominal uncertain strict-feedback-like subsystem, the input signal
to which is generated by an uncertain nonlinear input unmodeled dynamics that
is driven by the entire system state (including unmeasured state variables) and
is also allowed to depend on time delayed versions of the system state variable
and control input signals. The system also includes additive uncertain
nonlinear functions, coupled nonlinear appended dynamics, and uncertain dynamic
input nonlinearities with time-varying uncertain time delays. The proposed
control design approach provides a globally stabilizing delay-independent
robust adaptive output-feedback dynamic controller based on a dual dynamic
high-gain scaling based structure.
</dc:description>
 <dc:description>Comment: 2017 IEEE International Carpathian Control Conference (ICCC)</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2018-01-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05936</dc:identifier>
 <dc:identifier>doi:10.1109/CarpathianCC.2017.7970466</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05939</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HPatches: A benchmark and evaluation of handcrafted and learned local
  descriptors</dc:title>
 <dc:creator>Balntas, Vassileios</dc:creator>
 <dc:creator>Lenc, Karel</dc:creator>
 <dc:creator>Vedaldi, Andrea</dc:creator>
 <dc:creator>Mikolajczyk, Krystian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a novel benchmark for evaluating local image
descriptors. We demonstrate that the existing datasets and evaluation protocols
do not specify unambiguously all aspects of evaluation, leading to ambiguities
and inconsistencies in results reported in the literature. Furthermore, these
datasets are nearly saturated due to the recent improvements in local
descriptors obtained by learning them from large annotated datasets. Therefore,
we introduce a new large dataset suitable for training and testing modern
descriptors, together with strictly defined evaluation protocols in several
tasks such as matching, retrieval and classification. This allows for more
realistic, and thus more reliable comparisons in different application
scenarios. We evaluate the performance of several state-of-the-art descriptors
and analyse their properties. We show that a simple normalisation of
traditional hand-crafted descriptors can boost their performance to the level
of deep learning based descriptors within a realistic benchmarks evaluation.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05939</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05947</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Guaranteed Fault Detection and Isolation for Switched Affine Models</dc:title>
 <dc:creator>Harirchi, Farshad</dc:creator>
 <dc:creator>Yong, Sze Zheng</dc:creator>
 <dc:creator>Ozay, Necmiye</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper considers the problem of fault detection and isolation (FDI) for
switched affine models. We first study the model invalidation problem and its
application to guaranteed fault detection. Novel and intuitive
optimization-based formulations are proposed for model invalidation and
T-distinguishability problems, which we demonstrate to be computationally more
efficient than an earlier formulation that required a complicated change of
variables. Moreover, we introduce a distinguishability index as a measure of
separation between the system and fault models, which offers a practical method
for finding the smallest receding time horizon that is required for fault
detection, and for finding potential design recommendations for ensuring
T-distinguishability. Then, we extend our fault detection guarantees to the
problem of fault isolation with multiple fault models, i.e., the identification
of the type and location of faults, by introducing the concept of
I-isolability. An efficient way to implement the FDI scheme is also proposed,
whose run-time does not grow with the number of fault models that are
considered. Moreover, we derive bounds on detection and isolation delays and
present an adaptive scheme for reducing isolation delays. Finally, the
effectiveness of the proposed method is illustrated using several examples,
including an HVAC system model with multiple faults.
</dc:description>
 <dc:description>Comment: This material is copyrighted by IEEE and will appear in IEEE
  Conference on Decision and Control, 2017</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-10-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05948</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-supervised classification for dynamic Android malware detection</dc:title>
 <dc:creator>Chen, Li</dc:creator>
 <dc:creator>Zhang, Mingwei</dc:creator>
 <dc:creator>Yang, Chih-Yuan</dc:creator>
 <dc:creator>Sahita, Ravi</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A growing number of threats to Android phones creates challenges for malware
detection. Manually labeling the samples into benign or different malicious
families requires tremendous human efforts, while it is comparably easy and
cheap to obtain a large amount of unlabeled APKs from various sources.
Moreover, the fast-paced evolution of Android malware continuously generates
derivative malware families. These families often contain new signatures, which
can escape detection when using static analysis. These practical challenges can
also cause traditional supervised machine learning algorithms to degrade in
performance.
  In this paper, we propose a framework that uses model-based semi-supervised
(MBSS) classification scheme on the dynamic Android API call logs. The
semi-supervised approach efficiently uses the labeled and unlabeled APKs to
estimate a finite mixture model of Gaussian distributions via conditional
expectation-maximization and efficiently detects malwares during out-of-sample
testing. We compare MBSS with the popular malware detection classifiers such as
support vector machine (SVM), $k$-nearest neighbor (kNN) and linear
discriminant analysis (LDA). Under the ideal classification setting, MBSS has
competitive performance with 98\% accuracy and very low false positive rate for
in-sample classification. For out-of-sample testing, the out-of-sample test
data exhibit similar behavior of retrieving phone information and sending to
the network, compared with in-sample training set. When this similarity is
strong, MBSS and SVM with linear kernel maintain 90\% detection rate while
$k$NN and LDA suffer great performance degradation. When this similarity is
slightly weaker, all classifiers degrade in performance, but MBSS still
performs significantly better than other classifiers.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05948</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05952</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unassisted Quantitative Evaluation Of Despeckling Filters</dc:title>
 <dc:creator>Gomez, Luis</dc:creator>
 <dc:creator>Ospina, Raydonal</dc:creator>
 <dc:creator>Frery, Alejandro C.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  SAR (Synthetic Aperture Radar) imaging plays a central role in Remote Sensing
due to, among other important features, its ability to provide high-resolution,
day-and-night and almost weather-independent images. SAR images are affected
from a granular contamination, speckle, that can be described by a
multiplicative model. Many despeckling techniques have been proposed in the
literature, as well as measures of the quality of the results they provide.
Assuming the multiplicative model, the observed image $Z$ is the product of two
independent fields: the backscatter $X$ and the speckle $Y$. The result of any
speckle filter is $\widehat X$, an estimator of the backscatter $X$, based
solely on the observed data $Z$. An ideal estimator would be the one for which
the ratio of the observed image to the filtered one $I=Z/\widehat X$ is only
speckle: a collection of independent identically distributed samples from Gamma
variates. We, then, assess the quality of a filter by the closeness of $I$ to
the hypothesis that it is adherent to the statistical properties of pure
speckle. We analyze filters through the ratio image they produce with regards
to first- and second-order statistics: the former check marginal properties,
while the latter verifies lack of structure. A new quantitative image-quality
index is then defined, and applied to state-of-the-art despeckling filters.
This new measure provides consistent results with commonly used quality
measures (equivalent number of looks, PSNR, MSSIM, $\beta$ edge correlation,
and preservation of the mean), and ranks the filters results also in agreement
with their visual analysis. We conclude our study showing that the proposed
measure can be successfully used to optimize the (often many) parameters that
define a speckle filter.
</dc:description>
 <dc:description>Comment: Accepted for publication in Remote Sensing - Open Access Journal</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05952</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05954</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing Mission Critical Data Dissemination in Massive IoT Networks</dc:title>
 <dc:creator>Farooq, Muhammad Junaid</dc:creator>
 <dc:creator>Zhu, Quanyan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Mission critical data dissemination in massive Internet of things (IoT)
networks imposes constraints on the message transfer delay between devices. Due
to low power and communication range of IoT devices, data is foreseen to be
relayed over multiple device-to-device (D2D) links before reaching the
destination. The coexistence of a massive number of IoT devices poses a
challenge in maximizing the successful transmission capacity of the overall
network alongside reducing the multi-hop transmission delay in order to support
mission critical applications. There is a delicate interplay between the
carrier sensing threshold of the contention based medium access protocol and
the choice of packet forwarding strategy selected at each hop by the devices.
The fundamental problem in optimizing the performance of such networks is to
balance the tradeoff between conflicting performance objectives such as the
spatial frequency reuse, transmission quality, and packet progress towards the
destination. In this paper, we use a stochastic geometry approach to quantify
the performance of multi-hop massive IoT networks in terms of the spatial
frequency reuse and the transmission quality under different packet forwarding
schemes. We also develop a comprehensive performance metric that can be used to
optimize the system to achieve the best performance. The results can be used to
select the best forwarding scheme and tune the carrier sensing threshold to
optimize the performance of the network according to the delay constraints and
transmission quality requirements.
</dc:description>
 <dc:description>Comment: Accepted in Workshop on Spatial Stochastic Models for Wireless
  Networks (SpaSWiN), Paris, France, May, 2017</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05954</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05958</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Global Relation Embedding for Relation Extraction</dc:title>
 <dc:creator>Su, Yu</dc:creator>
 <dc:creator>Liu, Honglei</dc:creator>
 <dc:creator>Yavuz, Semih</dc:creator>
 <dc:creator>Gur, Izzeddin</dc:creator>
 <dc:creator>Sun, Huan</dc:creator>
 <dc:creator>Yan, Xifeng</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recent studies have shown that embedding textual relations using deep neural
networks greatly helps relation extraction. However, many existing studies rely
on supervised learning; their performance is dramatically limited by the
availability of training data. In this work, we generalize textual relation
embedding to the distant supervision setting, where much larger-scale but noisy
training data is available. We propose leveraging global statistics of
relations, i.e., the co-occurrence statistics of textual and knowledge base
relations collected from the entire corpus, to embed textual relations. This
approach turns out to be more robust to the training noise introduced by
distant supervision. On a popular relation extraction dataset, we show that the
learned textual relation embeddings can be used to augment existing relation
extraction models and significantly improve their performance. Most remarkably,
for the top 1,000 relational facts discovered by the best existing model, the
precision can be improved from 83.9% to 89.3%.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05958</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05959</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SLAM with Objects using a Nonparametric Pose Graph</dc:title>
 <dc:creator>Mu, Beipeng</dc:creator>
 <dc:creator>Liu, Shih-Yuan</dc:creator>
 <dc:creator>Paull, Liam</dc:creator>
 <dc:creator>Leonard, John</dc:creator>
 <dc:creator>How, Jonathan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Mapping and self-localization in unknown environments are fundamental
capabilities in many robotic applications. These tasks typically involve the
identification of objects as unique features or landmarks, which requires the
objects both to be detected and then assigned a unique identifier that can be
maintained when viewed from different perspectives and in different images. The
\textit{data association} and \textit{simultaneous localization and mapping}
(SLAM) problems are, individually, well-studied in the literature. But these
two problems are inherently tightly coupled, and that has not been
well-addressed. Without accurate SLAM, possible data associations are
combinatorial and become intractable easily. Without accurate data association,
the error of SLAM algorithms diverge easily. This paper proposes a novel
nonparametric pose graph that models data association and SLAM in a single
framework. An algorithm is further introduced to alternate between inferring
data association and performing SLAM. Experimental results show that our
approach has the new capability of associating object detections and localizing
objects at the same time, leading to significantly better performance on both
the data association and SLAM problems than achieved by considering only one
and ignoring imperfections in the other.
</dc:description>
 <dc:description>Comment: published at IROS 2016</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05959</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05960</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SAFS: A Deep Feature Selection Approach for Precision Medicine</dc:title>
 <dc:creator>Nezhad, Milad Zafar</dc:creator>
 <dc:creator>Zhu, Dongxiao</dc:creator>
 <dc:creator>Li, Xiangrui</dc:creator>
 <dc:creator>Yang, Kai</dc:creator>
 <dc:creator>Levy, Phillip</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we propose a new deep feature selection method based on deep
architecture. Our method uses stacked auto-encoders for feature representation
in higher-level abstraction. We developed and applied a novel feature learning
approach to a specific precision medicine problem, which focuses on assessing
and prioritizing risk factors for hypertension (HTN) in a vulnerable
demographic subgroup (African-American). Our approach is to use deep learning
to identify significant risk factors affecting left ventricular mass indexed to
body surface area (LVMI) as an indicator of heart damage risk. The results show
that our feature learning and representation approach leads to better results
in comparison with others.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05960</dc:identifier>
 <dc:identifier>doi:10.1109/BIBM.2016.7822569</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05963</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monte Carlo Tree Search with Sampled Information Relaxation Dual Bounds</dc:title>
 <dc:creator>Jiang, Daniel R.</dc:creator>
 <dc:creator>Al-Kanj, Lina</dc:creator>
 <dc:creator>Powell, Warren B.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Monte Carlo Tree Search (MCTS), most famously used in game-play artificial
intelligence (e.g., the game of Go), is a well-known strategy for constructing
approximate solutions to sequential decision problems. Its primary innovation
is the use of a heuristic, known as a default policy, to obtain Monte Carlo
estimates of downstream values for states in a decision tree. This information
is used to iteratively expand the tree towards regions of states and actions
that an optimal policy might visit. However, to guarantee convergence to the
optimal action, MCTS requires the entire tree to be expanded asymptotically. In
this paper, we propose a new technique called Primal-Dual MCTS that utilizes
sampled information relaxation upper bounds on potential actions, creating the
possibility of &quot;ignoring&quot; parts of the tree that stem from highly suboptimal
choices. This allows us to prove that despite converging to a partial decision
tree in the limit, the recommended action from Primal-Dual MCTS is optimal. The
new approach shows significant promise when used to optimize the behavior of a
single driver navigating a graph while operating on a ride-sharing platform.
Numerical experiments on a real dataset of 7,000 trips in New Jersey suggest
that Primal-Dual MCTS improves upon standard MCTS by producing deeper decision
trees and exhibits a reduced sensitivity to the size of the action space.
</dc:description>
 <dc:description>Comment: 33 pages, 6 figures</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05963</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05964</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal Clustering</dc:title>
 <dc:creator>Dey, Tamal K.</dc:creator>
 <dc:creator>Rossi, Alfred</dc:creator>
 <dc:creator>Sidiropoulos, Anastasios</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>I.5.3</dc:subject>
 <dc:description>  We study the problem of clustering sequences of unlabeled point sets taken
from a common metric space. Such scenarios arise naturally in applications
where a system or process is observed in distinct time intervals, such as
biological surveys and contagious disease surveillance. In this more general
setting existing algorithms for classical (i.e.~static) clustering problems are
not applicable anymore.
  We propose a set of optimization problems which we collectively refer to as
'temporal clustering'. The quality of a solution to a temporal clustering
instance can be quantified using three parameters: the number of clusters $k$,
the spatial clustering cost $r$, and the maximum cluster displacement $\delta$
between consecutive time steps. We consider spatial clustering costs which
generalize the well-studied $k$-center, discrete $k$-median, and discrete
$k$-means objectives of classical clustering problems. We develop new
algorithms that achieve trade-offs between the three objectives $k$, $r$, and
$\delta$. Our upper bounds are complemented by inapproximability results.
</dc:description>
 <dc:description>Comment: 27 pages, 10 figures</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05964</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05972</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SemEval-2017 Task 8: RumourEval: Determining rumour veracity and support
  for rumours</dc:title>
 <dc:creator>Derczynski, Leon</dc:creator>
 <dc:creator>Bontcheva, Kalina</dc:creator>
 <dc:creator>Liakata, Maria</dc:creator>
 <dc:creator>Procter, Rob</dc:creator>
 <dc:creator>Hoi, Geraldine Wong Sak</dc:creator>
 <dc:creator>Zubiaga, Arkaitz</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Media is full of false claims. Even Oxford Dictionaries named &quot;post-truth&quot; as
the word of 2016. This makes it more important than ever to build systems that
can identify the veracity of a story, and the kind of discourse there is around
it. RumourEval is a SemEval shared task that aims to identify and handle
rumours and reactions to them, in text. We present an annotation scheme, a
large dataset covering multiple topics - each having their own families of
claims and replies - and use these to pose two concrete challenges as well as
the results achieved by participants on these challenges.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05972</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05973</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Call Attention to Rumors: Deep Attention Based Recurrent Neural Networks
  for Early Rumor Detection</dc:title>
 <dc:creator>Chen, Tong</dc:creator>
 <dc:creator>Wu, Lin</dc:creator>
 <dc:creator>Li, Xue</dc:creator>
 <dc:creator>Zhang, Jun</dc:creator>
 <dc:creator>Yin, Hongzhi</dc:creator>
 <dc:creator>Wang, Yang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The proliferation of social media in communication and information
dissemination has made it an ideal platform for spreading rumors. Automatically
debunking rumors at their stage of diffusion is known as \textit{early rumor
detection}, which refers to dealing with sequential posts regarding disputed
factual claims with certain variations and highly textual duplication over
time. Thus, identifying trending rumors demands an efficient yet flexible model
that is able to capture long-range dependencies among postings and produce
distinct representations for the accurate early detection. However, it is a
challenging task to apply conventional classification algorithms to rumor
detection in earliness since they rely on hand-crafted features which require
intensive manual efforts in the case of large amount of posts. This paper
presents a deep attention model on the basis of recurrent neural networks (RNN)
to learn \textit{selectively} temporal hidden representations of sequential
posts for identifying rumors. The proposed model delves soft-attention into the
recurrence to simultaneously pool out distinct features with particular focus
and produce hidden representations that capture contextual variations of
relevant posts over time. Extensive experiments on real datasets collected from
social media websites demonstrate that (1) the deep attention based RNN model
outperforms state-of-the-arts that rely on hand-crafted features; (2) the
introduction of soft attention mechanism can effectively distill relevant parts
to rumors from original posts in advance; (3) the proposed method detects
rumors more quickly and accurately than competitors.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05973</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05974</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-domain Semantic Parsing via Paraphrasing</dc:title>
 <dc:creator>Su, Yu</dc:creator>
 <dc:creator>Yan, Xifeng</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Existing studies on semantic parsing mainly focus on the in-domain setting.
We formulate cross-domain semantic parsing as a domain adaptation problem:
train a semantic parser on some source domains and then adapt it to the target
domain. Due to the diversity of logical forms in different domains, this
problem presents unique and intriguing challenges. By converting logical forms
into canonical utterances in natural language, we reduce semantic parsing to
paraphrasing, and develop an attentive sequence-to-sequence paraphrase model
that is general and flexible to adapt to different domains. We discover two
problems, small micro variance and large macro variance, of pre-trained word
embeddings that hinder their direct use in neural networks, and propose
standardization techniques as a remedy. On the popular Overnight dataset, which
contains eight domains, we show that both cross-domain training and
standardized pre-trained word embeddings can bring significant improvement.
</dc:description>
 <dc:description>Comment: 12 pages, 2 figures, accepted by EMNLP2017</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:date>2017-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05974</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05982</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Retrospective Higher-Order Markov Processes for User Trails</dc:title>
 <dc:creator>Wu, Tao</dc:creator>
 <dc:creator>Gleich, David</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Users form information trails as they browse the web, checkin with a
geolocation, rate items, or consume media. A common problem is to predict what
a user might do next for the purposes of guidance, recommendation, or
prefetching. First-order and higher-order Markov chains have been widely used
methods to study such sequences of data. First-order Markov chains are easy to
estimate, but lack accuracy when history matters. Higher-order Markov chains,
in contrast, have too many parameters and suffer from overfitting the training
data. Fitting these parameters with regularization and smoothing only offers
mild improvements. In this paper we propose the retrospective higher-order
Markov process (RHOMP) as a low-parameter model for such sequences. This model
is a special case of a higher-order Markov chain where the transitions depend
retrospectively on a single history state instead of an arbitrary combination
of history states. There are two immediate computational advantages: the number
of parameters is linear in the order of the Markov chain and the model can be
fit to large state spaces. Furthermore, by providing a specific structure to
the higher-order chain, RHOMPs improve the model accuracy by efficiently
utilizing history states without risks of overfitting the data. We demonstrate
how to estimate a RHOMP from data and we demonstrate the effectiveness of our
method on various real application datasets spanning geolocation data, review
sequences, and business locations. The RHOMP model uniformly outperforms
higher-order Markov chains, Kneser-Ney regularization, and tensor
factorizations in terms of prediction accuracy.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05982</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05986</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strategic Arrivals to Queues Offering Priority Service</dc:title>
 <dc:creator>Talak, Rajat</dc:creator>
 <dc:creator>Manjunath, D.</dc:creator>
 <dc:creator>Proutiere, Alexandre</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We consider strategic arrivals to a FCFS service system that starts service
at a fixed time and has to serve a fixed number of customers, e.g., an airplane
boarding system. Arriving early induces a higher waiting cost (waiting before
service begins) while arriving late induces a cost because earlier arrivals
take the better seats. We first consider arrivals of heterogeneous customers
that choose arrival times to minimize the weighted sum of waiting cost and and
cost due to expected number of predecessors. We characterize the unique Nash
equilibria for this system.
  Next, we consider a system offering L levels of priority service with a FCFS
queue for each priority level. Higher priorities are charged higher admission
prices. Customers make two choices - time of arrival and priority of service.
We show that the Nash equilibrium corresponds to the customer types being
divided into L intervals and customers belonging to each interval choosing the
same priority level. We further analyze the net revenue to the server and
consider revenue maximizing strategies - number of priority levels and pricing.
Numerical results show that with only three queues the server can attain near
maximum revenue.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05986</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05992</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Subspace Designs based on Algebraic Function Fields</dc:title>
 <dc:creator>Guruswami, Venkatesan</dc:creator>
 <dc:creator>Xing, Chaoping</dc:creator>
 <dc:creator>Yuan, Chen</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Subspace designs are a (large) collection of high-dimensional subspaces
$\{H_i\}$ of $\F_q^m$ such that for any low-dimensional subspace $W$, only a
small number of subspaces from the collection have non-trivial intersection
with $W$; more precisely, the sum of dimensions of $W \cap H_i$ is at most some
parameter $L$. The notion was put forth by Guruswami and Xing (STOC'13) with
applications to list decoding variants of Reed-Solomon and algebraic-geometric
codes, and later also used for explicit rank-metric codes with optimal list
decoding radius.
  Guruswami and Kopparty (FOCS'13, Combinatorica'16) gave an explicit
construction of subspace designs with near-optimal parameters. This
construction was based on polynomials and has close connections to folded
Reed-Solomon codes, and required large field size (specifically $q \ge m$).
Forbes and Guruswami (RANDOM'15) used this construction to give explicit
constant degree &quot;dimension expanders&quot; over large fields, and noted that
subspace designs are a powerful tool in linear-algebraic pseudorandomness.
  Here, we construct subspace designs over any field, at the expense of a
modest worsening of the bound $L$ on total intersection dimension. Our approach
is based on a (non-trivial) extension of the polynomial-based construction to
algebraic function fields, and instantiating the approach with cyclotomic
function fields. Plugging in our new subspace designs in the construction of
Forbes and Guruswami yields dimension expanders over $\F^n$ for any field $\F$,
with logarithmic degree and expansion guarantee for subspaces of dimension
$\Omega(n/(\log \log n))$.
</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05992</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.05998</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Success Probability of the Box-Constrained Rounding and Babai
  Detectors</dc:title>
 <dc:creator>Chang, Xiao-Wen</dc:creator>
 <dc:creator>Wen, Jinming</dc:creator>
 <dc:creator>Tellambura, Chintha</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In communications, one frequently needs to detect a parameter vector $\hbx$
in a box from a linear model. The box-constrained rounding detector $\x^\sBR$
and Babai detector $\x^\sBB$ are often used to detect $\hbx$ due to their high
probability of correct detection, which is referred to as success probability,
and their high efficiency of implimentation. It is generally believed that the
success probability $P^\sBR$ of $\x^\sBR$ is not larger than the success
probability $P^\sBB$ of $\x^\sBB$. In this paper, we first present formulas for
$P^\sBR$ and $P^\sBB$ for two different situations: $\hbx$ is deterministic and
$\hbx$ is uniformly distributed over the constraint box. Then, we give a simple
example to show that $P^\sBR$ may be strictly larger than $P^\sBB$ if $\hbx$ is
deterministic, while we rigorously show that $P^\sBR\leq P^\sBB$ always holds
if $\hbx$ is uniformly distributed over the constraint box.
</dc:description>
 <dc:description>Comment: to appear in ISIT 2017</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.05998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06001</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Generation for Convolutional Autoregressive Models</dc:title>
 <dc:creator>Ramachandran, Prajit</dc:creator>
 <dc:creator>Paine, Tom Le</dc:creator>
 <dc:creator>Khorrami, Pooya</dc:creator>
 <dc:creator>Babaeizadeh, Mohammad</dc:creator>
 <dc:creator>Chang, Shiyu</dc:creator>
 <dc:creator>Zhang, Yang</dc:creator>
 <dc:creator>Hasegawa-Johnson, Mark A.</dc:creator>
 <dc:creator>Campbell, Roy H.</dc:creator>
 <dc:creator>Huang, Thomas S.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Convolutional autoregressive models have recently demonstrated
state-of-the-art performance on a number of generation tasks. While fast,
parallel training methods have been crucial for their success, generation is
typically implemented in a na\&quot;{i}ve fashion where redundant computations are
unnecessarily repeated. This results in slow generation, making such models
infeasible for production environments. In this work, we describe a method to
speed up generation in convolutional autoregressive models. The key idea is to
cache hidden states to avoid redundant computation. We apply our fast
generation method to the Wavenet and PixelCNN++ models and achieve up to
$21\times$ and $183\times$ speedups respectively.
</dc:description>
 <dc:description>Comment: Accepted at ICLR 2017 Workshop</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06008</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effects of virtual acoustics on dynamic auditory distance perception</dc:title>
 <dc:creator>Rungta, Atul</dc:creator>
 <dc:creator>Rewkowski, Nicholas</dc:creator>
 <dc:creator>Klatzky, Roberta</dc:creator>
 <dc:creator>Lin, Ming</dc:creator>
 <dc:creator>Manocha, Dinesh</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Sound propagation encompasses various acoustic phenomena including
reverberation. Current virtual acoustic methods, ranging from parametric
filters to physically-accurate solvers, can simulate reverberation with varying
degrees of fidelity. We investigate the effects of reverberant sounds generated
using different propagation algorithms on acoustic distance perception, i.e.,
how faraway humans perceive a sound source. In particular, we evaluate two
classes of methods for real-time sound propagation in dynamic scenes based on
parametric filters and ray tracing. Our study shows that the more accurate
method shows less distance compression as compared to the approximate,
filter-based method. This suggests that accurate reverberation in VR results in
a better reproduction of acoustic distances. We also quantify the levels of
distance compression introduced by different propagation methods in a virtual
environment.
</dc:description>
 <dc:description>Comment: 8 Pages, 7 figures</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06008</dc:identifier>
 <dc:identifier>doi:10.1121/1.4981234</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06010</identifier>
 <datestamp>2017-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BranchConnect: Large-Scale Visual Recognition with Learned Branch
  Connections</dc:title>
 <dc:creator>Ahmed, Karim</dc:creator>
 <dc:creator>Torresani, Lorenzo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce an architecture for large-scale image categorization that
enables the end-to-end learning of separate visual features for the different
classes to distinguish. The proposed model consists of a deep CNN shaped like a
tree. The stem of the tree includes a sequence of convolutional layers common
to all classes. The stem then splits into multiple branches implementing
parallel feature extractors, which are ultimately connected to the final
classification layer via learned gated connections. These learned gates
determine for each individual class the subset of features to use. Such a
scheme naturally encourages the learning of a heterogeneous set of specialized
features through the separate branches and it allows each class to use the
subset of features that are optimal for its recognition. We show the generality
of our proposed method by reshaping several popular CNNs from the literature
into our proposed architecture. Our experiments on the CIFAR100, CIFAR10, and
Synth datasets show that in each case our resulting model yields a substantial
improvement in accuracy over the original CNN. Our empirical analysis also
suggests that our scheme acts as a form of beneficial regularization improving
generalization performance.
</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:date>2017-04-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06012</identifier>
 <datestamp>2017-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph-based Joint Signal / Power Restoration for Energy Harvesting
  Wireless Sensor Networks</dc:title>
 <dc:creator>Kaneko, Megumi</dc:creator>
 <dc:creator>Cheung, Gene</dc:creator>
 <dc:creator>Su, Weng-tai</dc:creator>
 <dc:creator>Lin, Chia-Wen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The design of energy and spectrally efficient Wireless Sensor Networks (WSN)
is crucial to support the upcoming expansion of IoT/M2M mobile data traffic. In
this work, we consider an energy harvesting WSN where sensor data are
periodically reported to a Fusion Center (FC) by a sparse set of active
sensors. Unlike most existing works, the transmit power levels of each sensor
are assumed to be unknown at the FC in this distributed setting. We address the
inverse problem of joint signal / power restoration at the FC- a challenging
under-determined separation problem. To regularize the ill-posed problem, we
assume both a graph-signal smoothness prior (signal is smooth with respect to a
graph modeling spatial correlation among sensors) and a sparsity power prior
for the two unknown variables. We design an efficient algorithm by alternately
fixing one variable and solving for the other until convergence. Specifically,
when the signal is fixed, we solve for the power vector using Simplex pivoting
in linear programming (LP) to iteratively identify sparse feasible solutions,
locally minimizing an objective. Simulation results show that our proposal can
achieve very low reconstruction errors and outperform conventional schemes
under reasonable assumptions
</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:date>2017-06-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06016</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Genetic Algorithm Based Floor Planning System</dc:title>
 <dc:creator>Dalgic, Hamide Ozlem</dc:creator>
 <dc:creator>Bostanci, Erkan</dc:creator>
 <dc:creator>Guzel, Mehmet Serdar</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Genetic Algorithms are widely used in many different optimization problems
including layout design. The layout of the shelves play an important role in
the total sales metrics for superstores since this affects the customers'
shopping behaviour. This paper employed a genetic algorithm based approach to
design shelf layout of superstores. The layout design problem was tackled by
using a novel chromosome representation which takes many different parameters
to prevent dead-ends and improve shelf visibility into consideration. Results
show that the approach can produce reasonably good layout designs in very short
amounts of time.
</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06017</identifier>
 <datestamp>2017-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PAFit: an R Package for Estimating Preferential Attachment and Node
  Fitness in Temporal Complex Networks</dc:title>
 <dc:creator>Pham, Thong</dc:creator>
 <dc:creator>Sheridan, Paul</dc:creator>
 <dc:creator>Shimodaira, Hidetoshi</dc:creator>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  Many real-world systems are profitably described as complex networks that
grow over time. Preferential attachment and node fitness are two ubiquitous
growth mechanisms that not only explain certain structural properties commonly
observed in real-world systems, but are also tied to a number of applications
in modeling and inference. In the node fitness mechanism, the probability a
node acquires a new edge is proportional to a quantity called fitness that is
assumed to be independent of the network structure. On the other hand, in the
preferential attachment mechanism, this probability of acquiring new edges is
proportional to a function of the current number of edges of the node. While
this function is originally assumed to be the linear function, and hence fixed,
in general it can be arbitrary, and thus is the target of estimation in
real-world datasets. While there are standard statistical packages for
estimating the structural properties of complex networks, there is no
corresponding package when it comes to the estimation of preferential
attachment and node fitness mechanisms. This paper introduces the R package
PAFit, which implements well-established statistical methods for estimating
preferential attachment and node fitness, as well as a number of functions for
generating complex networks from these two mechanisms. The main computational
part of the package is implemented in C++ with OpenMP to ensure good
performance for large-scale networks. In this paper, we first introduce the
main functionalities of PAFit using simulated examples, and then use the
package to analyze a collaboration network between scientists in the field of
complex networks.
</dc:description>
 <dc:description>Comment: 22 pages, 3 tables, 5 figures</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:date>2017-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06018</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Fuzzy Brute Force Matching Method for Binary Image Features</dc:title>
 <dc:creator>Bostanci, Erkan</dc:creator>
 <dc:creator>Kanwal, Nadia</dc:creator>
 <dc:creator>Bostanci, Betul</dc:creator>
 <dc:creator>Guzel, Mehmet Serdar</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Matching of binary image features is an important step in many different
computer vision applications. Conventionally, an arbitrary threshold is used to
identify a correct match from incorrect matches using Hamming distance which
may improve or degrade the matching results for different input images. This is
mainly due to the image content which is affected by the scene, lighting and
imaging conditions. This paper presents a fuzzy logic based approach for brute
force matching of image features to overcome this situation. The method was
tested using a well-known image database with known ground truth. The approach
is shown to produce a higher number of correct matches when compared against
constant distance thresholds. The nature of fuzzy logic which allows the
vagueness of information and tolerance to errors has been successfully
exploited in an image processing context. The uncertainty arising from the
imaging conditions has been overcome with the use of compact fuzzy matching
membership functions.
</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06020</identifier>
 <datestamp>2017-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhancing Person Re-identification in a Self-trained Subspace</dc:title>
 <dc:creator>Yang, Xun</dc:creator>
 <dc:creator>Wang, Meng</dc:creator>
 <dc:creator>Hong, Richang</dc:creator>
 <dc:creator>Tian, Qi</dc:creator>
 <dc:creator>Rui, Yong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Despite the promising progress made in recent years, person re-identification
(re-ID) remains a challenging task due to the complex variations in human
appearances from different camera views. For this challenging problem, a large
variety of algorithms have been developed in the fully-supervised setting,
requiring access to a large amount of labeled training data. However, the main
bottleneck for fully-supervised re-ID is the limited availability of labeled
training samples. To address this problem, in this paper, we propose a
self-trained subspace learning paradigm for person re-ID which effectively
utilizes both labeled and unlabeled data to learn a discriminative subspace
where person images across disjoint camera views can be easily matched. The
proposed approach first constructs pseudo pairwise relationships among
unlabeled persons using the k-nearest neighbors algorithm. Then, with the
pseudo pairwise relationships, the unlabeled samples can be easily combined
with the labeled samples to learn a discriminative projection by solving an
eigenvalue problem. In addition, we refine the pseudo pairwise relationships
iteratively, which further improves the learning performance. A multi-kernel
embedding strategy is also incorporated into the proposed approach to cope with
the non-linearity in person's appearance and explore the complementation of
multiple kernels. In this way, the performance of person re-ID can be greatly
enhanced when training data are insufficient. Experimental results on six
widely-used datasets demonstrate the effectiveness of our approach and its
performance can be comparable to the reported results of most state-of-the-art
fully-supervised methods while using much fewer labeled data.
</dc:description>
 <dc:description>Comment: Accepted by ACM Transactions on Multimedia Computing, Communications,
  and Applications (TOMM)</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:date>2017-04-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06025</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Limits of Stochastic Sub-Gradient Learning, Part II:
  Multi-Agent Case</dc:title>
 <dc:creator>Ying, Bicheng</dc:creator>
 <dc:creator>Sayed, Ali H.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The analysis in Part I revealed interesting properties for subgradient
learning algorithms in the context of stochastic optimization when gradient
noise is present. These algorithms are used when the risk functions are
non-smooth and involve non-differentiable components. They have been long
recognized as being slow converging methods. However, it was revealed in Part I
that the rate of convergence becomes linear for stochastic optimization
problems, with the error iterate converging at an exponential rate $\alpha^i$
to within an $O(\mu)-$neighborhood of the optimizer, for some $\alpha \in
(0,1)$ and small step-size $\mu$. The conclusion was established under weaker
assumptions than the prior literature and, moreover, several important problems
(such as LASSO, SVM, and Total Variation) were shown to satisfy these weaker
assumptions automatically (but not the previously used conditions from the
literature). These results revealed that sub-gradient learning methods have
more favorable behavior than originally thought when used to enable continuous
adaptation and learning. The results of Part I were exclusive to single-agent
adaptation. The purpose of the current Part II is to examine the implications
of these discoveries when a collection of networked agents employs subgradient
learning as their cooperative mechanism. The analysis will show that, despite
the coupled dynamics that arises in a networked scenario, the agents are still
able to attain linear convergence in the stochastic case; they are also able to
reach agreement within $O(\mu)$ of the optimizer.
</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06033</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Cognitive Decline with Deep Learning of Brain Metabolism and
  Amyloid Imaging</dc:title>
 <dc:creator>Choi, Hongyoon</dc:creator>
 <dc:creator>Jin, Kyong Hwan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  For effective treatment of Alzheimer disease (AD), it is important to
identify subjects who are most likely to exhibit rapid cognitive decline.
Herein, we developed a novel framework based on a deep convolutional neural
network which can predict future cognitive decline in mild cognitive impairment
(MCI) patients using flurodeoxyglucose and florbetapir positron emission
tomography (PET). The architecture of the network only relies on baseline PET
studies of AD and normal subjects as the training dataset. Feature extraction
and complicated image preprocessing including nonlinear warping are unnecessary
for our approach. Accuracy of prediction (84.2%) for conversion to AD in MCI
patients outperformed conventional feature-based quantification approaches. ROC
analyses revealed that performance of CNN-based approach was significantly
higher than that of the conventional quantification methods (p &lt; 0.05). Output
scores of the network were strongly correlated with the longitudinal change in
cognitive measurements. These results show the feasibility of deep learning as
a tool for predicting disease outcome using brain images.
</dc:description>
 <dc:description>Comment: 24 pages</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06036</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-end representation learning for Correlation Filter based tracking</dc:title>
 <dc:creator>Valmadre, Jack</dc:creator>
 <dc:creator>Bertinetto, Luca</dc:creator>
 <dc:creator>Henriques, Jo&#xe3;o F.</dc:creator>
 <dc:creator>Vedaldi, Andrea</dc:creator>
 <dc:creator>Torr, Philip H. S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The Correlation Filter is an algorithm that trains a linear template to
discriminate between images and their translations. It is well suited to object
tracking because its formulation in the Fourier domain provides a fast
solution, enabling the detector to be re-trained once per frame. Previous works
that use the Correlation Filter, however, have adopted features that were
either manually designed or trained for a different task. This work is the
first to overcome this limitation by interpreting the Correlation Filter
learner, which has a closed-form solution, as a differentiable layer in a deep
neural network. This enables learning deep features that are tightly coupled to
the Correlation Filter. Experiments illustrate that our method has the
important practical benefit of allowing lightweight architectures to achieve
state-of-the-art performance at high framerates.
</dc:description>
 <dc:description>Comment: To appear at CVPR 2017</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06036</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06037</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flexible Level-1 Consensus Ensuring Stable Social Choice: Analysis and
  Algorithms</dc:title>
 <dc:creator>Nitzan, Mor</dc:creator>
 <dc:creator>Nitzan, Shmuel</dc:creator>
 <dc:creator>Segal-Halevi, Erel</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Level-1 Consensus is a property of a preference-profile. Intuitively, it
means that there exists a preference relation which induces an ordering of all
other preferences such that frequent preferences are those that are more
similar to it. This is a desirable property, since it enhances the stability of
social choice by guaranteeing that there exists a Condorcet winner and it is
elected by all scoring rules.
  In this paper, we present an algorithm for checking whether a given
preference profile exhibits level-1 consensus. We apply this algorithm to a
large number of preference profiles, both real and randomly-generated, and find
that level-1 consensus is very improbable. We support these empirical findings
theoretically, by showing that, under the impartial culture assumption, the
probability of level-1 consensus approaches zero when the number of individuals
approaches infinity.
  Motivated by these observations, we show that the level-1 consensus property
can be weakened while retaining its stability implications. We call this weaker
property Flexible Consensus. We show, both empirically and theoretically, that
it is considerably more probable than the original level-1 consensus. In
particular, under the impartial culture assumption, the probability for
Flexible Consensus converges to a positive number when the number of
individuals approaches infinity.
</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06037</dc:identifier>
 <dc:identifier>Social Choice and Welfare, 2/11/2017, pages 1-23</dc:identifier>
 <dc:identifier>doi:10.1007/s00355-017-1092-2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06040</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding the Mechanisms of Deep Transfer Learning for Medical
  Images</dc:title>
 <dc:creator>Ravishankar, Hariharan</dc:creator>
 <dc:creator>Sudhakar, Prasad</dc:creator>
 <dc:creator>Venkataramani, Rahul</dc:creator>
 <dc:creator>Thiruvenkadam, Sheshadri</dc:creator>
 <dc:creator>Annangi, Pavan</dc:creator>
 <dc:creator>Babu, Narayanan</dc:creator>
 <dc:creator>Vaidya, Vivek</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The ability to automatically learn task specific feature representations has
led to a huge success of deep learning methods. When large training data is
scarce, such as in medical imaging problems, transfer learning has been very
effective. In this paper, we systematically investigate the process of
transferring a Convolutional Neural Network, trained on ImageNet images to
perform image classification, to kidney detection problem in ultrasound images.
We study how the detection performance depends on the extent of transfer. We
show that a transferred and tuned CNN can outperform a state-of-the-art feature
engineered pipeline and a hybridization of these two techniques achieves 20\%
higher performance. We also investigate how the evolution of intermediate
response images from our network. Finally, we compare these responses to
state-of-the-art image processing filters in order to gain greater insight into
how transfer learning is able to effectively manage widely varying imaging
regimes.
</dc:description>
 <dc:description>Comment: Published in MICCAI Workshop on Deep Learning in Medical Image
  Analysis, 2016</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06040</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06053</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Inertial Sensors for Position and Orientation Estimation</dc:title>
 <dc:creator>Kok, Manon</dc:creator>
 <dc:creator>Hol, Jeroen D.</dc:creator>
 <dc:creator>Sch&#xf6;n, Thomas B.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In recent years, MEMS inertial sensors (3D accelerometers and 3D gyroscopes)
have become widely available due to their small size and low cost. Inertial
sensor measurements are obtained at high sampling rates and can be integrated
to obtain position and orientation information. These estimates are accurate on
a short time scale, but suffer from integration drift over longer time scales.
To overcome this issue, inertial sensors are typically combined with additional
sensors and models. In this tutorial we focus on the signal processing aspects
of position and orientation estimation using inertial sensors. We discuss
different modeling choices and a selected number of important algorithms. The
algorithms include optimization-based smoothing and filtering as well as
computationally cheaper extended Kalman filter and complementary filter
implementations. The quality of their estimates is illustrated using both
experimental and simulated data.
</dc:description>
 <dc:description>Comment: 92 pages, 38 figures</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06061</identifier>
 <datestamp>2017-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-view (Joint) Probability Linear Discrimination Analysis for
  Multi-view Feature Verification</dc:title>
 <dc:creator>Shi, Ziqiang</dc:creator>
 <dc:creator>Liu, Liu</dc:creator>
 <dc:creator>Wang, Mengjiao</dc:creator>
 <dc:creator>Liu, Rujie</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Multi-view feature has been proved to be very effective in many multimedia
applications. However, the current back-end classifiers cannot make full use of
such features. In this paper, we propose a method to model the multi-faceted
information in the multi-view features explicitly and jointly. In our approach,
the feature was modeled as a result derived by a generative multi-view
(joint\footnotemark[1]) Probability Linear Discriminant Analysis (PLDA) model,
which contains multiple kinds of latent variables. The usual PLDA model only
considers one single label. However, in practical use, when using multi-task
learned network as feature extractor, the extracted feature are always attached
to several labels. This type of feature is called multi-view feature. With
multi-view (joint) PLDA, we are able to explicitly build a model that can
combine multiple heterogeneous information from the multi-view features. In
verification step, we calculated the likelihood to describe whether the two
features having consistent labels or not. This likelihood are used in the
following decision-making. Experiments have been conducted on large scale
verification task. On the public RSR2015 data corpus, the results showed that
our approach can achieve 0.02\% EER and 0.09\% EER for impostor wrong and
impostor correct cases respectively.
</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:date>2017-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06061</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06062</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Every Untrue Label is Untrue in its Own Way: Controlling Error Type with
  the Log Bilinear Loss</dc:title>
 <dc:creator>Resheff, Yehezkel S.</dc:creator>
 <dc:creator>Mandelbaum, Amit</dc:creator>
 <dc:creator>Weinshall, Daphna</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep learning has become the method of choice in many application domains of
machine learning in recent years, especially for multi-class classification
tasks. The most common loss function used in this context is the cross-entropy
loss, which reduces to the log loss in the typical case when there is a single
correct response label. While this loss is insensitive to the identity of the
assigned class in the case of misclassification, in practice it is often the
case that some errors may be more detrimental than others. Here we present the
bilinear-loss (and related log-bilinear-loss) which differentially penalizes
the different wrong assignments of the model. We thoroughly test this method
using standard models and benchmark image datasets. As one application, we show
the ability of this method to better contain error within the correct
super-class, in the hierarchically labeled CIFAR100 dataset, without affecting
the overall performance of the classifier.
</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06065</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-End Unsupervised Deformable Image Registration with a
  Convolutional Neural Network</dc:title>
 <dc:creator>de Vos, Bob D.</dc:creator>
 <dc:creator>Berendsen, Floris F.</dc:creator>
 <dc:creator>Viergever, Max A.</dc:creator>
 <dc:creator>Staring, Marius</dc:creator>
 <dc:creator>I&#x161;gum, Ivana</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work we propose a deep learning network for deformable image
registration (DIRNet). The DIRNet consists of a convolutional neural network
(ConvNet) regressor, a spatial transformer, and a resampler. The ConvNet
analyzes a pair of fixed and moving images and outputs parameters for the
spatial transformer, which generates the displacement vector field that enables
the resampler to warp the moving image to the fixed image. The DIRNet is
trained end-to-end by unsupervised optimization of a similarity metric between
input image pairs. A trained DIRNet can be applied to perform registration on
unseen image pairs in one pass, thus non-iteratively. Evaluation was performed
with registration of images of handwritten digits (MNIST) and cardiac cine MR
scans (Sunnybrook Cardiac Data). The results demonstrate that registration with
DIRNet is as accurate as a conventional deformable image registration method
with substantially shorter execution times.
</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06065</dc:identifier>
 <dc:identifier>DLMIA/ML-CDS@MICCAI 2017</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-67558-9_24</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06070</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Certification of Compact Low-Stretch Routing Schemes</dc:title>
 <dc:creator>Balliu, Alkida</dc:creator>
 <dc:creator>Fraigniaud, Pierre</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  On the one hand, the correctness of routing protocols in networks is an issue
of utmost importance for guaranteeing the delivery of messages from any source
to any target. On the other hand, a large collection of routing schemes have
been proposed during the last two decades, with the objective of transmitting
messages along short routes, while keeping the routing tables small.
Regrettably, all these schemes share the property that an adversary may modify
the content of the routing tables with the objective of, e.g., blocking the
delivery of messages between some pairs of nodes, without being detected by any
node.
  In this paper, we present a simple certification mechanism which enables the
nodes to locally detect any alteration of their routing tables. In particular,
we show how to locally verify the stretch-3 routing scheme by Thorup and Zwick
[SPAA 2001] by adding certificates of $\widetilde{O}(\sqrt{n})$ bits at each
node in $n$-node networks, that is, by keeping the memory size of the same
order of magnitude as the original routing tables. We also propose a new
name-independent routing scheme using routing tables of size
$\widetilde{O}(\sqrt{n})$ bits. This new routing scheme can be locally verified
using certificates on $\widetilde{O}(\sqrt{n})$ bits. Its stretch is3 if using
handshaking, and 5 otherwise.
</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:date>2017-10-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06078</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Name Independent Fault Tolerant Routing Scheme</dc:title>
 <dc:creator>Balliu, Alkida</dc:creator>
 <dc:creator>Olivetti, Dennis</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We consider the problem of routing in presence of faults in undirected
weighted graphs. More specifically, we focus on the design of compact
name-independent fault-tolerant routing schemes, where the designer of the
scheme is not allowed to assign names to nodes, i.e., the name of a node is
just its identifier. Given a set $F$ of faulty (or forbidden) edges, the goal
is to route from a source node $s$ to a target $t$ avoiding the forbidden edges
in $F$.
  Given any name-dependent fault-tolerant routing scheme and any
name-independent routing scheme, we show how to use them as a black box to
construct a name-independent fault-tolerant routing scheme. In particular, we
present a name-independent routing scheme able to handle any set $F$ of
forbidden edges in $|F|+1$ connected graphs. This has stretch
$O(k^2\,|F|^3(|F|+\log^2 n)\log D)$, where $D$ is the diameter of the graph. It
uses tables of size $ \widetilde{O}(k\, n^{1/k}(k + deg(v)))$ bits at every
node $v$, where $deg(v)$ is the degree of node $v$. In the context of networks
that suffer only from occasional failures, we present a name-independent
routing scheme that handles only $1$ fault at a time, and another routing
scheme that handles at most $2$ faults at a time. The former uses
$\widetilde{O}(k^2\, n^{1/k} + k\,deg(v))$ bits of memory per node, with
stretch $O(k^3\log D)$. The latter consumes in average $ \widetilde{O}(k^2
\,n^{1/k} + deg(v))$ bits of memory per node, with stretch $O(k^2\log D)$.
</dc:description>
 <dc:description>Comment: The stretch analysis is faulty, so the whole idea does not work</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06084</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge Fusion via Embeddings from Text, Knowledge Graphs, and Images</dc:title>
 <dc:creator>Thoma, Steffen</dc:creator>
 <dc:creator>Rettinger, Achim</dc:creator>
 <dc:creator>Both, Fabian</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  We present a baseline approach for cross-modal knowledge fusion. Different
basic fusion methods are evaluated on existing embedding approaches to show the
potential of joining knowledge about certain concepts across modalities in a
fused concept representation.
</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06092</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Bandwidth Affects the $CONGEST$ Model</dc:title>
 <dc:creator>Olivetti, Dennis</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The $CONGEST$ model for distributed network computing is well suited for
analyzing the impact of limiting the throughput of a network on its capacity to
solve tasks efficiently. For many &quot;global&quot; problems there exists a lower bound
of $\Omega(D + \sqrt{n/B})$, where $B$ is the amount of bits that can be
exchanged between two nodes in one round of communication, $n$ is the number of
nodes and $D$ is the diameter of the graph. Typically, upper bounds are given
only for the case $B=O(\log n)$, or for the case $B = +\infty$. For $B=O(\log
n)$, the Minimum Spanning Tree (MST) construction problem can be solved in $O(D
+ \sqrt{n}\log^* n)$ rounds, and the Single Source Shortest Path (SSSP) problem
can be $(1+\epsilon)$-approximated in $\widetilde{O}(\epsilon^{-O(1)}
(D+\sqrt{n}) )$ rounds. We extend these results by providing algorithms with a
complexity parametric on $B$. We show that, for any $B=\Omega(\log n)$, there
exists an algorithm that constructs a MST in $\widetilde{O}(D + \sqrt{n/B})$
rounds, and an algorithm that $(1+\epsilon)$-approximate the SSSP problem in
$\widetilde{O}(\epsilon^{-O(1)} (D+\sqrt{n/B}) )$ rounds. We also show that
there exist problems that are bandwidth insensitive.
</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06092</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06096</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Dependent Doors Problem: An Investigation into Sequential Decisions
  without Feedback</dc:title>
 <dc:creator>Korman, Amos</dc:creator>
 <dc:creator>Rodeh, Yoav</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We introduce the dependent doors problem as an abstraction for situations in
which one must perform a sequence of possibly dependent decisions, without
receiving feedback information on the effectiveness of previously made actions.
Informally, the problem considers a set of $d$ doors that are initially closed,
and the aim is to open all of them as fast as possible. To open a door, the
algorithm knocks on it and it might open or not according to some probability
distribution. This distribution may depend on which other doors are currently
open, as well as on which other doors were open during each of the previous
knocks on that door. The algorithm aims to minimize the expected time until all
doors open. Crucially, it must act at any time without knowing whether or which
other doors have already opened. In this work, we focus on scenarios where
dependencies between doors are both positively correlated and acyclic.The
fundamental distribution of a door describes the probability it opens in the
best of conditions (with respect to other doors being open or closed). We show
that if in two configurations of $d$ doors corresponding doors share the same
fundamental distribution, then these configurations have the same optimal
running time up to a universal constant, no matter what are the dependencies
between doors and what are the distributions. We also identify algorithms that
are optimal up to a universal constant factor. For the case in which all doors
share the same fundamental distribution we additionally provide a simpler
algorithm, and a formula to calculate its running time. We furthermore analyse
the price of lacking feedback for several configurations governed by standard
fundamental distributions. In particular, we show that the price is logarithmic
in $d$ for memoryless doors, but can potentially grow to be linear in $d$ for
other distributions.We then turn our attention to investigate precise bounds.
Even for the case of two doors, identifying the optimal sequence is an
intriguing combinatorial question. Here, we study the case of two cascading
memoryless doors. That is, the first door opens on each knock independently
with probability $p\_1$. The second door can only open if the first door is
open, in which case it will open on each knock independently with probability
$p\_2$. We solve this problem almost completely by identifying algorithms that
are optimal up to an additive term of 1.
</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06096</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06099</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Smartphone App Identification Via Encrypted Network Traffic
  Analysis</dc:title>
 <dc:creator>Taylor, Vincent F.</dc:creator>
 <dc:creator>Spolaor, Riccardo</dc:creator>
 <dc:creator>conti, Mauro</dc:creator>
 <dc:creator>Martinovic, Ivan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The apps installed on a smartphone can reveal much information about a user,
such as their medical conditions, sexual orientation, or religious beliefs.
Additionally, the presence or absence of particular apps on a smartphone can
inform an adversary who is intent on attacking the device. In this paper, we
show that a passive eavesdropper can feasibly identify smartphone apps by
fingerprinting the network traffic that they send. Although SSL/TLS hides the
payload of packets, side-channel data such as packet size and direction is
still leaked from encrypted connections. We use machine learning techniques to
identify smartphone apps from this side-channel data. In addition to merely
fingerprinting and identifying smartphone apps, we investigate how app
fingerprints change over time, across devices and across different versions of
apps. Additionally, we introduce strategies that enable our app classification
system to identify and mitigate the effect of ambiguous traffic, i.e., traffic
in common among apps such as advertisement traffic. We fully implemented a
framework to fingerprint apps and ran a thorough set of experiments to assess
its performance. We fingerprinted 110 of the most popular apps in the Google
Play Store and were able to identify them six months later with up to 96%
accuracy. Additionally, we show that app fingerprints persist to varying
extents across devices and app versions.
</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06104</identifier>
 <datestamp>2017-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural End-to-End Learning for Computational Argumentation Mining</dc:title>
 <dc:creator>Eger, Steffen</dc:creator>
 <dc:creator>Daxenberger, Johannes</dc:creator>
 <dc:creator>Gurevych, Iryna</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We investigate neural techniques for end-to-end computational argumentation
mining (AM). We frame AM both as a token-based dependency parsing and as a
token-based sequence tagging problem, including a multi-task learning setup.
Contrary to models that operate on the argument component level, we find that
framing AM as dependency parsing leads to subpar performance results. In
contrast, less complex (local) tagging models based on BiLSTMs perform robustly
across classification scenarios, being able to catch long-range dependencies
inherent to the AM problem. Moreover, we find that jointly learning 'natural'
subtasks, in a multi-task learning setup, improves performance.
</dc:description>
 <dc:description>Comment: To be published at ACL 2017</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:date>2017-04-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06109</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Mise-En-Sc\`ene Visual Features based on MPEG-7 and Deep Learning
  for Movie Recommendation</dc:title>
 <dc:creator>Deldjoo, Yashar</dc:creator>
 <dc:creator>Quadrana, Massimo</dc:creator>
 <dc:creator>Elahi, Mehdi</dc:creator>
 <dc:creator>Cremonesi, Paolo</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Item features play an important role in movie recommender systems, where
recommendations can be generated by using explicit or implicit preferences of
users on traditional features (attributes) such as tag, genre, and cast.
Typically, movie features are human-generated, either editorially (e.g., genre
and cast) or by leveraging the wisdom of the crowd (e.g., tag), and as such,
they are prone to noise and are expensive to collect. Moreover, these features
are often rare or absent for new items, making it difficult or even impossible
to provide good quality recommendations.
  In this paper, we show that user's preferences on movies can be better
described in terms of the mise-en-sc\`ene features, i.e., the visual aspects of
a movie that characterize design, aesthetics and style (e.g., colors,
textures). We use both MPEG-7 visual descriptors and Deep Learning hidden
layers as example of mise-en-sc\`ene features that can visually describe
movies. Interestingly, mise-en-sc\`ene features can be computed automatically
from video files or even from trailers, offering more flexibility in handling
new items, avoiding the need for costly and error-prone human-based tagging,
and providing good scalability.
  We have conducted a set of experiments on a large catalogue of 4K movies.
Results show that recommendations based on mise-en-sc\`ene features
consistently provide the best performance with respect to richer sets of more
traditional features, such as genre and tag.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06124</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Achievable Rate for an Optical Channel with Finite Memory</dc:title>
 <dc:creator>Shenoy, K Gautam</dc:creator>
 <dc:creator>Sharma, Vinod</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A fiber optic channel is modeled in a variety of ways; from the simple
additive white complex Gaussian noise model, to models that incorporate memory
in the channel. Because of Kerr nonlinearity, a simple model is not a good
approximation to an optical fiber. Hence we study a fiber optic channel with
finite memory and provide an achievable bound on channel capacity that improves
upon a previously known bound.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures. To be submitted to IEEE ICC 2018</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06124</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06125</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BB_twtr at SemEval-2017 Task 4: Twitter Sentiment Analysis with CNNs and
  LSTMs</dc:title>
 <dc:creator>Cliche, Mathieu</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper we describe our attempt at producing a state-of-the-art Twitter
sentiment classifier using Convolutional Neural Networks (CNNs) and Long Short
Term Memory (LSTMs) networks. Our system leverages a large amount of unlabeled
data to pre-train word embeddings. We then use a subset of the unlabeled data
to fine tune the embeddings using distant supervision. The final CNNs and LSTMs
are trained on the SemEval-2017 Twitter dataset where the embeddings are fined
tuned again. To boost performances we ensemble several CNNs and LSTMs together.
Our approach achieved first rank on all of the five English subtasks amongst 40
teams.
</dc:description>
 <dc:description>Comment: Published in Proceedings of SemEval-2017, 8 pages</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06127</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extension of Technology Acceptance Model by using System Usability Scale
  to assess behavioral intention to use e-learning</dc:title>
 <dc:creator>Revythi, Anastasia</dc:creator>
 <dc:creator>Tselios, Nikolaos</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  This study examines the acceptance of technology and behavioral intention to
use learning management systems (LMS). More specifically, the aim of this
research is to examine whether students ultimately accept and use educational
learning systems such as e-class and the impact of behavioral intention on
their decision to use them. An extended version of technology acceptance model
has been used by employing the System Usability Scale to measure perceived ease
of use and the data analysis was based on partial least squares method. The
results were confirmed in most of the research hypotheses. In particular,
social norm, system access and self-efficacy significantly affect behavioral
intention to use. Therefore, e-learning developers and stakeholders should
focus on these factors to enable an educational technology to be effective in
educational process.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06127</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06131</identifier>
 <datestamp>2017-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Acquire Information</dc:title>
 <dc:creator>Pu, Yewen</dc:creator>
 <dc:creator>Kaelbling, Leslie P</dc:creator>
 <dc:creator>Solar-Lezama, Armando</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of diagnosis where a set of simple observations are
used to infer a potentially complex hidden hypothesis. Finding the optimal
subset of observations is intractable in general, thus we focus on the problem
of active diagnosis, where the agent selects the next most-informative
observation based on the results of previous observations. We show that under
the assumption of uniform observation entropy, one can build an implication
model which directly predicts the outcome of the potential next observation
conditioned on the results of past observations, and selects the observation
with the maximum entropy. This approach enjoys reduced computation complexity
by bypassing the complicated hypothesis space, and can be trained on
observation data alone, learning how to query without knowledge of the hidden
hypothesis.
</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:date>2017-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06131</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06140</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hazard Analysis and Risk Assessment for an Automated Unmanned Protective
  Vehicle</dc:title>
 <dc:creator>Stolte, Torben</dc:creator>
 <dc:creator>Bagschik, Gerrit</dc:creator>
 <dc:creator>Reschka, Andreas</dc:creator>
 <dc:creator>Maurer, and Markus</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  For future application of automated vehicles in public traffic, ensuring
functional safety is essential. In this context, a hazard analysis and risk
assessment is an important input for designing functionally vehicle automation
systems. In this contribution, we present a detailed hazard analysis and risk
assessment (HARA) according to the ISO 26262 standard for a specific Level 4
application, namely an unmanned protective vehicle operated without human
supervision for motorway hard shoulder roadworks.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures, 2 tables, accepted to appear on IEEE Intelligent
  Vehicle Symposium (IV), Redondo Beach, CA, USA, June 2017</dc:description>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06140</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06145</identifier>
 <datestamp>2017-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey and Discussion of Memcomputing Machines</dc:title>
 <dc:creator>Saunders, Daniel</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  This paper serves as a review and discussion of the recent works on
memcomputing. In particular, the $\textit{universal memcomputing machine}$
(UMM) and the $\textit{digital memcomputing machine}$ (DMM) are discussed. We
review the memcomputing concept in the dynamical systems framework and assess
the algorithms offered for computing $NP$ problems in the UMM and DMM
paradigms. We argue that the UMM is a physically implausible machine, and that
the DMM model, as described by numerical simulations, is no more powerful than
Turing-complete computation. We claim that the evidence for the resolution of
$P$ vs. $NP$ is therefore inconclusive, and conclude that the memcomputing
machine paradigm constitutes an energy efficient, special-purpose class of
models of dynamical systems computation.
</dc:description>
 <dc:description>Comment: Independent study work. Withdrawing since this submission was in bad
  taste</dc:description>
 <dc:date>2017-04-18</dc:date>
 <dc:date>2017-04-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06145</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06149</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Query Time for Encoding Range Majority</dc:title>
 <dc:creator>Gawrychowski, Pawel</dc:creator>
 <dc:creator>Nicholson, Patrick K.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We revisit the range $\tau$-majority problem, which asks us to preprocess an
array $A[1..n]$ for a fixed value of $\tau \in (0,1/2]$, such that for any
query range $[i,j]$ we can return a position in $A$ of each distinct
$\tau$-majority element. A $\tau$-majority element is one that has relative
frequency at least $\tau$ in the range $[i,j]$: i.e., frequency at least $\tau
(j-i+1)$. Belazzougui et al. [WADS 2013] presented a data structure that can
answer such queries in $O(1/\tau)$ time, which is optimal, but the space can be
as much as $\Theta(n \lg n)$ bits. Recently, Navarro and Thankachan
[Algorithmica 2016] showed that this problem could be solved using an $O(n \lg
(1/\tau))$ bit encoding, which is optimal in terms of space, but has suboptimal
query time. In this paper, we close this gap and present a data structure that
occupies $O(n \lg (1/\tau))$ bits of space, and has $O(1/\tau)$ query time. We
also show that this space bound is optimal, even for the much weaker query in
which we must decide whether the query range contains at least one
$\tau$-majority element.
</dc:description>
 <dc:description>Comment: To appear in WADS 2017 (modulo the appendix)</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06149</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06164</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Counterexample to the Vector Generalization of Costa's EPI, and
  Partial Resolution</dc:title>
 <dc:creator>Courtade, Thomas A.</dc:creator>
 <dc:creator>Han, Guangyue</dc:creator>
 <dc:creator>Wu, Yaochen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We give a counterexample to the vector generalization of Costa's entropy
power inequality (EPI) due to Liu, Liu, Poor and Shamai. In particular, the
claimed inequality can fail if the matix-valued parameter in the convex
combination does not commute with the covariance of the additive Gaussian
noise. Conversely, the inequality holds if these two matrices commute.
</dc:description>
 <dc:description>Comment: 3 pages</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06164</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06167</identifier>
 <datestamp>2017-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving DL-MU-MIMO Performance in IEEE 802.11ac Networks through
  Decoupled Scheduling</dc:title>
 <dc:creator>Kosek-Szott, Katarzyna</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The IEEE 802.11ac standard introduces new downlink multi-user MIMO
(DL-MU-MIMO) transmissions to up to four users in order to increase spatial
reuse in wireless local area networks (WLANs). We argue that even better WLAN
per- formance can be achieved by slightly modifying the DL-MU-MIMO scheduling.
To this end we propose a new queuing mechanism based on the decoupling of EDCA
and DL-MU-MIMO scheduling (DEMS) to avoid head-of-line blocking. We show that
DEMS outperforms traditional 802.11ac scheduling based on first in, first out
transmission queues. The improvement is shown in terms throughput achieved
with: (a) more efficient channel usage, (b) increased probability of
transmission of high priority traffic, and (c) decreased competition between
frames destined to distinct users.
</dc:description>
 <dc:description>Comment: Manuscript accepted for publication in Springer Wireless Networks</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:date>2017-04-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06167</dc:identifier>
 <dc:identifier>doi:10.1007/s11276-017-1520-3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06170</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boolean quadric polytopes are faces of linear ordering polytopes</dc:title>
 <dc:creator>Maksimenko, Aleksandr</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Let $BQP(n)$ be a boolean quadric polytope, $LOP(m)$ be a linear ordering
polytope. It is shown that $BQP(n)$ is linearly isomorphic to a face of
$LOP(2n)$.
</dc:description>
 <dc:description>Comment: 7 pages, in Russian</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06170</dc:identifier>
 <dc:language>ru</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06176</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Segmentation of the Proximal Femur from MR Images using Deep
  Convolutional Neural Networks</dc:title>
 <dc:creator>Deniz, Cem M.</dc:creator>
 <dc:creator>Xiang, Siyuan</dc:creator>
 <dc:creator>Hallyburton, Spencer</dc:creator>
 <dc:creator>Welbeck, Arakua</dc:creator>
 <dc:creator>Honig, Stephen</dc:creator>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:creator>Chang, Gregory</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Magnetic resonance imaging (MRI) has been proposed as a complimentary method
to measure bone quality and assess fracture risk. However, manual segmentation
of MR images of bone is time-consuming, limiting the use of MRI measurements in
the clinical practice. The purpose of this paper is to present an automatic
proximal femur segmentation method that is based on deep convolutional neural
networks (CNNs). This study had institutional review board approval and written
informed consent was obtained from all subjects. A dataset of volumetric
structural MR images of the proximal femur from 86 subject were
manually-segmented by an expert. We performed experiments by training two
different CNN architectures with multiple number of initial feature maps and
layers, and tested their segmentation performance against the gold standard of
manual segmentations using four-fold cross-validation. Automatic segmentation
of the proximal femur achieved a high dice similarity score of 0.94$\pm$0.05
with precision = 0.95$\pm$0.02, and recall = 0.94$\pm$0.08 using a CNN
architecture based on 3D convolution exceeding the performance of 2D CNNs. The
high segmentation accuracy provided by CNNs has the potential to help bring the
use of structural MRI measurements of bone quality into clinical practice for
management of osteoporosis.
</dc:description>
 <dc:description>Comment: 26 pages, 5 figures, and 2 tables</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:date>2017-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06176</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06178</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring epoch-dependent stochastic residual networks</dc:title>
 <dc:creator>Carrara, Fabio</dc:creator>
 <dc:creator>Esuli, Andrea</dc:creator>
 <dc:creator>Falchi, Fabrizio</dc:creator>
 <dc:creator>Fern&#xe1;ndez, Alejandro Moreo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The recently proposed stochastic residual networks selectively activate or
bypass the layers during training, based on independent stochastic choices,
each of which following a probability distribution that is fixed in advance. In
this paper we present a first exploration on the use of an epoch-dependent
distribution, starting with a higher probability of bypassing deeper layers and
then activating them more frequently as training progresses. Preliminary
results are mixed, yet they show some potential of adding an epoch-dependent
management of distributions, worth of further investigation.
</dc:description>
 <dc:description>Comment: Preliminary report</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06178</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06180</identifier>
 <datestamp>2017-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the DoF of Parallel MISO BCs with Partial CSIT: Total Order and
  Separability</dc:title>
 <dc:creator>Joudeh, Hamdi</dc:creator>
 <dc:creator>Clerckx, Bruno</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the degrees of freedom (DoF) of a $K$-user parallel MISO broadcast
channel with arbitrary levels of partial CSIT over each subchannel. We derive a
sum-DoF upperbound which depends on the average CSIT quality of each user. This
upperbound is shown to be tight under total order, i.e. when the order of users
with respect to their CSIT qualities is preserved over all subchannels. In this
case, it is shown that separate coding over each subchannel is optimum in a
sum-DoF sense.
</dc:description>
 <dc:description>Comment: A flaw in the application of the aligned image sets approach in the
  previous version has been corrected</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:date>2017-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06180</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06185</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cell-Probe Lower Bounds from Online Communication Complexity</dc:title>
 <dc:creator>Alman, Josh</dc:creator>
 <dc:creator>Wang, Joshua R.</dc:creator>
 <dc:creator>Yu, Huacheng</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In this work, we introduce an online model for communication complexity.
Analogous to how online algorithms receive their input piece-by-piece, our
model presents one of the players, Bob, his input piece-by-piece, and has the
players Alice and Bob cooperate to compute a result each time before the next
piece is revealed to Bob. This model has a closer and more natural
correspondence to dynamic data structures than classic communication models do,
and hence presents a new perspective on data structures.
  We first present a tight lower bound for the online set intersection problem
in the online communication model, demonstrating a general approach for proving
online communication lower bounds. The online communication model prevents a
batching trick that classic communication complexity allows, and yields a
stronger lower bound. We then apply the online communication model to prove
data structure lower bounds for two dynamic data structure problems: the Group
Range problem and the Dynamic Connectivity problem for forests. Both of the
problems admit a worst case $O(\log n)$-time data structure. Using online
communication complexity, we prove a tight cell-probe lower bound for each:
spending $o(\log n)$ (even amortized) time per operation results in at best an
$\exp(-\delta^2 n)$ probability of correctly answering a
$(1/2+\delta)$-fraction of the $n$ queries.
</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06185</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06189</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training object class detectors with click supervision</dc:title>
 <dc:creator>Papadopoulos, Dim P.</dc:creator>
 <dc:creator>Uijlings, Jasper R. R.</dc:creator>
 <dc:creator>Keller, Frank</dc:creator>
 <dc:creator>Ferrari, Vittorio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Training object class detectors typically requires a large set of images with
objects annotated by bounding boxes. However, manually drawing bounding boxes
is very time consuming. In this paper we greatly reduce annotation time by
proposing center-click annotations: we ask annotators to click on the center of
an imaginary bounding box which tightly encloses the object instance. We then
incorporate these clicks into existing Multiple Instance Learning techniques
for weakly supervised object localization, to jointly localize object bounding
boxes over all training images. Extensive experiments on PASCAL VOC 2007 and MS
COCO show that: (1) our scheme delivers high-quality detectors, performing
substantially better than those produced by weakly supervised techniques, with
a modest extra annotation effort; (2) these detectors in fact perform in a
range close to those trained from manually drawn bounding boxes; (3) as the
center-click task is very fast, our scheme reduces total annotation time by 9x
to 18x.
</dc:description>
 <dc:description>Comment: CVPR 2017</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06189</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06191</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Softmax GAN</dc:title>
 <dc:creator>Lin, Min</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Softmax GAN is a novel variant of Generative Adversarial Network (GAN). The
key idea of Softmax GAN is to replace the classification loss in the original
GAN with a softmax cross-entropy loss in the sample space of one single batch.
In the adversarial learning of $N$ real training samples and $M$ generated
samples, the target of discriminator training is to distribute all the
probability mass to the real samples, each with probability $\frac{1}{M}$, and
distribute zero probability to generated data. In the generator training phase,
the target is to assign equal probability to all data points in the batch, each
with probability $\frac{1}{M+N}$. While the original GAN is closely related to
Noise Contrastive Estimation (NCE), we show that Softmax GAN is the Importance
Sampling version of GAN. We futher demonstrate with experiments that this
simple change stabilizes GAN training.
</dc:description>
 <dc:description>Comment: NIPS 2017 submission</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06191</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06192</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Design, Implementation, and Deployment of a System to Transparently
  Compress Hundreds of Petabytes of Image Files for a File-Storage Service</dc:title>
 <dc:creator>Horn, Daniel Reiter</dc:creator>
 <dc:creator>Elkabany, Ken</dc:creator>
 <dc:creator>Lesniewski-Laas, Chris</dc:creator>
 <dc:creator>Winstein, Keith</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We report the design, implementation, and deployment of Lepton, a
fault-tolerant system that losslessly compresses JPEG images to 77% of their
original size on average. Lepton replaces the lowest layer of baseline JPEG
compression-a Huffman code-with a parallelized arithmetic code, so that the
exact bytes of the original JPEG file can be recovered quickly. Lepton matches
the compression efficiency of the best prior work, while decoding more than
nine times faster and in a streaming manner. Lepton has been released as
open-source software and has been deployed for a year on the Dropbox
file-storage backend. As of February 2017, it had compressed more than 203 PiB
of user JPEG files, saving more than 46 PiB.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2017-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06192</dc:identifier>
 <dc:identifier>Proc. NSDI 2017, Boston. p1-15</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06193</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intrusion Prevention and Detection in Grid Computing - The ALICE Case</dc:title>
 <dc:creator>Gomez, Andres</dc:creator>
 <dc:creator>Lara, Camilo</dc:creator>
 <dc:creator>Kebschull, Udo</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>High Energy Physics - Experiment</dc:subject>
 <dc:description>  Grids allow users flexible on-demand usage of computing resources through
remote communication networks. A remarkable example of a Grid in High Energy
Physics (HEP) research is used in the ALICE experiment at European Organization
for Nuclear Research CERN. Physicists can submit jobs used to process the huge
amount of particle collision data produced by the Large Hadron Collider (LHC).
Grids face complex security challenges. They are interesting targets for
attackers seeking for huge computational resources. Since users can execute
arbitrary code in the worker nodes on the Grid sites, special care should be
put in this environment. Automatic tools to harden and monitor this scenario
are required. Currently, there is no integrated solution for such requirement.
This paper describes a new security framework to allow execution of job
payloads in a sandboxed context. It also allows process behavior monitoring to
detect intrusions, even when new attack methods or zero day vulnerabilities are
exploited, by a Machine Learning approach. We plan to implement the proposed
framework as a software prototype that will be tested as a component of the
ALICE Grid middleware.
</dc:description>
 <dc:description>Comment: Journal of Physics: Conference Series, Volume 664</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06193</dc:identifier>
 <dc:identifier>J. Phys.: Conf. Ser. 664 062017 (2015)</dc:identifier>
 <dc:identifier>doi:10.1088/1742-6596/664/6/062017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06194</identifier>
 <datestamp>2017-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Neural Relation Detection for Knowledge Base Question Answering</dc:title>
 <dc:creator>Yu, Mo</dc:creator>
 <dc:creator>Yin, Wenpeng</dc:creator>
 <dc:creator>Hasan, Kazi Saidul</dc:creator>
 <dc:creator>Santos, Cicero dos</dc:creator>
 <dc:creator>Xiang, Bing</dc:creator>
 <dc:creator>Zhou, Bowen</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Relation detection is a core component for many NLP applications including
Knowledge Base Question Answering (KBQA). In this paper, we propose a
hierarchical recurrent neural network enhanced by residual learning that
detects KB relations given an input question. Our method uses deep residual
bidirectional LSTMs to compare questions and relation names via different
hierarchies of abstraction. Additionally, we propose a simple KBQA system that
integrates entity linking and our proposed relation detector to enable one
enhance another. Experimental results evidence that our approach achieves not
only outstanding relation detection performance, but more importantly, it helps
our KBQA system to achieve state-of-the-art accuracy for both single-relation
(SimpleQuestions) and multi-relation (WebQSP) QA benchmarks.
</dc:description>
 <dc:description>Comment: Accepted by ACL 2017 (updated for camera-ready)</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:date>2017-05-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06194</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06196</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Nuclear-norm Model for Multi-Frame Super-Resolution Reconstruction
  from Video Clips</dc:title>
 <dc:creator>Zhao, Rui</dc:creator>
 <dc:creator>Chan, Raymond H.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>65K10</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  We propose a variational approach to obtain super-resolution images from
multiple low-resolution frames extracted from video clips. First the
displacement between the low-resolution frames and the reference frame are
computed by an optical flow algorithm. Then a low-rank model is used to
construct the reference frame in high-resolution by incorporating the
information of the low-resolution frames. The model has two terms: a 2-norm
data fidelity term and a nuclear-norm regularization term. Alternating
direction method of multipliers is used to solve the model. Comparison of our
methods with other models on synthetic and real video clips show that our
resulting images are more accurate with less artifacts. It also provides much
finer and discernable details.
</dc:description>
 <dc:description>Comment: 12 pages, 7 numberical examples, 12 figure groups, 2 tables</dc:description>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06196</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06199</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Graph Convolutional Networks</dc:title>
 <dc:creator>Manessi, Franco</dc:creator>
 <dc:creator>Rozza, Alessandro</dc:creator>
 <dc:creator>Manzo, Mario</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Many different classification tasks need to manage structured data, which are
usually modeled as graphs. Moreover, these graphs can be dynamic, meaning that
the vertices/edges of each graph may change during time. Our goal is to jointly
exploit structured data and temporal information through the use of a neural
network model. To the best of our knowledge, this task has not been addressed
using these kind of architectures. For this reason, we propose two novel
approaches, which combine Long Short-Term Memory networks and Graph
Convolutional Networks to learn long short-term dependencies together with
graph structure. The quality of our methods is confirmed by the promising
results achieved.
</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06199</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06209</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ADMM Penalty Parameter Selection by Residual Balancing</dc:title>
 <dc:creator>Wohlberg, Brendt</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  Appropriate selection of the penalty parameter is crucial to obtaining good
performance from the Alternating Direction Method of Multipliers (ADMM). While
analytic results for optimal selection of this parameter are very limited,
there is a heuristic method that appears to be relatively successful in a
number of different problems. The contribution of this paper is to demonstrate
that their is a potentially serious flaw in this heuristic approach, and to
propose a modification that at least partially addresses it.
</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06209</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06214</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coverage Analysis for Low-Altitude UAV Networks in Urban Environments</dc:title>
 <dc:creator>Galkin, Boris</dc:creator>
 <dc:creator>Kibi&#x142;da, Jacek</dc:creator>
 <dc:creator>DaSilva, Luiz A.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Wireless access points on unmanned aerial vehicles (UAVs) are being
considered for mobile service provisioning in commercial networks. To be able
to efficiently use these devices in cellular networks it is necessary to first
have a qualitative and quantitative understanding of how their design
parameters reflect on the service quality experienced by the end user. In this
paper we set up a scenario where a network of UAVs operating at a certain
height above ground provide wireless service within coverage areas shaped by
their directional antennas. We provide an analytical expression for the
coverage probability experienced by a typical user as a function of the UAV
parameters.
</dc:description>
 <dc:description>Comment: Under Submission</dc:description>
 <dc:date>2017-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06214</dc:identifier>
 <dc:identifier>doi:10.1109/GLOCOM.2017.8254658</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06215</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Singleton Arc Consistency for CSPs Defined by Monotone Patterns</dc:title>
 <dc:creator>Carbonnel, Clement</dc:creator>
 <dc:creator>Cohen, David A.</dc:creator>
 <dc:creator>Cooper, Martin C.</dc:creator>
 <dc:creator>Zivny, Stanislav</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Singleton arc consistency is an important type of local consistency which has
been recently shown to solve all constraint satisfaction problems (CSPs) over
constraint languages of bounded width. We aim to characterise all classes of
CSPs defined by a forbidden pattern that are solved by singleton arc
consistency and closed under removing constraints. We identify five new
patterns whose absence ensures solvability by singleton arc consistency, four
of which are provably maximal and three of which generalise 2-SAT. Combined
with simple counter-examples for other patterns, we make significant progress
towards a complete classification.
</dc:description>
 <dc:description>Comment: v3: Full version of a STACS'18 paper. Improved presentation, a
  slightly different title</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06217</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinforcement Learning with External Knowledge and Two-Stage Q-functions
  for Predicting Popular Reddit Threads</dc:title>
 <dc:creator>He, Ji</dc:creator>
 <dc:creator>Ostendorf, Mari</dc:creator>
 <dc:creator>He, Xiaodong</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper addresses the problem of predicting popularity of comments in an
online discussion forum using reinforcement learning, particularly addressing
two challenges that arise from having natural language state and action spaces.
First, the state representation, which characterizes the history of comments
tracked in a discussion at a particular point, is augmented to incorporate the
global context represented by discussions on world events available in an
external knowledge source. Second, a two-stage Q-learning framework is
introduced, making it feasible to search the combinatorial action space while
also accounting for redundancy among sub-actions. We experiment with five
Reddit communities, showing that the two methods improve over previous reported
results on this task.
</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06217</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06221</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discrete configuration spaces of squares and hexagons</dc:title>
 <dc:creator>Alpert, Hannah</dc:creator>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05C85, 55R80, 68W10</dc:subject>
 <dc:description>  We consider generalizations of the familiar fifteen-piece sliding puzzle on
the 4 by 4 square grid. On larger grids with more pieces and more holes,
asymptotically how fast can we move the puzzle into the solved state? We also
give a variation with sliding hexagons. The square puzzles and the hexagon
puzzles are both discrete versions of configuration spaces of disks, which are
of interest in statistical mechanics and topological robotics. The
combinatorial theorems and proofs in this paper suggest followup questions in
both combinatorics and topology, and may turn out to be useful for proving
topological statements about configuration spaces.
</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06221</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06226</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modelling information manufacturing systems</dc:title>
 <dc:creator>Thi, Thanh Thoa Pham</dc:creator>
 <dc:creator>Helfert, Markus</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The manufacture of an information product (IP) is akin to the manufacture of
a physical product. Current approaches to model such information manufacturing
systems (IMS), lack the ability to systematically represent the dynamic changes
involved in manufacturing (or creating) an IP. They also have limitations to
consistently include aspects of process and information management at an
organizational level. This paper aims to address these limitations and presents
a modelling approach, the IASDO model. Our work also represents a framework to
evaluate the quality of the meta-models for IMS modelling which enable us to
compare the IASDO model with current approaches.
</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06226</dc:identifier>
 <dc:identifier>Int. J. Information Quality, Vol. 1, No. 1, 2007</dc:identifier>
 <dc:identifier>doi:10.1504/IJIQ.2007.013373</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06227</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovering Dynamic Integrity Rules with a Rules-Based Tool for Data
  Quality Analyzing</dc:title>
 <dc:creator>Thi, Thanh Thoa Pham</dc:creator>
 <dc:creator>Helfert, Markus</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Rules based approaches for data quality solutions often use business rules or
integrity rules for data monitoring purpose. Integrity rules are constraints on
data derived from business rules into a formal form in order to allow
computerization. One of challenges of these approaches is rules discovering,
which is usually manually made by business experts or system analysts based on
experiences. In this paper, we present our rule-based approach for data quality
analyzing, in which we discuss a comprehensive method for discovering dynamic
integrity rules.
</dc:description>
 <dc:description>Comment: International conference on Computer Systems and Technologies, 2010.
  6 pages</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06227</dc:identifier>
 <dc:identifier>doi:10.1145/1839379.1839396</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06228</identifier>
 <datestamp>2017-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal Action Detection with Structured Segment Networks</dc:title>
 <dc:creator>Zhao, Yue</dc:creator>
 <dc:creator>Xiong, Yuanjun</dc:creator>
 <dc:creator>Wang, Limin</dc:creator>
 <dc:creator>Wu, Zhirong</dc:creator>
 <dc:creator>Tang, Xiaoou</dc:creator>
 <dc:creator>Lin, Dahua</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Detecting actions in untrimmed videos is an important yet challenging task.
In this paper, we present the structured segment network (SSN), a novel
framework which models the temporal structure of each action instance via a
structured temporal pyramid. On top of the pyramid, we further introduce a
decomposed discriminative model comprising two classifiers, respectively for
classifying actions and determining completeness. This allows the framework to
effectively distinguish positive proposals from background or incomplete ones,
thus leading to both accurate recognition and localization. These components
are integrated into a unified network that can be efficiently trained in an
end-to-end fashion. Additionally, a simple yet effective temporal action
proposal scheme, dubbed temporal actionness grouping (TAG) is devised to
generate high quality action proposals. On two challenging benchmarks, THUMOS14
and ActivityNet, our method remarkably outperforms previous state-of-the-art
methods, demonstrating superior accuracy and strong adaptivity in handling
actions with various temporal structures.
</dc:description>
 <dc:description>Comment: To appear in ICCV2017. Code &amp; models available at
  http://yjxiong.me/others/ssn</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:date>2017-09-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06228</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06229</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovering Business Rules from Business Process Models</dc:title>
 <dc:creator>Thi, Thanh Thoa Pham</dc:creator>
 <dc:creator>Helfert, Markus</dc:creator>
 <dc:creator>Hossain, Fakir</dc:creator>
 <dc:creator>Dinh, Thang Le</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Discovering business rules from business process models are of advantage to
ensure the compliance of business processes with business rules. Furthermore it
provides the agility of business processes in case of business rules evolution.
Current approaches are limited on types of rules that can be discovered. This
paper analyses the expression power of some popular business process modelling
languages in embedding business rules in its presentation and provides
indicators to extract various types of business rules from business process
models.
</dc:description>
 <dc:description>Comment: International Conference on Computer Systems and Technologies -
  CompSysTech'11, 7 pages</dc:description>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06229</dc:identifier>
 <dc:identifier>doi:10.1145/2023607.2023652</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06241</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On monotone circuits with local oracles and clique lower bounds</dc:title>
 <dc:creator>Krajicek, Jan</dc:creator>
 <dc:creator>Oliveira, Igor C.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>68Q17</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We investigate monotone circuits with local oracles (K., 2016), i.e.,
circuits containing additional inputs $y_i = y_i(\vec{x})$ that can perform
unstructured computations on the input string $\vec{x}$. Let $\mu \in [0,1]$ be
the locality of the circuit, a parameter that bounds the combined strength of
the oracle functions $y_i(\vec{x})$, and $U_{n,k}, V_{n,k} \subseteq \{0,1\}^m$
be the classical sets of positive and negative inputs considered for $k$-clique
in the approximation method (Razborov, 1985). Our results can be informally
stated as follows.
  1. For an appropriate extension of depth-$2$ monotone circuits with local
oracles, we show that the size of the smallest circuits separating $U_{n,3}$
(triangles) and $V_{n,3}$ (complete bipartite graphs) undergoes two phase
transitions according to $\mu$.
  2. For $5 \leq k(n) \leq n^{1/4}$, arbitrary depth, and $\mu \leq 1/50$, we
prove that the monotone circuit size complexity of separating the sets
$U_{n,k}$ and $V_{n,k}$ is $n^{\Theta(\sqrt{k})}$, under a certain technical
assumption on the local oracle gates.
  The second result, which concerns monotone circuits with restricted oracles,
extends and provides a matching upper bound for the exponential lower bounds on
the monotone circuit size complexity of $k$-clique obtained by Alon and Boppana
(1987).
</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06241</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06244</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Large-Pose Face Frontalization in the Wild</dc:title>
 <dc:creator>Yin, Xi</dc:creator>
 <dc:creator>Yu, Xiang</dc:creator>
 <dc:creator>Sohn, Kihyuk</dc:creator>
 <dc:creator>Liu, Xiaoming</dc:creator>
 <dc:creator>Chandraker, Manmohan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Despite recent advances in face recognition using deep learning, severe
accuracy drops are observed for large pose variations in unconstrained
environments. Learning pose-invariant features is one solution, but needs
expensively labeled large-scale data and carefully designed feature learning
algorithms. In this work, we focus on frontalizing faces in the wild under
various head poses, including extreme profile views. We propose a novel deep 3D
Morphable Model (3DMM) conditioned Face Frontalization Generative Adversarial
Network (GAN), termed as FF-GAN, to generate neutral head pose face images. Our
framework differs from both traditional GANs and 3DMM based modeling.
Incorporating 3DMM into the GAN structure provides shape and appearance priors
for fast convergence with less training data, while also supporting end-to-end
training. The 3DMM-conditioned GAN employs not only the discriminator and
generator loss but also a new masked symmetry loss to retain visual quality
under occlusions, besides an identity loss to recover high frequency
information. Experiments on face recognition, landmark localization and 3D
reconstruction consistently show the advantage of our frontalization method on
faces in the wild datasets.
</dc:description>
 <dc:description>Comment: To appear at ICCV2017. Details refer to
  http://cvlab.cse.msu.edu/project-face-frontalization.html</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06244</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06254</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-view Supervision for Single-view Reconstruction via Differentiable
  Ray Consistency</dc:title>
 <dc:creator>Tulsiani, Shubham</dc:creator>
 <dc:creator>Zhou, Tinghui</dc:creator>
 <dc:creator>Efros, Alexei A.</dc:creator>
 <dc:creator>Malik, Jitendra</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We study the notion of consistency between a 3D shape and a 2D observation
and propose a differentiable formulation which allows computing gradients of
the 3D shape given an observation from an arbitrary view. We do so by
reformulating view consistency using a differentiable ray consistency (DRC)
term. We show that this formulation can be incorporated in a learning framework
to leverage different types of multi-view observations e.g. foreground masks,
depth, color images, semantics etc. as supervision for learning single-view 3D
prediction. We present empirical analysis of our technique in a controlled
setting. We also show that this approach allows us to improve over existing
techniques for single-view reconstruction of objects from the PASCAL VOC
dataset.
</dc:description>
 <dc:description>Comment: To appear at CVPR 2017. Project webpage :
  https://shubhtuls.github.io/drc/</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06254</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06256</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Wirtinger Flow for Phase Retrieval with Arbitrary Corruption</dc:title>
 <dc:creator>Chen, Jinghui</dc:creator>
 <dc:creator>Wang, Lingxiao</dc:creator>
 <dc:creator>Zhang, Xiao</dc:creator>
 <dc:creator>Gu, Quanquan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the robust phase retrieval problem of recovering the unknown
signal from the magnitude-only measurements, where the measurements can be
contaminated by both sparse arbitrary corruption and bounded random noise. We
propose a new nonconvex algorithm for robust phase retrieval, namely Robust
Wirtinger Flow to jointly estimate the unknown signal and the sparse
corruption. We show that our proposed algorithm is guaranteed to converge
linearly to the unknown true signal up to a minimax optimal statistical
precision in such a challenging setting. Compared with existing robust phase
retrieval methods, we achieve an optimal sample complexity of $O(n)$ in both
noisy and noise-free settings. Thorough experiments on both synthetic and real
datasets corroborate our theory.
</dc:description>
 <dc:description>Comment: 29 pages, 5 figures, 2 tables</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:date>2018-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06256</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06258</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving the Uncapacitated Single Allocation p-Hub Median Problem on GPU</dc:title>
 <dc:creator>Benaini, Abdelhamid</dc:creator>
 <dc:creator>Berrajaa, Achraf</dc:creator>
 <dc:creator>Boukachour, Jaouad</dc:creator>
 <dc:creator>Oudani, Mustapha</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  A parallel genetic algorithm (GA) implemented on GPU clusters is proposed to
solve the Uncapacitated Single Allocation p-Hub Median problem. The GA uses
binary and integer encoding and genetic operators adapted to this problem. Our
GA is improved by generated initial solution with hubs located at middle nodes.
The obtained experimental results are compared with the best known solutions on
all benchmarks on instances up to 1000 nodes. Furthermore, we solve our own
randomly generated instances up to 6000 nodes. Our approach outperforms most
well-known heuristics in terms of solution quality and time execution and it
allows hitherto unsolved problems to be solved.
</dc:description>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06258</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06259</identifier>
 <datestamp>2017-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Semantic QA-Based Approach for Text Summarization Evaluation</dc:title>
 <dc:creator>Chen, Ping</dc:creator>
 <dc:creator>Wu, Fei</dc:creator>
 <dc:creator>Wang, Tong</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Many Natural Language Processing and Computational Linguistics applications
involves the generation of new texts based on some existing texts, such as
summarization, text simplification and machine translation. However, there has
been a serious problem haunting these applications for decades, that is, how to
automatically and accurately assess quality of these applications. In this
paper, we will present some preliminary results on one especially useful and
challenging problem in NLP system evaluation: how to pinpoint content
differences of two text passages (especially for large pas-sages such as
articles and books). Our idea is intuitive and very different from existing
approaches. We treat one text passage as a small knowledge base, and ask it a
large number of questions to exhaustively identify all content points in it. By
comparing the correctly answered questions from two text passages, we will be
able to compare their content precisely. The experiment using 2007 DUC
summarization corpus clearly shows promising results.
</dc:description>
 <dc:date>2017-04-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06297</identifier>
 <datestamp>2017-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Time Hierarchy Theorem for the LOCAL Model</dc:title>
 <dc:creator>Chang, Yi-Jun</dc:creator>
 <dc:creator>Pettie, Seth</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The celebrated Time Hierarchy Theorem for Turing machines states, informally,
that more problems can be solved given more time. The extent to which a time
hierarchy-type theorem holds in the distributed LOCAL model has been open for
many years. It is consistent with previous results that all natural problems in
the LOCAL model can be classified according to a small constant number of
complexities, such as $O(1),O(\log^* n), O(\log n), 2^{O(\sqrt{\log n})}$, etc.
  In this paper we establish the first time hierarchy theorem for the LOCAL
model and prove that several gaps exist in the LOCAL time hierarchy.
  1. We define an infinite set of simple coloring problems called Hierarchical
$2\frac{1}{2}$-Coloring}. A correctly colored graph can be confirmed by simply
checking the neighborhood of each vertex, so this problem fits into the class
of locally checkable labeling (LCL) problems. However, the complexity of the
$k$-level Hierarchical $2\frac{1}{2}$-Coloring problem is $\Theta(n^{1/k})$,
for $k\in\mathbb{Z}^+$. The upper and lower bounds hold for both general graphs
and trees, and for both randomized and deterministic algorithms.
  2. Consider any LCL problem on bounded degree trees. We prove an
automatic-speedup theorem that states that any randomized $n^{o(1)}$-time
algorithm solving the LCL can be transformed into a deterministic $O(\log
n)$-time algorithm. Together with a previous result, this establishes that on
trees, there are no natural deterministic complexities in the ranges
$\omega(\log^* n)$---$o(\log n)$ or $\omega(\log n)$---$n^{o(1)}$.
  3. We expose a gap in the randomized time hierarchy on general graphs. Any
randomized algorithm that solves an LCL problem in sublogarithmic time can be
sped up to run in $O(T_{LLL})$ time, which is the complexity of the distributed
Lovasz local lemma problem, currently known to be $\Omega(\log\log n)$ and
$O(\log n)$.
</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06297</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06298</identifier>
 <datestamp>2017-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical Analysis of Time-Variant Channels in Diffusive Mobile
  Molecular Communications</dc:title>
 <dc:creator>Ahmadzadeh, Arman</dc:creator>
 <dc:creator>Jamali, Vahid</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  In this paper, we consider a diffusive mobile molecular communication (MC)
system consisting of a pair of mobile transmitter and receiver nano-machines
suspended in a fluid medium, where we model the mobility of the nano-machines
by Brownian motion. The transmitter and receiver nano-machines exchange
information via diffusive signaling molecules. Due to the random movements of
the transmitter and receiver nano-machines, the statistics of the channel
impulse response (CIR) change over time. We introduce a statistical framework
for characterization of the impulse response of time-variant MC channels. In
particular, we derive closed-form analytical expressions for the mean and the
autocorrelation function of the impulse response of the channel. Given the
autocorrelation function, we define the coherence time of the time-variant MC
channel as a metric that characterizes the variations of the impulse response.
Furthermore, we derive an analytical expression for evaluation of the expected
error probability of a simple detector for the considered system. In order to
investigate the impact of CIR decorrelation over time, we compare the
performances of a detector with perfect channel state information (CSI)
knowledge and a detector with outdated CSI knowledge. The accuracy of the
proposed analytical expression is verified via particle-based simulation of the
Brownian motion.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures, 1 table. Submitted to the 2017 IEEE Global
  Communications Conference (GLOBECOM), Communication Theory Symposium, on
  April 14, 2017</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06298</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06300</identifier>
 <datestamp>2017-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Reinforcement Learning Approach to Weaning of Mechanical Ventilation
  in Intensive Care Units</dc:title>
 <dc:creator>Prasad, Niranjani</dc:creator>
 <dc:creator>Cheng, Li-Fang</dc:creator>
 <dc:creator>Chivers, Corey</dc:creator>
 <dc:creator>Draugelis, Michael</dc:creator>
 <dc:creator>Engelhardt, Barbara E</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The management of invasive mechanical ventilation, and the regulation of
sedation and analgesia during ventilation, constitutes a major part of the care
of patients admitted to intensive care units. Both prolonged dependence on
mechanical ventilation and premature extubation are associated with increased
risk of complications and higher hospital costs, but clinical opinion on the
best protocol for weaning patients off of a ventilator varies. This work aims
to develop a decision support tool that uses available patient information to
predict time-to-extubation readiness and to recommend a personalized regime of
sedation dosage and ventilator support. To this end, we use off-policy
reinforcement learning algorithms to determine the best action at a given
patient state from sub-optimal historical ICU data. We compare treatment
policies from fitted Q-iteration with extremely randomized trees and with
feedforward neural networks, and demonstrate that the policies learnt show
promise in recommending weaning protocols with improved outcomes, in terms of
minimizing rates of reintubation and regulating physiological stability.
</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06300</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06302</identifier>
 <datestamp>2017-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quality of Service of an Asynchronous Crash-Recovery Leader Election
  Algorithm</dc:title>
 <dc:creator>Reis, Vin&#xed;cius A.</dc:creator>
 <dc:creator>Vieira, Gustavo M. D.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In asynchronous distributed systems it is very hard to assess if one of the
processes taking part in a computation is operating correctly or has failed. To
overcome this problem, distributed algorithms are created using unreliable
failure detectors that capture in an abstract way timing assumptions necessary
to assess the operating status of a process. One particular type of failure
detector is a leader election, that indicates a single process that has not
failed. The unreliability of these failure detectors means that they can make
mistakes, however if they are to be used in practice there must be limits to
the eventual behavior of these detectors. These limits are defined as the
quality of service (QoS) provided by the detector. Many works have tackled the
problem of creating failure detectors with predictable QoS, but only for
crash-stop processes and synchronous systems. This paper presents and analyzes
the behavior of a new leader election algorithm named NFD-L for the
asynchronous crash-recovery failure model that is efficient in terms of its use
of stable memory and message exchanges.
</dc:description>
 <dc:description>Comment: 14 pages, published in the Proc. of the 35th Brazilian Symposium on
  Computer Networks, Belem, Brazil, May 2017</dc:description>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1704.06302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<resumptionToken cursor="121000" completeListSize="155308">2369777|122001</resumptionToken>
</ListRecords>
</OAI-PMH>
