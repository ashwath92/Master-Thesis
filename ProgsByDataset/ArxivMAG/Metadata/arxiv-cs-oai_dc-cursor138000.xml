<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2018-01-29T03:39:25Z</responseDate>
<request verb="ListRecords" resumptionToken="2369777|138001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09722</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exhaustive Exploration of the Failure-oblivious Computing Search Space</dc:title>
 <dc:creator>Durieux, Thomas</dc:creator>
 <dc:creator>Hamadi, Youssef</dc:creator>
 <dc:creator>Yu, Zhongxing</dc:creator>
 <dc:creator>Monperrus, Martin</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  High-availability of software systems requires automated handling of crashes
in presence of errors. Failure-oblivious computing is one technique that aims
to achieve high availability. We note that failure-obliviousness has not been
studied in depth yet, and there is very few study that helps understand why
failure-oblivious techniques work. In order to make failure-oblivious computing
to have an impact in practice, we need to deeply understand failure-oblivious
behaviors in software. In this paper, we study, design and perform an
experiment that analyzes the size and the diversity of the failure-oblivious
behaviors. Our experiment consists of exhaustively computing the search space
of 16 field failures of large-scale open-source Java software. The outcome of
this experiment is a much better understanding of what really happens when
failure-oblivious computing is used, and this opens new promising research
directions.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1603.07631</dc:description>
 <dc:date>2017-10-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09722</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09738</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Chance-Constrained ADMM Approach for Decentralized Control of
  Distributed Energy Resources</dc:title>
 <dc:creator>Hassan, Ali</dc:creator>
 <dc:creator>Dvorkin, Yury</dc:creator>
 <dc:creator>Deka, Deepjyoti</dc:creator>
 <dc:creator>Chertkov, Michael</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Distribution systems are undergoing a dramatic transition from a passive
circuit that routinely disseminates electric power among downstream nodes to
the system with distributed energy resources. The distributed energy resources
come in a variety of technologies and typically include photovoltaic (PV)
arrays, thermostatically controlled loads, energy storage units. Often these
resources are interfaced with the system via inverters that can adjust active
and reactive power injections, thus supporting the operational performance of
the system. This paper designs a control policy for such inverters using the
local power flow measurements. The control actuates active and reactive power
injections of the inverter-based distributed energy resources. This strategy is
then incorporated into a chance-constrained, decentralized optimal power flow
formulation to maintain voltage levels and power flows within their limits and
to mitigate the volatility of (PV) resources.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09738</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09753</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impact of Coreference Resolution on Slot Filling</dc:title>
 <dc:creator>Adel, Heike</dc:creator>
 <dc:creator>Sch&#xfc;tze, Hinrich</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we demonstrate the importance of coreference resolution for
natural language processing on the example of the TAC Slot Filling shared task.
We illustrate the strengths and weaknesses of automatic coreference resolution
systems and provide experimental results to show that they improve performance
in the slot filling end-to-end setting. Finally, we publish KBPchains, a
resource containing automatically extracted coreference chains from the TAC
source corpus in order to support other researchers working on this topic.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09753</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09754</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time-Division Transmission is Optimal for Covert Communication over
  Broadcast Channels</dc:title>
 <dc:creator>Tan, Vincent Y. F.</dc:creator>
 <dc:creator>Lee, Si-Hyeon</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We consider a covert communication scenario where a legitimate transmitter
wishes to communicate simultaneously to two legitimate receivers while ensuring
that the communication is not detected by an adversary, also called the warden.
The legitimate receivers and the adversary observe the transmission from the
legitimate transmitter via a three-user discrete or Gaussian memoryless
broadcast channel. We focus on the case where the &quot;no-input&quot; symbol is not
redundant, i.e., the output distribution at the warden induced by the no-input
symbol is not a mixture of the output distributions induced by other input
symbols, so that the covert communication is governed by the square root law,
i.e., at most $\Theta(\sqrt{n})$ bits can be transmitted over $n$ channel uses.
We show that for such a setting of covert communication over broadcast
channels, a simple time-division strategy achieves the optimal throughputs. Our
result implies that a code that uses two separate optimal point-to-point codes
each designed for the constituent channels and each used for a fraction of the
time is optimal in the sense that it achieves the best constants of the
$\sqrt{n}$-scaling for the throughputs. Our proof strategy combines several
elements in the network information theory literature, including concave
envelope representations of the capacity regions of broadcast channels and El
Gamal's outer bound for more capable broadcast channels.
</dc:description>
 <dc:description>Comment: 12 pages, 2 figures</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09754</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09756</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Haskell: practical linearity in a higher-order polymorphic
  language</dc:title>
 <dc:creator>Bernardy, Jean-Philippe</dc:creator>
 <dc:creator>Boespflug, Mathieu</dc:creator>
 <dc:creator>Newton, Ryan R.</dc:creator>
 <dc:creator>Jones, Simon Peyton</dc:creator>
 <dc:creator>Spiwack, Arnaud</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Linear type systems have a long and storied history, but not a clear path
forward to integrate with existing languages such as OCaml or Haskell. In this
paper, we study a linear type system designed with two crucial properties in
mind: backwards-compatibility and code reuse across linear and non-linear users
of a library. Only then can the benefits of linear types permeate conventional
functional programming. Rather than bifurcate types into linear and non-linear
counterparts, we instead attach linearity to function arrows. Linear functions
can receive inputs from linearly-bound values, but can also operate over
unrestricted, regular values.
  To demonstrate the efficacy of our linear type system - both how easy it can
be integrated in an existing language implementation and how streamlined it
makes it to write programs with linear types - we implemented our type system
in GHC, the leading Haskell compiler, and demonstrate two kinds of applications
of linear types: mutable data with pure interfaces; and enforcing protocols in
I/O-performing functions.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09756</dc:identifier>
 <dc:identifier>doi:10.1145/3158093</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09757</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Spatial Regression Model for Image Crowd Counting</dc:title>
 <dc:creator>Yao, Haiyan</dc:creator>
 <dc:creator>Han, Kang</dc:creator>
 <dc:creator>Wan, Wanggen</dc:creator>
 <dc:creator>Hou, Li</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Computer vision techniques have been used to produce accurate and generic
crowd count estimators in recent years. Due to severe occlusions, appearance
variations, perspective distortions and illumination conditions, crowd counting
is a very challenging task. To this end, we propose a deep spatial regression
model(DSRM) for counting the number of individuals present in a still image
with arbitrary perspective and arbitrary resolution. Our proposed model is
based on Convolutional Neural Network (CNN) and long short term memory (LSTM).
First, we put the images into a pretrained CNN to extract a set of high-level
features. Then the features in adjacent regions are used to regress the local
counts with a LSTM structure which takes the spatial information into
consideration. The final global count is obtained by a sum of the local
patches. We apply our framework on several challenging crowd counting datasets,
and the experiment results illustrate that our method on the crowd counting and
density estimation problem outperforms state-of-the-art methods in terms of
reliability and effectiveness.
</dc:description>
 <dc:description>Comment: 15pages</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09757</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09762</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to Fool Radiologists with Generative Adversarial Networks? A Visual
  Turing Test for Lung Cancer Diagnosis</dc:title>
 <dc:creator>Chuquicusma, Maria J. M.</dc:creator>
 <dc:creator>Hussein, Sarfaraz</dc:creator>
 <dc:creator>Burt, Jeremy</dc:creator>
 <dc:creator>Bagci, Ulas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  Discriminating lung nodules as malignant or benign is still an underlying
challenge. To address this challenge, radiologists need computer aided
diagnosis (CAD) systems which can assist in learning discriminative imaging
features corresponding to malignant and benign nodules. However, learning
highly discriminative imaging features is an open problem. In this paper, our
aim is to learn the most discriminative features pertaining to lung nodules by
using an adversarial learning methodology. Specifically, we propose to use
unsupervised learning with Deep Convolutional-Generative Adversarial Networks
(DC-GANs) to generate lung nodule samples realistically. We hypothesize that
imaging features of lung nodules will be discriminative if it is hard to
differentiate them (fake) from real (true) nodules. To test this hypothesis, we
present Visual Turing tests to two radiologists in order to evaluate the
quality of the generated (fake) nodules. Extensive comparisons are performed in
discerning real, generated, benign, and malignant nodules. This experimental
set up allows us to validate the overall quality of the generated nodules,
which can then be used to (1) improve diagnostic decisions by mining highly
discriminative imaging features, (2) train radiologists for educational
purposes, and (3) generate realistic samples to train deep networks with big
data.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE International Symposium on
  Biomedical Imaging (ISBI) 2018</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:date>2018-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09762</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09764</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impact of Random Receiver Orientation on Visible Light Communications
  Channel</dc:title>
 <dc:creator>Eroglu, Yusuf Said</dc:creator>
 <dc:creator>Yapici, Yavuz</dc:creator>
 <dc:creator>Guvenc, Ismail</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Visible Light Communications (VLC) has been studied thoroughly in recent
years as an alternative or complementary technology to radio frequency
communications. The reliability of VLC channels highly depends on the
availability and alignment of line of sight links. In this work, we study the
effect of random receiver orientation for mobile users over VLC downlink
channels, which affects the existence of line of sight links and the receiver
field of view. Based on the statistics of vertical receiver orientation and
user mobility, we develop a unified analytical framework to characterize the
statistical distribution of VLC downlink channels, which is then utilized to
obtain the outage probability and the bit error rate. Our analysis is
generalized for arbitrary distributions of receiver orientation/location for a
single transmitter, and extended to multiple transmitter case for certain
scenarios. Extensive Monte Carlo simulations show a perfect match between the
analytical and the simulation data in terms of both the statistical channel
distribution and the resulting bit error rate. Our results also characterize
the channel attenuation due to random receiver orientation/location for various
scenarios of interest.
</dc:description>
 <dc:description>Comment: Submitted to IEEE JLT. Has been partially published in Proc. Asilomar
  Conf. Signals, Systems, and Computers, Nov. 2017</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09764</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09767</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Meta Learning Shared Hierarchies</dc:title>
 <dc:creator>Frans, Kevin</dc:creator>
 <dc:creator>Ho, Jonathan</dc:creator>
 <dc:creator>Chen, Xi</dc:creator>
 <dc:creator>Abbeel, Pieter</dc:creator>
 <dc:creator>Schulman, John</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We develop a metalearning approach for learning hierarchically structured
policies, improving sample efficiency on unseen tasks through the use of shared
primitives---policies that are executed for large numbers of timesteps.
Specifically, a set of primitives are shared within a distribution of tasks,
and are switched between by task-specific policies. We provide a concrete
metric for measuring the strength of such hierarchies, leading to an
optimization problem for quickly reaching high reward on unseen tasks. We then
present an algorithm to solve this problem end-to-end through the use of any
off-the-shelf reinforcement learning method, by repeatedly sampling new tasks
and resetting task-specific policies. We successfully discover meaningful motor
primitives for the directional movement of four-legged robots, solely by
interacting with distributions of mazes. We also demonstrate the
transferability of primitives to solve long-timescale sparse-reward obstacle
courses, and we enable 3D humanoid robots to robustly walk and crawl with the
same policy.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09767</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09779</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Multi-Modal Classification of Intraductal Papillary Mucinous
  Neoplasms (IPMN) with Canonical Correlation Analysis</dc:title>
 <dc:creator>Hussein, Sarfaraz</dc:creator>
 <dc:creator>Kandel, Pujan</dc:creator>
 <dc:creator>Corral, Juan E.</dc:creator>
 <dc:creator>Bolan, Candice W.</dc:creator>
 <dc:creator>Wallace, Michael B.</dc:creator>
 <dc:creator>Bagci, Ulas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Quantitative Biology - Tissues and Organs</dc:subject>
 <dc:description>  Pancreatic cancer has the poorest prognosis among all cancer types.
Intraductal Papillary Mucinous Neoplasms (IPMNs) are radiographically
identifiable precursors to pancreatic cancer; hence, early detection and
precise risk assessment of IPMN are vital. In this work, we propose a
Convolutional Neural Network (CNN) based computer aided diagnosis (CAD) system
to perform IPMN diagnosis and risk assessment by utilizing multi-modal MRI. In
our proposed approach, we use minimum and maximum intensity projections to ease
the annotation variations among different slices and type of MRIs. Then, we
present a CNN to obtain deep feature representation corresponding to each MRI
modality (T1-weighted and T2-weighted). At the final step, we employ canonical
correlation analysis (CCA) to perform a fusion operation at the feature level,
leading to discriminative canonical correlation features. Extracted features
are used for classification. Our results indicate significant improvements over
other potential approaches to solve this important problem. The proposed
approach doesn't require explicit sample balancing in cases of imbalance
between positive and negative examples. To the best of our knowledge, our study
is the first to automatically diagnose IPMN using multi-modal MRI.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE International Symposium on
  Biomedical Imaging (ISBI) 2018</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:date>2018-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09779</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09780</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interactions of Computational Complexity Theory and Mathematics</dc:title>
 <dc:creator>Wigderson, Avi</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  $ $[This paper is a (self contained) chapter in a new book, Mathematics and
Computation, whose draft is available on my homepage at
https://www.math.ias.edu/avi/book ].
  We survey some concrete interaction areas between computational complexity
theory and different fields of mathematics. We hope to demonstrate here that
hardly any area of modern mathematics is untouched by the computational
connection (which in some cases is completely natural and in others may seem
quite surprising). In my view, the breadth, depth, beauty and novelty of these
connections is inspiring, and speaks to a great potential of future
interactions (which indeed, are quickly expanding). We aim for variety. We give
short, simple descriptions (without proofs or much technical detail) of ideas,
motivations, results and connections; this will hopefully entice the reader to
dig deeper. Each vignette focuses only on a single topic within a large
mathematical filed. We cover the following:
  $\bullet$ Number Theory: Primality testing
  $\bullet$ Combinatorial Geometry: Point-line incidences
  $\bullet$ Operator Theory: The Kadison-Singer problem
  $\bullet$ Metric Geometry: Distortion of embeddings
  $\bullet$ Group Theory: Generation and random generation
  $\bullet$ Statistical Physics: Monte-Carlo Markov chains
  $\bullet$ Analysis and Probability: Noise stability
  $\bullet$ Lattice Theory: Short vectors
  $\bullet$ Invariant Theory: Actions on matrix tuples
</dc:description>
 <dc:description>Comment: 27 pages</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09780</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09786</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Offset-Based Beamforming: A New Approach to Robust Downlink Transmission</dc:title>
 <dc:creator>Medra, Mostafa</dc:creator>
 <dc:creator>Huang, Yongwei</dc:creator>
 <dc:creator>Davidson, Timothy N.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The design of a set of beamformers for the multiuser multiple-input
single-output (MISO) downlink that provides the receivers with prespecified
levels of quality-of-service (QoS) can be quite challenging when the channel
state information is not perfectly known at the base station. The constraint of
having the SINR meet or exceed a given threshold with high probability is
intractable in general, which results in problems that are fundamentally hard
to solve. In this paper, we will develop a high quality approximation of the
SINR outage constraint that, along with a semidefinite relaxation, enables us
to formulate the beamformer design problem as a convex optimization problem
that can be efficiently solved. For systems in which the uncertainty size is
small, a further approximation yields algorithms based on iterative evaluations
of closed-form expressions that have substantially lower computational cost.
Since finding the beamforming directions incurs most of the computational load
of these algorithms, analogous power loading algorithms for predefined
beamforming directions are developed and their performance is shown to be close
to optimal. When the system contains a large number of antennas, the proposed
power loading can be obtained at a computational cost that grows only linearly
in the number of antennas. The proposed power loading algorithm provides an
explicit relationship between the outage probability required and the power
consumed, which allows us to precisely control the power consumption, and
automatically identifies users who are consuming most of the power resources.
The flexibility of the proposed approach is illustrated by developing a power
loading technique that minimizes an average notion of outage.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09786</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09787</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Shrinkage of Singular Values Under Random Data Contamination</dc:title>
 <dc:creator>Barash, Danny</dc:creator>
 <dc:creator>Gavish, Matan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A low rank matrix X has been contaminated by uniformly distributed noise,
missing values, outliers and corrupt entries. Reconstruction of X from the
singular values and singular vectors of the contaminated matrix Y is a key
problem in machine learning, computer vision and data science. In this paper we
show that common contamination models (including arbitrary combinations of
uniform noise,missing values, outliers and corrupt entries) can be described
efficiently using a single framework. We develop an asymptotically optimal
algorithm that estimates X by manipulation of the singular values of Y , which
applies to any of the contamination models considered. Finally, we find an
explicit signal-to-noise cutoff, below which estimation of X from the singular
value decomposition of Y must fail, in a well-defined sense.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:date>2017-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09788</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FashionBrain Project: A Vision for Understanding Europe's Fashion Data
  Universe</dc:title>
 <dc:creator>Checco, Alessandro</dc:creator>
 <dc:creator>Demartini, Gianluca</dc:creator>
 <dc:creator>Loeser, Alexander</dc:creator>
 <dc:creator>Arous, Ines</dc:creator>
 <dc:creator>Khayati, Mourad</dc:creator>
 <dc:creator>Dantone, Matthias</dc:creator>
 <dc:creator>Koopmanschap, Richard</dc:creator>
 <dc:creator>Stalinov, Svetlin</dc:creator>
 <dc:creator>Kersten, Martin</dc:creator>
 <dc:creator>Zhang, Ying</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  A core business in the fashion industry is the understanding and prediction
of customer needs and trends. Search engines and social networks are at the
same time a fundamental bridge and a costly middleman between the customer's
purchase intention and the retailer. To better exploit Europe's distinctive
characteristics e.g., multiple languages, fashion and cultural differences, it
is pivotal to reduce retailers' dependence to search engines. This goal can be
achieved by harnessing various data channels (manufacturers and distribution
networks, online shops, large retailers, social media, market observers, call
centers, press/magazines etc.) that retailers can leverage in order to gain
more insight about potential buyers, and on the industry trends as a whole.
This can enable the creation of novel on-line shopping experiences, the
detection of influencers, and the prediction of upcoming fashion trends.
  In this paper, we provide an overview of the main research challenges and an
analysis of the most promising technological solutions that we are
investigating in the FashionBrain project.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09788</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09789</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating Password Advice</dc:title>
 <dc:creator>Murray, Hazel</dc:creator>
 <dc:creator>Malone, David</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Password advice is constantly circulated by standards agencies, companies,
websites and specialists. But there appears to be great diversity in terms of
the advice that is given. Users have noticed that different websites are
enforcing different restrictions. For example, requiring different combinations
of uppercase and lowercase letters, numbers and special characters. We
collected password advice and found that the advice distributed by one
organization can directly contradict advice given by another. Our paper aims to
illuminate interesting characteristics for a sample of the password advice
distributed. We also create a framework for identifying the costs associated
with implementing password advice. In doing so we identify a reason for why
password advice is often both derided and ignored.
</dc:description>
 <dc:description>Comment: 6 pages, 4 tables, 2 figures, conference paper</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09789</dc:identifier>
 <dc:identifier>Murray, H. and Malone, D., 2017, June. Evaluating password advice.
  In Signals and Systems Conference (ISSC), 2017 28th Irish (pp. 1-6). IEEE</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09795</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synchronization Strings: Explicit Constructions, Local Decoding, and
  Applications</dc:title>
 <dc:creator>Haeupler, Bernhard</dc:creator>
 <dc:creator>Shahrasbi, Amirbehshad</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  This paper gives new results for synchronization strings, a powerful
combinatorial object that allows to efficiently deal with insertions and
deletions in various communication settings:
  $\bullet$ We give a deterministic, linear time synchronization string
construction, improving over an $O(n^5)$ time randomized construction.
Independently of this work, a deterministic $O(n\log^2\log n)$ time
construction was just put on arXiv by Cheng, Li, and Wu. We also give a
deterministic linear time construction of an infinite synchronization string,
which was not known to be computable before. Both constructions are highly
explicit, i.e., the $i^{th}$ symbol can be computed in $O(\log i)$ time.
  $\bullet$ This paper also introduces a generalized notion we call
long-distance synchronization strings that allow for local and very fast
decoding. In particular, only $O(\log^3 n)$ time and access to logarithmically
many symbols is required to decode any index.
  We give several applications for these results:
  $\bullet$ For any $\delta&lt;1$ and $\epsilon&gt;0$ we provide an insdel correcting
code with rate $1-\delta-\epsilon$ which can correct any $O(\delta)$ fraction
of insdel errors in $O(n\log^3n)$ time. This near linear computational
efficiency is surprising given that we do not even know how to compute the
(edit) distance between the decoding input and output in sub-quadratic time. We
show that such codes can not only efficiently recover from $\delta$ fraction of
insdel errors but, similar to [Schulman, Zuckerman; TransInf'99], also from any
$O(\delta/\log n)$ fraction of block transpositions and replications.
  $\bullet$ We show that highly explicitness and local decoding allow for
infinite channel simulations with exponentially smaller memory and decoding
time requirements. These simulations can be used to give the first near linear
time interactive coding scheme for insdel errors.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09795</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09797</identifier>
 <datestamp>2017-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interference Queuing Networks on Grids</dc:title>
 <dc:creator>Sankararaman, Abishek</dc:creator>
 <dc:creator>Baccelli, Fran&#xe7;ois</dc:creator>
 <dc:creator>Foss, Sergey</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  Motivated by applications in large scale wireless networks, we introduce and
study queuing systems of interacting queues where the interactions mimic
wireless interference. Our network model is an abstraction of an ad-hoc
wireless network and is intended to capture the interplay between the geometry
of wireless links, which determine how the links interfere with each other, and
their temporal traffic dynamics. When a link accesses the spectrum, it causes
interference to other nearby links, and thus their rate of communication is
lowered. This in turn implies they access the spectrum longer and cause
interference to nearby links for a larger duration. This coupling between the
geometry and temporal dynamics is one of the main challenges in assessing the
performance of wireless systems. Most prior work have modeled this phenomenon
in a cellular network setting by generalizing the so called coupled processors
model. These models are difficult to analyze and even in the simplest case, and
one has to typically resort to bounds and approximations to derive insight. We
consider the ad-hoc network setting and propose a new model of queues, which
interact through interference. We show that this model is tractable, in the
sense we can compute certain performance metrics even when there is an infinite
number of queues. Specifically, we prove a stability phase-transition for such
queuing systems. Furthermore, we also derive exactly the mean number of
customers in any queue in steady state. Thanks to Little's Law, this also
yields an exact expression for mean delay of a typical link in steady state.
The key to our results is the analysis of certain Rate Conservation equations
along with monotonicity and tightness arguments, which are new and interesting
in their own right. Our model and results thus provide a basis to evaluate the
performance of various protocols on large networks.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09797</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09798</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lip2AudSpec: Speech reconstruction from silent lip movements video</dc:title>
 <dc:creator>Akbari, Hassan</dc:creator>
 <dc:creator>Arora, Himani</dc:creator>
 <dc:creator>Cao, Liangliang</dc:creator>
 <dc:creator>Mesgarani, Nima</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  In this study, we propose a deep neural network for reconstructing
intelligible speech from silent lip movement videos. We use auditory
spectrogram as spectral representation of speech and its corresponding sound
generation method resulting in a more natural sounding reconstructed speech.
Our proposed network consists of an autoencoder to extract bottleneck features
from the auditory spectrogram which is then used as target to our main lip
reading network comprising of CNN, LSTM and fully connected layers. Our
experiments show that the autoencoder is able to reconstruct the original
auditory spectrogram with a 98% correlation and also improves the quality of
reconstructed speech from the main lip reading network. Our model, trained
jointly on different speakers is able to extract individual speaker
characteristics and gives promising results of reconstructing intelligible
speech with superior word recognition accuracy.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09805</identifier>
 <datestamp>2017-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Negative Sampling for Word Representation using Self-embedded
  Features</dc:title>
 <dc:creator>Chen, Long</dc:creator>
 <dc:creator>Yuan, Fajie</dc:creator>
 <dc:creator>Jose, Joemon M.</dc:creator>
 <dc:creator>Zhang, Weinan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Although the word-popularity based negative sampler has shown superb
performance in the skip-gram model, the theoretical motivation behind
oversampling popular (non-observed) words as negative samples is still not well
understood. In this paper, we start from an investigation of the gradient
vanishing issue in the skip-gram model without a proper negative sampler. By
performing an insightful analysis from the stochastic gradient descent (SGD)
learning perspective, we demonstrate that, both theoretically and intuitively,
negative samples with larger inner product scores are more informative than
those with lower scores for the SGD learner in terms of both convergence rate
and accuracy. Understanding this, we propose an alternative sampling algorithm
that dynamically selects informative negative samples during each SGD update.
More importantly, the proposed sampler accounts for multi-dimensional
self-embedded features during the sampling process, which essentially makes it
more effective than the original popularity-based (one-dimensional) sampler.
Empirical experiments further verify our observations, and show that our
fine-grained samplers gain significant improvement over the existing ones
without increasing computational complexity.
</dc:description>
 <dc:description>Comment: Accepted in WSDM 2018</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:date>2017-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09805</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09806</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimum Circuit Size, Graph Isomorphism, and Related Problems</dc:title>
 <dc:creator>Allender, Eric</dc:creator>
 <dc:creator>Grochow, Joshua A.</dc:creator>
 <dc:creator>van Melkebeek, Dieter</dc:creator>
 <dc:creator>Moore, Cristopher</dc:creator>
 <dc:creator>Morgan, Andrew</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We study the computational power of deciding whether a given truth-table can
be described by a circuit of a given size (the Minimum Circuit Size Problem, or
MCSP for short), and of the variant denoted as MKTP where circuit size is
replaced by a polynomially-related Kolmogorov measure. All prior reductions
from supposedly-intractable problems to MCSP / MKTP hinged on the power of MCSP
/ MKTP to distinguish random distributions from distributions produced by
hardness-based pseudorandom generator constructions. We develop a fundamentally
different approach inspired by the well-known interactive proof system for the
complement of Graph Isomorphism (GI). It yields a randomized reduction with
zero-sided error from GI to MKTP. We generalize the result and show that GI can
be replaced by any isomorphism problem for which the underlying group satisfies
some elementary properties. Instantiations include Linear Code Equivalence,
Permutation Group Conjugacy, and Matrix Subspace Conjugacy. Along the way we
develop encodings of isomorphism classes that are efficiently decodable and
achieve compression that is at or near the information-theoretic optimum; those
encodings may be of independent interest.
</dc:description>
 <dc:description>Comment: 35 pages</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09806</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09809</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Screening Tests for LASSO</dc:title>
 <dc:creator>Herzet, C.</dc:creator>
 <dc:creator>Dr&#xe9;meau, A.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper focusses on &quot;safe&quot; screening techniques for the LASSO problem.
Motivated by the need for low-complexity algorithms, we propose a new approach,
dubbed &quot;joint&quot; screening test, allowing to screen a set of atoms by carrying
out one single test. The approach is particularized to two different sets of
atoms, respectively expressed as sphere and dome regions. After presenting the
mathematical derivations of the tests, we elaborate on their relative
effectiveness and discuss the practical use of such procedures.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09809</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09813</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Diffusion-Convolutional Neural Networks</dc:title>
 <dc:creator>Atwood, James</dc:creator>
 <dc:creator>Pal, Siddharth</dc:creator>
 <dc:creator>Towsley, Don</dc:creator>
 <dc:creator>Swami, Ananthram</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The predictive power and overall computational efficiency of
Diffusion-convolutional neural networks make them an attractive choice for node
classification tasks. However, a naive dense-tensor-based implementation of
DCNNs leads to $\mathcal{O}(N^2)$ memory complexity which is prohibitive for
large graphs. In this paper, we introduce a simple method for thresholding
input graphs that provably reduces memory requirements of DCNNs to O(N) (i.e.
linear in the number of nodes in the input) without significantly affecting
predictive performance.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09813</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09820</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spiking Optical Flow for Event-based Sensors Using IBM's TrueNorth
  Neurosynaptic System</dc:title>
 <dc:creator>Haessig, Germain</dc:creator>
 <dc:creator>Cassidy, Andrew</dc:creator>
 <dc:creator>Alvarez, Rodrigo</dc:creator>
 <dc:creator>Benosman, Ryad</dc:creator>
 <dc:creator>Orchard, Garrick</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper describes a fully spike-based neural network for optical flow
estimation from Dynamic Vision Sensor data. A low power embedded implementation
of the method which combines the Asynchronous Time-based Image Sensor with
IBM's TrueNorth Neurosynaptic System is presented. The sensor generates spikes
with sub-millisecond resolution in response to scene illumination changes.
These spike are processed by a spiking neural network running on TrueNorth with
a 1 millisecond resolution to accurately determine the order and time
difference of spikes from neighboring pixels, and therefore infer the velocity.
The spiking neural network is a variant of the Barlow Levick method for optical
flow estimation. The system is evaluated on two recordings for which ground
truth motion is available, and achieves an Average Endpoint Error of 11% at an
estimated power budget of under 80mW for the sensor and computation.
</dc:description>
 <dc:description>Comment: 11 pages, 11 figures without biography figures</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09820</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09824</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Klout Topics for Modeling Interests and Expertise of Users Across Social
  Networks</dc:title>
 <dc:creator>Ellinger, Sarah</dc:creator>
 <dc:creator>Bhattacharyya, Prantik</dc:creator>
 <dc:creator>Bhargava, Preeti</dc:creator>
 <dc:creator>Spasojevic, Nemanja</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  This paper presents Klout Topics, a lightweight ontology to describe social
media users' topics of interest and expertise. Klout Topics is designed to: be
human-readable and consumer-friendly; cover multiple domains of knowledge in
depth; and promote data extensibility via knowledge base entities. We discuss
why this ontology is well-suited for text labeling and interest modeling
applications, and how it compares to available alternatives. We show its
coverage against common social media interest sets, and examples of how it is
used to model the interests of over 780M social media users on Klout.com.
Finally, we open the ontology for external use.
</dc:description>
 <dc:description>Comment: 4 pages, 2 figures, 5 tables</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09824</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09825</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the role of synaptic stochasticity in training low-precision neural
  networks</dc:title>
 <dc:creator>Baldassi, Carlo</dc:creator>
 <dc:creator>Gerace, Federica</dc:creator>
 <dc:creator>Kappen, Hilbert J.</dc:creator>
 <dc:creator>Lucibello, Carlo</dc:creator>
 <dc:creator>Saglietti, Luca</dc:creator>
 <dc:creator>Tartaglione, Enzo</dc:creator>
 <dc:creator>Zecchina, Riccardo</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Stochasticity and limited precision of synaptic weights in neural network
models is a key aspect of both biological and hardware modeling of learning
processes. Here we show that a neural network model with stochastic binary
weights naturally gives prominence to exponentially rare dense regions of
solutions with a number of desirable properties such as robustness and good
generalization per- formance, while typical solutions are isolated and hard to
find. Binary solutions of the standard perceptron problem are obtained from a
simple gradient descent procedure on a set of real values parametrizing a
probability distribution over the binary synapses. Both analytical and
numerical results are presented. An algorithmic extension aimed at training
discrete deep neural networks is also investigated.
</dc:description>
 <dc:description>Comment: 6 pages + 10 pages of supplementary material</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09825</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09828</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gaussian Process Regression for Generalized Frequency Response Function
  Estimation</dc:title>
 <dc:creator>Stoddard, Jeremy</dc:creator>
 <dc:creator>Birpoutsoukis, Georgios</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Kernel-based modeling of dynamic systems has garnered a significant amount of
attention in the system identification literature since its introduction to the
field. While the method was originally applied to linear impulse response
estimation in the time domain, the concepts have since been extended to the
frequency domain for estimation of frequency response functions (FRFs), as well
as to the estimation of the Volterra series in time domain. In the latter case,
smoothness and exponential decay was imposed along the hypersurfaces of the
multidimensional impulse responses, allowing lower variance estimates than
could be obtained in a simple least squares framework. The Volterra series can
also be expressed in a frequency domain context, however there are several
competing representations which all possess some unique advantages. Perhaps the
most natural representation is the generalized frequency response function
(GFRF), which is defined as the multidimensional Fourier transform of the
corresponding Volterra kernel in the time-domain series. The representation
leads to a series of frequency domain functions with increasing dimension.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09828</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09829</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Routing Between Capsules</dc:title>
 <dc:creator>Sabour, Sara</dc:creator>
 <dc:creator>Frosst, Nicholas</dc:creator>
 <dc:creator>Hinton, Geoffrey E</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A capsule is a group of neurons whose activity vector represents the
instantiation parameters of a specific type of entity such as an object or an
object part. We use the length of the activity vector to represent the
probability that the entity exists and its orientation to represent the
instantiation parameters. Active capsules at one level make predictions, via
transformation matrices, for the instantiation parameters of higher-level
capsules. When multiple predictions agree, a higher level capsule becomes
active. We show that a discrimininatively trained, multi-layer capsule system
achieves state-of-the-art performance on MNIST and is considerably better than
a convolutional net at recognizing highly overlapping digits. To achieve these
results we use an iterative routing-by-agreement mechanism: A lower-level
capsule prefers to send its output to higher level capsules whose activity
vectors have a big scalar product with the prediction coming from the
lower-level capsule.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09829</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09834</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Illumination: Approximating Dynamic Global Illumination with
  Generative Adversarial Network</dc:title>
 <dc:creator>Thomas, Manu Mathew</dc:creator>
 <dc:creator>Forbes, Angus G.</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  We present Deep Illumination, a novel machine learning technique for
approximating global illumination (GI) in real-time applications using a
Conditional Generative Adversarial Network. Our primary focus is on generating
indirect illumination and soft shadows with offline rendering quality at
interactive rates. Inspired from recent advancement in image-to-image
translation problems using deep generative convolutional networks, we introduce
a variant of this network that learns a mapping from Gbuffers (depth map,
normal map, and diffuse map) and direct illumination to any global illumination
solution. Our primary contribution is showing that a generative model can be
used to learn a density estimation from screen space buffers to an advanced
illumination model for a 3D environment. Once trained, our network can
approximate global illumination for scene configurations it has never
encountered before within the environment it was trained on. We evaluate Deep
Illumination through a comparison with both a state of the art real-time GI
technique (VXGI) and an offline rendering GI technique (path tracing). We show
that our method produces effective GI approximations and is also
computationally cheaper than existing GI techniques. Our technique has the
potential to replace existing precomputed and screen-space techniques for
producing global illumination effects in dynamic scenes with physically-based
rendering quality.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09834</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09844</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Alone Together: Compositional Reasoning and Inference for Weak Isolation</dc:title>
 <dc:creator>Kaki, Gowtham</dc:creator>
 <dc:creator>Nagar, Kartik</dc:creator>
 <dc:creator>Nazafzadeh, Mahsa</dc:creator>
 <dc:creator>Jagannathan, Suresh</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Serializability is a well-understood correctness criterion that simplifies
reasoning about the behavior of concurrent transactions by ensuring they are
isolated from each other while they execute. However, enforcing serializable
isolation comes at a steep cost in performance and hence database systems in
practice support, and often encourage, developers to implement transactions
using weaker alternatives. Unfortunately, the semantics of weak isolation is
poorly understood, and usually explained only informally in terms of low-level
implementation artifacts. Consequently, verifying high-level correctness
properties in such environments remains a challenging problem.
  To address this issue, we present a novel program logic that enables
compositional reasoning about the behavior of concurrently executing
weakly-isolated transactions. Recognizing that the proof burden necessary to
use this logic may dissuade application developers, we also describe an
inference procedure based on this foundation that ascertains the weakest
isolation level that still guarantees the safety of high-level consistency
invariants associated with such transactions. The key to effective inference is
the observation that weakly-isolated transactions can be viewed as functional
(monadic) computations over an abstract database state, allowing us to treat
their operations as state transformers over the database. This interpretation
enables automated verification using off-the-shelf SMT solvers. Case studies
and experiments of real-world applications (written in an embedded DSL in
OCaml) demonstrate the utility of our approach.
</dc:description>
 <dc:description>Comment: 46 pages, 12 figures</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09844</dc:identifier>
 <dc:identifier>doi:10.1145/3158115</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09854</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gradient Sparsification for Communication-Efficient Distributed
  Optimization</dc:title>
 <dc:creator>Wangni, Jianqiao</dc:creator>
 <dc:creator>Wang, Jialei</dc:creator>
 <dc:creator>Liu, Ji</dc:creator>
 <dc:creator>Zhang, Tong</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Modern large scale machine learning applications require stochastic
optimization algorithms to be implemented on distributed computational
architectures. A key bottleneck is the communication overhead for exchanging
information such as stochastic gradients among different workers. In this
paper, to reduce the communication cost we propose a convex optimization
formulation to minimize the coding length of stochastic gradients. To solve the
optimal sparsification efficiently, several simple and fast algorithms are
proposed for approximate solution, with theoretical guaranteed for sparseness.
Experiments on $\ell_2$ regularized logistic regression, support vector
machines, and convolutional neural networks validate our sparsification
approaches.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09854</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09856</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Software Engineering Modeling Applied to English Verb Classification
  (and Poetry)</dc:title>
 <dc:creator>Al-Fedaghi, Sabah</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In requirements specification, software engineers create a textual
description of the envisioned system as well as develop conceptual models using
such tools as Universal Modeling Language (UML) and System Modeling Language
(SysML). One such tool, called FM, has recently been developed as an extension
of the INPUT-PROCESS-OUTPUT (IPO) model. IPO has been used extensively in many
interdisciplinary applications and is described as one of the most fundamental
and important of all descriptive tools. This paper is an attempt to
understanding the PROCESS in IPO. The fundamental way to describe PROCESS is in
verbs. This use of language has an important implication for systems modeling
since verbs express the vast range of actions and movements of all things. It
is clear that modeling needs to examine verbs. Accordingly, this paper involves
a study of English verbs as a bridge to learn about processes, not as
linguistic analysis but rather to reveal the semantics of processes,
particularly the five verbs that form the basis of FM states: create, process,
receive, release, and transfer. The paper focuses on verb classification, and
specifically on how to model the action of verbs diagrammatically. From the
linguistics point of view, according to some researchers, further exploration
of the notion of verb classes is needed for real-world tasks such as machine
translation, language generation, and document classification. Accordingly,
this non-linguistics study may benefit linguistics.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09856</dc:identifier>
 <dc:identifier>IJCSIS Vol. 15, No. 10, October 2017 International Journal of
  Computer Science and Information Security</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09859</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy Clustering</dc:title>
 <dc:creator>Fran&#xe7;a, Guilherme</dc:creator>
 <dc:creator>Vogelstein, Joshua T.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  Energy statistics was proposed by Sz\'{e}kely in the 80's inspired by the
Newtonian gravitational potential from classical mechanics, and it provides a
hypothesis test for equality of distributions. It was further generalized from
Euclidean spaces to metric spaces of strong negative type, and more recently, a
connection with reproducing kernel Hilbert spaces (RKHS) was established. Here
we consider the clustering problem from an energy statistics theory
perspective, providing a precise mathematical formulation yielding a
quadratically constrained quadratic program (QCQP) in the associated RKHS, thus
establishing the connection with kernel methods. We show that this QCQP is
equivalent to kernel $k$-means optimization problem once the kernel is fixed.
These results imply a first principles derivation of kernel $k$-means from
energy statistics. However, energy statistics fixes a family of standard
kernels. Furthermore, we also consider a weighted version of energy statistics,
making connection to graph partitioning problems. To find local optimizers of
such QCQP we propose an iterative algorithm based on Hartigan's method, which
in this case has the same computational cost as kernel $k$-means algorithm,
based on Lloyd's heuristic, but usually with better clustering quality. We
provide carefully designed numerical experiments showing the superiority of the
proposed method compared to kernel $k$-means, spectral clustering, standard
$k$-means, and Gaussian mixture models in a variety of settings.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09859</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09860</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DoShiCo: a Domain Shift Challenge for Control</dc:title>
 <dc:creator>Kelchtermans, Klaas</dc:creator>
 <dc:creator>Tuytelaars, Tinne</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Training deep neural control networks end-to-end for real-world applications
typically requires big demonstration datasets in the real world or big sets
consisting of a large variety of realistic and closely related 3D CAD models.
These real or virtual data should, moreover, have very similar characteristics
to the conditions expected at test time. These stringent requirements and the
time consuming data collection processes that they entail, are probably the
most important impediment that keeps deep neural policies from being deployed
in real-world applications. Therefore, in this work we advocate an alternative
approach, where instead of avoiding any domain shift by carefully selecting the
training data, the goal is to learn a policy that can cope with it. To this
end, we propose a new challenge: to train a model in very basic synthetic
environments, far from realistic, in a way that it can fly in more realistic
environments as well as take the control decisions on real-world data. We
collected a benchmark dataset and implemented a baseline method, exploiting
depth prediction as an auxiliary task to help overcome the domain shift. Even
though the policy is trained in very basic environments, it can learn to fly in
a very different realistic simulated environment. It is even capable to compete
and in some cases outperform a policy trained in the more realistic environment
when testing on real-world data.
</dc:description>
 <dc:description>Comment: Submitted for ICRA 2018. Please visit the paper webpage for more
  information, a movie and code for reproducing results:
  https://kkelchte.github.io/doshico</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09860</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09864</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recursive functions and existentially closed structures</dc:title>
 <dc:creator>Je&#x159;&#xe1;bek, Emil</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03C45, 03F25</dc:subject>
 <dc:description>  The purpose of this paper is to clarify the relationship between various
conditions implying essential undecidability: our main result is that there
exists a theory $T$ in which all partially recursive functions are
representable, yet $T$ does not interpret Robinson's theory $R$. To this end,
we borrow tools from model theory---specifically, we investigate
model-theoretic properties of the model completion of the empty theory in a
language with function symbols. We obtain a certain characterization of
$\exists\forall$ theories interpretable in existential theories in the process.
</dc:description>
 <dc:description>Comment: 42 pages</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09864</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09867</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Grounded Language Learning Agents</dc:title>
 <dc:creator>Hill, Felix</dc:creator>
 <dc:creator>Hermann, Karl Moritz</dc:creator>
 <dc:creator>Blunsom, Phil</dc:creator>
 <dc:creator>Clark, Stephen</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Neural network-based systems can now learn to locate the referents of words
and phrases in images, answer questions about visual scenes, and even execute
symbolic instructions as first-person actors in partially-observable worlds. To
achieve this so-called grounded language learning, models must overcome certain
well-studied learning challenges that are also fundamental to infants learning
their first words. While it is notable that models with no meaningful prior
knowledge overcome these learning obstacles, AI researchers and practitioners
currently lack a clear understanding of exactly how they do so. Here we address
this question as a way of achieving a clearer general understanding of grounded
language learning, both to inform future research and to improve confidence in
model predictions. For maximum control and generality, we focus on a simple
neural network-based language learning agent trained via policy-gradient
methods to interpret synthetic linguistic instructions in a simulated 3D world.
We apply experimental paradigms from developmental psychology to this agent,
exploring the conditions under which established human biases and learning
effects emerge. We further propose a novel way to visualise and analyse
semantic representation in grounded language learning agents that yields a
plausible computational account of the observed effects.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09867</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09868</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How far did we get in face spoofing detection?</dc:title>
 <dc:creator>Souza, Luiz</dc:creator>
 <dc:creator>Pamplona, Mauricio</dc:creator>
 <dc:creator>Oliveira, Luciano</dc:creator>
 <dc:creator>Papa, Jo&#xe3;o</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The growing use of control access systems based on face recognition shed
light over the need for even more accurate systems to detect face spoofing
attacks. In this paper, an extensive analysis on face spoofing detection works
published in the last decade is presented. The analyzed works are categorized
by their fundamental parts, i.e., descriptors and classifiers. This structured
survey also brings the temporal evolution of the face spoofing detection field,
as well as a comparative analysis of the works considering the most important
public data sets in the field. The methodology followed in this work is
particularly relevant to observe trends in the existing approaches, to discuss
still opened issues, and to propose new perspectives for the future of face
spoofing detection.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09868</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09869</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounds for traces of Hecke operators and applications to modular and
  elliptic curves over a finite field</dc:title>
 <dc:creator>Petrow, Ian</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>11F11, 11F25, 11G20, 11T71</dc:subject>
 <dc:description>  We give an upper bound for the trace of a Hecke operator acting on the space
of holomorphic cusp forms with respect to a congruence subgroup. Such an
estimate has applications to the analytic theory of elliptic curves over a
finite field, going beyond the Riemann hypothesis over finite fields. As the
main tool to prove our bound on traces of Hecke operators, we develop a
Petersson formula for newforms for general nebentype characters.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09869</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09871</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trajectory Deformations from Physical Human-Robot Interaction</dc:title>
 <dc:creator>Losey, Dylan P.</dc:creator>
 <dc:creator>O'Malley, Marcia K.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Robots are finding new applications where physical interaction with a human
is necessary: manufacturing, healthcare, and social tasks. Accordingly, the
field of physical human-robot interaction (pHRI) has leveraged impedance
control approaches, which support compliant interactions between human and
robot. However, a limitation of traditional impedance control is that---despite
provisions for the human to modify the robot's current trajectory---the human
cannot affect the robot's future desired trajectory through pHRI. In this
paper, we present an algorithm for physically interactive trajectory
deformations which, when combined with impedance control, allows the human to
modulate both the actual and desired trajectories of the robot. Unlike related
works, our method explicitly deforms the future desired trajectory based on
forces applied during pHRI, but does not require constant human guidance. We
present our approach and verify that this method is compatible with traditional
impedance control. Next, we use constrained optimization to derive the
deformation shape. Finally, we describe an algorithm for real time
implementation, and perform simulations to test the arbitration parameters.
Experimental results demonstrate reduction in the human's effort and
improvement in the movement quality when compared to pHRI with impedance
control alone.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09871</dc:identifier>
 <dc:identifier>doi:10.1109/TRO.2017.2765335</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09875</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase Transitions in Image Denoising via Sparsely Coding Convolutional
  Neural Networks</dc:title>
 <dc:creator>Carroll, Jacob</dc:creator>
 <dc:creator>Carlson, Nils</dc:creator>
 <dc:creator>Kenyon, Garrett T.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Neural networks are analogous in many ways to spin glasses, systems which are
known for their rich set of dynamics and equally complex phase diagrams. We
apply well-known techniques in the study of spin glasses to a convolutional
sparsely encoding neural network and observe power law finite-size scaling
behavior in the sparsity and reconstruction error as the network denoises
32$\times$32 RGB CIFAR-10 images. This finite-size scaling indicates the
presence of a continuous phase transition at a critical value of this sparsity.
By using the power law scaling relations inherent to finite-size scaling, we
can determine the optimal value of sparsity for any network size by tuning the
system to the critical point and operate the system at the minimum denoising
error.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures, submitted to NIPS 2017 workshop: Advances in
  Modeling and Learning Interactions from Complex Data</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09875</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09876</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing the Line Index of Balance Using Integer Programming
  Optimisation</dc:title>
 <dc:creator>Aref, Samin</dc:creator>
 <dc:creator>Mason, Andrew J.</dc:creator>
 <dc:creator>Wilson, Mark C.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>05C22, 15C22, 90C09, 90C11, 90C90, 90C35</dc:subject>
 <dc:description>  An important measure of a signed graph is the line index of balance which has
several applications in many fields. However, this graph-theoretic measure was
underused for decades because of the inherent complexity in its computation
which is closely related to solving NP-hard graph optimisation problems like
MAXCUT. We develop new quadratic and linear programming models to compute the
line index of balance exactly. Using the Gurobi integer programming
optimisation solver, we evaluate the line index of balance on real-world and
synthetic datasets. The synthetic data involves Erd\H{o}s-R\'enyi graphs,
Barab\'asi-Albert graphs, and specially structured random graphs. We also use
well known datasets from the sociology literature, such as signed graphs
inferred from students' choice and rejection as well as datasets from the
biology literature including gene regulatory networks. The results show that
exact values of the line index of balance in relatively large signed graphs can
be efficiently computed using our suggested optimisation models. We find that
most real-world social networks and some biological networks have small line
index of balance which indicates that they are close to balanced.
</dc:description>
 <dc:description>Comment: Accepted author copy, 21 pages, 5 tables and 3 figures. arXiv admin
  note: substantial text overlap with arXiv:1611.09030</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09876</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09879</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>StochSoCs: High performance biocomputing simulations for large scale
  Systems Biology</dc:title>
 <dc:creator>Manolakos, Elias S.</dc:creator>
 <dc:creator>Kouskoumvekakis, Elias</dc:creator>
 <dc:subject>Quantitative Biology - Molecular Networks</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  The stochastic simulation of large-scale biochemical reaction networks is of
great importance for systems biology since it enables the study of inherently
stochastic biological mechanisms at the whole cell scale. Stochastic Simulation
Algorithms (SSA) allow us to simulate the dynamic behavior of complex kinetic
models, but their high computational cost makes them very slow for many
realistic size problems. We present a pilot service, named WebStoch, developed
in the context of our StochSoCs research project, allowing life scientists with
no high-performance computing expertise to perform over the internet stochastic
simulations of large-scale biological network models described in the SBML
standard format. Biomodels submitted to the service are parsed automatically
and then placed for parallel execution on distributed worker nodes. The workers
are implemented using multi-core and many-core processors, or FPGA accelerators
that can handle the simulation of thousands of stochastic repetitions of
complex biomodels, with possibly thousands of reactions and interacting
species. Using benchmark LCSE biomodels, whose workload can be scaled on
demand, we demonstrate linear speedup and more than two orders of magnitude
higher throughput than existing serial simulators.
</dc:description>
 <dc:description>Comment: The 2017 International Conference on High Performance Computing &amp;
  Simulation (HPCS 2017), 8 pages</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09879</dc:identifier>
 <dc:identifier>doi:10.1109/HPCS.2017.156</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09884</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Quantum Stabilizer Codes derived from Local Frobenius Rings</dc:title>
 <dc:creator>Gluesing-Luerssen, Heide</dc:creator>
 <dc:creator>Pllaha, Tefjol</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Rings and Algebras</dc:subject>
 <dc:subject>94B05</dc:subject>
 <dc:description>  In this paper we consider stabilizer codes over local Frobenius rings. First,
we study the relative minimum distances of a stabilizer code and its reduction
onto the residue field. We show that for various scenarios, a free stabilizer
code over the ring does not underperform the according stabilizer code over the
field. This leads us to conjecture that the same is true for all free
stabilizer codes. Secondly, we focus on the isometries of stabilizer codes. We
present some preliminary results and introduce some interesting open problems.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09884</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09887</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Critical trees: counterexamples in model checking of CSM systems using
  CBS algorithm</dc:title>
 <dc:creator>Daszczuk, Wiktor B.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>68N30</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:description>  The important feature of temporal model checking is the generation of
counterexamples. In the report, the requirements for generation of
counterexample (called critical tree) in model checking of CSM systems are
described. The output of TempoRG model checker for QsCTL logic (a version of
CTL) is presented. A contradiction between counterexample generation and state
space reduction is commented.
</dc:description>
 <dc:description>Comment: 20 pages, 12 figures</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09887</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09897</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Global analysis of a geometric PDAV controller by means of
  coordinate-free linearization</dc:title>
 <dc:creator>Ramp, Michalis</dc:creator>
 <dc:creator>Papadopoulos, Evangelos</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  Tracking a desired Pointing Direction and simultaneously obtaining a
reference Angular Velocity (PDAV) around the pointing direction constitutes a
very involved and complicated motion encountered in a variaty of robotic,
industrial and military applications. In this paper through the utilization of
global analysis and simulation techniques, the smooth closed-loop vector fields
induced by the geometric PDAV controller from [1], are visualized to gain a
deeper understanding of its global stabilization properties. First through the
calculation of a coordinate-free form of the closed-loop linearized dynamics,
the local stability of each equilibrium of the system is analyzed. The results
acquired by means of eigenstructure analysis, are used in predicting the
frequency of complex precession/nutation oscillations that arise during PDAV
trajectory tracking; an important tool in actuator selection. Finally, by
utilizing variational integration schemes, the flow converging to the desired
equilibrium and the flow &quot;close&quot; to the stable manifold of the saddle
equilibrium of the closed-loop system is visualized and analyzed. Results offer
intimate knowledge of the closed-loop vector fields bestowing to the control
engineer the ability to anticipate and/or have a rough estimate of the
evolution of the solutions.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09897</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09901</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Crowdsourced Classification with a Reject Option in the Presence
  of Spammers</dc:title>
 <dc:creator>Li, Qunwei</dc:creator>
 <dc:creator>Varshney, Pramod K.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We explore the design of an effective crowdsourcing system for an $M$-ary
classification task. Crowd workers complete simple binary microtasks whose
results are aggregated to give the final decision. We consider the scenario
where the workers have a reject option so that they are allowed to skip
microtasks when they are unable to or choose not to respond to binary
microtasks. We present an aggregation approach using a weighted majority voting
rule, where each worker's response is assigned an optimized weight to maximize
crowd's classification performance.
</dc:description>
 <dc:description>Comment: submitted to ICASSP 2018</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09901</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09912</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Orthogonal Precoding for Ultra Reliable Wireless Communication Links</dc:title>
 <dc:creator>Zemen, Thomas</dc:creator>
 <dc:creator>Hofer, Markus</dc:creator>
 <dc:creator>Loeschenbrand, David</dc:creator>
 <dc:creator>Pacher, Christoph</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  All diversity sources of a wireless communication channel must be utilized to
enable ultra-reliable wireless communication links. Hadani et al. propose the
two dimensional discrete symplectic Fourier transform (DSFT) as orthogonal
pre-coder for orthogonal frequency division multiplexing (OFDM) in time- and
frequency-selective channels. In this paper we investigate general orthogonal
precoding (OP) and develop a low-complexity iterative channel estimation and
(near) maximum likelihood detection algorithm using soft-symbol feedback. We
present a general but compact framework to analyze the performance of OP and
its ability to utilize time- and frequency-diversity. We are able to proof that
all constant modulus sequences, e.g. such as the DSFT or Walsh-Hadamard
sequences, lead to the same performance for OP. Our OP receiver is tested by
numerical link level simulation for the DSFT, two dimensional discrete prolate
spheroidal sequences, and Walsh-Hadamard sequences. We demonstrate that our
receiver achieves a gain of about $4.8\,\text{dB}$ for a bit error rate of
$10^{-4}$ compared to OFDM for a relative velocity of $0\ldots200\,\text{km/h}$
for the exemplary use-case of a vehicle-to-vehicle communication link.
</dc:description>
 <dc:description>Comment: 23 pages, 6 figures, submitted to IEEE Transactions on Wireless
  Communications</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09912</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09916</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-Complexity Equalization for Orthogonal Time and Frequency Signaling
  (OTFS)</dc:title>
 <dc:creator>Zemen, Thomas</dc:creator>
 <dc:creator>Hofer, Markus</dc:creator>
 <dc:creator>Loeschenbrand, David</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Recently, a new precoding technique called orthogonal time-frequency
signaling (OTFS) has been proposed for time- and frequency-selective
communication channels. OTFS precodes a data frame with a complete set of
spreading sequences and transmits the results via orthogonal frequency division
multiplexing (OFDM). OTFS uses two dimensional (2D) linear spreading sequences
in time and frequency which are the basis functions of a symplectic Fourier
transform. OTFS allows the utilization of time- and frequency-diversity but
requires maximum likelihood decoding to achieve full diversity. In this paper
we show performance results of a low-complexity equalizer using soft-symbol
feedback for interference cancellation after an initial minimum-mean square
error equalization step. Performance results for an implementation in the
delay-Doppler domain and in the time-frequency domain are compared. With our
equalizer, OTFS achieves a gain of 5dB compared to OFDM for a bit error rate of
$10^{-4}$ and a velocity of $200\,\text{km/h}$.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures, submitted to IEEE 18th International Workshop on
  Signal Processing Advances in Wireless Communications (WCNC), Barcelona,
  Spain, April 2018</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09916</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09918</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EduCTX: A blockchain-based higher education credit platform</dc:title>
 <dc:creator>Turkanovi&#x107;, Muhamed</dc:creator>
 <dc:creator>H&#xf6;lbl, Marko</dc:creator>
 <dc:creator>Ko&#x161;i&#x10d;, Kristjan</dc:creator>
 <dc:creator>Heri&#x10d;ko, Marjan</dc:creator>
 <dc:creator>Kami&#x161;ali&#x107;, Aida</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Blockchain technology enables the creation of a decentralized environment
where transactions and data are not under the control of any third party
organization. Any transaction ever completed is recorded in a public ledger in
a verifiable and permanent way. Based on blockchain technology, we propose a
global higher education credit platform, named EduCTX. This platform is based
on the concept of the European Credit Transfer and Accumulation System (ECTS).
It constitutes a globally trusted, decentralized higher education credit and
grading system that can offer a globally unified viewpoint for students and
higher education institutions (HEIs), as well as for other potential
stakeholders such as companies, institutions, and organizations. As a proof of
concept, we present a prototype implementation of the environment, based on the
open-source Ark Blockchain Platform. Based on a globally distributed
peer-to-peer network, EduCTX will process, manage and control ECTX tokens,
which represent credits that students gain for completed courses such as ECTS.
HEIs are the peers of the blockchain network. The platform is a first step
towards a more transparent and technologically advanced form of higher
education systems. The EduCTX platform represents the basis of the EduCTX
initiative which anticipates that various HEIs would join forces in order to
create a globally efficient, simplified and ubiquitous environment in order to
avoid language and administrative barriers. Therefore we invite and encourage
HEIs to join the EduCTX initiative and the EduCTX blockchain network.
</dc:description>
 <dc:description>Comment: 20 pages, 6 figures</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09918</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09919</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>JND-Based Perceptual Video Coding for 4:4:4 Screen Content Data in HEVC</dc:title>
 <dc:creator>Prangnell, Lee</dc:creator>
 <dc:creator>Sanchez, Victor</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  The JCT-VC standardized Screen Content Coding (SCC) extension in the HEVC HM
RExt + SCM reference codec offers an impressive coding efficiency performance
when compared with HM RExt alone; however, it is not significantly perceptually
optimized. For instance, it does not include advanced HVS-based perceptual
coding methods, such as JND-based spatiotemporal masking schemes. In this
paper, we propose a novel JND-based perceptual video coding technique for HM
RExt + SCM. The proposed method is designed to further improve the compression
performance of HM RExt + SCM when applied to YCbCr 4:4:4 SC video data. In the
proposed technique, luminance masking and chrominance masking are exploited to
perceptually adjust the Quantization Step Size (QStep) at the Coding Block (CB)
level. Compared with HM RExt 16.10 + SCM 8.0, the proposed method considerably
reduces bitrates (Kbps), with a maximum reduction of 48.3%. In addition to
this, the subjective evaluations reveal that SC-PAQ achieves visually lossless
coding at very low bitrates.
</dc:description>
 <dc:description>Comment: Preprint: 2018 IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP 2018)</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09919</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09921</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Commutativity For Practical Fast Replication</dc:title>
 <dc:creator>Park, Seo Jin</dc:creator>
 <dc:creator>Ousterhout, John</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  Traditional approaches to replication require client requests to be ordered
before making them durable by copying them to replicas. As a result, clients
must wait for two round-trip times (RTTs) before updates complete. In this
paper, we show that this entanglement of ordering and durability is unnecessary
for strong consistency. Consistent Unordered Replication Protocol (CURP) allows
clients to replicate requests that have not yet been ordered, as long as they
are commutative. This strategy allows most operations to complete in 1 RTT (the
same as an unreplicated system). We implemented CURP in the Redis and RAMCloud
storage systems. In RAMCloud, CURP improved write latency by ~2x (13.8 us -&gt;
7.3 us) and write throughput by 4x. Compared to unreplicated RAMCloud, CURP's
latency overhead for 3-way replication is just 0.4 us (6.9 us vs 7.3 us). CURP
transformed a non-durable Redis cache into a consistent and durable storage
system with only a small performance overhead.
</dc:description>
 <dc:description>Comment: 16 pages, 13 figures</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09921</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09924</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Ensemble Control of Loads in Distribution Grids with Network
  Constraints</dc:title>
 <dc:creator>Chertkov, Michael</dc:creator>
 <dc:creator>Deka, Deepjyoti</dc:creator>
 <dc:creator>Dvorkin, Yury</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Flexible loads, e.g. thermostatically controlled loads (TCLs), are
technically feasible to participate in demand response (DR) programs. On the
other hand, there is a number of challenges that need to be resolved before it
can be implemented in practice en masse. First, individual TCLs must be
aggregated and operated in sync to scale DR benefits. Second, the uncertainty
of TCLs needs to be accounted for. Third, exercising the flexibility of TCLs
needs to be coordinated with distribution system operations to avoid
unnecessary power losses and compliance with power flow and voltage limits.
This paper addresses these challenges.
  We propose a network-constrained, open-loop, stochastic optimal control
formulation. The first part of this formulation represents ensembles of
collocated TCLs modeled by an aggregated Markov Process (MP), where each MP
state is associated with a given power consumption or production level. The
second part extends MPs to a multi-period distribution power flow optimization.
In this optimization, the control of TCL ensembles is regulated by transition
probability matrices and physically enabled by local active and reactive power
controls at TCL locations. The optimization is solved with a Spatio-Temporal
Dual Decomposition (ST-D2) algorithm. The performance of the proposed
formulation and algorithm is demonstrated on the IEEE 33-bus distribution
model.
</dc:description>
 <dc:description>Comment: 7 pages, 6 figures, submitted to PSCC 2018</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09924</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09926</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Compression: Sparse Coding vs. Bottleneck Autoencoders</dc:title>
 <dc:creator>Watkins, Yijing</dc:creator>
 <dc:creator>Sayeh, Mohammad</dc:creator>
 <dc:creator>Iaroshenko, Oleksandr</dc:creator>
 <dc:creator>Kenyon, Garrett</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Bottleneck autoencoders have been actively researched as a solution to image
compression tasks. However, we observed that bottleneck autoencoders produce
subjectively low quality reconstructed images. In this work, we explore the
ability of sparse coding to improve reconstructed image quality for the same
degree of compression. We observe that sparse image compression produces
visually superior reconstructed images and yields higher values of pixel-wise
measures of reconstruction quality (PSNR and SSIM) compared to bottleneck
autoencoders. % In addition, we find that using alternative metrics that
correlate better with human perception, such as feature perceptual loss and the
classification accuracy, sparse image compression scores up to 18.06\% and
2.7\% higher, respectively, compared to bottleneck autoencoders. Although
computationally much more intensive, we find that sparse coding is otherwise
superior to bottleneck autoencoders for the same degree of compression.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09926</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09932</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A polynomial time algorithm to compute geodesics in CAT(0) cubical
  complexes</dc:title>
 <dc:creator>Hayashi, Koyo</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:description>  This paper presents the first polynomial time algorithm to compute geodesics
in a CAT(0) cubical complex in general dimension. The algorithm is a simple
iterative method to update breakpoints of a path joining two points using Owen
and Provan's algorithm (2011) as a subroutine. Our algorithm is applicable to
any CAT(0) space in which geodesics between two close points can be computed,
not limited to CAT(0) cubical complexes.
</dc:description>
 <dc:description>Comment: 17 pages</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09932</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09933</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SEGMENT3D: A Web-based Application for Collaborative Segmentation of 3D
  images used in the Shoot Apical Meristem</dc:title>
 <dc:creator>Spina, Thiago V.</dc:creator>
 <dc:creator>Stegmaier, Johannes</dc:creator>
 <dc:creator>Falc&#xe3;o, Alexandre X.</dc:creator>
 <dc:creator>Meyerowitz, Elliot</dc:creator>
 <dc:creator>Cunha, Alexandre</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The quantitative analysis of 3D confocal microscopy images of the shoot
apical meristem helps understanding the growth process of some plants. Cell
segmentation in these images is crucial for computational plant analysis and
many automated methods have been proposed. However, variations in signal
intensity across the image mitigate the effectiveness of those approaches with
no easy way for user correction. We propose a web-based collaborative 3D image
segmentation application, SEGMENT3D, to leverage automatic segmentation
results. The image is divided into 3D tiles that can be either segmented
interactively from scratch or corrected from a pre-existing segmentation.
Individual segmentation results per tile are then automatically merged via
consensus analysis and then stitched to complete the segmentation for the
entire image stack. SEGMENT3D is a comprehensive application that can be
applied to other 3D imaging modalities and general objects. It also provides an
easy way to create supervised data to advance segmentation using machine
learning models.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09933</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09934</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data-driven Feature Sampling for Deep Hyperspectral Classification and
  Segmentation</dc:title>
 <dc:creator>Severa, William M.</dc:creator>
 <dc:creator>Timlin, Jerilyn A.</dc:creator>
 <dc:creator>Kholwadwala, Suraj</dc:creator>
 <dc:creator>James, Conrad D.</dc:creator>
 <dc:creator>Aimone, James B.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>68T01</dc:subject>
 <dc:subject>I.2.1</dc:subject>
 <dc:subject>I.4.6</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:description>  The high dimensionality of hyperspectral imaging forces unique challenges in
scope, size and processing requirements. Motivated by the potential for an
in-the-field cell sorting detector, we examine a $\textit{Synechocystis sp.}$
PCC 6803 dataset wherein cells are grown alternatively in nitrogen rich or
deplete cultures. We use deep learning techniques to both successfully classify
cells and generate a mask segmenting the cells/condition from the background.
Further, we use the classification accuracy to guide a data-driven, iterative
feature selection method, allowing the design neural networks requiring 90%
fewer input features with little accuracy degradation.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09934</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09942</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CANDiS: Coupled &amp; Attention-Driven Neural Distant Supervision</dc:title>
 <dc:creator>Nagarajan, Tushar</dc:creator>
 <dc:creator>Sharmistha</dc:creator>
 <dc:creator>Talukdar, Partha</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Distant Supervision for Relation Extraction uses heuristically aligned text
data with an existing knowledge base as training data. The unsupervised nature
of this technique allows it to scale to web-scale relation extraction tasks, at
the expense of noise in the training data. Previous work has explored
relationships among instances of the same entity-pair to reduce this noise, but
relationships among instances across entity-pairs have not been fully
exploited. We explore the use of inter-instance couplings based on verb-phrase
and entity type similarities. We propose a novel technique, CANDiS, which casts
distant supervision using inter-instance coupling into an end-to-end neural
network model. CANDiS incorporates an attention module at the instance-level to
model the multi-instance nature of this problem. CANDiS outperforms existing
state-of-the-art techniques on a standard benchmark dataset.
</dc:description>
 <dc:description>Comment: WiNLP 2017</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09942</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09951</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Couplings for Probabilistic Reasoning</dc:title>
 <dc:creator>Hsu, Justin</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  This thesis explores proofs by coupling from the perspective of formal
verification. Long employed in probability theory and theoretical computer
science, these proofs construct couplings between the output distributions of
two probabilistic processes. Couplings can imply various guarantees comparing
two runs of a probabilistic computation. We first show that proofs in the
program logic pRHL describe couplings. We formalize couplings that establish
various probabilistic properties, including distribution equivalence,
convergence, and stochastic domination. Then we give a proofs-as-programs
interpretation: a coupling proof encodes a probabilistic product program, whose
properties imply relational properties of the original programs. We design the
logic xpRHL to construct the product, with extensions to model shift coupling
and path coupling. We then propose an approximate version of probabilistic
coupling and a corresponding proof technique---proof by approximate
coupling---inspired by the logic apRHL, a version of pRHL for building
approximate liftings. Drawing on ideas from existing privacy proofs, we extend
apRHL with novel proof rules for constructing new approximate couplings. We
give an approximate coupling proof of privacy for the Sparse Vector mechanism,
a well-known algorithm from the privacy literature whose privacy proof is
notoriously subtle, and produce the first formalized proof of privacy for
Sparse Vector in apRHL. Finally, we propose several more sophisticated
constructions for approximate couplings: a principle for showing
accuracy-dependent privacy, a generalization of the advanced composition
theorem, and an optimal approximate coupling relating two subsets. We also show
equivalences between our approximate couplings and other existing definitions.
These ingredients support the first formalized proof of privacy for the Between
Thresholds mechanism.
</dc:description>
 <dc:description>Comment: PhD thesis, University of Pennsylvania, 2017</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09951</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09952</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhancements of linked data expressiveness for ontologies</dc:title>
 <dc:creator>Fabbri, Renato</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The semantic web has received many contributions of researchers as ontologies
which, in this context, i.e. within RDF linked data, are formalized
conceptualizations that might use different protocols, such as RDFS, OWL DL and
OWL FULL. In this article, we describe new expressive techniques which were
found necessary after elaborating dozens of OWL ontologies for the scientific
academy, the State and the civil society. They consist in: 1) stating possible
uses a property might have without incurring into axioms or restrictions; 2)
assigning a level of priority for an element (class, property, triple); 3)
correct depiction in diagrams of relations between classes, between individuals
which are imperative, and between individuals which are optional; 4) a
convenient association between OWL classes and SKOS concepts. We propose
specific rules to accomplish these enhancements and exemplify both its use and
the difficulties that arise because these techniques are currently not
established as standards to the ontology designer.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09952</dc:identifier>
 <dc:identifier>Anais do XX ENMC - Encontro Nacional de Modelagem Computacional e
  VIII ECTM - Encontro de Ci\^encias e Tecnologia de Materiais, Nova Friburgo,
  RJ - 16 a 19 Outubro 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09953</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Error Probability of Random Fourier Features is Dimensionality
  Independent</dc:title>
 <dc:creator>Honorio, Jean</dc:creator>
 <dc:creator>Li, Yu-Jun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We show that the error probability of reconstructing kernel matrices from
Random Fourier Features for any shift-invariant kernel function is at most
$\mathcal{O}(\exp(-D))$, where $D$ is the number of random features. We also
provide a matching information-theoretic method-independent lower bound of
$\Omega(\exp(-D))$ for standard Gaussian distributions. Compared to prior work,
we are the first to show that the error probability for random Fourier features
is independent of the dimensionality of data points as well as the size of
their domain. As applications of our theory, we obtain dimension-independent
bounds for kernel ridge regression and support vector machines.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09953</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09954</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Audiovisual Analytics Vocabulary and Ontology (AAVO): initial core and
  example expansion</dc:title>
 <dc:creator>Fabbri, Renato</dc:creator>
 <dc:creator>de Oliveira, Maria Cristina Ferreira</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Visual Analytics might be defined as data mining assisted by interactive
visual interfaces. The field has been receiving prominent consideration by
researchers, developers and the industry. The literature, however, is complex
because it involves multiple fields of knowledge and is considerably recent. In
this article we describe an initial tentative organization of the knowledge in
the field as an OWL ontology and a SKOS vocabulary. This effort might be useful
in many ways that include conceptual considerations and software
implementations. Within the results and discussions, we expose a core and an
example expansion of the conceptualization, and incorporate design issues that
enhance the expressive power of the abstraction.
</dc:description>
 <dc:description>Comment: Scripts in https://github.com/ttm/aavo/</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09954</dc:identifier>
 <dc:identifier>Anais do XX ENMC - Encontro Nacional de Modelagem Computacional e
  VIII ECTM - Encontro de Ci\^encias e Tecnologia de Materiais, Nova Friburgo,
  RJ - 16 a 19 Outubro 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09961</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Edge-Based Wedge Sampling to Estimate Triangle Counts in Very Large
  Graphs</dc:title>
 <dc:creator>T&#xfc;rko&#x11f;lu, Duru</dc:creator>
 <dc:creator>Turk, Ata</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The number of triangles in a graph is useful to deduce a plethora of
important features of the network that the graph is modeling. However, finding
the exact value of this number is computationally expensive. Hence, a number of
approximation algorithms based on random sampling of edges, or wedges (adjacent
edge pairs) have been proposed for estimating this value. We argue that for
large sparse graphs with power-law degree distribution, random edge sampling
requires sampling large number of edges before providing enough information for
accurate estimation, and existing wedge sampling methods lead to biased
samplings, which in turn lead to less accurate estimations. In this paper, we
propose a hybrid algorithm between edge and wedge sampling that addresses the
deficiencies of both approaches. We start with uniform edge sampling and then
extend each selected edge to form a wedge that is more informative for
estimating the overall triangle count. The core estimate we make is the number
of triangles each sampled edge in the first phase participates in. This
approach provides accurate approximations with very small sampling ratios,
outperforming the state-of-the-art up to 8 times in sample size while providing
estimations with 95% confidence.
</dc:description>
 <dc:description>Comment: ICDM 2017, 10 pages</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09961</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09967</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Deep Learning by Inverse Square Root Linear Units (ISRLUs)</dc:title>
 <dc:creator>Carlile, Brad</dc:creator>
 <dc:creator>Delamarter, Guy</dc:creator>
 <dc:creator>Kinney, Paul</dc:creator>
 <dc:creator>Marti, Akiko</dc:creator>
 <dc:creator>Whitney, Brian</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce the &quot;inverse square root linear unit&quot; (ISRLU) to speed up
learning in deep neural networks. ISRLU has better performance than ELU but has
many of the same benefits. ISRLU and ELU have similar curves and
characteristics. Both have negative values, allowing them to push mean unit
activation closer to zero, and bring the normal gradient closer to the unit
natural gradient, ensuring a noise-robust deactivation state, lessening the
over fitting risk. The significant performance advantage of ISRLU on
traditional CPUs also carry over to more efficient HW implementations on HW/SW
codesign for CNNs/RNNs. In experiments with TensorFlow, ISRLU leads to faster
learning and better generalization than ReLU on CNNs. This work also suggests a
computationally efficient variant called the &quot;inverse square root unit&quot; (ISRU)
which can be used for RNNs. Many RNNs use either long short-term memory (LSTM)
and gated recurrent units (GRU) which are implemented with tanh and sigmoid
activation functions. ISRU has less com- putational complexity but still has a
similar curve to tanh and sigmoid.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures, 5 tables</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09967</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09968</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Espresso: Brewing Java For More Non-Volatility with Non-volatile Memory</dc:title>
 <dc:creator>Wu, Mingyu</dc:creator>
 <dc:creator>Zhao, Ziming</dc:creator>
 <dc:creator>Li, Haoyu</dc:creator>
 <dc:creator>Li, Heting</dc:creator>
 <dc:creator>Chen, Haibo</dc:creator>
 <dc:creator>Zang, Binyu</dc:creator>
 <dc:creator>Guan, Haibing</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Fast, byte-addressable non-volatile memory (NVM) embraces both near-DRAM
latency and disk-like persistence, which has generated considerable interests
to revolutionize system software stack and programming models. However, it is
less understood how NVM can be combined with managed runtime like Java virtual
machine (JVM) to ease persistence management. This paper proposes Espresso, a
holistic extension to Java and its runtime, to enable Java programmers to
exploit NVM for persistence management with high performance. Espresso first
provides a general persistent heap design called Persistent Java Heap (PJH) to
manage persistent data as normal Java objects. The heap is then strengthened
with a recoverable mechanism to provide crash consistency for heap metadata. It
then provides a new abstraction called Persistent Java Object (PJO) to provide
an easy-to-use but safe persistent programming model for programmers to persist
application data. The evaluation confirms that Espresso significantly
outperforms state-of-art NVM support for Java (i.e., JPA and PCJ) while being
compatible to existing data structures in Java programs.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09968</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09972</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse recovery using the preservability of the null space property
  under random measurements</dc:title>
 <dc:creator>Casazza, Pete</dc:creator>
 <dc:creator>Chen, Xuemei</dc:creator>
 <dc:creator>Lynch, Richard</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:description>  The field of compressed sensing has become a major tool in high-dimensional
analysis, with the realization that vectors can be recovered from relatively
very few linear measurements as long as the vectors lie in a low-dimensional
structure, typically the vectors that are zero in most coordinates with respect
to a basis. However, there are many applications where we instead want to
recover vectors that are sparse not with respect to a basis, but rather to a
general dictionary. That is, the vector can be written as the linear
combination of very few columns of a matrix $\mathbf{D}$, where the columns of
$\mathbf{D}$ form a (typically overcomplete) spanning set.
  In this direction, we show that as an matrix $\mathbf{D}$ stays bounded away
from zero in norm on a set $S$ and a provided map ${\boldsymbol \Phi}$
comprised of i.i.d. subgaussian rows has number of measurements at least
proportional to the square of $w(\mathbf{D}S)$, the Gaussian width of the
related set $\mathbf{D}S$, then with high probability the composition
${\boldsymbol \Phi} \mathbf{D}$ also stays bounded away from zero in norm on
$S$ with bound proportional to $w(\mathbf{D}S)$. This result has potential as a
powerful tool in dimension reduction analysis. As a specific application, we
obtain that the null space property is preserved under such subgaussian maps
with high probability. This result is nearly optimal in the sense that we
require only a minimal condition on $\mathbf{D}$. Consequently we obtain stable
recovery guarantees for dictionary-sparse signals via the $\ell_1$-synthesis
method, which is typically challenging, even with random measurements.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09972</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09975</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Single-Channel Architecture for Algebraic Integer Based 8$\times$8 2-D
  DCT Computation</dc:title>
 <dc:creator>Edirisuriya, A.</dc:creator>
 <dc:creator>Madanayake, A.</dc:creator>
 <dc:creator>Cintra, R. J.</dc:creator>
 <dc:creator>Dimitrov, V. S.</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  An area efficient row-parallel architecture is proposed for the real-time
implementation of bivariate algebraic integer (AI) encoded 2-D discrete cosine
transform (DCT) for image and video processing. The proposed architecture
computes 8$\times$8 2-D DCT transform based on the Arai DCT algorithm. An
improved fast algorithm for AI based 1-D DCT computation is proposed along with
a single channel 2-D DCT architecture. The design improves on the 4-channel AI
DCT architecture that was published recently by reducing the number of integer
channels to one and the number of 8-point 1-D DCT cores from 5 down to 2. The
architecture offers exact computation of 8$\times$8 blocks of the 2-D DCT
coefficients up to the FRS, which converts the coefficients from the AI
representation to fixed-point format using the method of expansion factors.
Prototype circuits corresponding to FRS blocks based on two expansion factors
are realized, tested, and verified on FPGA-chip, using a Xilinx Virtex-6
XC6VLX240T device. Post place-and-route results show a 20% reduction in terms
of area compared to the 2-D DCT architecture requiring five 1-D AI cores. The
area-time and area-time${}^2$ complexity metrics are also reduced by 23% and
22% respectively for designs with 8-bit input word length. The digital
realizations are simulated up to place and route for ASICs using 45 nm CMOS
standard cells. The maximum estimated clock rate is 951 MHz for the CMOS
realizations indicating 7.608$\cdot$10$^9$ pixels/seconds and a 8$\times$8
block rate of 118.875 MHz.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures, 5 tables</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09975</dc:identifier>
 <dc:identifier>IEEE Transactions on Circuits and Systems for Video Technology,
  volume 23, number 12, pages 2083-2089, Dec. 2013</dc:identifier>
 <dc:identifier>doi:10.1109/TCSVT.2013.2270397</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09979</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Conjugate Gradient Algorithm with Variance Reduction</dc:title>
 <dc:creator>Jin, Xiao-Bo</dc:creator>
 <dc:creator>Zhang, Xu-Yao</dc:creator>
 <dc:creator>Huang, Kaizhu</dc:creator>
 <dc:creator>Geng, Guang-Gang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Conjugate gradient methods are a class of important methods for solving
linear equations and nonlinear optimization. In our work, we propose a new
stochastic conjugate gradient algorithm with variance reduction (CGVR) and
prove its linear convergence with the Fletcher and Revves method for strongly
convex and smooth functions. We experimentally demonstrate that the CGVR
algorithm converges faster than its counterparts for six large-scale
optimization problems that may be convex, non-convex or non-smooth, and its AUC
(Area Under Curve) performance with $L2$-regularized $L2$-loss is comparable to
that of LIBLINEAR but with significant improvement in computational efficiency.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures, submmited to IEEE TRANSACTIONS ON NEURAL
  NETWORKS AND LEARNING SYSTEMS</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09979</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09980</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Watching Videos with Certain and Constant Quality: PID-based Quality
  Control Method</dc:title>
 <dc:creator>Song, Yuhang</dc:creator>
 <dc:creator>Xu, Mai</dc:creator>
 <dc:creator>Li, Shengxi</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  In video coding, compressed videos with certain and constant quality can
ensure quality of experience (QoE). To this end, we propose in this paper a
novel PID-based quality control (PQC) method for video coding. Specifically, a
formulation is modelled to control quality of video coding with two objectives:
minimizing control error and quality fluctuation. Then, we apply the Laplace
domain analysis to model the relationship between quantization parameter (QP)
and control error in this formulation. Given the relationship between QP and
control error, we propose a solution to the PQC formulation, such that videos
can be compressed at certain and constant quality. Finally, experimental
results show that our PQC method is effective in both control accuracy and
quality fluctuation.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09980</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09983</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing Caching Policy at Base Stations by Exploiting User Preference
  and Spatial Locality</dc:title>
 <dc:creator>Liu, Dong</dc:creator>
 <dc:creator>Yang, Chenyang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Most prior works of proactive caching at wireless edge optimize caching
policies under the following assumptions: the preference of each user is
identical to content popularity, all users request contents with the same
active level and at uniformly-distributed locations. In this paper, we
investigate what happens without these assumptions. To this end, we establish a
framework to optimize caching policy at base stations exploiting user
preference, active level, and spatial locality. We obtain optimal caching
policy to minimize the weighted sum of the file download time averaged over all
file requests and user locations in the network (reflecting network
performance) and the maximal weighted download time averaged over possible file
requests and locations of each user (reflecting user fairness). To investigate
how user preference similarity and active level skewness affect the optimal
caching policy, we then provide a method to synthesize user preference for
given content popularity and user active level. The analysis and simulation
results show that exploiting user preference can improve both network
performance and user fairness remarkably compared with priori works. The gain
of exploiting user preference increases with user preference heterogeneity,
user spatial locality, and skewness of user active level.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09983</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09985</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Acoustic Landmarks Contain More Information About the Phone String than
  Other Frames</dc:title>
 <dc:creator>He, Di</dc:creator>
 <dc:creator>Lim, Boon Pang</dc:creator>
 <dc:creator>Yang, Xuesong</dc:creator>
 <dc:creator>Hasegawa-Johnson, Mark</dc:creator>
 <dc:creator>Chen, Deming</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Most mainstream Automatic Speech Recognition (ASR) systems consider all
feature frames equally important. However, acoustic landmark theory is based on
a contradictory idea, that some frames are more important than others. Acoustic
landmark theory exploits the quantal nonlinear articulatory-acoustic
relationships from human speech perception experiments, and provides
theoretical support for extracting acoustic features in the vicinity of
landmark regions where an abrupt change occurs in the spectrum of speech
signals. In this work, we conduct experiments on the TIMIT corpus, with both
GMM and DNN based ASR systems and found that frames containing landmarks are
more informative than others. We found that altering the level of emphasis on
landmarks through accordingly re-weighting acoustic likelihood in frames, tends
to reduce the phone error rate (PER). Furthermore, by leveraging the landmark
as a heuristic, one of our hybrid DNN frame dropping strategies maintained a
PER within 0.44% of optimal when scoring less than half (41.2% to be precise)
of the frames. This hybrid strategy out-performs other non-heuristicbased
methods and demonstrates the potential of landmarks for reducing computation.
</dc:description>
 <dc:description>Comment: The article has been submitted to Journal of the Acoustical Society
  of America</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09985</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09988</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variance Reduced Value Iteration and Faster Algorithms for Solving
  Markov Decision Processes</dc:title>
 <dc:creator>Sidford, Aaron</dc:creator>
 <dc:creator>Wang, Mengdi</dc:creator>
 <dc:creator>Wu, Xian</dc:creator>
 <dc:creator>Ye, Yinyu</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper we provide faster algorithms for approximately solving
discounted Markov Decision Processes in multiple parameter regimes. Given a
discounted Markov Decision Process (DMDP) with $|S|$ states, $|A|$ actions,
discount factor $\gamma\in(0,1)$, and rewards in the range $[-M, M]$, we show
how to compute an $\epsilon$-optimal policy, with probability $1 - \delta$ in
time \[ \tilde{O} \left( \left(|S|^2 |A| + \frac{|S| |A|}{(1 - \gamma)^3}
\right)
  \log\left( \frac{M}{\epsilon} \right) \log\left( \frac{1}{\delta} \right)
\right) \] This contribution reflects the first nearly linear time, nearly
linearly convergent algorithm for solving DMDP's for intermediate values of
$\gamma$.
  We also show how to obtain improved sublinear time algorithms and provide an
algorithm which computes an $\epsilon$-optimal policy with probability $1 -
\delta$ in time
  \[ \tilde{O} \left(\frac{|S| |A| M^2}{(1 - \gamma)^4 \epsilon^2} \log
\left(\frac{1}{\delta}\right) \right)
  \] provided we can sample from the transition function in $O(1)$ time.
  Interestingly, we obtain our results by a careful modification of approximate
value iteration. We show how to combine classic approximate value iteration
analysis with new techniques in variance reduction. Our fastest algorithms
leverage further insights to ensure that our algorithms make monotonic progress
towards the optimal value. This paper is one of few instances in using sampling
to obtain a linearly convergent linear programming algorithm and we hope that
the analysis may be useful more broadly.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09988</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09990</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Near-Optimal Straggler Mitigation for Distributed Gradient Methods</dc:title>
 <dc:creator>Li, Songze</dc:creator>
 <dc:creator>Kalan, Seyed Mohammadreza Mousavi</dc:creator>
 <dc:creator>Avestimehr, A. Salman</dc:creator>
 <dc:creator>Soltanolkotabi, Mahdi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Modern learning algorithms use gradient descent updates to train inferential
models that best explain data. Scaling these approaches to massive data sizes
requires proper distributed gradient descent schemes where distributed worker
nodes compute partial gradients based on their partial and local data sets, and
send the results to a master node where all the computations are aggregated
into a full gradient and the learning model is updated. However, a major
performance bottleneck that arises is that some of the worker nodes may run
slow. These nodes a.k.a. stragglers can significantly slow down computation as
the slowest node may dictate the overall computational time. We propose a
distributed computing scheme, called Batched Coupon's Collector (BCC) to
alleviate the effect of stragglers in gradient methods. We prove that our BCC
scheme is robust to a near optimal number of random stragglers. We also
empirically demonstrate that our proposed BCC scheme reduces the run-time by up
to 85.4% over Amazon EC2 clusters when compared with other straggler mitigation
strategies. We also generalize the proposed BCC scheme to minimize the
completion time when implementing gradient descent-based algorithms over
heterogeneous worker nodes.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09990</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09995</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance optimizations for scalable CFD applications on hybrid
  CPU+MIC heterogeneous computing system with millions of cores</dc:title>
 <dc:creator>Wang, Yong-Xian</dc:creator>
 <dc:creator>Zhang, Li-Lun</dc:creator>
 <dc:creator>Liu, Wei</dc:creator>
 <dc:creator>Cheng, Xing-Hua</dc:creator>
 <dc:creator>Zhuang, Yu</dc:creator>
 <dc:creator>Chronopoulos, Anthony T.</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  For computational fluid dynamics (CFD) applications with a large number of
grid points/cells, parallel computing is a common efficient strategy to reduce
the computational time. How to achieve the best performance in the modern
supercomputer system, especially with heterogeneous computing resources such as
hybrid CPU+GPU, or a CPU + Intel Xeon Phi (MIC) co-processors, is still a great
challenge.
  An in-house parallel CFD code capable of simulating three dimensional
structured grid applications is developed and tested in this study. Several
methods of parallelization, performance optimization and code tuning both in
the CPU-only homogeneous system and in the heterogeneous system are proposed
based on identifying potential parallelism of applications, balancing the work
load among all kinds of computing devices, tuning the multi-thread code toward
better performance in intra-machine node with hundreds of CPU/MIC cores, and
optimizing the communication among inter-nodes, inter-cores, and between CPUs
and MICs.
  Some benchmark cases from model and/or industrial CFD applications are tested
on the Tianhe-1A and Tianhe-2 supercomputer to evaluate the performance. Among
these CFD cases, the maximum number of grid cells reached 780 billion. The
tuned solver successfully scales up to half of the entire Tianhe-2
supercomputer system with over 1.376 million of heterogeneous cores. The test
results and performance analysis are discussed in detail.
</dc:description>
 <dc:description>Comment: 12pages, 12 figures</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.09995</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10000</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PoseTrack: A Benchmark for Human Pose Estimation and Tracking</dc:title>
 <dc:creator>Andriluka, Mykhaylo</dc:creator>
 <dc:creator>Iqbal, Umar</dc:creator>
 <dc:creator>Milan, Anton</dc:creator>
 <dc:creator>Insafutdinov, Eldar</dc:creator>
 <dc:creator>Pishchulin, Leonid</dc:creator>
 <dc:creator>Gall, Juergen</dc:creator>
 <dc:creator>Schiele, Bernt</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Human poses and motions are important cues for analysis of videos with people
and there is strong evidence that representations based on body pose are highly
effective for a variety of tasks such as activity recognition, content
retrieval and social signal processing. In this work, we aim to further advance
the state of the art by establishing &quot;PoseTrack&quot; , a new large-scale benchmark
for video-based human pose estimation and articulated tracking, and bringing
together the community of researchers working on visual human analysis. The
benchmark encompasses three competition tracks focusing on i) single-frame
multi-person pose estimation, ii) multi-person pose estimation in videos, and
iii) multi-person articulated tracking. To facilitate the benchmark and
challenge we collect, annotate and release a new %large-scale benchmark dataset
that features videos with multiple people labeled with person tracks and
articulated pose. A centralized evaluation server is provided to allow
participants to evaluate on a held-out test set. We envision that the proposed
benchmark will stimulate productive research both by providing a large and
representative training dataset as well as providing a platform to objectively
evaluate and compare the proposed methods. The benchmark is freely accessible
at https://posetrack.net.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10001</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flexible Multi-Group Single-Carrier Modulation: Optimal Subcarrier
  Grouping and Rate Maximization</dc:title>
 <dc:creator>Yang, Yifei</dc:creator>
 <dc:creator>Zhang, Shuowen</dc:creator>
 <dc:creator>Lie, Joni Polili</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Orthogonal frequency division multiplexing (OFDM) and single-carrier
frequency domain equalization (SC-FDE) are two commonly adopted modulation
schemes for frequency-selective channels. Compared to SC-FDE, OFDM generally
achieves higher data rate, but at the cost of higher transmit signal
peak-to-average power ratio (PAPR) that leads to lower power amplifier
efficiency. This paper proposes a new modulation scheme, called flexible
multi-group single-carrier (FMG-SC), which encapsulates both OFDM and SC-FDE as
special cases, thus achieving more flexible rate-PAPR trade-offs between them.
Specifically, a set of frequency subcarriers are flexibly divided into
orthogonal groups based on their channel gains, and SC-FDE is applied over each
of the groups to send different data streams in parallel. We aim to maximize
the achievable sum-rate of all groups by optimizing the subcarrier-group
mapping. We propose two low-complexity subcarrier grouping methods and show via
simulation that they perform very close to the optimal grouping by exhaustive
search. Simulation results also show the effectiveness of the proposed FMG-SC
modulation scheme with optimized subcarrier grouping in improving the rate-PAPR
trade-off over conventional OFDM and SC-FDE.
</dc:description>
 <dc:description>Comment: Submitted for possible conference publication</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10002</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online linear optimization with the log-determinant regularizer</dc:title>
 <dc:creator>Moridomi, Ken-ichiro</dc:creator>
 <dc:creator>Hatano, Kohei</dc:creator>
 <dc:creator>Takimoto, Eiji</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider online linear optimization over symmetric positive semi-definite
matrices, which has various applications including the online collaborative
filtering. The problem is formulated as a repeated game between the algorithm
and the adversary, where in each round t the algorithm and the adversary choose
matrices X_t and L_t, respectively, and then the algorithm suffers a loss given
by the Frobenius inner product of X_t and L_t. The goal of the algorithm is to
minimize the cumulative loss. We can employ a standard framework called Follow
the Regularized Leader (FTRL) for designing algorithms, where we need to choose
an appropriate regularization function to obtain a good performance guarantee.
We show that the log-determinant regularization works better than other popular
regularization functions in the case where the loss matrices L_t are all
sparse. Using this property, we show that our algorithm achieves an optimal
performance guarantee for the online collaborative filtering. The technical
contribution of the paper is to develop a new technique of deriving performance
bounds by exploiting the property of strong convexity of the log-determinant
with respect to the loss matrices, while in the previous analysis the strong
convexity is defined with respect to a norm. Intuitively, skipping the norm
analysis results in the improved bound. Moreover, we apply our method to online
linear optimization over vectors and show that the FTRL with the Burg entropy
regularizer, which is the analogue of the log-determinant regularizer in the
vector case, works well.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10003</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deterministic Approximate Methods for Maximum Consensus Robust Fitting</dc:title>
 <dc:creator>Le, Huu</dc:creator>
 <dc:creator>Chin, Tat-Jun</dc:creator>
 <dc:creator>Eriksson, Anders</dc:creator>
 <dc:creator>Suter, David</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Maximum consensus estimation plays a critically important role in robust
fitting problems in computer vision. Currently, the most prevalent algorithms
for consensus maximization draw from the class of randomized
hypothesize-and-verify algorithms, which are cheap but can usually deliver only
rough approximate solutions. On the other extreme, there are exact algorithms
which are exhaustive search in nature and can be costly for practical-sized
inputs. This paper fills the gap between the two extremes by proposing
deterministic algorithms to approximately optimize the maximum consensus
criterion. Our work begins by reformulating consensus maximization with linear
complementarity constraints. Then, we develop two novel algorithms: one based
on non-smooth penalty method with a Frank-Wolfe style optimization scheme, the
other based on the Alternating Direction Method of Multipliers (ADMM). Both
algorithms solve convex subproblems to efficiently perform the optimization. We
demonstrate the capability of our algorithms to greatly improve a rough initial
estimate, such as those obtained using least squares or a randomized algorithm.
Compared to the exact algorithms, our approach is much more practical on
realistic input sizes. Further, our approach is naturally applicable to
estimation problems with geometric residuals
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10005</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Separation of Moving Sound Sources Using Multichannel NMF and Acoustic
  Tracking</dc:title>
 <dc:creator>Nikunen, Joonas</dc:creator>
 <dc:creator>Diment, Aleksandr</dc:creator>
 <dc:creator>Virtanen, Tuomas</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  In this paper we propose a method for separation of moving sound sources. The
method is based on first tracking the sources and then estimation of source
spectrograms using multichannel non-negative matrix factorization (NMF) and
extracting the sources from the mixture by single-channel Wiener filtering. We
propose a novel multichannel NMF model with time-varying mixing of the sources
denoted by spatial covariance matrices (SCM) and provide update equations for
optimizing model parameters minimizing squared Frobenius norm. The SCMs of the
model are obtained based on estimated directions of arrival of tracked sources
at each time frame. The evaluation is based on established objective separation
criteria and using real recordings of two and three simultaneous moving sound
sources. The compared methods include conventional beamforming and ideal ratio
mask separation. The proposed method is shown to exceed the separation quality
of other evaluated blind approaches according to all measured quantities.
Additionally, we evaluate the method's susceptibility towards tracking errors
by comparing the separation quality achieved using annotated ground truth
source trajectories.
</dc:description>
 <dc:description>Comment: Preprint of manuscript submitted to IEEE/ACM Transactions on Audio
  Speech and Language processing (R1)</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10006</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning for Accelerated Ultrasound Imaging</dc:title>
 <dc:creator>Yoon, Yeo Hun</dc:creator>
 <dc:creator>Ye, Jong Chul</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In portable, 3-D, or ultra-fast ultrasound (US) imaging systems, there is an
increasing demand to reconstruct high quality images from limited number of
data. However, the existing solutions require either hardware changes or
computationally expansive algorithms. To overcome these limitations, here we
propose a novel deep learning approach that interpolates the missing RF data by
utilizing the sparsity of the RF data in the Fourier domain. Extensive
experimental results from sub-sampled RF data from a real US system confirmed
that the proposed method can effectively reduce the data rate without
sacrificing the image quality.
</dc:description>
 <dc:description>Comment: Invited paper for ICASSP 2018 Special Session for &quot;Machine Learning
  in Medical Imaging: from Measurement to Diagnosis&quot;</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10010</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On distance r-dominating and 2r-independent sets in sparse graphs</dc:title>
 <dc:creator>Dvo&#x159;&#xe1;k, Zden&#x11b;k</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C69</dc:subject>
 <dc:description>  Dvorak (2013) gave a bound on the minimum size of a distance r dominating set
in the terms of the maximum size of a distance 2r independent set and
generalized coloring numbers, thus obtaining a constant factor approximation
algorithm for the parameters in any class of graphs with bounded expansion. We
improve and clarify this dependence using an LP-based argument inspired by the
work of Bansal and Umboh (2017).
</dc:description>
 <dc:description>Comment: 14 pages, no figures</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10013</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Declarative vs Rule-based Control for Flocking Dynamics</dc:title>
 <dc:creator>Mehmood, Usama</dc:creator>
 <dc:creator>Paoletti, Nicola</dc:creator>
 <dc:creator>Phan, Dung</dc:creator>
 <dc:creator>Grosu, Radu</dc:creator>
 <dc:creator>Lin, Shan</dc:creator>
 <dc:creator>Stoller, Scott D.</dc:creator>
 <dc:creator>Tiwari, Ashish</dc:creator>
 <dc:creator>Yang, Junxing</dc:creator>
 <dc:creator>Smolka, Scott A.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The popularity of rule-based flocking models, such as Reynolds' classic
flocking model, raises the question of whether more declarative flocking models
are possible. This question is motivated by the observation that declarative
models are generally simpler and easier to design, understand, and analyze than
operational models. We introduce a very simple control law for flocking based
on a cost function capturing cohesion (agents want to stay together) and
separation (agents do not want to get too close). We refer to it as {\textit
declarative flocking} (DF). We use model-predictive control (MPC) to define
controllers for DF in centralized and distributed settings. A thorough
performance comparison of our declarative flocking with Reynolds' model, and
with more recent flocking models that use MPC with a cost function based on
lattice structures, demonstrate that DF-MPC yields the best cohesion and least
fragmentation, and maintains a surprisingly good level of geometric regularity
while still producing natural flock shapes similar to those produced by
Reynolds' model. We also show that DF-MPC has high resilience to sensor noise.
</dc:description>
 <dc:description>Comment: 7 Pages</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10016</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regularization via Mass Transportation</dc:title>
 <dc:creator>Shafieezadeh-Abadeh, Soroosh</dc:creator>
 <dc:creator>Kuhn, Daniel</dc:creator>
 <dc:creator>Esfahani, Peyman Mohajerin</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The goal of regression and classification methods in supervised learning is
to minimize the empirical risk, that is, the expectation of some loss function
quantifying the prediction error under the empirical distribution. When facing
scarce training data, overfitting is typically mitigated by adding
regularization terms to the objective that penalize hypothesis complexity. In
this paper we introduce new regularization techniques using ideas from
distributionally robust optimization, and we give new probabilistic
interpretations to existing techniques. Specifically, we propose to minimize
the worst-case expected loss, where the worst case is taken over the ball of
all (continuous or discrete) distributions that have a bounded transportation
distance from the (discrete) empirical distribution. By choosing the radius of
this ball judiciously, we can guarantee that the worst-case expected loss
provides an upper confidence bound on the loss on test data, thus offering new
generalization bounds. We prove that the resulting regularized learning
problems are tractable and can be tractably kernelized for many popular loss
functions. We validate our theoretical out-of-sample guarantees through
simulated and empirical experiments.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10021</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Learning of Power Transmission Dynamics</dc:title>
 <dc:creator>Lokhov, Andrey Y.</dc:creator>
 <dc:creator>Vuffray, Marc</dc:creator>
 <dc:creator>Shemetov, Dmitry</dc:creator>
 <dc:creator>Deka, Deepjyoti</dc:creator>
 <dc:creator>Chertkov, Michael</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of reconstructing the dynamic state matrix of
transmission power grids from time-stamped PMU measurements in the regime of
ambient fluctuations. Using a maximum likelihood based approach, we construct a
family of convex estimators that adapt to the structure of the problem
depending on the available prior information. The proposed method is fully
data-driven and does not assume any knowledge of system parameters. It can be
implemented in near real-time and requires a small amount of data. Our learning
algorithms can be used for model validation and calibration, and can also be
applied to related problems of system stability, detection of forced
oscillations, generation re-dispatch, as well as to the estimation of the
system state.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10022</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Online Consent Maturity Model: Moving from Acceptable Use towards
  Ethical Practice</dc:title>
 <dc:creator>Rooney, Vivien M.</dc:creator>
 <dc:creator>Foley, Simon N.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The particular characteristics associated with qualitative longitudinal
research in the disciplines of psychology and social science have prompted the
development of informed consent. There are analogies between these
characteristics and the collection and analysis of data in online settings. How
and why informed consent has developed in qualitative longitudinal research,
both theoretically and practically, can provide a useful resource for
considering what informed consent means in online settings. Building on this
analogy, criteria are proposed that can be used to provide an ethical judgement
on consent practices in an online data handling activity, and form the basis
for a consent maturity model. It is argued that if we are to learn from from
the history of informed consent in qualitative longitudinal research, then we
should strive for an Ethics of Virtue approach to informed consent online, the
highest level of maturity.
</dc:description>
 <dc:description>Comment: 18 pages, 2 tables</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10026</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note on faithful coupling of Markov chains</dc:title>
 <dc:creator>Dey, Debojyoti</dc:creator>
 <dc:creator>Dutta, Pranjal</dc:creator>
 <dc:creator>Biswas, Somenath</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>60J10</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  One often needs to turn a coupling $(X_i, Y_i)_{i\geq 0}$ of a Markov chain
into a sticky coupling where once $X_T = Y_T$ at some $T$, then from then on,
at each subsequent time step $T'\geq T$, we shall have $X_{T'} = Y_{T'}$.
However, not all of what are considered couplings in literature, even Markovian
couplings, can be turned into sticky couplings, as proved by Rosenthal through
a counter example. Rosenthal then proposed a strengthening of the Markovian
coupling notion, termed as faithful coupling, from which a sticky coupling can
indeed be obtained. We identify the reason why a sticky coupling could not be
obtained in the counter example of Rosenthal, which motivates us to define a
type of coupling which can obviously be turned into a sticky coupling. We show
then that the new type of coupling that we define, and the faithful coupling as
defined by Rosenthal, are actually identical. Our note may be seen as a
demonstration of the naturalness of the notion of faithful coupling.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10033</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards efficient coexistence of IEEE 802.15.4e TSCH and IEEE 802.11</dc:title>
 <dc:creator>Chwalisz, Miko&#x142;aj</dc:creator>
 <dc:creator>Wolisz, Adam</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  A major challenge in wide deployment of smart wireless devices, using
different technologies and sharing the same 2.4 GHz spectrum, is to achieve
coexistence across multiple technologies. The IEEE~802.11 (WLAN) and the IEEE
802.15.4e TSCH (WSN) where designed with different goals in mind and both play
important roles for respective applications. However, they cause mutual
interference and degraded performance while operating in the same space. To
improve this situation we propose an approach to enable a cooperative control
which type of network is transmitting at given time, frequency and place.
  We recognize that TSCH based sensor network is expected to occupy only small
share of time, and that the nodes are by design tightly synchronized. We
develop mechanism enabling over-the-air synchronization of the Wi-Fi network to
the TSCH based sensor network. Finally, we show that Wi-Fi network can avoid
transmitting in the &quot;collision periods&quot;. We provide full design and show
prototype implementation based on the Commercial off-the-shelf (COTS) devices.
Our solution does not require changes in any of the standards.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10035</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional neural networks on irregular domains through approximate
  translations on inferred graphs</dc:title>
 <dc:creator>Pasdeloup, Bastien</dc:creator>
 <dc:creator>Gripon, Vincent</dc:creator>
 <dc:creator>Vialatte, Jean-Charles</dc:creator>
 <dc:creator>Pastor, Dominique</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We propose a generalization of convolutional neural networks (CNNs) to
irregular domains, through the use of an inferred graph structure. In more
details, we introduce a three-step methodology to create convolutional layers
that are adapted to the signals to process: 1) From a training set of signals,
infer a graph representing the topology on which they evolve; 2) Identify
translation operators in the vertex domain; 3) Emulate a convolution operator
by translating a localized kernel on the graph. Using these layers, a
convolutional neural network is built, and is trained on the initial signals to
perform a classification task. Contributions are twofold. First, we adapt a
definition of translations on graphs to make them more robust to
irregularities, and to take into account locality of the kernel. Second, we
introduce a procedure to build CNNs from data. We apply our methodology on a
scrambled version of the CIFAR-10 and Haxby datasets. Without using any
knowledge on the signals, we significantly outperform existing methods.
Moreover, our approach extends classical CNNs on images in the sense that such
networks are a particular case of our approach when the inferred graph is a
grid.
</dc:description>
 <dc:description>Comment: Submitted to IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP), 2018</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10036</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalization Tower Network: A Novel Deep Neural Network Architecture
  for Multi-Task Learning</dc:title>
 <dc:creator>Song, Yuhang</dc:creator>
 <dc:creator>Xu, Main</dc:creator>
 <dc:creator>Zhang, Songyang</dc:creator>
 <dc:creator>Huo, Liangyu</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep learning (DL) advances state-of-the-art reinforcement learning (RL), by
incorporating deep neural networks in learning representations from the input
to RL. However, the conventional deep neural network architecture is limited in
learning representations for multi-task RL (MT-RL), as multiple tasks can refer
to different kinds of representations. In this paper, we thus propose a novel
deep neural network architecture, namely generalization tower network (GTN),
which can achieve MT-RL within a single learned model. Specifically, the
architecture of GTN is composed of both horizontal and vertical streams. In our
GTN architecture, horizontal streams are used to learn representation shared in
similar tasks. In contrast, the vertical streams are introduced to be more
suitable for handling diverse tasks, which encodes hierarchical shared
knowledge of these tasks. The effectiveness of the introduced vertical stream
is validated by experimental results. Experimental results further verify that
our GTN architecture is able to advance the state-of-the-art MT-RL, via being
tested on 51 Atari games.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:date>2018-01-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10036</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10037</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rapidly Mixing Markov Chain Monte Carlo Technique for Matching Problems
  with Global Utility Function</dc:title>
 <dc:creator>Moothedath, Shana</dc:creator>
 <dc:creator>Chaporkar, Prasanna</dc:creator>
 <dc:creator>Belur, Madhu N.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  This paper deals with a complete bipartite matching problem with the
objective of finding an optimal matching that maximizes a certain generic
predefined utility function on the set of all matchings. After proving the
NP-hardness of the problem using reduction from the 3-SAT problem, we propose a
randomized algorithm based on Markov Chain Monte Carlo (MCMC) technique for
solving this. We sample from Gibb's distribution and construct a reversible
positive recurrent discrete time Markov chain (DTMC) that has the steady state
distribution same as the Gibb's distribution. In one of our key contributions,
we show that the constructed chain is `rapid mixing', i.e., the convergence
time to reach within a specified distance to the desired distribution is
polynomial in the problem size. The rapid mixing property is established by
obtaining a lower bound on the conductance of the DTMC graph and this result is
of independent interest.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10044</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributional Reinforcement Learning with Quantile Regression</dc:title>
 <dc:creator>Dabney, Will</dc:creator>
 <dc:creator>Rowland, Mark</dc:creator>
 <dc:creator>Bellemare, Marc G.</dc:creator>
 <dc:creator>Munos, R&#xe9;mi</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In reinforcement learning an agent interacts with the environment by taking
actions and observing the next state and reward. When sampled
probabilistically, these state transitions, rewards, and actions can all induce
randomness in the observed long-term return. Traditionally, reinforcement
learning algorithms average over this randomness to estimate the value
function. In this paper, we build on recent work advocating a distributional
approach to reinforcement learning in which the distribution over returns is
modeled explicitly instead of only estimating the mean. That is, we examine
methods of learning the value distribution instead of the value function. We
give results that close a number of gaps between the theoretical and
algorithmic results given by Bellemare, Dabney, and Munos (2017). First, we
extend existing results to the approximate distribution setting. Second, we
present a novel distributional reinforcement learning algorithm consistent with
our theoretical formulation. Finally, we evaluate this new algorithm on the
Atari 2600 games, observing that it significantly outperforms many of the
recent improvements on DQN, including the related distributional algorithm C51.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10057</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Group Fairness in Multiwinner Voting</dc:title>
 <dc:creator>Celis, L. Elisa</dc:creator>
 <dc:creator>Huang, Lingxiao</dc:creator>
 <dc:creator>Vishnoi, Nisheeth K.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study multiwinner voting problems when there is an additional requirement
that the selected committee should be fair with respect to attributes such as
gender, ethnicity, or political parties. Every setting of an attribute gives
rise to a group, and the goal is to ensure that each group is neither over nor
under represented in the selected committee. Prior work has largely focused on
designing specialized score functions that lead to a precise level of
representation with respect to disjoint attributes (e.g., only political
affiliation). Here we propose a general algorithmic framework that allows the
use of any score function and can guarantee flexible notions of fairness with
respect to multiple, non-disjoint attributes (e.g., political affiliation and
gender). Technically, we study the complexity of this constrained multiwinner
voting problem subject to group-fairness constraints for monotone submodular
score functions. We present approximation algorithms and hardness of
approximation results for various attribute set structures and score functions.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10057</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10059</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Direction of arrival estimation for multiple sound sources using
  convolutional recurrent neural network</dc:title>
 <dc:creator>Adavanne, Sharath</dc:creator>
 <dc:creator>Politis, Archontis</dc:creator>
 <dc:creator>Virtanen, Tuomas</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  This paper proposes a deep neural network for estimating the directions of
arrival (DOA) of multiple sound sources. The proposed stacked convolutional and
recurrent neural network (DOAnet) generates a spatial pseudo-spectrum along
with the DOA estimates in both azimuth and elevation. We avoid any explicit
feature extraction step by using the magnitude and phase of the spectrogram as
input to the network. The proposed DOAnet is evaluated by estimating the DOAs
of multiple concurrently present sources in anechoic, matched and unmatched
reverberant conditions. The results show that the proposed DOAnet is capable of
estimating the number of sources and their respective DOAs with good precision
and generate SPS with high signal-to-noise ratio.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10059</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10060</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transform-Invariant Non-Parametric Clustering of Covariance Matrices and
  its Application to Unsupervised Joint Segmentation and Action Discovery</dc:title>
 <dc:creator>Figueroa, Nadia</dc:creator>
 <dc:creator>Billard, Aude</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this work, we tackle the problem of transform-invariant unsupervised
learning in the space of Covariance matrices and applications thereof. We begin
by introducing the Spectral Polytope Covariance Matrix (SPCM) Similarity
function; a similarity function for Covariance matrices, invariant to any type
of transformation. We then derive the SPCM-CRP mixture model, a
transform-invariant non-parametric clustering approach for Covariance matrices
that leverages the proposed similarity function, spectral embedding and the
distance-dependent Chinese Restaurant Process (dd-CRP) (Blei and Frazier,
2011). The scalability and applicability of these two contributions is
extensively validated on real-world Covariance matrix datasets from diverse
research fields. Finally, we couple the SPCM-CRP mixture model with the
Bayesian non-parametric Indian Buffet Process (IBP) - Hidden Markov Model (HMM)
(Fox et al., 2009), to jointly segment and discover transform-invariant action
primitives from complex sequential data. Resulting in a topic-modeling inspired
hierarchical model for unsupervised time-series data analysis which we call
ICSC-HMM (IBP Coupled SPCM-CRP Hidden Markov Model). The ICSC-HMM is validated
on kinesthetic demonstrations of uni-manual and bi-manual cooking tasks;
achieving unsupervised human-level decomposition of complex sequential tasks.
</dc:description>
 <dc:description>Comment: 51 pages, 20 figures. Submitted to Journal of Machine Learning
  Research, currently under review</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10060</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10061</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>State of the art of Trust and Reputation Systems in E-Commerce Context</dc:title>
 <dc:creator>Rahimi, Hasnae</dc:creator>
 <dc:creator>Bekkali, Hanan El</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  This article proposes in depth comparative study of the most popular, used
and analyzed Trust and Reputation System (TRS) according to the trust and
reputation literature and in terms of specific trustworthiness criteria. This
survey is realized relying on a selection of trustworthiness criteria that
analyze and evaluate the maturity and effectiveness of TRS. These criteria
describe the utility, the usability, the performance and the effectiveness of
the TRS. We also provide a summary table of the compared TRS within a detailed
and granular selection of trust and reputation aspects.
</dc:description>
 <dc:description>Comment: State of the art (survey) published in IJCSI journal paper indexed by
  DBLP, EBSCO, Proquest, DOAJ, Google Scholar, with 53 References;
  http://www.ijcsi.org/ Volume 14, Issue 3, May 2017</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10061</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10062</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recovery of Structured Signals with Prior Information via Maximizing
  Correlation</dc:title>
 <dc:creator>Zhang, Xu</dc:creator>
 <dc:creator>Cui, Wei</dc:creator>
 <dc:creator>Liu, Yulong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers the problem of recovering a structured signal from a
relatively small number of noisy measurements with the aid of a similar signal
which is known beforehand. We propose a new approach to integrate prior
information into the standard recovery procedure by maximizing the correlation
between the prior knowledge and the desired signal. We then establish
performance guarantees (in terms of the number of measurements) for the
proposed method under sub-Gaussian measurements. Specific structured signals
including sparse vectors, block-sparse vectors, and low-rank matrices are also
analyzed. Furthermore, we present an interesting geometrical interpretation for
the proposed procedure. Our results demonstrate that if prior information is
good enough, then the proposed approach can (remarkably) outperform the
standard recovery procedure. Simulations are provided to verify our results.
</dc:description>
 <dc:description>Comment: 27 pages, 27 figures</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10088</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fine-grained Pattern Matching Over Streaming Time Series</dc:title>
 <dc:creator>Kang, Rong</dc:creator>
 <dc:creator>Wang, Chen</dc:creator>
 <dc:creator>Wang, Peng</dc:creator>
 <dc:creator>Ding, Yuting</dc:creator>
 <dc:creator>Wang, Jianmin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Pattern matching of streaming time series with lower latency under limited
computing resource comes to a critical problem, especially as the growth of
Industry 4.0 and Industry Internet of Things. However, against traditional
single pattern matching problem, a pattern may contain multiple segments
representing different statistical properties or physical meanings for more
precise and expressive matching in real world. Hence, we formulate a new
problem, called &quot;fine-grained pattern matching&quot;, which allows users to specify
varied granularities of matching deviation to different segments of a given
pattern, and fuzzy regions for adaptive breakpoints determination between
consecutive segments. In this paper, we propose a novel two-phase approach. In
the pruning phase, we introduce Equal-Length Block (ELB) representation
together with Block-Skipping Pruning (BSP) policy, which guarantees low cost
feature calculation, effective pruning and no false dismissals. In the
post-processing phase, a delta-function is proposed to enable us to conduct
exact matching in linear complexity. Extensive experiments are conducted to
evaluate on synthetic and real-world datasets, which illustrates that our
algorithm outperforms the brute-force method and MSM, a multi-step filter
mechanism over the multi-scaled representation.
</dc:description>
 <dc:description>Comment: 14 pages, 14 figures, 29 conference</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:date>2017-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10088</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10089</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Decomposition-Based Approach to Reasoning about Free Space
  Path-Connectivity for Rigid Objects in 2D</dc:title>
 <dc:creator>Varava, Anastasiia</dc:creator>
 <dc:creator>Carvalho, J. Frederico</dc:creator>
 <dc:creator>Kragic, Danica</dc:creator>
 <dc:creator>Pokorny, Florian T.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this paper, we compute a conservative approximation of the path-connected
components of the free space of a rigid object in a 2D workspace in order to
solve two closely related problems: to determine whether there exists a
collision-free path between two given configurations, and to verify whether an
object can escape arbitrarily far from its initial configuration -- i.e.,
whether the object is caged. Furthermore, we consider two quantitative
characteristics of the free space: the volume of path-connected components and
the width of narrow passages. To address these problems, we decompose the
configuration space into a set of two-dimensional slices, approximate them as
two-dimensional alpha-complexes, and then study the relations between them.
This significantly reduces the computational complexity compared to a direct
approximation of the free space. We implement our algorithm and run experiments
in a three-dimensional configuration space of a simple object showing runtime
of less than 2 seconds.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10089</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10090</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Edge-as-a-Service: Towards Distributed Cloud Architectures</dc:title>
 <dc:creator>Varghese, Blesson</dc:creator>
 <dc:creator>Wang, Nan</dc:creator>
 <dc:creator>Li, Jianyu</dc:creator>
 <dc:creator>Nikolopoulos, Dimitrios S.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We present an Edge-as-a-Service (EaaS) platform for realising distributed
cloud architectures and integrating the edge of the network in the computing
ecosystem. The EaaS platform is underpinned by (i) a lightweight discovery
protocol that identifies edge nodes and make them publicly accessible in a
computing environment, and (ii) a scalable resource provisioning mechanism for
offloading workloads from the cloud on to the edge for servicing multiple user
requests. We validate the feasibility of EaaS on an online game use-case to
highlight the improvement in the QoS of the application hosted on our
cloud-edge platform. On this platform we demonstrate (i) low overheads of less
than 6%, (ii) reduced data traffic to the cloud by up to 95% and (iii)
minimised application latency between 40%-60%.
</dc:description>
 <dc:description>Comment: 10 pages; presented at the EdgeComp Symposium 2017; will appear in
  Proceedings of the International Conference on Parallel Computing, 2017</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10090</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10091</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>External Memory Pipelining Made Easy With TPIE</dc:title>
 <dc:creator>Arge, Lars</dc:creator>
 <dc:creator>Rav, Mathias</dc:creator>
 <dc:creator>Svendsen, Svend C.</dc:creator>
 <dc:creator>Truelsen, Jakob</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  When handling large datasets that exceed the capacity of the main memory,
movement of data between main memory and external memory (disk), rather than
actual (CPU) computation time, is often the bottleneck in the computation.
Since data is moved between disk and main memory in large contiguous blocks,
this has led to the development of a large number of I/O-efficient algorithms
that minimize the number of such block movements.
  TPIE is one of two major libraries that have been developed to support
I/O-efficient algorithm implementations. TPIE provides an interface where list
stream processing and sorting can be implemented in a simple and modular way
without having to worry about memory management or block movement. However, if
care is not taken, such streaming-based implementations can lead to practically
inefficient algorithms since lists of data items are typically written to (and
read from) disk between components.
  In this paper we present a major extension of the TPIE library that includes
a pipelining framework that allows for practically efficient streaming-based
implementations while minimizing I/O-overhead between streaming components. The
framework pipelines streaming components to avoid I/Os between components, that
is, it processes several components simultaneously while passing output from
one component directly to the input of the next component in main memory. TPIE
automatically determines which components to pipeline and performs the required
main memory management, and the extension also includes support for
parallelization of internal memory computation and progress tracking across an
entire application. The extended library has already been used to evaluate
I/O-efficient algorithms in the research literature and is heavily used in
I/O-efficient commercial terrain processing applications by the Danish startup
SCALGO.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10093</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On modeling vagueness and uncertainty in data-to-text systems through
  fuzzy sets</dc:title>
 <dc:creator>Ramos-Soto, A.</dc:creator>
 <dc:creator>Pereira-Fari&#xf1;a, M.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Vagueness and uncertainty management is counted among one of the challenges
that remain unresolved in systems that generate texts from non-linguistic data,
known as data-to-text systems. In the last decade, work in fuzzy linguistic
summarization and description of data has raised the interest of using fuzzy
sets to model and manage the imprecision of human language in data-to-text
systems. However, despite some research in this direction, there has not been
an actual clear discussion and justification on how fuzzy sets can contribute
to data-to-text for modeling vagueness and uncertainty in words and
expressions. This paper intends to bridge this gap by answering the following
questions: What does vagueness mean in fuzzy sets theory? What does vagueness
mean in data-to-text contexts? In what ways can fuzzy sets theory contribute to
improve data-to-text systems? What are the challenges that researchers from
both disciplines need to address for a successful integration of fuzzy sets
into data-to-text systems? In what cases should the use of fuzzy sets be
avoided in D2T? For this, we review and discuss the state of the art of
vagueness modeling in natural language generation and data-to-text, describe
potential and actual usages of fuzzy sets in data-to-text contexts, and provide
some additional insights about the engineering of data-to-text systems that
make use of fuzzy set-based techniques.
</dc:description>
 <dc:description>Comment: 31 pages including references (in a review-friendly format), 4
  figures, 1 table</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10093</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10096</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SceneFlowFields: Dense Interpolation of Sparse Scene Flow
  Correspondences</dc:title>
 <dc:creator>Schuster, Ren&#xe9;</dc:creator>
 <dc:creator>Wasenm&#xfc;ller, Oliver</dc:creator>
 <dc:creator>Kuschk, Georg</dc:creator>
 <dc:creator>Bailer, Christian</dc:creator>
 <dc:creator>Stricker, Didier</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  While most scene flow methods use either variational optimization or a strong
rigid motion assumption, we show for the first time that scene flow can also be
estimated by dense interpolation of sparse matches. To this end, we find sparse
matches across two stereo image pairs that are detected without any prior
regularization and perform dense interpolation preserving geometric and motion
boundaries by using edge information. A few iterations of variational energy
minimization are performed to refine our results, which are thoroughly
evaluated on the KITTI benchmark and additionally compared to state-of-the-art
on MPI Sintel. For application in an automotive context, we further show that
an optional ego-motion model helps to boost performance and blends smoothly
into our approach to produce a segmentation of the scene into static and
dynamic parts.
</dc:description>
 <dc:description>Comment: IEEE Winter Conference on Applications of Computer Vision (WACV),
  2018</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10096</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10098</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An efficient SAT formulation for learning multiple criteria
  non-compensatory sorting rules from examples</dc:title>
 <dc:creator>Belahc&#xe8;ne, K.</dc:creator>
 <dc:creator>Labreuche, C.</dc:creator>
 <dc:creator>Maudet, N.</dc:creator>
 <dc:creator>Mousseau, V.</dc:creator>
 <dc:creator>Ouerdane, W.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The literature on Multiple Criteria Decision Analysis (MCDA) proposes several
methods in order to sort alternatives evaluated on several attributes into
ordered classes. Non Compensatory Sorting models (NCS) assign alternatives to
classes based on the way they compare to multicriteria profiles separating the
consecutive classes. Previous works have proposed approaches to learn the
parameters of a NCS model based on a learning set. Exact approaches based on
mixed integer linear programming ensures that the learning set is best
restored, but can only handle datasets of limited size. Heuristic approaches
can handle large learning sets, but do not provide any guarantee about the
inferred model. In this paper, we propose an alternative formulation to learn a
NCS model. This formulation, based on a SAT problem, guarantees to find a model
fully consistent with the learning set (whenever it exists), and is
computationally much more efficient than existing exact MIP approaches.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10098</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10101</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image matting with normalized weight and semi-supervised learning</dc:title>
 <dc:creator>Li, Ping</dc:creator>
 <dc:creator>Duan, Tingyan</dc:creator>
 <dc:creator>Cao, Yongfeng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image matting is an important vision problem. The main stream methods for it
combine sampling-based methods and propagation-based methods. In this paper, we
deal with the combination with a normalized weighting parameter, which could
well control the relative relationship between information from sampling and
from propagation. A reasonable value range for this parameter is given based on
statistics from the standard benchmark dataset. The matting is further improved
by introducing semi-supervised learning iterations, which automatically refine
the trimap without user's interaction. This is especially beneficial when the
trimap is coarse. The experimental results on standard benchmark dataset have
shown that both the normalized weighting parameter and the semi-supervised
learning iteration could significantly improve the matting performance.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10105</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lyndon Array Construction during Burrows-Wheeler Inversion</dc:title>
 <dc:creator>Louza, Felipe A.</dc:creator>
 <dc:creator>Smyth, W. F.</dc:creator>
 <dc:creator>Manzini, Giovanni</dc:creator>
 <dc:creator>Telles, Guilherme P.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper we present an algorithm to compute the Lyndon array of a string
$T$ of length $n$ as a byproduct of the inversion of the Burrows-Wheeler
transform of $T$. Our algorithm runs in linear time using only a stack in
addition to the data structures used for Burrows-Wheeler inversion. We compare
our algorithm with two other linear-time algorithms for Lyndon array
construction and show that computing the Burrows-Wheeler transform and then
constructing the Lyndon array is competitive compared to the known approaches.
We also propose a new balanced parenthesis representation for the Lyndon array
that uses $2n+o(n)$ bits of space and supports constant time access. This
representation can be built in linear time using $O(n)$ words of space, or in
$O(n\log n/\log\log n)$ time using asymptotically the same space as $T$.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10109</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The word and order problems for self-similar and automata groups</dc:title>
 <dc:creator>Bartholdi, Laurent</dc:creator>
 <dc:creator>Mitrofanov, Ivan</dc:creator>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We prove that the word problem is undecidable in functionally recursive
groups, and that the order problem is undecidable in automata groups, even
under the assumption that they are contracting.
</dc:description>
 <dc:description>Comment: Fixed broken references</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:date>2017-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10112</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hyperopic Cops and Robbers</dc:title>
 <dc:creator>Bonato, A.</dc:creator>
 <dc:creator>Clarke, N. E.</dc:creator>
 <dc:creator>Cox, D.</dc:creator>
 <dc:creator>Finbow, S.</dc:creator>
 <dc:creator>Inerney, F. Mc</dc:creator>
 <dc:creator>Messinger, M. E.</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We introduce a new variant of the game of Cops and Robbers played on graphs,
where the robber is invisible unless outside the neighbor set of a cop. The
hyperopic cop number is the corresponding analogue of the cop number, and we
investigate bounds and other properties of this parameter. We characterize the
cop-win graphs for this variant, along with graphs with the largest possible
hyperopic cop number. We analyze the cases of graphs with diameter 2 or at
least 3, focusing on when the hyperopic cop number is at most one greater than
the cop number. We show that for planar graphs, as with the usual cop number,
the hyperopic cop number is at most 3. The hyperopic cop number is considered
for countable graphs, and it is shown that for connected chains of graphs, the
hyperopic cop density can be any real number in $[0,1/2].$
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10112</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10116</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inverse Reinforcement Learning Under Noisy Observations</dc:title>
 <dc:creator>Shahryari, Shervin</dc:creator>
 <dc:creator>Doshi, Prashant</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the problem of performing inverse reinforcement learning when the
trajectory of the expert is not perfectly observed by the learner. Instead, a
noisy continuous-time observation of the trajectory is provided to the learner.
This problem exhibits wide-ranging applications and the specific application we
consider here is the scenario in which the learner seeks to penetrate a
perimeter patrolled by a robot. The learner's field of view is limited due to
which it cannot observe the patroller's complete trajectory. Instead, we allow
the learner to listen to the expert's movement sound, which it can also use to
estimate the expert's state and action using an observation model. We treat the
expert's state and action as hidden data and present an algorithm based on
expectation maximization and maximum entropy principle to solve the non-linear,
non-convex problem. Related work considers discrete-time observations and an
observation model that does not include actions. In contrast, our technique
takes expectations over both state and action of the expert, enabling learning
even in the presence of extreme noise and broader applications.
</dc:description>
 <dc:description>Comment: Full version of the extended abstract published in AAMAS 2017
  conference, pages 1733 - 1735</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10116</dc:identifier>
 <dc:identifier>In Proceedings of the 16th Conference on Autonomous Agents and
  MultiAgent Systems (AAMAS '17). International Foundation for Autonomous
  Agents and Multiagent Systems, Richland, SC, 1733-1735, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10117</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incorporating Reality into Social Choice</dc:title>
 <dc:creator>Shapiro, Ehud</dc:creator>
 <dc:creator>Talmon, Nimrod</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  When voting on a proposal one in fact chooses between two alternatives: (i) A
new hypothetical social state depicted by the proposal and (ii) the status quo
(henceforth: Reality); a Yes vote favors a transition to the proposed
hypothetical state, while a No vote favors Reality. Social Choice theory
generalizes voting on one proposal to ranking multiple proposals; that Reality
was forsaken during this generalization is, in our view, inexplicable. Here we
propose to rectify this neglect and incorporate Reality into Social Choice,
distinguishing between Reality and hypothesis. We do so by recognizing Reality
as an ever-present, always-relevant, evolving social state that is
distinguished from hypothetical social states, and explore the ramifications of
this recognition.
  Incorporating Reality into Social Choice offers: (i) A natural way to resolve
the Condorcet paradox and Condorcet cycles; (ii) a resolution to the vexing
ambiguity regarding what do approval voters, in fact, approve? (iii) a simple
and practical show-of-hands agenda that implements an approval vote in one
round and Condorcet-consistent voting in multiple rounds; and (iv) reasoned
nullification of Independence of Irrelevant Alternatives and hence abdication
of Arrow's Theorem.
  Arrow's theorem was taken to show that democracy, conceived as government by
the will of the people, is an incoherent illusion. Incorporating Reality into
Social Choice may clear this intellectual blemish on democracy; pave the way
for the broad application of the Condorcet criterion; and, more generally, help
restore trust in democracy by showing that it offers a coherent and hopeful
vision.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10117</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10121</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond Finite Layer Neural Networks: Bridging Deep Architectures and
  Numerical Differential Equations</dc:title>
 <dc:creator>Lu, Yiping</dc:creator>
 <dc:creator>Zhong, Aoxiao</dc:creator>
 <dc:creator>Li, Quanzheng</dc:creator>
 <dc:creator>Dong, Bin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In our work, we bridge deep neural network design with numerical differential
equations. We show that many effective networks, such as ResNet, PolyNet,
FractalNet and RevNet, can be interpreted as different numerical
discretizations of differential equations. This finding brings us a brand new
perspective on the design of effective deep architectures. We can take
advantage of the rich knowledge in numerical analysis to guide us in designing
new and potentially more effective deep networks. As an example, we propose a
linear multi-step architecture (LM-architecture) which is inspired by the
linear multi-step method solving ordinary differential equations. The
LM-architecture is an effective structure that can be used on any ResNet-like
networks. In particular, we demonstrate that LM-ResNet and LM-ResNeXt (i.e. the
networks obtained by applying the LM-architecture on ResNet and ResNeXt
respectively) can achieve noticeably higher accuracy than ResNet and ResNeXt on
both CIFAR and ImageNet with comparable numbers of trainable parameters. In
particular, on both CIFAR and ImageNet, LM-ResNet/LM-ResNeXt can significantly
compress ($&gt;50$\%) the original networks while maintaining a similar
performance. This can be explained mathematically using the concept of modified
equation from numerical analysis. Last but not least, we also establish a
connection between stochastic control and noise injection in the training
process which helps to improve generalization of the networks. Furthermore, by
relating stochastic training strategy with stochastic dynamic system, we can
easily apply stochastic training to the networks with the LM-architecture. As
an example, we introduced stochastic depth to LM-ResNet and achieve significant
improvement over the original LM-ResNet on CIFAR10.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10122</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RRT-CoLearn: towards kinodynamic planning without numerical trajectory
  optimization</dc:title>
 <dc:creator>Wolfslag, Wouter</dc:creator>
 <dc:creator>Bharatheesha, Mukunda</dc:creator>
 <dc:creator>Moerland, Thomas</dc:creator>
 <dc:creator>Wisse, Martijn</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Sampling-based kinodynamic planners, such as Rapidly-exploring Random Trees
(RRTs), pose two fundamental challenges: computing a reliable (pseudo-)metric
for the distance between two randomly sampled nodes, and computing a steering
input to connect the nodes. The core of these challenges is a Two Point
Boundary Value Problem, which is known to be NP-hard. Recently, the distance
metric has been approximated using supervised learning, reducing computation
time drastically. The previous work on such learning RRTs use direct optimal
control to generate the data for supervised learning. This paper proposes to
use indirect optimal control instead, because it provides two benefits: it
reduces the computational effort to generate the data, and it provides a low
dimensional parametrization of the action space. The latter allows us to learn
both the distance metric and the steering input to connect two nodes. This
eliminates the need for a local planner in learning RRTs. Experimental results
on a pendulum swing up show 10-fold speed-up in both the offline data
generation and the online planning time, leading to at least a 10-fold speed-up
in the overall planning time.
</dc:description>
 <dc:description>Comment: This paper is currently under review at IEEE RA-L</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10141</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cultural, Economic and Societal Impacts on Users' Behaviour and Mobile
  Broadband Adoption Trends</dc:title>
 <dc:creator>Miraz, Mahdi H.</dc:creator>
 <dc:creator>Ali, Maaruf</dc:creator>
 <dc:creator>Excell, Peter S.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The diverse range of Internet enabled devices both mobile and fixed has not
only impacted the global economy but the very fabric of human communications
and lifestyles. The ease of access and lowered cost has enabled hitherto
diametrically opposed people to interact and influence each other globally. The
consequence of which is the dire need to address the way culture affects
interaction with information systems across the world. The many facets of which
encompasses human behaviour, socio-economic and cultural factors including
lifestyles and the way of interaction with the information system. The study
group involved participants from Bangladesh and the United Kingdom to ascertain
the users'behavioural patterns and mobile broadband technology diffusion
trends.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1708.02798</dc:description>
 <dc:date>2017-10-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10141</dc:identifier>
 <dc:identifier>Annals of Emerging Technologies in Computing (AETiC), Volume #1,
  Issue #1, pp-34-44, October 2017,
  http://aetic.theiaer.org/archive/v1n1/p5.html</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10145</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ideal Node Enquiry Search Algorithm (INESH) in MANETS</dc:title>
 <dc:creator>Belgaum, Mohammad Riyaz</dc:creator>
 <dc:creator>Soomro, Safeeullah</dc:creator>
 <dc:creator>Alansari, Zainab</dc:creator>
 <dc:creator>Alam, Muhammad</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The different routing protocols in Mobile Ad hoc Networks take after various
methodologies to send the data starting from one node then onto the next. The
nodes in the system are non-static and they move arbitrarily and are inclined
to interface disappointment which makes dependably to discover new routes to
the destination. During the forwarding of packets to the destination, various
intermediate nodes take part in routing, where such node should be an ideal
node. An algorithm is proposed here to know the ideal node after studying the
features of the reactive routing protocols. The malicious node can be
eliminated from the networking function and the overhead on the protocol can be
reduced. The node chooses the neighbor which can be found in less number of
bounces and with less time delay and keeping up the QoS.
</dc:description>
 <dc:description>Comment: 26-33. arXiv admin note: text overlap with arXiv:1708.01639</dc:description>
 <dc:date>2017-10-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10145</dc:identifier>
 <dc:identifier>Annals of Emerging Technologies in Computing (AETiC), Vol 1, issue
  1, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10164</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a new paradigm for assistive technology at home: research
  challenges, design issues and performance assessment</dc:title>
 <dc:creator>Buoncompagni, Luca</dc:creator>
 <dc:creator>Bruno, Barbara</dc:creator>
 <dc:creator>Giuni, Antonella</dc:creator>
 <dc:creator>Mastrogiovanni, Fulvio</dc:creator>
 <dc:creator>Zaccaria, Renato</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>68T30</dc:subject>
 <dc:description>  Providing elderly and people with special needs, including those suffering
from physical disabilities and chronic diseases, with the possibility of
retaining their independence at best is one of the most important challenges
our society is expected to face. Assistance models based on the home care
paradigm are being adopted rapidly in almost all industrialized and emerging
countries. Such paradigms hypothesize that it is necessary to ensure that the
so-called Activities of Daily Living are correctly and regularly performed by
the assisted person to increase the perception of an improved quality of life.
This chapter describes the computational inference engine at the core of
Arianna, a system able to understand whether an assisted person performs a
given set of ADL and to motivate him/her in performing them through a
speech-mediated motivational dialogue, using a set of nearables to be installed
in an apartment, plus a wearable to be worn or fit in garments.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10164</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10169</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uplink Performance Analysis in D2D-Enabled mmWave Cellular Networks with
  Clustered Users</dc:title>
 <dc:creator>Turgut, Esma</dc:creator>
 <dc:creator>Gursoy, M. Cenk</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, an analytical framework is provided to analyze the uplink
performance of device-to-device (D2D)-enabled millimeter wave (mmWave) cellular
networks with clustered D2D user equipments (UEs). Locations of cellular UEs
are modeled as a Poison Point Process (PPP), while locations of potential D2D
UEs are modeled as a Poisson Cluster Process (PCP).
Signal-to-interference-plus-noise ratio (SINR) outage probabilities are derived
for both cellular and D2D links using tools from stochastic geometry. The
distinguishing features of mmWave communications such as directional
beamforming and having different path loss laws for line-of-sight (LOS) and
non-line-of-sight (NLOS) links are incorporated into the outage analysis by
employing a flexible mode selection scheme. Also, the effect of beamforming
alignment errors on the outage probability is investigated to get insight on
the performance in practical scenarios. Moreover, area spectral efficiency
(ASE) of the entire network is determined for both underlay and overlay types
of sharing. Optimal spectrum partition factor is determined for overlay sharing
by considering the optimal weighted proportional fair spectrum partition.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1704.01027</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:date>2018-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10174</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SGD Learns Over-parameterized Networks that Provably Generalize on
  Linearly Separable Data</dc:title>
 <dc:creator>Brutzkus, Alon</dc:creator>
 <dc:creator>Globerson, Amir</dc:creator>
 <dc:creator>Malach, Eran</dc:creator>
 <dc:creator>Shalev-Shwartz, Shai</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Neural networks exhibit good generalization behavior in the
over-parameterized regime, where the number of network parameters exceeds the
number of observations. Nonetheless, current generalization bounds for neural
networks fail to explain this phenomenon. In an attempt to bridge this gap, we
study the problem of learning a two-layer over-parameterized neural network,
when the data is generated by a linearly separable function. In the case where
the network has Leaky ReLU activations, we provide both optimization and
generalization guarantees for over-parameterized networks. Specifically, we
prove convergence rates of SGD to a global minimum and provide generalization
guarantees for this global minimum that are independent of the network size.
Therefore, our result clearly shows that the use of SGD for optimization both
finds a global minimum, and avoids overfitting despite the high capacity of the
model. This is the first theoretical demonstration that SGD can avoid
overfitting, when learning over-specified neural network classifiers.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10177</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Aspects of Genetic Algorithms with Weighted Recommender
  Hybridization</dc:title>
 <dc:creator>Mueller, Juergen</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Recommender systems are established means to inspire users to watch
interesting movies, discover baby names, or read books. The recommendation
quality further improves by combining the results of multiple recommendation
algorithms using hybridization methods. In this paper, we focus on the task of
combining unscored recommendations into a single ensemble. Our proposed method
is inspired by genetic algorithms. It repeatedly selects items from the
recommendations to create a population of items that will be used for the final
ensemble. We compare our method with a weighted voting method and test the
performance of both in a movie- and name-recommendation scenario. We were able
to outperform the weighted method on both datasets by 20.3 % and 31.1 % and
decreased the overall execution time by up to 19.9 %. Our results do not only
propose a new kind of hybridization method, but introduce the field of
recommender hybridization to further work with genetic algorithms.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures, 2 tables, iiWAS '17, December 4-6, 2017,
  Salzburg, Austria</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10177</dc:identifier>
 <dc:identifier>doi:10.1145/3151759.3151765</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10182</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-Quality Facial Photo-Sketch Synthesis Using Multi-Adversarial
  Networks</dc:title>
 <dc:creator>Wang, Lidan</dc:creator>
 <dc:creator>Sindagi, Vishwanath A.</dc:creator>
 <dc:creator>Patel, Vishal M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Synthesizing face sketches from real photos and its inverse are well studied
problems and they have many applications in digital forensics and
entertainment. However, photo/sketch synthesis remains a challenging problem
due to the fact that photo and sketch have different characteristics. In this
work, we consider this task as an image-to-image translation problem and
explore the recently popular generative models (GANs) to generate high-quality
realistic photos from sketches and sketches from photos. Recent methods such as
Pix2Pix, CycleGAN and DualGAN have shown promising results on image-to-image
translation problems and photo-to-sketch synthesis in particular, however, they
are known to have limited abilities in generating high-resolution realistic
images. To this end, we propose a novel synthesis framework called Photo-Sketch
Synthesis using Multi-Adversarial Networks, (PS\textsuperscript{2}-MAN) that
iteratively generates low resolution to high resolution images in an
adversarial way. The hidden layers of the generator are supervised to first
generate lower resolution images followed by implicit refinement in the network
to generate higher resolution images. Furthermore, since photo-sketch synthesis
is a coupled/paired translation problem where photo-sketch and sketch-photo are
equally important, we leverage the pair information in the CycleGAN framework.
Evaluation of the proposed method is performed on two datasets: CUHK and CUFSF.
Both Image Quality Assessment (IQA) and Photo-Sketch Matching experiments are
conducted to demonstrate the superior performance of our framework in
comparison to existing state-of-the-art solutions. Additionally, ablation
studies are conducted to verify the effectiveness iterative synthesis and
various loss functions.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10182</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10188</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhanced Biologically Inspired Model for Image Recognition Based on a
  Novel Patch Selection Method with Moment</dc:title>
 <dc:creator>Lu, Yan-Feng</dc:creator>
 <dc:creator>Jia, Li-Hao</dc:creator>
 <dc:creator>Qaio, Hong</dc:creator>
 <dc:creator>Li, Yi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Biologically inspired model (BIM) for image recognition is a robust
computational architecture, which has attracted widespread attention. BIM can
be described as a four-layer structure based on the mechanisms of the visual
cortex. Although the performance of BIM for image recognition is robust, it
takes the randomly selected ways for the patch selection, which is sightless,
and results in heavy computing burden. To address this issue, we propose a
novel patch selection method with oriented Gaussian-Hermite moment (PSGHM), and
we enhanced the BIM based on the proposed PSGHM, named as PBIM. In contrast to
the conventional BIM which adopts the random method to select patches within
the feature representation layers processed by multi-scale Gabor filter banks,
the proposed PBIM takes the PSGHM way to extract a small number of
representation features while offering promising distinctiveness. To show the
effectiveness of the proposed PBIM, experimental studies on object
categorization are conducted on the CalTech05, TU Darmstadt (TUD), and GRAZ01
databases. Experimental results demonstrate that the performance of PBIM is a
significant improvement on that of the conventional BIM.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10188</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10192</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dual Path Networks for Multi-Person Human Pose Estimation</dc:title>
 <dc:creator>Ning, Guanghan</dc:creator>
 <dc:creator>He, Zhihai</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The task of multi-person human pose estimation in natural scenes is quite
challenging. Existing methods include both top-down and bottom-up approaches.
The main advantage of bottom-up methods is its excellent tradeoff between
estimation accuracy and computational cost. We follow this path and aim to
design smaller, faster, and more accurate neural networks for the regression of
keypoints and limb association vectors. These two regression tasks are
naturally dependent on each other. In this work, we propose a dual-path network
specially designed for multi-person human pose estimation, and compare our
performance with the openpose network in aspects of model size, forward speed,
and estimation accuracy.
</dc:description>
 <dc:description>Comment: ICCV 2017 Workshop on PoseTrack Challenge. Challenge results
  available at:
  https://posetrack.net/workshops/iccv2017/posetrack-challenge-results.html</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10192</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10196</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Progressive Growing of GANs for Improved Quality, Stability, and
  Variation</dc:title>
 <dc:creator>Karras, Tero</dc:creator>
 <dc:creator>Aila, Timo</dc:creator>
 <dc:creator>Laine, Samuli</dc:creator>
 <dc:creator>Lehtinen, Jaakko</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We describe a new training methodology for generative adversarial networks.
The key idea is to grow both the generator and discriminator progressively:
starting from a low resolution, we add new layers that model increasingly fine
details as training progresses. This both speeds the training up and greatly
stabilizes it, allowing us to produce images of unprecedented quality, e.g.,
CelebA images at 1024^2. We also propose a simple way to increase the variation
in generated images, and achieve a record inception score of 8.80 in
unsupervised CIFAR10. Additionally, we describe several implementation details
that are important for discouraging unhealthy competition between the generator
and discriminator. Finally, we suggest a new metric for evaluating GAN results,
both in terms of image quality and variation. As an additional contribution, we
construct a higher-quality version of the CelebA dataset.
</dc:description>
 <dc:description>Comment: A few clarifications in the appendix</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10196</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10197</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Advanced LSTM: A Study about Better Time Dependency Modeling in Emotion
  Recognition</dc:title>
 <dc:creator>Tao, Fei</dc:creator>
 <dc:creator>Liu, Gang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Long short-term memory (LSTM) is normally used in recurrent neural network
(RNN) as basic recurrent unit. However,conventional LSTM assumes that the state
at current time step depends on previous time step. This assumption constraints
the time dependency modeling capability. In this study, we propose a new
variation of LSTM, advanced LSTM (A-LSTM), for better temporal context
modeling. We employ A-LSTM in weighted pooling RNN for emotion recognition. The
A-LSTM outperforms the conventional LSTM by 5.5% relatively. The A-LSTM based
weighted pooling RNN can also complement the state-of-the-art emotion
classification framework. This shows the advantage of A-LSTM.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10197</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10198</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection and Analysis of Human Emotions through Voice and Speech
  Pattern Processing</dc:title>
 <dc:creator>Dasgupta, Poorna Banerjee</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The ability to modulate vocal sounds and generate speech is one of the
features which set humans apart from other living beings. The human voice can
be characterized by several attributes such as pitch, timbre, loudness, and
vocal tone. It has often been observed that humans express their emotions by
varying different vocal attributes during speech generation. Hence, deduction
of human emotions through voice and speech analysis has a practical
plausibility and could potentially be beneficial for improving human
conversational and persuasion skills. This paper presents an algorithmic
approach for detection and analysis of human emotions with the help of voice
and speech processing. The proposed approach has been developed with the
objective of incorporation with futuristic artificial intelligence systems for
improving human-computer interactions.
</dc:description>
 <dc:description>Comment: 3 pages, Published with International Journal of Computer Trends and
  Technology (IJCTT), Volume-52 Number-1, 2017</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10198</dc:identifier>
 <dc:identifier>International Journal of Computer Trends and Technology (IJCTT)
  V52(1):01-03, October 2017</dc:identifier>
 <dc:identifier>doi:10.14445/22312803/IJCTT-V52P101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10201</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Methods for Metadata Extraction from Scientific Literature</dc:title>
 <dc:creator>Tkaczyk, Dominika</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>I.7.5</dc:subject>
 <dc:subject>H.3.7</dc:subject>
 <dc:description>  Within the past few decades we have witnessed digital revolution, which moved
scholarly communication to electronic media and also resulted in a substantial
increase in its volume. Nowadays keeping track with the latest scientific
achievements poses a major challenge for the researchers. Scientific
information overload is a severe problem that slows down scholarly
communication and knowledge propagation across the academia. Modern research
infrastructures facilitate studying scientific literature by providing
intelligent search tools, proposing similar and related documents, visualizing
citation and author networks, assessing the quality and impact of the articles,
and so on. In order to provide such high quality services the system requires
the access not only to the text content of stored documents, but also to their
machine-readable metadata. Since in practice good quality metadata is not
always available, there is a strong demand for a reliable automatic method of
extracting machine-readable metadata directly from source documents. This
research addresses these problems by proposing an automatic, accurate and
flexible algorithm for extracting wide range of metadata directly from
scientific articles in born-digital form. Extracted information includes basic
document metadata, structured full text and bibliography section. Designed as a
universal solution, proposed algorithm is able to handle a vast variety of
publication layouts with high precision and thus is well-suited for analyzing
heterogeneous document collections. This was achieved by employing supervised
and unsupervised machine-learning algorithms trained on large, diverse
datasets. The evaluation we conducted showed good performance of proposed
metadata extraction algorithm. The comparison with other similar solutions also
proved our algorithm performs better than competition for most metadata types.
</dc:description>
 <dc:description>Comment: PhD Thesis</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10201</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10202</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polar Coding for the Cognitive Interference Channel with Confidential
  Messages</dc:title>
 <dc:creator>Zheng, Mengfan</dc:creator>
 <dc:creator>Chen, Wen</dc:creator>
 <dc:creator>Ling, Cong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose a low-complexity, secrecy capacity achieving polar
coding scheme for the cognitive interference channel with confidential messages
(CICC) under the strong secrecy criterion. Existing polar coding schemes for
interference channels rely on the use of polar codes for the multiple access
channel, the code construction problem of which can be complicated. We show
that the whole secrecy capacity region of the CICC can be achieved by simple
point-to-point polar codes due to the cognitivity, and our proposed scheme
requires the minimum rate of randomness at the encoder.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10202</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10203</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intensional and Extensional Semantics of Bounded and Unbounded
  Nondeterminism</dc:title>
 <dc:creator>Laird, James</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We give extensional and intensional characterizations of nondeterministic
functional programs: as structure preserving functions between biorders, and as
nondeterministic sequential algorithms on ordered concrete data structures
which compute them. A fundamental result establishes that the extensional and
intensional representations of non-deterministic programs are equivalent, by
showing how to construct a unique sequential algorithm which computes a given
monotone and stable function, and describing the conditions on sequential
algorithms which correspond to continuity with respect to each order.
  We illustrate by defining may and must-testing denotational semantics for a
sequential functional language with bounded and unbounded choice operators. We
prove that these are computationally adequate, despite the non-continuity of
the must-testing semantics of unbounded nondeterminism. In the bounded case, we
prove that our continuous models are fully abstract with respect to
may-and-must testing by identifying a simple universal type, which may also
form the basis for models of the untyped lambda-calculus. In the unbounded case
we observe that our model contains computable functions which are not denoted
by terms, by identifying a further &quot;weak continuity&quot; property of the definable
elements, and use this to establish that it is not fully abstract.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10204</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An integral quadratic constraint framework for real-time steady-state
  optimization of linear time-invariant systems</dc:title>
 <dc:creator>Nelson, Zachary E.</dc:creator>
 <dc:creator>Mallada, Enrique</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Achieving optimal steady-state performance in real-time is an increasingly
necessary requirement of many critical infrastructure systems. In pursuit of
this goal, this paper builds a systematic design framework of feedback
controllers for Linear Time-Invariant (LTI) systems that continuously track the
optimal solution of some predefined optimization problem. The proposed solution
can be logically divided into three components. The first component estimates
the system state from the output measurements. The second component uses the
estimated state and computes a drift direction based on an optimization
algorithm. The third component computes an input to the LTI system that aims to
drive the system toward the optimal steady-state.
  We analyze the equilibrium characteristics of the closed-loop system and
provide conditions for optimality and stability. Our analysis shows that the
proposed solution guarantees optimal steady-state performance, even in the
presence of constant disturbances. Furthermore, by leveraging recent results on
the analysis of optimization algorithms using integral quadratic constraints
(IQCs), the proposed framework is able to translate input-output properties of
our optimization component into sufficient conditions, based on linear matrix
inequalities (LMIs), for global exponential asymptotic stability of the closed
loop system. We illustrate the versatility of our framework using several
examples.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10205</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polymorphism and the obstinate circularity of second order logic: a
  victims' tale</dc:title>
 <dc:creator>Pistone, Paolo</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03F05, 03F35</dc:subject>
 <dc:description>  The investigations on higher-order type theories and on the related notion of
parametric polymorphism constitute the technical counterpart of the old
foundational problem of the circularity (or impredicativity) of second and
higher order logic. However, the epistemological significance of such
investigations, and of their often non trivial results, has not received much
attention in the contemporary foundational debate. The results recalled in this
paper suggest that the question of the circularity of second order logic cannot
be reduced to the simple assessment of a vicious circle. Through a comparison
between the faulty consistency arguments given by Frege and Martin-L\&quot;of,
respectively for the logical system of the Grundgesetze (shown inconsistent by
Russell's paradox) and for the intuitionistic type theory with a type of all
types (shown inconsistent by Girard's paradox), and the normalization argument
for second order type theory (or System F), we indicate a bunch of subtle
mathematical problems and logical concepts hidden behind the hazardous idea of
impredicative quantification, constituting a vast (and largely unexplored)
domain for foundational research.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10217</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fronthaul-Aware Software-Defined Wireless Networks: Resource Allocation
  and User Scheduling</dc:title>
 <dc:creator>Liu, Chen-Feng</dc:creator>
 <dc:creator>Samarakoon, Sumudu</dc:creator>
 <dc:creator>Bennis, Mehdi</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Software-defined networking (SDN) provides an agile and programmable way to
optimize radio access networks via a control-data plane separation.
Nevertheless, reaping the benefits of wireless SDN hinges on making optimal use
of the limited wireless fronthaul capacity. In this work, the problem of
fronthaul-aware resource allocation and user scheduling is studied. To this
end, a two-timescale fronthaul-aware SDN control mechanism is proposed in which
the controller maximizes the time-averaged network throughput by enforcing a
coarse correlated equilibrium in the long timescale. Subsequently, leveraging
the controller's recommendations, each base station schedules its users using
Lyapunov stochastic optimization in the short timescale, i.e., at each time
slot. Simulation results show that significant network throughput enhancements
and up to 40% latency reduction are achieved with the aid of the SDN
controller. Moreover, the gains are more pronounced for denser network
deployments.
</dc:description>
 <dc:description>Comment: Accepted in IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10217</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2017.2768358</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10224</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BridgeNets: Student-Teacher Transfer Learning Based on Recursive Neural
  Networks and its Application to Distant Speech Recognition</dc:title>
 <dc:creator>Kim, Jaeyoung</dc:creator>
 <dc:creator>El-Khamy, Mostafa</dc:creator>
 <dc:creator>Lee, Jungwon</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Despite the remarkable progress achieved on automatic speech recognition,
recognizing far-field speeches mixed with various noise sources is still a
challenging task. In this paper, we introduce novel student-teacher transfer
learning, BridgeNet which can provide a solution to improve distant speech
recognition. There are two key features in BridgeNet. First, BridgeNet extends
traditional student-teacher frameworks by providing multiple hints from a
teacher network. Hints are not limited to the soft labels from a teacher
network. Teacher's intermediate feature representations can better guide a
student network to learn how to denoise or dereverberate noisy input. Second,
the proposed recursive architecture in the BridgeNet can iteratively improve
denoising and recognition performance. The experimental results of BridgeNet
showed significant improvements in tackling the distant speech recognition
problem, where it achieved up to 13.24% relative WER reductions on AMI corpus
compared to a baseline neural network without teacher's hints.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10225</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Detection of Flash Malware: Limitations and Open Issues</dc:title>
 <dc:creator>Maiorca, Davide</dc:creator>
 <dc:creator>Biggio, Battista</dc:creator>
 <dc:creator>Chiappe, Maria Elena</dc:creator>
 <dc:creator>Giacinto, Giorgio</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  During the past two years, Flash malware has become one of the most insidious
threats to detect, with almost 600 critical vulnerabilities targeting Adobe
Flash Player disclosed in the wild. Research has shown that machine learning
can be successfully used to tackle this increasing variability and
sophistication of Flash malware, by simply leveraging static analysis to
extract information from the structure of the file or from its bytecode.
However, the robustness of such systems against well-crafted evasion attempts -
also known as adversarial examples - has never been investigated. In this
paper, we first discuss how to craft adversarial Flash malware examples, and
show that it suffices to only slightly manipulate them to evade detection. We
then empirically demonstrate that popular defense techniques proposed to
mitigate such threat, including re-training on adversarial examples, may not
always be effective. We argue that this occurs when the feature vectors
extracted from adversarial examples become indistinguishable from those of
benign data, meaning that the given feature representation is intrinsically
vulnerable. In this respect, we are the first to formally define and
quantitatively characterize this vulnerability, highlighting when an attack can
be countered by solely improving the security of the learning algorithm, or
when it requires also considering additional features. We conclude the paper by
suggesting alternative research directions to improve the security of
learning-based Flash malware detectors.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10225</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10227</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unified Functorial Signal Representation III: Foundations, Redundancy,
  $L^0$ and $L^2$ functors</dc:title>
 <dc:creator>Samant, Salil</dc:creator>
 <dc:creator>Joshi, Shiv Dutt</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:description>  In this paper we propose and lay the foundations of a functorial framework
for representing signals. By incorporating additional category-theoretic
relative and generative perspective alongside the classic set-theoretic measure
theory the fundamental concepts of redundancy, compression are formulated in a
novel authentic arrow-theoretic way. The existing classic framework
representing a signal as a vector of appropriate linear space is shown as a
special case of the proposed framework.
  Next in the context of signal-spaces as a categories we study the various
covariant and contravariant forms of $L^0$ and $L^2$ functors using categories
of measurable or measure spaces and their opposites involving Boolean and
measure algebras along with partial extension. Finally we contribute a novel
definition of intra-signal redundancy using general concept of isomorphism
arrow in a category covering the translation case and others as special cases.
Through category-theory we provide a simple yet precise explanation for the
well-known heuristic of lossless differential encoding standards yielding
better compressions in image types such as line drawings, iconic image, text
etc; as compared to classic representation techniques such as JPEG which choose
bases or frames in a global Hilbert space.
</dc:description>
 <dc:description>Comment: First draft version</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10227</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10230</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Not-So-Random Features</dc:title>
 <dc:creator>Bullins, Brian</dc:creator>
 <dc:creator>Zhang, Cyril</dc:creator>
 <dc:creator>Zhang, Yi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a principled method for kernel learning, which relies on a
Fourier-analytic characterization of translation-invariant or
rotation-invariant kernels. Our method produces a sequence of feature maps,
iteratively refining the SVM margin. We provide rigorous guarantees for
optimality and generalization, interpreting our algorithm as online
equilibrium-finding dynamics in a certain two-player min-max game. Evaluations
on synthetic and real-world datasets demonstrate scalability and consistent
improvements over related random features-based methods.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10230</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10237</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PriFi: A Low-Latency Local-Area Anonymous Communication Network</dc:title>
 <dc:creator>Barman, Ludovic</dc:creator>
 <dc:creator>Dacosta, Italo</dc:creator>
 <dc:creator>Zamani, Mahdi</dc:creator>
 <dc:creator>Zhai, Ennan</dc:creator>
 <dc:creator>Ford, Bryan</dc:creator>
 <dc:creator>Hubaux, Jean-Pierre</dc:creator>
 <dc:creator>Feigenbaum, Joan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Popular anonymity protocols such as Tor provide low communication latency but
are vulnerable to traffic-analysis attacks that can de-anonymize users.
Traffic-analysis resistant protocols typically do not achieve low-latency
communication (e.g., Dissent, Riffle), or are restricted to a specific type of
traffic (e.g., Herd, Aqua). In this paper, we present PriFi, the first
practical protocol for anonymous communication in local-area networks that is
provably secure against traffic-analysis attacks, has a low communication
latency, and is traffic agnostic. PriFi is based on Dining Cryptographer's
networks}, and uses a 3-layer architecture which removes the usual
anonymization bottleneck seen in mix networks: packets sent by the clients
follow their usual path, without any additional hop that would add latency. As
a second contribution, we propose a novel technique for protecting against
equivocation attacks, in which a malicious relay de-anonymizes clients by
sending them different information. In PriFi's architecture, this is achieved
without adding extra latency; in particular, clients do not need to gossip or
run consensus among themselves. Finally, we describe a technique for detecting
disruption (jamming) attacks by malicious clients and a blaming mechanism to
enforce accountability against such attacks. We have fully implemented PriFi
and evaluated its performance with well-known datasets. Our analysis is
twofold: first, we show that our architecture tolerates well client churn;
second, we show that the system can be used in practice with minimal latency
overhead (e.g., 70ms for 50 clients), and is compatible with delay-sensitive
application such as VoIP.
</dc:description>
 <dc:description>Comment: 13 pages, 10 figures</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10237</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10244</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimal Reachability is Hard To Approximate</dc:title>
 <dc:creator>Jadbabaie, Ali</dc:creator>
 <dc:creator>Olshevsky, Alexander</dc:creator>
 <dc:creator>Pappas, George J.</dc:creator>
 <dc:creator>Tzoumas, Vasileios</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this note, we consider the problem of choosing which nodes of a linear
dynamical system should be actuated so that the state transfer from the
system's initial condition to a given final state is possible. Assuming a
standard complexity hypothesis, we show that this problem cannot be efficiently
solved or approximated in polynomial, or even quasi-polynomial, time.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10244</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10248</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tensor network language model</dc:title>
 <dc:creator>Pestun, Vasily</dc:creator>
 <dc:creator>Vlassopoulos, Yiannis</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a new statistical model suitable for machine learning of systems
with long distance correlations such as natural languages. The model is based
on directed acyclic graph decorated by multi-linear tensor maps in the vertices
and vector spaces in the edges, called tensor network. Such tensor networks
have been previously employed for effective numerical computation of the
renormalization group flow on the space of effective quantum field theories and
lattice models of statistical mechanics. We provide explicit algebro-geometric
analysis of the parameter moduli space for tree graphs, discuss model
properties and applications such as statistical translation.
</dc:description>
 <dc:description>Comment: 21 pages</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10248</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10252</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimized quantum f-divergences and data processing</dc:title>
 <dc:creator>Wilde, Mark M.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>High Energy Physics - Theory</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:description>  The quantum relative entropy is a measure of the distinguishability of two
quantum states, and it is a unifying concept in quantum information theory:
many information measures such as entropy, conditional entropy, mutual
information, and entanglement measures can be realized from it. As such, there
has been broad interest in generalizing the notion to further understand its
most basic properties, one of which is the data processing inequality. The
quantum f-divergence of Petz is one generalization of the quantum relative
entropy, and it also leads to other relative entropies, such as the Petz-Renyi
relative entropies. In this paper, I introduce the optimized quantum
f-divergence as a related generalization of quantum relative entropy. I prove
that it satisfies the data processing inequality, and the method of proof
relies upon the operator Jensen inequality, similar to Petz's original
approach. Interestingly, the sandwiched Renyi relative entropies are particular
examples of the optimized f-divergence. Thus, one benefit of this paper is that
there is now a single, unified approach for establishing the data processing
inequality for both the Petz-Renyi and sandwiched Renyi relative entropies, for
the full range of parameters for which it is known to hold. This paper
discusses other aspects of the optimized f-divergence, such as the classical
case, the classical-quantum case, and how to construct optimized f-information
measures.
</dc:description>
 <dc:description>Comment: 36 pages</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10252</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10255</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequential Empirical Coordination Under an Output Entropy Constraint</dc:title>
 <dc:creator>Shafieepoorfard, Ehsan</dc:creator>
 <dc:creator>Raginsky, Maxim</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper considers the problem of sequential empirical coordination, where
the objective is to achieve a given value of the expected uniform deviation
between state-action empirical averages and statistical expectations under a
given strategic probability measure, with respect to a given universal
Glivenko-Cantelli class of test functions. A communication constraint is
imposed on the Shannon entropy of the resulting action sequence. It is shown
that the fundamental limit on the output entropy is given by the minimum of the
mutual information between the state and the action processes under all
strategic measures that have the same marginal state process as the target
measure and approximate the target measure to desired accuracy with respect to
the underlying Glivenko-Cantelli seminorm. The fundamental limit is shown to be
asymptotically achievable by tree-structured codes.
</dc:description>
 <dc:description>Comment: 26 pages</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10255</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10280</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One-shot and few-shot learning of word embeddings</dc:title>
 <dc:creator>Lampinen, Andrew K.</dc:creator>
 <dc:creator>McClelland, James L.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Standard deep learning systems require thousands or millions of examples to
learn a concept, and cannot integrate new concepts easily. By contrast, humans
have an incredible ability to do one-shot or few-shot learning. For instance,
from just hearing a word used in a sentence, humans can infer a great deal
about it, by leveraging what the syntax and semantics of the surrounding words
tells us. Here, we draw inspiration from this to highlight a simple technique
by which deep recurrent networks can similarly exploit their prior knowledge to
learn a useful representation for a new word from little data. This could make
natural language processing systems much more flexible, by allowing them to
learn continually from the new words they encounter.
</dc:description>
 <dc:description>Comment: 15 pages, 7 figures, under review as a conference paper at ICLR 2018</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:date>2018-01-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10280</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10289</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Numerical Analysis of Stability of High-Order Systems With a
  Time Delay</dc:title>
 <dc:creator>Armanious, George</dc:creator>
 <dc:creator>Lind, Rick</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Time delays are a common perturbation in systems with many states, such as
networked, distributed, or decentralized systems. Current methods analyzing the
stability of large systems with time delay typically produce very conservative
results. While more exact methods exist, these become inefficient for large
systems. This paper provides a methodology for analyzing the stability of
time-delayed systems that is derived from exact methods but is efficient for
high-order systems. The computational and memory cost of this new technique is
compared to the costs of existing techniques, and its efficiency is shown using
a distributed system with over four hundred states.
</dc:description>
 <dc:description>Comment: 20 pages, 7 figures, 5 Matlab files (3 scripts and 2 mat files), AIAA</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10289</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10290</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Vivado-HLS for Structural Design: a NoC Case Study</dc:title>
 <dc:creator>Zhao, Zhipeng</dc:creator>
 <dc:creator>Hoe, James C.</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  There have been ample successful examples of applying Xilinx Vivado's
&quot;function-to-module&quot; high-level synthesis (HLS) where the subject is
algorithmic in nature. In this work, we carried out a design study to assess
the effectiveness of applying Vivado-HLS in structural design. We employed
Vivado-HLS to synthesize C functions corresponding to standalone
network-on-chip (NoC) routers as well as complete multi-endpoint NoCs.
Interestingly, we find that describing a complete NoC comprising router
submodules faces fundamental difficulties not present in describing the routers
as standalone modules. Ultimately, we succeeded in using Vivado-HLS to produce
router and NoC modules that are exact cycle- and bit-accurate replacements of
our reference RTL-based router and NoC modules. Furthermore, the routers and
NoCs resulting from HLS and RTL are comparable in resource utilization and
critical path delay. Our experience subjectively suggests that HLS is able to
simplify the design effort even though much of the structural details had to be
provided in the HLS description through a combination of coding discipline and
explicit pragmas. The C++ source code can be found at
http://www.ece.cmu.edu/calcm/connect_hls.
</dc:description>
 <dc:description>Comment: A poster with the same title was presented at the 2017 International
  Symposium on Field Programmable Gate Arrays</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10290</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10292</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ranking Functions for Vector Addition Systems</dc:title>
 <dc:creator>Zuleger, Florian</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Vector addition systems are an important model in theoretical computer
science and have been used for the analysis of systems in a variety of areas.
Termination is a crucial property of vector addition systems and has received
considerable interest in the literature. In this paper we give a complete
method for the construction of ranking functions for vector addition systems
with states. The interest in ranking functions is motivated by the fact that
ranking functions provide valuable additional information in case of
termination: They provide an explanation for the progress of the vector
addition system, which can be reported to the user of a verification tool, and
can be used as certificates for termination. Moreover, we show how ranking
functions can be used for the computational complexity analysis of vector
addition systems (here complexity refers to the number of steps the vector
addition system under analysis can take in terms of the given initial vector).
</dc:description>
 <dc:date>2017-10-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10292</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10294</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Permissive Finite-State Controllers of POMDPs using Parameter Synthesis</dc:title>
 <dc:creator>Junges, Sebastian</dc:creator>
 <dc:creator>Jansen, Nils</dc:creator>
 <dc:creator>Wimmer, Ralf</dc:creator>
 <dc:creator>Quatmann, Tim</dc:creator>
 <dc:creator>Winterer, Leonore</dc:creator>
 <dc:creator>Katoen, Joost-Pieter</dc:creator>
 <dc:creator>Becker, Bernd</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We study finite-state controllers (FSCs) for partially observable Markov
decision processes (POMDPs).
  The key insight is that computing (randomized) FSCs on POMDPs is equivalent
to synthesis for parametric Markov chains (pMCs).
  This correspondence enables using parameter synthesis techniques to compute
FSCs for POMDPs in a black-box fashion.
  We investigate how typical restrictions on parameter values affect the
quality of the obtained FSCs.
  Permissive strategies for POMDPs are obtained as regions of parameter values,
a natural output of parameter synthesis techniques.
  Experimental evaluation on several POMDP benchmarks shows promising results.
</dc:description>
 <dc:date>2017-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10295</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rhetorically-Induced Group Polarization in Small Opinion Networks</dc:title>
 <dc:creator>Gabbay, Michael</dc:creator>
 <dc:creator>Kelly, Zane</dc:creator>
 <dc:creator>Reedy, Justin</dc:creator>
 <dc:creator>Gastil, John</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We present a novel explanation for the group polarization effect whereby
discussion induces shifts toward the extreme. In our theory,
rhetorically-induced asymmetry preferentially facilitates majority formation
among extreme group members thereby skewing consensus outcomes further in the
extreme direction. Additionally, heuristic issue substitution can shift the
effective reference point for discussion from the policy reference, yielding
differential polarization by policy side. Two mathematical models implementing
the theory are introduced: a simple rhetorically-proximate majority model and
the accept-shift-constrict model of opinion dynamics on networks which allows
for the emergence of enduring majority positions. These models produce shifts
toward the extreme without the typical modeling assumption of greater
resistance to persuasion among extremists. Our online group discussion
experiment manipulated policy side, disagreement level, and network structure.
The results, which challenge existing polarization theories, are in qualitative
and quantitative accord with our theory and models.
</dc:description>
 <dc:description>Comment: 58 pages, 10 figures, 5 tables</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10295</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10296</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The implementation of a Deep Recurrent Neural Network Language Model on
  a Xilinx FPGA</dc:title>
 <dc:creator>Hao, Yufeng</dc:creator>
 <dc:creator>Quigley, Steven</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Recently, FPGA has been increasingly applied to problems such as speech
recognition, machine learning, and cloud computation such as the Bing search
engine used by Microsoft. This is due to FPGAs great parallel computation
capacity as well as low power consumption compared to general purpose
processors. However, these applications mainly focus on large scale FPGA
clusters which have an extreme processing power for executing massive matrix or
convolution operations but are unsuitable for portable or mobile applications.
This paper describes research on single-FPGA platform to explore the
applications of FPGAs in these fields. In this project, we design a Deep
Recurrent Neural Network (DRNN) Language Model (LM) and implement a hardware
accelerator with AXI Stream interface on a PYNQ board which is equipped with a
XILINX ZYNQ SOC XC7Z020 1CLG400C. The PYNQ has not only abundant programmable
logic resources but also a flexible embedded operation system, which makes it
suitable to be applied in the natural language processing field. We design the
DRNN language model with Python and Theano, train the model on a CPU platform,
and deploy the model on a PYNQ board to validate the model with Jupyter
notebook. Meanwhile, we design the hardware accelerator with Overlay, which is
a kind of hardware library on PYNQ, and verify the acceleration effect on the
PYNQ board. Finally, we have found that the DRNN language model can be deployed
on the embedded system smoothly and the Overlay accelerator with AXI Stream
interface performs at 20 GOPS processing throughput, which constitutes a 70.5X
and 2.75X speed up compared to the work in Ref.30 and Ref.31 respectively.
</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10296</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10304</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Few-shot Autoregressive Density Estimation: Towards Learning to Learn
  Distributions</dc:title>
 <dc:creator>Reed, Scott</dc:creator>
 <dc:creator>Chen, Yutian</dc:creator>
 <dc:creator>Paine, Thomas</dc:creator>
 <dc:creator>Oord, A&#xe4;ron van den</dc:creator>
 <dc:creator>Eslami, S. M. Ali</dc:creator>
 <dc:creator>Rezende, Danilo</dc:creator>
 <dc:creator>Vinyals, Oriol</dc:creator>
 <dc:creator>de Freitas, Nando</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep autoregressive models have shown state-of-the-art performance in density
estimation for natural images on large-scale datasets such as ImageNet.
However, such models require many thousands of gradient-based weight updates
and unique image examples for training. Ideally, the models would rapidly learn
visual concepts from only a handful of examples, similar to the manner in which
humans learns across many vision tasks. In this paper, we show how 1) neural
attention and 2) meta learning techniques can be used in combination with
autoregressive models to enable effective few-shot density estimation. Our
proposed modifications to PixelCNN result in state-of-the art few-shot density
estimation on the Omniglot dataset. Furthermore, we visualize the learned
attention policy and find that it learns intuitive algorithms for simple tasks
such as image mirroring on ImageNet and handwriting on Omniglot without
supervision. Finally, we extend the model to natural images and demonstrate
few-shot image generation on the Stanford Online Products dataset.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10304</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10307</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The James construction and $\pi_4(\mathbb{S}^3)$ in homotopy type theory</dc:title>
 <dc:creator>Brunerie, Guillaume</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:description>  In the first part of this paper we present a formalization in Agda of the
James construction in homotopy type theory. We include several fragments of
code to show what the Agda code looks like, and we explain several techniques
that we used in the formalization. In the second part, we use the James
construction to give a constructive proof that $\pi_4(\mathbb{S}^3)$ is of the
form $\mathbb{Z}/n\mathbb{Z}$ (but we do not compute the $n$ here).
</dc:description>
 <dc:description>Comment: 30 pages</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10307</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10313</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Self-Training Method for Semi-Supervised GANs</dc:title>
 <dc:creator>Do-Omri, Alan</dc:creator>
 <dc:creator>Wu, Dalei</dc:creator>
 <dc:creator>Liu, Xiaohua</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Since the creation of Generative Adversarial Networks (GANs), much work has
been done to improve their training stability, their generated image quality,
their range of application but nearly none of them explored their self-training
potential. Self-training has been used before the advent of deep learning in
order to allow training on limited labelled training data and has shown
impressive results in semi-supervised learning. In this work, we combine these
two ideas and make GANs self-trainable for semi-supervised learning tasks by
exploiting their infinite data generation potential. Results show that using
even the simplest form of self-training yields an improvement. We also show
results for a more complex self-training scheme that performs at least as well
as the basic self-training scheme but with significantly less data
augmentation.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10313</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10321</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectral Graph Wavelets for Structural Role Similarity in Networks</dc:title>
 <dc:creator>Donnat, Claire</dc:creator>
 <dc:creator>Zitnik, Marinka</dc:creator>
 <dc:creator>Hallac, David</dc:creator>
 <dc:creator>Leskovec, Jure</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Nodes residing in different parts of a graph can have similar structural
roles within their local network topology. The identification of such roles
provides key insight into the organization of networks and can also be used to
inform machine learning on graphs. However, learning structural representations
of nodes is a challenging unsupervised-learning task, which typically involves
manually specifying and tailoring topological features for each node. Here we
develop GraphWave, a method that represents each node's local network
neighborhood via a low-dimensional embedding by leveraging spectral graph
wavelet diffusion patterns. We prove that nodes with similar local network
neighborhoods will have similar GraphWave embeddings even though these nodes
may reside in very different parts of the network. Our method scales linearly
with the number of edges and does not require any hand-tailoring of topological
features. We evaluate performance on both synthetic and real-world datasets,
obtaining improvements of up to 71% over state-of-the-art baselines.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10322</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Maximally Recoverable Local Reconstruction Codes</dc:title>
 <dc:creator>Gopi, Sivakanth</dc:creator>
 <dc:creator>Guruswami, Venkatesan</dc:creator>
 <dc:creator>Yekhanin, Sergey</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In recent years the explosion in the volumes of data being stored online has
resulted in distributed storage systems transitioning to erasure coding based
schemes. Local Reconstruction Codes (LRCs) have emerged as the codes of choice
for these applications. An $(n,r,h,a,q)$-LRC is a $q$-ary code, where encoding
is as a two stage process. In the first stage, $h$ redundant parity symbols are
generated from $k$ data symbols. In the second stage, the $k+h$ symbols are
partitioned into sets of size $r-a$ and each set is extended with $a$ redundant
symbols using an MDS code to form a local group. Local groups ensure that when
at most $a$ coordinates are erased, any missing coordinate can be recovered by
accessing at most $r-a$ symbols. Also, if a larger number of coordinates is
erased; then missing symbols can be recovered by potentially accessing all
remaining symbols.
  An $(n,r,h,a,q)$-LRC code as above is Maximally Recoverable (MR), if it
corrects all erasure patterns which are information theoretically correctable
given the presence of local groups. Obtaining MR LRCs over finite fields of
minimal size is important in practice and has been the goal of a line of work
in coding theory. In this work we make progress towards this goal. In
particular, we show that when $a$ and $h$ are constant and $r$ may grow, for
every maximally recoverable LRC, $q\geq \Omega_{a,h}\left(n\cdot
r^{\min\{a,h-2\}}\right).$ Prior to our work, there was no super-linear lower
bound known on the field size of MR LRCs for any setting of parameters. We also
give an optimal construction when there are two global parities ($h=2$) and
improve existing constructions when there are three global parities ($h=3$).
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:date>2017-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10322</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10325</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Power Modelling for Heterogeneous Cloud-Edge Data Centers</dc:title>
 <dc:creator>Chen, Kai</dc:creator>
 <dc:creator>Varghese, Blesson</dc:creator>
 <dc:creator>Kilpatrick, Peter</dc:creator>
 <dc:creator>Nikolopoulos, Dimitrios S.</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Existing power modelling research focuses not on the method used for
developing models but rather on the model itself. This paper aims to develop a
method for deploying power models on emerging processors that will be used, for
example, in cloud-edge data centers. Our research first develops a hardware
counter selection method that appropriately selects counters most correlated to
power on ARM and Intel processors. Then, we propose a two stage power model
that works across multiple architectures. The key results are: (i) the
automated hardware performance counter selection method achieves comparable
selection to the manual selection methods reported in literature, and (ii) the
two stage power model can predict dynamic power more accurately on both ARM and
Intel processors when compared to classic power models.
</dc:description>
 <dc:description>Comment: 10 pages,10 figures,conference</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10325</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10328</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisit Fuzzy Neural Network: Demystifying Batch Normalization and ReLU
  with Generalized Hamming Network</dc:title>
 <dc:creator>Fan, Lixin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We revisit fuzzy neural network with a cornerstone notion of generalized
hamming distance, which provides a novel and theoretically justified framework
to re-interpret many useful neural network techniques in terms of fuzzy logic.
In particular, we conjecture and empirically illustrate that, the celebrated
batch normalization (BN) technique actually adapts the normalized bias such
that it approximates the rightful bias induced by the generalized hamming
distance. Once the due bias is enforced analytically, neither the optimization
of bias terms nor the sophisticated batch normalization is needed. Also in the
light of generalized hamming distance, the popular rectified linear units
(ReLU) can be treated as setting a minimal hamming distance threshold between
network inputs and weights. This thresholding scheme, on the one hand, can be
improved by introducing double thresholding on both extremes of neuron outputs.
On the other hand, ReLUs turn out to be non-essential and can be removed from
networks trained for simple tasks like MNIST classification. The proposed
generalized hamming network (GHN) as such not only lends itself to rigorous
analysis and interpretation within the fuzzy logic theory but also demonstrates
fast learning speed, well-controlled behaviour and state-of-the-art
performances on a variety of learning tasks.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures, NIPS 2017</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10328</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10329</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lower Bounds for Higher-Order Convex Optimization</dc:title>
 <dc:creator>Agarwal, Naman</dc:creator>
 <dc:creator>Hazan, Elad</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  State-of-the-art methods in convex and non-convex optimization employ
higher-order derivative information, either implicitly or explicitly. We
explore the limitations of higher-order optimization and prove that even for
convex optimization, a polynomial dependence on the approximation guarantee and
higher-order smoothness parameters is necessary. As a special case, we show
Nesterov's accelerated cubic regularization method to be nearly tight.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10329</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10330</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-modal Aggregation for Video Classification</dc:title>
 <dc:creator>Chen, Chen</dc:creator>
 <dc:creator>Zhao, Xiaowei</dc:creator>
 <dc:creator>Liu, Yang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we present a solution to Large-Scale Video Classification
Challenge (LSVC2017) [1] that ranked the 1st place. We focused on a variety of
modalities that cover visual, motion and audio. Also, we visualized the
aggregation process to better understand how each modality takes effect. Among
the extracted modalities, we found Temporal-Spatial features calculated by 3D
convolution quite promising that greatly improved the performance. We attained
the official metric mAP 0.8741 on the testing set with the ensemble model.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10330</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10335</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Similarity-based Multi-label Learning</dc:title>
 <dc:creator>Rossi, Ryan A.</dc:creator>
 <dc:creator>Ahmed, Nesreen K.</dc:creator>
 <dc:creator>Eldardiry, Hoda</dc:creator>
 <dc:creator>Zhou, Rong</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Multi-label classification is an important learning problem with many
applications. In this work, we propose a principled similarity-based approach
for multi-label learning called SML. We also introduce a similarity-based
approach for predicting the label set size. The experimental results
demonstrate the effectiveness of SML for multi-label classification where it is
shown to compare favorably with a wide variety of existing algorithms across a
range of evaluation criterion.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10335</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10336</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling and Real-Time Scheduling of DC Platform Supply Vessel for Fuel
  Efficient Operation</dc:title>
 <dc:creator>Satpathi, Kuntal</dc:creator>
 <dc:creator>Balijepalli, VSK Murthy</dc:creator>
 <dc:creator>Ukil, Abhisek</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  DC marine architecture integrated with variable speed diesel generators (DGs)
has garnered the attention of the researchers primarily because of its ability
to deliver fuel efficient operation. This paper aims in modeling and to
autonomously perform real-time load scheduling of dc platform supply vessel
(PSV) with an objective to minimize specific fuel oil consumption (SFOC) for
better fuel efficiency. Focus has been on the modeling of various components
and control routines, which are envisaged to be an integral part of dc PSVs.
Integration with photovoltaic-based energy storage system (ESS) has been
considered as an option to cater for the short time load transients. In this
context, this paper proposes a real-time transient simulation scheme, which
comprises of optimized generation scheduling of generators and ESS using dc
optimal power flow algorithm. This framework considers real dynamics of dc PSV
during various marine operations with possible contingency scenarios, such as
outage of generation systems, abrupt load changes, and unavailability of ESS.
The proposed modeling and control routines with real-time transient simulation
scheme have been validated utilizing the real-time marine simulation platform.
The results indicate that the coordinated treatment of renewable based ESS with
DGs operating with optimized speed yields better fuel savings. This has been
observed in improved SFOC operating trajectory for critical marine missions.
Furthermore, SFOC minimization at multiple suboptimal points with its treatment
in the real-time marine system is also highlighted.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10336</dc:identifier>
 <dc:identifier>IEEE Transactions on Transportation Electrification, vol. 3, no.
  3, pp. 762-778, 2017</dc:identifier>
 <dc:identifier>doi:10.1109/TTE.2017.2744180</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10339</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved approximation of layout problems on random graphs</dc:title>
 <dc:creator>Cheung, Kevin K. H.</dc:creator>
 <dc:creator>Girardet, Patrick D.</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Inspired by previous work of Diaz, Petit, Serna, and Trevisan (Approximating
layout problems on random graphs Discrete Mathematics, 235, 2001, 245--253), we
show that several well-known graph layout problems are approximable to within a
factor arbitrarily close to 1 of the optimal with high probability for random
graphs drawn from an Erd\&quot;os-Renyi distribution with appropriate sparsity
conditions. Moreover, we show that the same results hold for the analogous
problems on directed acyclic graphs.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10345</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Implicit Bias of Gradient Descent on Separable Data</dc:title>
 <dc:creator>Soudry, Daniel</dc:creator>
 <dc:creator>Hoffer, Elad</dc:creator>
 <dc:creator>Srebro, Nathan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We show that gradient descent on an unregularized logistic regression problem
with separable data converges to the max-margin solution. The result
generalizes also to other monotone decreasing loss functions with an infimum at
infinity, and we also discuss a multi-class generalizations to the cross
entropy loss. Furthermore, we show this convergence is very slow, and only
logarithmic in the convergence of the loss itself. This can help explain the
benefit of continuing to optimize the logistic or cross-entropy loss even after
the training error is zero and the training loss is extremely small, and, as we
show, even if the validation loss increases. Our methodology can also aid in
understanding implicit regularization in more complex models and with other
optimization methods.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10348</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-level Residual Networks from Dynamical Systems View</dc:title>
 <dc:creator>Chang, Bo</dc:creator>
 <dc:creator>Meng, Lili</dc:creator>
 <dc:creator>Haber, Eldad</dc:creator>
 <dc:creator>Tung, Frederick</dc:creator>
 <dc:creator>Begert, David</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep residual networks (ResNets) and their variants are widely used in many
computer vision applications and natural language processing tasks. However,
the theoretical principles for designing and training ResNets are still not
fully understood. Recently, several points of view have emerged to try to
interpret ResNet theoretically, such as unraveled view, unrolled iterative
estimation and dynamical systems view. In this paper, we adopt the dynamical
systems point of view, and analyze the lesioning properties of ResNet both
theoretically and experimentally. Based on these analyses, we additionally
propose a novel method for accelerating ResNet training. We apply the proposed
method to train ResNets and Wide ResNets for three image classification
benchmarks, reducing training time by more than 40\% with superior or on-par
accuracy.
</dc:description>
 <dc:description>Comment: Submitted as a conference paper at ICLR 2018</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10348</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10350</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-Time Robust Finger Gaits Planning under Object Shape and Dynamics
  Uncertainties</dc:title>
 <dc:creator>Fan, Yongxiang</dc:creator>
 <dc:creator>Tang, Te</dc:creator>
 <dc:creator>Lin, Hsien-Chung</dc:creator>
 <dc:creator>Zhao, Yu</dc:creator>
 <dc:creator>Tomizuka, Masayoshi</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Dexterous manipulation has broad applications in assembly lines, warehouses
and agriculture. To perform large-scale manipulation tasks for various objects,
a multi-fingered robotic hand sometimes has to sequentially adjust its grasping
gestures, i.e. the finger gaits, to address the workspace limits and guarantee
the object stability. However, realizing finger gaits planning in dexterous
manipulation is challenging due to the complicated grasp quality metrics,
uncertainties on object shapes and dynamics (mass and moment of inertia), and
unexpected slippage under uncertain contact dynamics. In this paper, a
dual-stage optimization based planner is proposed to handle these challenges.
In the first stage, a velocity-level finger gaits planner is introduced by
combining object grasp quality with hand manipulability. The proposed finger
gaits planner is computationally efficient and realizes finger gaiting without
3D model of the object. In the second stage, a robust manipulation controller
using robust control and force optimization is proposed to address object
dynamics uncertainties and external disturbances. The dual-stage planner is
able to guarantee stability under unexpected slippage caused by uncertain
contact dynamics. Moreover, it does not require velocity measurement or
expensive 3D/6D tactile sensors. The proposed dual-stage optimization based
planner is verified by simulations on Mujoco.
</dc:description>
 <dc:description>Comment: Accepted by IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS) 2017</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10352</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Design using Neural Networks and Gradient Descent</dc:title>
 <dc:creator>Hennigh, Oliver</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  We propose a novel method that makes use of deep neural networks and gradient
decent to perform automated design on complex real world engineering tasks. Our
approach works by training a neural network to mimic the fitness function of a
design optimization task and then, using the differential nature of the neural
network, perform gradient decent to maximize the fitness. We demonstrate this
methods effectiveness by designing an optimized heat sink and both 2D and 3D
airfoils that maximize the lift drag ratio under steady state flow conditions.
We highlight that our method has two distinct benefits over other automated
design approaches. First, evaluating the neural networks prediction of fitness
can be orders of magnitude faster then simulating the system of interest.
Second, using gradient decent allows the design space to be searched much more
efficiently then other gradient free methods. These two strengths work together
to overcome some of the current shortcomings of automated design.
</dc:description>
 <dc:description>Comment: 12 pages, 9 figures</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10352</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10355</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional Neural Networks Via Node-Varying Graph Filters</dc:title>
 <dc:creator>Gama, Fernando</dc:creator>
 <dc:creator>Leus, Geert</dc:creator>
 <dc:creator>Marques, Antonio Garcia</dc:creator>
 <dc:creator>Ribeiro, Alejandro</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Convolutional neural networks (CNNs) are being applied to an increasing
number of problems and fields due to their superior performance in
classification and regression tasks. Since two of the key operations that CNNs
implement are convolution and pooling, this type of networks is implicitly
designed to act on data described by regular structures such as images.
Motivated by the recent interest in processing signals defined in irregular
domains, we advocate a CNN architecture that operates on signals supported on
graphs. The proposed design replaces the classical convolution not with a
node-invariant graph filter (GF), which is the natural generalization of
convolution to graph domains, but with a node-varying GF. This filter extracts
different local features without increasing the output dimension of each layer
and, as a result, bypasses the need for a pooling stage while involving only
local operations. A second contribution is to replace the node-varying GF with
a hybrid node-varying GF, which is a new type of GF introduced in this paper.
While the alternative architecture can still be run locally without requiring a
pooling stage, the number of trainable parameters is smaller and can be
rendered independent of the data dimension. Tests are run on a synthetic source
localization problem and on the 20NEWS dataset.
</dc:description>
 <dc:description>Comment: Submitted to ICASSP 2018 (IEEE International Conference on Acoustics,
  Speech and Signal Processing)</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10355</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10356</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Control of Wireless Computing Networks</dc:title>
 <dc:creator>Feng, Hao</dc:creator>
 <dc:creator>Llorca, Jaime</dc:creator>
 <dc:creator>Tulino, Antonia M.</dc:creator>
 <dc:creator>Molisch, Andreas F.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Augmented information (AgI) services allow users to consume information that
results from the execution of a chain of service functions that process source
information to create real-time augmented value. Applications include real-time
analysis of remote sensing data, real-time computer vision, personalized video
streaming, and augmented reality, among others. We consider the problem of
optimal distribution of AgI services over a wireless computing network, in
which nodes are equipped with both communication and computing resources. We
characterize the wireless computing network capacity region and design a joint
flow scheduling and resource allocation algorithm that stabilizes the
underlying queuing system while achieving a network cost arbitrarily close to
the minimum, with a tradeoff in network delay. Our solution captures the unique
chaining and flow scaling aspects of AgI services, while exploiting the use of
the broadcast approach coding scheme over the wireless channel.
</dc:description>
 <dc:description>Comment: 30 pages, journal</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10356</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10361</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Residual Learning for Small-Footprint Keyword Spotting</dc:title>
 <dc:creator>Tang, Raphael</dc:creator>
 <dc:creator>Lin, Jimmy</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We explore the application of deep residual learning and dilated convolutions
to the keyword spotting task, using the recently-released Google Speech
Commands Dataset as our benchmark. Our best residual network (ResNet)
implementation significantly outperforms Google's previous convolutional neural
networks in terms of accuracy. By varying model depth and width, we can achieve
compact models that also outperform previous small-footprint variants. To our
knowledge, we are the first to examine these approaches for keyword spotting,
and our results establish an open-source state-of-the-art reference to support
the development of future speech-based interfaces.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10361</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10363</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diff-DAC: Distributed Actor-Critic for Multitask Deep Reinforcement
  Learning</dc:title>
 <dc:creator>Macua, Sergio Valcarcel</dc:creator>
 <dc:creator>Tukiainen, Aleksi</dc:creator>
 <dc:creator>Hern&#xe1;ndez, Daniel Garc&#xed;a-Oca&#xf1;a</dc:creator>
 <dc:creator>Baldazo, David</dc:creator>
 <dc:creator>de Cote, Enrique Munoz</dc:creator>
 <dc:creator>Zazo, Santiago</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a multiagent distributed actor-critic algorithm for multitask
reinforcement learning (MRL), named Diff-DAC. The agents are connected, forming
a (possibly sparse) network. Each agent is assigned a task and has access to
data from this local task only. During the learning process, the agents are
able to communicate some parameters to their neighbors. Since the agents
incorporate their neighbors' parameters into their own learning rules, the
information is diffused across the network, and they can learn a common policy
that generalizes well across all tasks. Diff-DAC is scalable since the
computational complexity and communication overhead per agent grow with the
number of neighbors, rather than with the total number of agents. Moreover, the
algorithm is fully distributed in the sense that agents self-organize, with no
need for coordinator node. Diff-DAC follows an actor-critic scheme where the
value function and the policy are approximated with deep neural networks, being
able to learn expressive policies from raw data. As a by-product of Diff-DAC's
derivation from duality theory, we provide novel insights into the standard
actor-critic framework, showing that it is actually an instance of the dual
ascent method to approximate the solution of a linear program. Experiments
illustrate the performance of the algorithm in the cart-pole, inverted
pendulum, and swing-up cart-pole environments.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:date>2017-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10363</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10364</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consistency of Lipschitz learning with infinite unlabeled data and
  finite labeled data</dc:title>
 <dc:creator>Calder, Jeff</dc:creator>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>35D40, 35J60, 65N06,</dc:subject>
 <dc:description>  We prove that Lipschitz learning on graphs is consistent with the absolutely
minimal Lipschitz extension problem in the limit of infinite unlabeled data and
finite labeled data. In particular, we show that the continuum limit is
independent of the distribution of the unlabeled data, which suggests the
algorithm is fully supervised (and not semi- supervised) in this setting. We
also present some new ideas for modifying Lipschitz learning to incorporate the
distribution of the unlabeled data.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10364</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10366</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lower Bounds for Two-Sample Structural Change Detection in Ising and
  Gaussian Models</dc:title>
 <dc:creator>Gangrade, Aditya</dc:creator>
 <dc:creator>Nazer, Bobak</dc:creator>
 <dc:creator>Saligrama, Venkatesh</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  The change detection problem is to determine if the Markov network structures
of two Markov random fields differ from one another given two sets of samples
drawn from the respective underlying distributions. We study the trade-off
between the sample sizes and the reliability of change detection, measured as a
minimax risk, for the important cases of the Ising models and the Gaussian
Markov random fields restricted to the models which have network structures
with $p$ nodes and degree at most $d$, and obtain information-theoretic lower
bounds for reliable change detection over these models. We show that for the
Ising model, $\Omega\left(\frac{d^2}{(\log d)^2}\log p\right)$ samples are
required from each dataset to detect even the sparsest possible changes, and
that for the Gaussian, $\Omega\left( \gamma^{-2} \log(p)\right)$ samples are
required from each dataset to detect change, where $\gamma$ is the smallest
ratio of off-diagonal to diagonal terms in the precision matrices of the
distributions. These bounds are compared to the corresponding results in
structure learning, and closely match them under mild conditions on the model
parameters. Thus, our change detection bounds inherit partial tightness from
the structure learning schemes in previous literature, demonstrating that in
certain parameter regimes, the naive structure learning based approach to
change detection is minimax optimal up to constant factors.
</dc:description>
 <dc:description>Comment: Presented at the 55th Annual Allerton Conference on Communication,
  Control, and Computing, Oct. 2017</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10368</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Generative Dual Memory Network for Continual Learning</dc:title>
 <dc:creator>Kamra, Nitin</dc:creator>
 <dc:creator>Gupta, Umang</dc:creator>
 <dc:creator>Liu, Yan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Despite advances in deep learning, artificial neural networks do not learn
the same way as humans do. Today, neural networks can learn multiple tasks when
trained on them jointly, but cannot maintain performance on learnt tasks when
tasks are presented one at a time -- this phenomenon called catastrophic
forgetting is a fundamental challenge to overcome before neural networks can
learn continually from incoming data. In this work, we derive inspiration from
human memory to develop an architecture capable of learning continuously from
sequentially incoming tasks, while averting catastrophic forgetting.
Specifically, our model consists of a dual memory architecture to emulate the
complementary learning systems (hippocampus and the neocortex) in the human
brain, and maintains a consolidated long-term memory via generative replay of
past experiences. We (i) substantiate our claim that replay should be
generative, (ii) show the benefits of generative replay and dual memory via
experiments, and (iii) demonstrate improved performance retention even for
small models with low capacity. Our architecture displays many important
characteristics of the human memory and provides insights on the connection
between sleep and learning in humans.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10370</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topology Adaptive Graph Convolutional Networks</dc:title>
 <dc:creator>Du, Jian</dc:creator>
 <dc:creator>Zhang, Shanghang</dc:creator>
 <dc:creator>Wu, Guanhang</dc:creator>
 <dc:creator>Moura, Jose M. F.</dc:creator>
 <dc:creator>Kar, Soummya</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Convolution acts as a local feature extractor in convolutional neural
networks (CNNs). However, the convolution operation is not applicable when the
input data is supported on an irregular graph such as with social networks,
citation networks, or knowledge graphs. This paper proposes the topology
adaptive graph convolutional network (TAGCN), a novel graph convolutional
network that generalizes CNN architectures to graph-structured data and
provides a systematic way to design a set of fixed-size learnable filters to
perform convolutions on graphs. The topologies of these filters are adaptive to
the topology of the graph when they scan the graph to perform convolution,
replacing the square filter for the grid-structured data in traditional CNNs.
The outputs are the weighted sum of these filters' outputs, extraction of both
vertex features and strength of correlation between vertices. It can be used
with both directed and undirected graphs. The proposed TAGCN not only inherits
the properties of convolutions in CNN for grid-structured data, but it is also
consistent with convolution as defined in graph signal processing. Further, as
no approximation to the convolution is needed, TAGCN exhibits better
performance than existing graph-convolution-approximation methods on a number
of data sets. As only the polynomials of degree two of the adjacency matrix are
used, TAGCN is also computationally simpler than other recent methods.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:date>2017-12-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10370</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10378</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Change Detection Based on Average Consensus</dc:title>
 <dc:creator>Liu, Qinghua</dc:creator>
 <dc:creator>Xie, Yao</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Distributed change-point detection has been a fundamental problem when
performing real-time monitoring using sensor-networks. Most existing algorithms
require local sensors to exchange information with a global fusion center. We
present a distributed detection algorithm, where each sensor only exchanges
CUSUM statistic with their neighbors based on average consensus, and an alarm
is fired when local statistic exceeds a pre-specified global threshold. We
provide theoretical performance bounds showing that the performance of the
fully distributed scheme can match the centralized algorithms under some mild
conditions. Numerical experiments demonstrate the good performance of the
algorithm.
</dc:description>
 <dc:description>Comment: 17 pages, 10 figures</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:date>2017-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10378</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10379</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Almost-global tracking of the unactuated joint in a pendubot</dc:title>
 <dc:creator>Nayak, Aradhana</dc:creator>
 <dc:creator>Banavar, Ravi N.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Tracking the unactuated configuration variable in an underactuated system, in
a global sense, has not received much attention. Here we present a scheme to do
so for a pendubot - a two link robot actuated only at the first link. We
propose a control law for almost-global asymptotic tracking (AGAT) of a smooth
reference trajectory for the unactuated second joint of the pendubot. The
control law achieves almost-global tracking for any smooth reference trajectory
specified for the unactuated joint. Further, we generalize the proposed scheme
to an n-link system with as many (or more) degrees of actuation than
unactuation, and show that the result holds.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10380</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring Asymmetric Encoder-Decoder Structure for Context-based
  Sentence Representation Learning</dc:title>
 <dc:creator>Tang, Shuai</dc:creator>
 <dc:creator>Jin, Hailin</dc:creator>
 <dc:creator>Fang, Chen</dc:creator>
 <dc:creator>Wang, Zhaowen</dc:creator>
 <dc:creator>de Sa, Virginia R.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Context information plays an important role in human language understanding,
and it is also useful for machines to learn vector representations of language.
In this paper, we explore an asymmetric encoder-decoder structure for
unsupervised context-based sentence representation learning. As a result, we
build an encoder-decoder architecture with an RNN encoder and a CNN decoder. We
further combine a suite of effective designs to significantly improve model
efficiency while also achieving better performance. Our model is trained on two
different large unlabeled corpora, and in both cases transferability is
evaluated on a set of downstream language understanding tasks. We empirically
show that our model is simple and fast while producing rich sentence
representations that excel in downstream tasks.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:date>2018-01-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10380</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10381</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Partitioning Relational Matrices of Similarities or Dissimilarities
  using the Value of Information</dc:title>
 <dc:creator>Sledge, Isaac J.</dc:creator>
 <dc:creator>Principe, Jose C.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we provide an approach to clustering relational matrices whose
entries correspond to either similarities or dissimilarities between objects.
Our approach is based on the value of information, a parameterized,
information-theoretic criterion that measures the change in costs associated
with changes in information. Optimizing the value of information yields a
deterministic annealing style of clustering with many benefits. For instance,
investigators avoid needing to a priori specify the number of clusters, as the
partitions naturally undergo phase changes, during the annealing process,
whereby the number of clusters changes in a data-driven fashion. The
global-best partition can also often be identified.
</dc:description>
 <dc:description>Comment: Submitted to the IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10385</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capturing the Future by Replaying the Past</dc:title>
 <dc:creator>Koppel, James</dc:creator>
 <dc:creator>Solar-Lezama, Armando</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Delimited continuations are the mother of all monads! So goes the slogan
inspired by Filinski's 1994 paper, which showed that delimited continuations
can implement any monadic effect, letting the programmer use an effect as
easily as if it was built into the language. It's a shame that not many
languages have delimited continuations.
  Luckily, exceptions and state are also the mother of all monads! In this
Pearl, we show how to implement delimited continuations in terms of exceptions
and state, a construction we call thermometer continuations. While traditional
implementations of delimited continuations require some way of &quot;capturing&quot; an
intermediate state of the computation, the insight of thermometer continuations
is to reach this intermediate state by replaying the entire computation from
the start, guiding it using a &quot;replay stack&quot; it so that the same thing happens
until the captured point.
  Along the way, we explain delimited continuations and monadic reflection,
show how the Filinski construction lets thermometer continuations express any
monadic effect, share an elegant special-case for nondeterminism, and discuss
why our construction is not prevented by theoretical results that exceptions
and state cannot macro-express continuations.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10385</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10386</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Left-Right Skip-DenseNets for Coarse-to-Fine Object Categorization</dc:title>
 <dc:creator>Cheng, Changmao</dc:creator>
 <dc:creator>Fu, Yanwei</dc:creator>
 <dc:creator>Lu, Wenlian</dc:creator>
 <dc:creator>Jiang, Yu-Gang</dc:creator>
 <dc:creator>Feng, Jianfeng</dc:creator>
 <dc:creator>Xue, Xiangyang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Inspired by the recent neuroscience studies on the left-right asymmetry of
the brains in the low and high spatial frequency processing, we introduce a
novel type of network -- the left-right skip-densenets for coarse-to-fine
object categorization. This network can enable both coarse and fine-grained
classification in a single framework. We also for the first time propose the
layer-skipping mechanism which learns a gating network to predict whether skip
some layers in the testing stage. This layer-skipping mechanism assigns more
flexibility and capability to our network for the categorization tasks. Our
network is evaluated on three widely used datasets; the results show that our
network is more promising in solving the coarse-to-fine object categorization
than the competitors.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10387</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Range-Doppler-Angle Estimation Method for Passive Bistatic Radar</dc:title>
 <dc:creator>Wan, Liangtian</dc:creator>
 <dc:creator>Wang, Xianpeng</dc:creator>
 <dc:creator>Bi, Guoan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, an effective target detection and localization method is
proposed for a passive bistatic radar (PBR) system. The PBR system consists of
a commercial FM radio station, which is a non-cooperative illuminator of
opportunity (IO), referred to as the transmitter antenna and multiple
surveillance antennas that form an antenna array, e.g., uniform linear array
(ULA). Unlike other literatures where the reference signal is received by a
directional antenna, here, the reference signal (direct path) is estimated by
beamforming method. Then a modified extensive cancellation algorithm (MECA)
based on (least squares) LS method is proposed to solve the disturbance
cancellation. After cancelling the disturbance, the matched filter (MF) and LS
methods are used for range-Doppler estimation of targets, and then the angles
of targets are estimated based on beamforming method. The proposed method is
suitable for an antenna array. Simulation results are presented to illustrate
the superiority of the proposed MECA disturbance cancellation method and
parameter estimation method.
</dc:description>
 <dc:description>Comment: 5 pages, 7 figures</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10387</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10388</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimax Rates and Efficient Algorithms for Noisy Sorting</dc:title>
 <dc:creator>Mao, Cheng</dc:creator>
 <dc:creator>Weed, Jonathan</dc:creator>
 <dc:creator>Rigollet, Philippe</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  There has been a recent surge of interest in studying permutation-based
models for ranking from pairwise comparison data. Despite being structurally
richer and more robust than parametric ranking models, permutation-based models
are less well understood statistically and generally lack efficient learning
algorithms. In this work, we study a prototype of permutation-based ranking
models, namely, the noisy sorting model. We establish the optimal rates of
learning the model under two sampling procedures. Furthermore, we provide a
fast algorithm to achieve near-optimal rates if the observations are sampled
independently. Along the way, we discover properties of the symmetric group
which are of theoretical interest.
</dc:description>
 <dc:description>Comment: 27 pages, 2 figures</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10388</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10389</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Blocking Probability and Spatial Throughput Characterization for
  Cellular-Enabled UAV Network with Directional Antenna</dc:title>
 <dc:creator>Lyu, Jiangbin</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The past few years have witnessed a tremendous increase on the use of
unmanned aerial vehicles (UAVs) in civilian applications, which call for
high-performance communication between UAVs and their ground clients,
especially when they are densely deployed. To achieve this goal, cellular base
stations (BSs) can be leveraged to provide a new and promising solution to
support massive UAV communications simultaneously in a cost-effective way.
However, different from terrestrial communication channels, UAV-to-BS channels
are usually dominated by the light-of-sight (LoS) link, which aggravates the
co-channel interference and renders the spatial frequency reuse in existing
cellular networks ineffective. In this paper, we consider the use of a
directional antenna at each UAV to confine the interference to/from other UAV
users within a limited region and hence improve the spatial reuse of the
spectrum. Under this model, a UAV user may be temporarily blocked from
communication if it cannot find any BS in its antenna main-lobe, or it finds
that all BSs under its main-lobe are simultaneously covered by those of some
other UAVs and hence suffer from strong co-channel interference. Assuming
independent homogeneous Poisson point processes (HPPPs) for the UAVs' and
ground BSs' locations respectively, we first analytically derive a closed-form
upper bound for the UAV blocking probability and then characterize the
achievable average spatial throughput of the cellular-enabled UAV communication
network, in terms of various key parameters including the BS/UAV densities as
well as the UAV's flying altitude and antenna beamwidth. Simulation results
verify that the derived bound is practically tight, and further show that
adaptively adjusting the UAV altitude and/or beamwidth with different BS/UAV
densities can significantly reduce the UAV blocking probability and hence
improve the network spatial throughput.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures, submitted for possible publication</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10389</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10393</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Label Embedding Network: Learning Label Representation for Soft Training
  of Deep Networks</dc:title>
 <dc:creator>Sun, Xu</dc:creator>
 <dc:creator>Wei, Bingzhen</dc:creator>
 <dc:creator>Ren, Xuancheng</dc:creator>
 <dc:creator>Ma, Shuming</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a method, called Label Embedding Network, which can learn label
representation (label embedding) during the training process of deep networks.
With the proposed method, the label embedding is adaptively and automatically
learned through back propagation. The original one-hot represented loss
function is converted into a new loss function with soft distributions, such
that the originally unrelated labels have continuous interactions with each
other during the training process. As a result, the trained model can achieve
substantially higher accuracy and with faster convergence speed. Experimental
results based on competitive tasks demonstrate the effectiveness of the
proposed method, and the learned label embedding is reasonable and
interpretable. The proposed method achieves comparable or even better results
than the state-of-the-art systems. The source code is available at
\url{https://github.com/lancopku/LabelEmb}.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10393</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10394</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>M-RWTL: Learning Signal-Matched Rational Wavelet Transform in Lifting
  Framework</dc:title>
 <dc:creator>Ansari, Naushad</dc:creator>
 <dc:creator>Gupta, Anubha</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Transform learning is being extensively applied in several applications
because of its ability to adapt to a class of signals of interest. Often, a
transform is learned using a large amount of training data, while only limited
data may be available in many applications. Motivated with this, we propose
wavelet transform learning in the lifting framework for a given signal.
Significant contributions of this work are: 1) the existing theory of lifting
framework of the dyadic wavelet is extended to more generic rational wavelet
design, where dyadic is a special case and 2) the proposed work allows to learn
rational wavelet transform from a given signal and does not require large
training data. Since it is a signal-matched design, the proposed methodology is
called Signal-Matched Rational Wavelet Transform Learning in the Lifting
Framework (M-RWTL). The proposed M-RWTL method inherits all the advantages of
lifting, i.e., the learned rational wavelet transform is always invertible,
method is modular, and the corresponding M-RWTL system can also incorporate
nonlinear filters, if required. This may enhance the use of RWT in applications
which is so far restricted. M-RWTL is observed to perform better compared to
standard wavelet transforms in the applications of compressed sensing based
signal reconstruction.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10394</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10398</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Study of All-Convolutional Encoders for Connectionist Temporal
  Classification</dc:title>
 <dc:creator>Krishna, Kalpesh</dc:creator>
 <dc:creator>Lu, Liang</dc:creator>
 <dc:creator>Gimpel, Kevin</dc:creator>
 <dc:creator>Livescu, Karen</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Connectionist temporal classification (CTC) is a popular sequence prediction
approach for automatic speech recognition that is typically used with models
based on recurrent neural networks (RNNs). We explore whether deep
convolutional neural networks (CNNs) can be used effectively instead of RNNs as
the &quot;encoder&quot; in CTC. CNNs lack an explicit representation of the entire
sequence, but have the advantage that they are much faster to train. We present
an exploration of CNNs as encoders for CTC models, in the context of
character-based (lexicon-free) automatic speech recognition. In particular, we
explore a range of one-dimensional convolutional layers, which are particularly
efficient. We compare the performance of our CNN-based models against typical
RNNbased models in terms of training time, decoding time, model size and word
error rate (WER) on the Switchboard Eval2000 corpus. We find that our CNN-based
models are close in performance to LSTMs, while not matching them, and are much
faster to train and decode.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10398</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10400</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Total-Text: A Comprehensive Dataset for Scene Text Detection and
  Recognition</dc:title>
 <dc:creator>Chng, Chee Kheng</dc:creator>
 <dc:creator>Chan, Chee Seng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Text in curve orientation, despite being one of the common text orientations
in real world environment, has close to zero existence in well received scene
text datasets such as ICDAR2013 and MSRA-TD500. The main motivation of
Total-Text is to fill this gap and facilitate a new research direction for the
scene text community. On top of the conventional horizontal and multi-oriented
texts, it features curved-oriented text. Total-Text is highly diversified in
orientations, more than half of its images have a combination of more than two
orientations. Recently, a new breed of solutions that casted text detection as
a segmentation problem has demonstrated their effectiveness against
multi-oriented text. In order to evaluate its robustness against curved text,
we fine-tuned DeconvNet and benchmark it on Total-Text. Total-Text with its
annotation is available at https://github.com/cs-chan/Total-Text-Dataset
</dc:description>
 <dc:description>Comment: Accepted as Oral presentation in ICDAR2017 (Extended version, 13
  pages 17 figures). We introduce a new scene text dataset namely as
  Total-Text, which is more comprehensive than the existing scene text datasets
  as it consists of 1555 natural images with more than 3 different text
  orientations, one of a kind</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10402</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Termination in Convex Sets of Distributions</dc:title>
 <dc:creator>Sokolova, Ana</dc:creator>
 <dc:creator>Woracek, Harald</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Convex algebras, also called (semi)convex sets, are at the heart of modelling
probabilistic systems including probabilistic automata. Abstractly, they are
the Eilenberg-Moore algebras of the finitely supported distribution monad.
Concretely, they have been studied for decades within algebra and convex
geometry.
  In this paper we study the problem of extending a convex algebra by a single
point. Such extensions enable the modelling of termination in probabilistic
systems. We provide a full description of all possible extensions for a
particular class of convex algebras: For a fixed convex subset $D$ of a vector
space satisfying additional technical condition, we consider the algebra of
convex subsets of $D$. This class contains the convex algebras of convex
subsets of distributions, modelling (nondeterministic) probabilistic automata.
We also provide a full description of all possible extensions for the class of
free convex algebras, modelling fully probabilistic systems. Finally, we show
that there is a unique functorial extension, the so-called black-hole
extension.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10402</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10403</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trainable back-propagated functional transfer matrices</dc:title>
 <dc:creator>Cai, Cheng-Hao</dc:creator>
 <dc:creator>Xu, Yanyan</dc:creator>
 <dc:creator>Ke, Dengfeng</dc:creator>
 <dc:creator>Su, Kaile</dc:creator>
 <dc:creator>Sun, Jing</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Connections between nodes of fully connected neural networks are usually
represented by weight matrices. In this article, functional transfer matrices
are introduced as alternatives to the weight matrices: Instead of using real
weights, a functional transfer matrix uses real functions with trainable
parameters to represent connections between nodes. Multiple functional transfer
matrices are then stacked together with bias vectors and activations to form
deep functional transfer neural networks. These neural networks can be trained
within the framework of back-propagation, based on a revision of the delta
rules and the error transmission rule for functional connections. In
experiments, it is demonstrated that the revised rules can be used to train a
range of functional connections: 20 different functions are applied to neural
networks with up to 10 hidden layers, and most of them gain high test
accuracies on the MNIST database. It is also demonstrated that a functional
transfer matrix with a memory function can roughly memorise a non-cyclical
sequence of 400 digits.
</dc:description>
 <dc:description>Comment: 39 pages, 4 figures, submitted as a journal article</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10403</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10404</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Localized Inference for Large Graphical Models</dc:title>
 <dc:creator>Chen, Jinglin</dc:creator>
 <dc:creator>Peng, Jian</dc:creator>
 <dc:creator>Liu, Qiang</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a new localized inference algorithm for answering marginalization
queries in large graphical models with the correlation decay property. Given a
query variable and a large graphical model, we define a much smaller model in a
local region around the query variable in the target model so that the marginal
distribution of the query variable can be accurately approximated. We introduce
two approximation error bounds based on the Dobrushin's comparison theorem and
apply our bounds to derive a greedy expansion algorithm that efficiently guides
the selection of neighbor nodes for localized inference. We verify our
theoretical bounds on various datasets and demonstrate that our localized
inference algorithm can provide fast and accurate approximation for large
graphical models.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10404</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10415</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Distributed Parallel Model to Analyze Journal Impact Factors</dc:title>
 <dc:creator>Zhou, Jian</dc:creator>
 <dc:creator>Cai, Ning</dc:creator>
 <dc:creator>Tan, Zong-Yuan</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  A simple abstract model is developed as a parallel experimental basis for the
aim of exploring the differences of journal impact factors, particularly
between different disciplines. Our model endeavors to simulate the publication
and citation behaviors of the articles in the journals belonging to a similar
discipline, in a distributed manner. Based on simulation experiments, the
mechanism of influence from several fundamental factors to the trend of impact
factor is revealed. These factors include the average review cycle, average
number of references and yearly distribution of references. Moreover,
satisfactory approximation could possibly be observed between certain actual
data and simulation results.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10415</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10418</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Licence Plate Detection By Unique Edge Detection Algorithm and
  Smarter Interpretation Through IoT</dc:title>
 <dc:creator>K, Tejas</dc:creator>
 <dc:creator>K, Ashok Reddy</dc:creator>
 <dc:creator>D, Pradeep Reddy</dc:creator>
 <dc:creator>M, Rajesh Kumar</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Vehicles play a vital role in modern day transportation systems. Number plate
provides a standard means of identification for any vehicle. To serve this
purpose, automatic licence plate recognition system was developed. This
consisted of four major steps: Pre-processing of the obtained image, extraction
of licence plate region, segmentation and character recognition. In earlier
research, direct application of Sobel edge detection algorithm or applying
threshold were used as key steps to extract the licence plate region, which
does not produce effective results when the captured image is subjected to the
high intensity of light. The use of morphological operations causes deformity
in the characters during segmentation. We propose a novel algorithm to tackle
the mentioned issues through a unique edge detection algorithm. It is also a
tedious task to create and update the database of required vehicles frequently.
This problem is solved by the use of Internet of things(IOT) where an online
database can be created and updated from any module instantly. Also, through
IoT, we connect all the cameras in a geographical area to one server to create
a universal eye which drastically increases the probability of tracing a
vehicle over having manual database attached to each camera for identification
purpose.
</dc:description>
 <dc:description>Comment: Paper has been submitted to SocPros17, 7th international conference
  on soft computing and problem solving, Scopus indexed. If accepted paper will
  be published in AISC series SPRINGER. Some of the extended/modified selected
  quality papers will be published in a Special Issue of 'Swarm and
  Evolutionary Computation journal, Elsevier (SCI). 10 pages</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10418</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10419</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Channel Coherence Classification with Frame-Shifting in Massive MIMO
  Systems</dc:title>
 <dc:creator>Abboud, Ahmad</dc:creator>
 <dc:creator>Habachi, Oussama</dc:creator>
 <dc:creator>Jaber, Ali</dc:creator>
 <dc:creator>Cances, Jean-Pierre</dc:creator>
 <dc:creator>Meghdadi, Vahid</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers the uplink pilot overhead in a time division duplexing
(TDD) massive Multiple Input Multiple Output (MIMO) mobile systems. A common
scenario of conventional massive MIMO systems is a Base Station (BS) serving
all user terminals (UTs) in the cell with the same TDD frame format that fits
the coherence interval of the worst-case scenario of user mobility (e.g. a
moving train with velocity 300 Km/s). Furthermore, the BS has to estimate all
the channels each time-slot for all users even for those with long coherence
intervals. In fact, within the same cell, sensors or pedestrian with low
mobility UTs (e.g. moving 1.38 m/s) share the same short TDD frame and thus are
obliged to upload their pilots each time-slot. The channel coherence interval
of the pedestrian UTs with a carrier frequency of 1.9 GHz can be as long as 60
times that of the train passenger users. In other words, conventional
techniques waste 59-uploaded pilot sequences for channel estimation. In this
paper, we are aware of the resources waste due to various coherence intervals
among different user mobility. We classify users based on their coherence
interval length, and we propose to skip uploading pilots of UTs with large
coherence intervals. Then, we shift frames with the same pilot reused sequence
toward an empty pilot time-slot. Simulation results had proved that the
proposed technique overcome the performance of conventional massive MIMO
systems in both energy and spectral efficiency.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10419</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10421</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topic-based Integrator Matching for Pull Request</dc:title>
 <dc:creator>Liao, Zhifang</dc:creator>
 <dc:creator>Li, Yanbing</dc:creator>
 <dc:creator>Wu, Jinsong</dc:creator>
 <dc:creator>He, Dayu</dc:creator>
 <dc:creator>Fan, Xiaoping</dc:creator>
 <dc:creator>Zhang, Yan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Pull Request (PR) is the main method for code contributions from the external
contributors in GitHub. PR review is an essential part of open source software
developments to maintain the quality of software. Matching a new PR for an
appropriate integrator will make the PR reviewing more effective. However, PR
and integrator matching are now organized manually in GitHub. To make this
process more efficient, we propose a Topic-based Integrator Matching Algorithm
(TIMA) to predict highly relevant collaborators(the core developers) as the
integrator to incoming PRs . TIMA takes full advantage of the textual semantics
of PRs. To define the relationships between topics and collaborators, TIMA
builds a relation matrix about topic and collaborators. According to the
relevance between topics and collaborators, TIMA matches the suitable
collaborators as the PR integrator.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10421</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10427</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DevRank: Mining Influential Developers In Github</dc:title>
 <dc:creator>Liao, Zhifang</dc:creator>
 <dc:creator>Jin, Haozhi</dc:creator>
 <dc:creator>Li, Yifan</dc:creator>
 <dc:creator>Zhao, Benhong</dc:creator>
 <dc:creator>Wu, Jinsong</dc:creator>
 <dc:creator>Liu, Shengzong</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  As the social coding is becoming increasingly popular, understanding the
influence of developers can benefit various applications, such as advertisement
for new projects and innovations. However, most existing works have focused
only on ranking influential nodes in non-weighted and homogeneous networks,
which are not able to transfer proper importance scores to the real important
node. To rank developers in Github, we define developer's influence on the
capacity of attracting attention which can be measured by the number of
followers obtained in the future. We further defined a new method, DevRank,
which ranks the developers by influence propagation through heterogeneous
network constructed according to user behaviors, including &quot;commit&quot; and
&quot;follow&quot;. Our experiment compares the performance between DevRank and some
other link analysis algorithms, the results have shown that DevRank can improve
the ranking accuracy.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10427</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10432</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Jointly Tracking and Separating Speech Sources Using Multiple Features
  and the generalized labeled multi-Bernoulli Framework</dc:title>
 <dc:creator>Lin, Shoufeng</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  This paper proposes a novel joint multi-speaker tracking-and-separation
method based on the generalized labeled multi-Bernoulli (GLMB) multi-target
tracking filter, using sound mixtures recorded by microphones. Standard
multi-speaker tracking algorithms usually only track speaker locations, and
ambiguity occurs when speakers are spatially close. The proposed multi-feature
GLMB tracking filter treats the set of vectors of associated speaker features
(location, pitch and sound) as the multi-target multi-feature observation,
characterizes transitioning features with corresponding transition models and
overall likelihood function, thus jointly tracks and separates each
multi-feature speaker, and addresses the spatial ambiguity problem. Numerical
evaluation verifies that the proposed method can correctly track locations of
multiple speakers and meanwhile separate speech signals.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10432</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10433</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Ontology to support automated negotiation</dc:title>
 <dc:creator>Fernandez, Susel</dc:creator>
 <dc:creator>Ito, Takayuki</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  In this work we propose an ontology to support automated negotiation in
multiagent systems. The ontology can be connected with some domain-specific
ontologies to facilitate the negotiation in different domains, such as
Intelligent Transportation Systems (ITS), e-commerce, etc. The specific
negotiation rules for each type of negotiation strategy can also be defined as
part of the ontology, reducing the amount of knowledge hardcoded in the agents
and ensuring the interoperability. The expressiveness of the ontology was
proved in a multiagent architecture for the automatic traffic light setting
application on ITS.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10433</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10436</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Investigation of Frame Alignments for GMM-based Text-prompted Speaker
  Verification</dc:title>
 <dc:creator>Liu, Yi</dc:creator>
 <dc:creator>He, Liang</dc:creator>
 <dc:creator>Liu, Jia</dc:creator>
 <dc:creator>Johnson, Michael T.</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  The frame alignment acts as an important role in GMM-based speaker
verification. In text-prompted speaker verification, it is common practice to
use the transcriptions to align speech frames to phonetic units. In this paper,
we compare the performance of alignments from hidden Markov model (HMM) and
deep neural network (DNN), using the same training data and phonetic units. We
incorporate a phonetic Gaussian mixture model (PGMM) in the DNN-based
alignment, making the total number of Gaussian mixtures equal to that of the
HMM. Based on the Kullback-Leibler divergence (KLD) between the HMM and DNN
alignments, we also present a fast and efficient way to verify the text
content. Our experiments on RSR2015 Part-3 show that, even with a small
training set, the DNN-based alignment outperforms HMM alignment. Results also
show that it is not effective to utilize the DNN posteriors in the HMM system.
This phenomenon illustrates that under clean conditions (e.g., RSR2015),
text-prompted speaker verification does not benefit from the use of
transcriptions. However, the prompted text can be used as pass-phrase to
enhance the security. The content verification experiment demonstrates the
effectiveness of our proposed KLD-based method.
</dc:description>
 <dc:description>Comment: submitted to ICASSP 2018</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10444</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Framework for Compressive Time-of-Flight 3D Sensing</dc:title>
 <dc:creator>Antholzer, Stephan</dc:creator>
 <dc:creator>Wolf, Christoph</dc:creator>
 <dc:creator>Sandbichler, Michael</dc:creator>
 <dc:creator>Dielacher, Markus</dc:creator>
 <dc:creator>Haltmeier, Markus</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Spatially and temporally highly resolved depth information enables numerous
applications including human-machine interaction in gaming industry or safety
functions in the automotive industry. In this paper we address this issue using
Time-of-flight (ToF) 3D cameras which are compact devices providing highly
resolved depth information. Practical restrictions often require to reduce the
amount of data to be read out and transmitted. Using standard ToF cameras, this
can only be achieved by lowering the spatial or temporal resolution. To
overcome such a limitation, we propose a compressive ToF camera design that
allows to reduce the amount of data while keeping high spatial and temporal
resolution. This uses the theory of compressive sensing and sparse recovery. We
propose efficient block-wise reconstruction algorithms based on
$\ell_1$-minimization. We apply the developed reconstruction methods to data
captured by a real ToF camera system and evaluate them in terms of
reconstruction quality and computational effort.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10444</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10451</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sample-level CNN Architectures for Music Auto-tagging Using Raw
  Waveforms</dc:title>
 <dc:creator>Kim, Taejun</dc:creator>
 <dc:creator>Lee, Jongpil</dc:creator>
 <dc:creator>Nam, Juhan</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Recent work has shown that the end-to-end approach using convolutional neural
network (CNN) is effective in various types of machine learning tasks. For
audio signals, the approach takes raw waveforms as input using an 1-D
convolution layer. In this paper, we improve the 1-D CNN architecture for music
auto-tagging by adopting building blocks from state-of-the-art image
classification models, ResNets and SENets, and adding multi-level feature
aggregation to it. We compare different combinations of the modules in building
CNN architectures. The results show that they achieve significant improvements
over previous state-of-the-art models on the MagnaTagATune dataset and
comparable results on Million Song Dataset. Furthermore, we analyze and
visualize our model to show how the 1-D CNN operates.
</dc:description>
 <dc:description>Comment: 5 pages, submitted to 2018 IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP)</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10451</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10453</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inducing Regular Grammars Using Recurrent Neural Networks</dc:title>
 <dc:creator>Cohen, Mor</dc:creator>
 <dc:creator>Caciularu, Avi</dc:creator>
 <dc:creator>Rejwan, Idan</dc:creator>
 <dc:creator>Berant, Jonathan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Grammar induction is the task of learning a grammar from a set of examples.
Recently, neural networks have been shown to be powerful learning machines that
can identify patterns in streams of data. In this work we investigate their
effectiveness in inducing a regular grammar from data, without any assumptions
about the grammar. We train a recurrent neural network to distinguish between
strings that are in or outside a regular language, and utilize an algorithm for
extracting the learned finite-state automaton. We apply this method to several
regular languages and find unexpected results regarding the connections between
the network's states that may be regarded as evidence for generalization.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10453</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10457</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wasserstein Identity Testing</dc:title>
 <dc:creator>Deng, Shichuan</dc:creator>
 <dc:creator>Li, Wenzheng</dc:creator>
 <dc:creator>Wu, Xuan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  Uniformity testing and the more general identity testing are well studied
problems in distributional property testing. Most previous work focuses on
testing under $L_1$-distance. However, when the support is very large or even
continuous, testing under $L_1$-distance may require a huge (even infinite)
number of samples. Motivated by such issues, we consider the identity testing
in Wasserstein distance (a.k.a. transportation distance and earthmover
distance) on a metric space (discrete or continuous).
  In this paper, we propose the Wasserstein identity testing problem (Identity
Testing in Wasserstein distance). We obtain nearly optimal worst-case sample
complexity for the problem. Moreover, for a large class of probability
distributions satisfying the so-called &quot;Doubling Condition&quot;, we provide nearly
instance-optimal sample complexity.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10457</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10460</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward predictive machine learning for active vision</dc:title>
 <dc:creator>Dauc&#xe9;, Emmanuel</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We develop a comprehensive description of the active inference framework, as
proposed by Friston (2010), under a machine-learning compliant perspective.
Stemming from a biological inspiration and the auto-encoding principles, the
sketch of a cognitive architecture is proposed that should provide ways to
implement estimation-oriented control policies. Computer simulations illustrate
the effectiveness of the approach through a foveated inspection of the input
data. The pros and cons of the control policy are analyzed in detail, showing
interesting promises in terms of processing compression. Though optimizing
future posterior entropy over the actions set is shown enough to attain locally
optimal action selection, offline calculation using class-specific saliency
maps is shown better for it saves processing costs through saccades pathways
pre-processing, with a negligible effect on the recognition/compression rates.
</dc:description>
 <dc:description>Comment: submitted to ICLR 2018</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:date>2018-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10460</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10464</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Omnidirectional Precoding and Combining Based Synchronization for
  Millimeter Wave Massive MIMO Systems</dc:title>
 <dc:creator>Meng, Xin</dc:creator>
 <dc:creator>Gao, Xiqi</dc:creator>
 <dc:creator>Xia, Xiang-Gen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we design the precoding matrices at the base station side and
the combining matrices at the user terminal side for initial downlink
synchronization in millimeter wave massive multiple-input multiple-output
systems. First, we demonstrate two basic requirements for the precoding and
combining matrices, including that all the entries therein should have constant
amplitude under the implementation architecture constraint, and the average
transmission power over the total K time slots taking for synchronization
should be constant for any spatial direction. Then, we derive the optimal
synchronization detector based on generalized likelihood ratio test. By
utilizing this detector, we analyze the effect of the precoding and combining
matrices to the missed detection probability and the false alarm probability,
respectively, and present the corresponding conditions that should be
satisfied. It is shown that, both of the precoding and combining matrices
should guarantee the perfect omnidirectional coverage at each time slot, i.e.,
the average transmission power at each time slot is constant for any spatial
direction, which is more strict than the second basic requirement mentioned
above. We also show that such omnidirectional precoding matrices and
omnidirectional combining matrices exist only when both of the number of
transmit streams and the number of receive streams are equal to or greater than
two. In this case, we propose to utilize Golay complementary pairs and
Golay-Hadamard matrices to design the precoding and combining matrices.
Simulation results verify the effectiveness of the propose approach.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10464</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10466</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Long-Distance Loop Closure Using General Object Landmarks</dc:title>
 <dc:creator>Holliday, Andrew</dc:creator>
 <dc:creator>Dudek, Gregory</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Visual localization under large changes in scale is an important capability
in many robotic mapping applications, such as localizing at low altitudes in
maps built at high altitudes, or performing loop closure over long distances.
Existing approaches, however, are robust only up to a 3x difference in scale
between map and query images. We propose a novel combination of
deep-learning-based object features and hand-engineered point-features that
yields improved robustness to scale change, perspective change, and image
noise. We conduct experiments in simulation and in real-world outdoor scenes
exhibiting up to a 7x change in scale, and compare our approach against
localization using state-of-the-art SIFT features. This technique is
training-free and class-agnostic, and in principle can be deployed in any
environment out-of-the-box.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10466</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10467</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized End-to-End Loss for Speaker Verification</dc:title>
 <dc:creator>Wan, Li</dc:creator>
 <dc:creator>Wang, Quan</dc:creator>
 <dc:creator>Papir, Alan</dc:creator>
 <dc:creator>Moreno, Ignacio Lopez</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we propose a new loss function called generalized end-to-end
(GE2E) loss, which makes the training of speaker verification models more
efficient than our previous tuple-based end-to-end (TE2E) loss function. Unlike
TE2E, the GE2E loss function updates the network in a way that emphasizes
examples that are difficult to verify at each step of the training process.
Additionally, the GE2E loss does not require an initial stage of example
selection. With these properties, the model with new loss function learns a
better model, by decreasing EER by more than 10%, in shorter period of time, by
reducing the training time by &gt;60%. We also introduce the MultiReader
technique, which allow us do domain adaptation - training more accurate model
that supports multiple keywords (i.e. &quot;OK Google&quot; and &quot;Hey Google&quot;) as well as
multiple dialects.
</dc:description>
 <dc:description>Comment: Submitted to ICASSP 2018</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10467</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10468</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Speaker Diarization with LSTM</dc:title>
 <dc:creator>Wang, Quan</dc:creator>
 <dc:creator>Downey, Carlton</dc:creator>
 <dc:creator>Wan, Li</dc:creator>
 <dc:creator>Mansfield, Philip Andrew</dc:creator>
 <dc:creator>Moreno, Ignacio Lopez</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  For many years, i-vector based speaker embedding techniques were the dominant
approach for speaker verification and speaker diarization applications.
However, mirroring the rise of deep learning in various domains, neural network
based speaker embeddings, also known as d-vectors, have consistently
demonstrated superior speaker verification performance. In this paper, we build
on the success of d-vector based speaker verification systems to develop a new
d-vector based approach to speaker diarization. Specifically, we combine
LSTM-based d-vector audio embeddings with recent work in non-parametric
clustering to obtain a state-of-the-art speaker diarization system. Our system
is evaluated on three standard public datasets, suggesting that d-vector based
diarization systems offer significant advantages over traditional i-vector
based systems. We achieved a 12.0% diarization error rate on NIST SRE 2000
CALLHOME, while our model is trained with out-of-domain data from voice search
logs.
</dc:description>
 <dc:description>Comment: Submitted to ICASSP 2018</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10468</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10470</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attention-Based Models for Text-Dependent Speaker Verification</dc:title>
 <dc:creator>Chowdhury, F A Rezaur Rahman</dc:creator>
 <dc:creator>Wang, Quan</dc:creator>
 <dc:creator>Moreno, Ignacio Lopez</dc:creator>
 <dc:creator>Wan, Li</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Attention-based models have recently shown great performance on a range of
tasks, such as speech recognition, machine translation, and image captioning
due to their ability to summarize relevant information that expands through the
entire length of an input sequence. In this paper, we analyze the usage of
attention mechanisms to the problem of sequence summarization in our end-to-end
text-dependent speaker recognition system. We explore different topologies and
their variants of the attention layer, and compare different pooling methods on
the attention weights. Ultimately, we show that attention-based models can
improves the Equal Error Rate (EER) of our speaker verification system by
relatively 14% compared to our non-attention LSTM baseline model.
</dc:description>
 <dc:description>Comment: Submitted to ICASSP 2018</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10470</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10473</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SeeThrough: Finding Chairs in Heavily Occluded Indoor Scene Images</dc:title>
 <dc:creator>Hueting, Moos</dc:creator>
 <dc:creator>Reddy, Pradyumna</dc:creator>
 <dc:creator>Kim, Vladimir</dc:creator>
 <dc:creator>Yumer, Ersin</dc:creator>
 <dc:creator>Carr, Nathan</dc:creator>
 <dc:creator>Mitra, Niloy</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Discovering 3D arrangements of objects from single indoor images is important
given its many applications including interior design, content creation, etc.
Although heavily researched in the recent years, existing approaches break down
under medium or heavy occlusion as the core object detection module starts
failing in absence of directly visible cues. Instead, we take into account
holistic contextual 3D information, exploiting the fact that objects in indoor
scenes co-occur mostly in typical near-regular configurations. First, we use a
neural network trained on real indoor annotated images to extract 2D keypoints,
and feed them to a 3D candidate object generation stage. Then, we solve a
global selection problem among these 3D candidates using pairwise co-occurrence
statistics discovered from a large 3D scene database. We iterate the process
allowing for candidates with low keypoint response to be incrementally detected
based on the location of the already discovered nearby objects. Focusing on
chairs, we demonstrate significant performance improvement over combinations of
state-of-the-art methods, especially for scenes with moderately to severely
occluded objects.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:date>2017-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10473</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10474</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reverse Engineering Camouflaged Sequential Integrated Circuits Without
  Scan Access</dc:title>
 <dc:creator>Massad, Mohamed El</dc:creator>
 <dc:creator>Garg, Siddharth</dc:creator>
 <dc:creator>Tripunitara, Mahesh</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Integrated circuit (IC) camouflaging is a promising technique to protect the
design of a chip from reverse engineering. However, recent work has shown that
even camouflaged ICs can be reverse engineered from the observed input/output
behaviour of a chip using SAT solvers. However, these so-called SAT attacks
have so far targeted only camouflaged combinational circuits. For camouflaged
sequential circuits, the SAT attack requires that the internal state of the
circuit is controllable and observable via the scan chain. It has been
implicitly assumed that restricting scan chain access increases the security of
camouflaged ICs from reverse engineering attacks. In this paper, we develop a
new attack methodology to decamouflage sequential circuits without scan access.
Our attack uses a model checker (a more powerful reasoning tool than a SAT
solver) to find a discriminating set of input sequences, i.e., one that is
sufficient to determine the functionality of camouflaged gates. We propose
several refinements, including the use of a bounded model checker, and
sufficient conditions for determining when a set of input sequences is
discriminating to improve the run-time and scalabilty of our attack. Our attack
is able to decamouflage a large sequential benchmark circuit that implements a
subset of the VIPER processor.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10474</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10477</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geographic Differential Privacy for Mobile Crowd Coverage Maximization</dc:title>
 <dc:creator>Wang, Leye</dc:creator>
 <dc:creator>Qin, Gehua</dc:creator>
 <dc:creator>Yang, Dingqi</dc:creator>
 <dc:creator>Han, Xiao</dc:creator>
 <dc:creator>Ma, Xiaojuan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  For real-world mobile applications such as location-based advertising and
spatial crowdsourcing, a key to success is targeting mobile users that can
maximally cover certain locations in a future period. To find an optimal group
of users, existing methods often require information about users' mobility
history, which may cause privacy breaches. In this paper, we propose a method
to maximize mobile crowd's future location coverage under a guaranteed location
privacy protection scheme. In our approach, users only need to upload one of
their frequently visited locations, and more importantly, the uploaded location
is obfuscated using a geographic differential privacy policy. We propose both
analytic and practical solutions to this problem. Experiments on real user
mobility datasets show that our method significantly outperforms the
state-of-the-art geographic differential privacy methods by achieving a higher
coverage under the same level of privacy protection.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:date>2017-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10477</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10490</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analytical Estimation of the Scalability of Iterative Numerical
  Algorithms on Distributed Memory Multiprocessors</dc:title>
 <dc:creator>Sokolinsky, Leonid B.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  This article presents a new high-level parallel computational model named BSF
- Bulk Synchronous Farm. The BSF model extends the BSP model to deal with the
compute-intensive iterative numerical methods executed on distributed-memory
multiprocessor systems. The BSF model is based on the master-worker paradigm
and the SPMD programming model. The BSF model makes it possible to predict the
upper scalability bound of a BSF-program with great accuracy. The BSF model
also provides equations for estimating the speedup and parallel efficiency of a
BSF-program.
</dc:description>
 <dc:description>Comment: Submitted to a special issue of Lobachevskii Journal of Mathematics
  on &quot;Parallel Structure of Algorithms&quot;</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10490</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10498</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topic Based Sentiment Analysis Using Deep Learning</dc:title>
 <dc:creator>S., Sharath T.</dc:creator>
 <dc:creator>Tandon, Shubhangi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  In this paper , we tackle Sentiment Analysis conditioned on a Topic in
Twitter data using Deep Learning . We propose a 2-tier approach : In the first
phase we create our own Word Embeddings and see that they do perform better
than state-of-the-art embeddings when used with standard classifiers. We then
perform inference on these embeddings to learn more about a word with respect
to all the topics being considered, and also the top n-influencing words for
each topic. In the second phase we use these embeddings to predict the
sentiment of the tweet with respect to a given topic, and all other topics
under discussion.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10498</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10501</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to diagnose from scratch by exploiting dependencies among
  labels</dc:title>
 <dc:creator>Yao, Li</dc:creator>
 <dc:creator>Poblenz, Eric</dc:creator>
 <dc:creator>Dagunts, Dmitry</dc:creator>
 <dc:creator>Covington, Ben</dc:creator>
 <dc:creator>Bernard, Devon</dc:creator>
 <dc:creator>Lyman, Kevin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The field of medical diagnostics contains a wealth of challenges which
closely resemble classical machine learning problems; practical constraints,
however, complicate the translation of these endpoints naively into classical
architectures. Many tasks in radiology, for example, are largely problems of
multi-label classification wherein medical images are interpreted to indicate
multiple present or suspected pathologies. Clinical settings drive the
necessity for high accuracy simultaneously across a multitude of pathological
outcomes and greatly limit the utility of tools which consider only a subset.
This issue is exacerbated by a general scarcity of training data and maximizes
the need to extract clinically relevant features from available samples --
ideally without the use of pre-trained models which may carry forward
undesirable biases from tangentially related tasks. We present and evaluate a
partial solution to these constraints in using LSTMs to leverage
interdependencies among target labels in predicting 14 pathologic patterns from
chest x-rays and establish state of the art results on the largest publicly
available chest x-ray dataset from the NIH without pre-training. Furthermore,
we propose and discuss alternative evaluation metrics and their relevance in
clinical practice.
</dc:description>
 <dc:description>Comment: submitted to ICLR2018</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10504</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase Conductor on Multi-layered Attentions for Machine Comprehension</dc:title>
 <dc:creator>Liu, Rui</dc:creator>
 <dc:creator>Wei, Wei</dc:creator>
 <dc:creator>Mao, Weiguang</dc:creator>
 <dc:creator>Chikina, Maria</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Attention models have been intensively studied to improve NLP tasks such as
machine comprehension via both question-aware passage attention model and
self-matching attention model. Our research proposes phase conductor
(PhaseCond) for attention models in two meaningful ways. First, PhaseCond, an
architecture of multi-layered attention models, consists of multiple phases
each implementing a stack of attention layers producing passage representations
and a stack of inner or outer fusion layers regulating the information flow.
Second, we extend and improve the dot-product attention function for PhaseCond
by simultaneously encoding multiple question and passage embedding layers from
different perspectives. We demonstrate the effectiveness of our proposed model
PhaseCond on the SQuAD dataset, showing that our model significantly
outperforms both state-of-the-art single-layered and multiple-layered attention
models. We deepen our results with new findings via both detailed qualitative
analysis and visualized examples showing the dynamic changes through
multi-layered attention models.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10504</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10511</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Approximate Optimal Station Keeping of a Marine Craft in the
  Presence of a Current</dc:title>
 <dc:creator>Walters, Patrick</dc:creator>
 <dc:creator>Kamalapurkar, Rushikesh</dc:creator>
 <dc:creator>Voight, Forrest</dc:creator>
 <dc:creator>Schwartz, Eric M.</dc:creator>
 <dc:creator>Dixon, Warren E.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Online approximation of the optimal station keeping strategy for a fully
actuated six degrees-of-freedom marine craft subject to an irrotational ocean
current is considered. An approximate solution to the optimal control problem
is obtained using an adaptive dynamic programming technique. The hydrodynamic
drift dynamics of the dynamic model are assumed to be unknown; therefore, a
concurrent learning-based system identifier is developed to identify the
unknown model parameters. The identified model is used to implement an adaptive
model-based reinforcement learning technique to estimate the unknown value
function. The developed policy guarantees uniformly ultimately bounded
convergence of the vehicle to the desired station and uniformly ultimately
bounded convergence of the approximated policies to the optimal polices without
the requirement of persistence of excitation. The developed strategy is
validated using an autonomous underwater vehicle, where the three
degrees-of-freedom in the horizontal plane are regulated. The experiments are
conducted in a second-magnitude spring located in central Florida.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10511</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10513</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Crime incidents embedding using restricted Boltzmann machines</dc:title>
 <dc:creator>Zhu, Shixiang</dc:creator>
 <dc:creator>Xie, Yao</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present a new approach for detecting related crime series, by unsupervised
learning of the latent feature embeddings from narratives of crime record via
the Gaussian-Bernoulli Restricted Boltzmann Machines (RBM). This is a
drastically different approach from prior work on crime analysis, which
typically considers only time and location and at most category information.
After the embedding, related cases are closer to each other in the Euclidean
feature space, and the unrelated cases are far apart, which is a good property
can enable subsequent analysis such as detection and clustering of related
cases. Experiments over several series of related crime incidents hand labeled
by the Atlanta Police Department reveal the promise of our embedding methods.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10513</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10515</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward Reducing Crop Spoilage and Increasing Small Farmer Profits in
  India: a Simultaneous Hardware and Software Solution</dc:title>
 <dc:creator>Chen, George H.</dc:creator>
 <dc:creator>Nowocin, Kendall</dc:creator>
 <dc:creator>Marathe, Niraj</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  India's agricultural system has been facing a severe problem of crop wastage.
A key contributing factor to this problem is that many small farmers lack
access to reliable cold storage that extends crop shelf-life. To avoid having
leftover crops that spoil, these farmers often sell their crops at unfavorable
low prices. Inevitably, not all crops are sold before spoilage. Even if the
farmers have access to cold storage, the farmers may not know how long to hold
different crops in cold storage for, which hinges on strategizing over when and
where to sell their harvest. In this note, we present progress toward a
simultaneous hardware and software solution that aims to help farmers reduce
crop spoilage and increase their profits. The hardware is a cost-effective
solar-powered refrigerator and control unit. The software refers to a produce
price forecasting system, for which we have tested a number of machine learning
methods. Note that unlike standard price forecasting tasks such as for stock
market data, the produce price data from predominantly rural Indian markets
have a large amount of missing values. In developing our two-pronged solution,
we are actively working with farmers at two pilot sites in Karnataka and
Odisha.
</dc:description>
 <dc:description>Comment: International Conference on Information and Communication
  Technologies for Development 2017, fixed Figure 4 sparsity pattern issue,
  added acknowledgments</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:date>2017-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10515</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10519</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Points and Lines in Regression Forests for RGB-D Camera
  Relocalization</dc:title>
 <dc:creator>Meng, Lili</dc:creator>
 <dc:creator>Tung, Frederick</dc:creator>
 <dc:creator>Little, James J.</dc:creator>
 <dc:creator>Valentin, Julien</dc:creator>
 <dc:creator>de Silva, Clarence W.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Camera relocalization plays a vital role in many robotics and computer vision
tasks, such as global localization, recovery from tracking failure and loop
closure detection. Recent random forests based methods exploit randomly sampled
pixel comparison features to predict 3D world locations for 2D image locations
to guide the camera pose optimization. However, these image features are only
sampled randomly in the images, without considering the spatial structures or
geometric information, leading to large errors or failure cases with the
existence of poorly textured areas or in motion blur. Line segment features are
more robust in these environments. In this work, we propose to jointly exploit
points and lines within the framework of uncertainty driven regression forests.
The proposed approach is thoroughly evaluated on three publicly available
datasets against several strong state-of-the-art baselines in terms of several
different error metrics. Experimental results prove the efficacy of our method,
showing superior or on-par state-of-the-art performance.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10519</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10520</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Dual Encoder Sequence to Sequence Model for Open-Domain Dialogue
  Modeling</dc:title>
 <dc:creator>S., Sharath T.</dc:creator>
 <dc:creator>Tandon, Shubhangi</dc:creator>
 <dc:creator>Bauer, Ryan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Ever since the successful application of sequence to sequence learning for
neural machine translation systems, interest has surged in its applicability
towards language generation in other problem domains. Recent work has
investigated the use of these neural architectures towards modeling open-domain
conversational dialogue, where it has been found that although these models are
capable of learning a good distributional language model, dialogue coherence is
still of concern. Unlike translation, conversation is much more a one-to-many
mapping from utterance to a response, and it is even more pressing that the
model be aware of the preceding flow of conversation. In this paper we propose
to tackle this problem by introducing previous conversational context in terms
of latent representations of dialogue acts over time. We inject the latent
context representations into a sequence to sequence neural network in the form
of dialog acts using a second encoder to enhance the quality and the coherence
of the conversations generated. The main task of this research work is to show
that adding latent variables that capture discourse relations does indeed
result in more coherent responses when compared to conventional sequence to
sequence models.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10521</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Fr\'echet Distance Between Curves With Long Edges</dc:title>
 <dc:creator>Gudmundsson, Joachim</dc:creator>
 <dc:creator>Mirzanezhad, Majid</dc:creator>
 <dc:creator>Mohades, Ali</dc:creator>
 <dc:creator>Wenk, Carola</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Computing Fr\'echet distance between two curves takes roughly quadratic time.
In this paper, we show that for curves with long edges the Fr\'echet distance
computations become easier. Let $P$ and $Q$ be two polygonal curves in
$\mathbb{R}^d$ with $n$ and $m$ vertices, respectively. We prove four main
results for the case when all edges of both curves are long compared to the
Fr\'echet distance between them: (1) a linear-time algorithm for deciding the
Fr\'echet distance between two curves, (2) an algorithm that computes the
Fr\'echet distance in $O((n+m)\log (n+m))$ time, (3) a linear-time $\sqrt{d}$
-approximation algorithm, and (4) a data structure that supports $O(m\log^2
n)$-time decision queries, where $m$ is the number of vertices of the query
curve and $n$ the number of vertices of the preprocessed curve.
</dc:description>
 <dc:description>Comment: 15 pages, 8 figures</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10521</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10522</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Object Recognition by Using Multi-level Feature Point Extraction</dc:title>
 <dc:creator>Cheng, Yang</dc:creator>
 <dc:creator>Dubois, Timeo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we present a novel approach for object recognition in
real-time by employing multilevel feature analysis and demonstrate the
practicality of adapting feature extraction into a Naive Bayesian
classification framework that enables simple, efficient, and robust
performance. We also show the proposed method scales well as the number of
level-classes grows. To effectively understand the patches surrounding a
keypoint, the trained classifier uses hundreds of simple binary features and
models class posterior probabilities. In addition, the classification process
is computationally cheap under the assumed independence between arbitrary sets
of features. Even though for some particular scenarios, this assumption can be
invalid. We demonstrate that the efficient classifier nevertheless performs
remarkably well on image datasets with a large variation in the illumination
environment and image capture perspectives. The experiment results show
consistent accuracy can be achieved on many challenging dataset while offer
interactive speed for large resolution images. The method demonstrates
promising results that outperform the state-of-the-art methods on pattern
recognition.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10522</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10523</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Autonomous Mobile Robot Navigation in Uneven and Unstructured Indoor
  Environments</dc:title>
 <dc:creator>Wang, Chaoqun</dc:creator>
 <dc:creator>Meng, Lili</dc:creator>
 <dc:creator>She, Sizhen</dc:creator>
 <dc:creator>Mitchell, Ian M.</dc:creator>
 <dc:creator>Li, Teng</dc:creator>
 <dc:creator>Tung, Frederick</dc:creator>
 <dc:creator>Wan, Weiwei</dc:creator>
 <dc:creator>Meng, Max. Q. -H.</dc:creator>
 <dc:creator>de Silva, Clarence W.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Robots are increasingly operating in indoor environments designed for and
shared with people. However, robots working safely and autonomously in uneven
and unstructured environments still face great challenges. Many modern indoor
environments are designed with wheelchair accessibility in mind. This presents
an opportunity for wheeled robots to navigate through sloped areas while
avoiding staircases. In this paper, we present an integrated software and
hardware system for autonomous mobile robot navigation in uneven and
unstructured indoor environments. This modular and reusable software framework
incorporates capabilities of perception and navigation. Our robot first builds
a 3D OctoMap representation for the uneven environment with the 3D mapping
using wheel odometry, 2D laser and RGB-D data. Then we project multilayer 2D
occupancy maps from OctoMap to generate the the traversable map based on layer
differences. The safe traversable map serves as the input for efficient
autonomous navigation. Furthermore, we employ a variable step size Rapidly
Exploring Random Trees that could adjust the step size automatically,
eliminating tuning step sizes according to environments. We conduct extensive
experiments in simulation and real-world, demonstrating the efficacy and
efficiency of our system.
</dc:description>
 <dc:description>Comment: 2017 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS)</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10523</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10532</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpretable Apprenticeship Learning with Temporal Logic Specifications</dc:title>
 <dc:creator>Kasenberg, Daniel</dc:creator>
 <dc:creator>Scheutz, Matthias</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recent work has addressed using formulas in linear temporal logic (LTL) as
specifications for agents planning in Markov Decision Processes (MDPs). We
consider the inverse problem: inferring an LTL specification from demonstrated
behavior trajectories in MDPs. We formulate this as a multiobjective
optimization problem, and describe state-based (&quot;what actually happened&quot;) and
action-based (&quot;what the agent expected to happen&quot;) objective functions based on
a notion of &quot;violation cost&quot;. We demonstrate the efficacy of the approach by
employing genetic programming to solve this problem in two simple domains.
</dc:description>
 <dc:description>Comment: Accepted to the 56th IEEE Conference on Decision and Control (CDC
  2017)</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10532</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10538</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Partial Knowledge In Embeddings</dc:title>
 <dc:creator>Guha, Ramanathan V.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Representing domain knowledge is crucial for any task. There has been a wide
range of techniques developed to represent this knowledge, from older logic
based approaches to the more recent deep learning based techniques (i.e.
embeddings). In this paper, we discuss some of these methods, focusing on the
representational expressiveness tradeoffs that are often made. In particular,
we focus on the the ability of various techniques to encode `partial knowledge'
- a key component of successful knowledge systems. We introduce and describe
the concepts of `ensembles of embeddings' and `aggregate embeddings' and
demonstrate how they allow for partial knowledge.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10538</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10545</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A $o(d) \cdot \text{polylog}~n$ Monotonicity Tester for Boolean
  Functions over the Hypergrid $[n]^d$</dc:title>
 <dc:creator>Black, Hadley</dc:creator>
 <dc:creator>Chakrabarty, Deeparnab</dc:creator>
 <dc:creator>Seshadhri, C.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study monotonicity testing of Boolean functions over the hypergrid $[n]^d$
and design a non-adaptive tester with $1$-sided error whose query complexity is
$\tilde{O}(d^{5/6})\cdot \text{poly}(\log n,1/\epsilon)$. Previous to our work,
the best known testers had query complexity linear in $d$ but independent of
$n$. We improve upon these testers as long as $n = 2^{d^{o(1)}}$.
  To obtain our results, we work with what we call the augmented hypergrid,
which adds extra edges to the hypergrid. Our main technical contribution is a
Margulis-style isoperimetric result for the augmented hypergrid, and our
tester, like previous testers for the hypercube domain, performs directed
random walks on this structure.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10545</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10546</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Controlled Sequential Information Fusion with Social Sensors</dc:title>
 <dc:creator>Bhatt, Sujay</dc:creator>
 <dc:creator>Krishnamurthy, Vikram</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  A network of social sensors estimate an unknown state of nature by performing
Bayesian Social Learning, and myopically optimize individual reward functions.
The decisions of the social sensors contain quantized information about the
underlying state. How should a fusion center dynamically incen- tivize the
social sensors for acquiring the information about the underlying state? This
paper presents four results. First, sufficient conditions on the model
parameters are provided under which the optimal policy for the fusion center
has a threshold structure. The optimal policy is determined in closed form, and
is such that it switches between two exactly specified incentive policies at
the threshold. Second, a sample path characterization of the optimal threshold
policy is provided, i.e, the nature of the incentives (average trend over time)
resulting from the fusion center employing the optimal threshold policy. It is
shown that the optimal incentive sequence is a sub-martingale, i.e, the optimal
incentives increase on average over time. Third, it is shown that it is
possible for the fusion center to learn the true state asymptotically by
employing a sub-optimal policy; in other words, controlled information fusion
with social sensors can be consistent. Finally, uniform bounds on the average
additional cost incurred by the fusion center for employing a sub-optimal
policy are provided. This characterizes the trade-off between the cost of
information acquisition and consistency, for the fusion center.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10546</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10547</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpretation of Neural Networks is Fragile</dc:title>
 <dc:creator>Ghorbani, Amirata</dc:creator>
 <dc:creator>Abid, Abubakar</dc:creator>
 <dc:creator>Zou, James</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In order for machine learning to be deployed and trusted in many
applications, it is crucial to be able to reliably explain why the machine
learning algorithm makes certain predictions. For example, if an algorithm
classifies a given pathology image to be a malignant tumor, then the doctor may
need to know which parts of the image led the algorithm to this classification.
How to interpret black-box predictors is thus an important and active area of
research. A fundamental question is: how much can we trust the interpretation
itself? In this paper, we show that interpretation of deep learning predictions
is extremely fragile in the following sense: two perceptively indistinguishable
inputs with the same predicted label can be assigned very different
interpretations. We systematically characterize the fragility of several
widely-used feature-importance interpretation methods (saliency maps, relevance
propagation, and DeepLIFT) on ImageNet and CIFAR-10. Our experiments show that
even small random perturbation can change the feature importance and new
systematic perturbations can lead to dramatically different interpretations
without changing the label. We extend these results to show that
interpretations based on exemplars (e.g. influence functions) are similarly
fragile. Our analysis of the geometry of the Hessian matrix gives insight on
why fragility could be a fundamental challenge to the current interpretation
approaches.
</dc:description>
 <dc:description>Comment: Submitted for review at ICLR 2018</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10550</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vehicle Routing Problem with Vector Profits (VRPVP) with Max-Min
  Criterion</dc:title>
 <dc:creator>Lee, Dongoo</dc:creator>
 <dc:creator>Ahn, Jaemyung</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper introduces a new routing problem referred to as the vehicle
routing problem with vector profits. Given a network composed of nodes
(depot/sites) and arcs connecting the nodes, the problem determines routes that
depart from the depot, visit sites to collect profits, and return to the depot.
There are multiple stakeholders interested in the mission and each site is
associated with a vector whose k-th element represents the profit value for the
k-th stakeholder. The objective of the problem is to maximize the profit sum
for the least satisfied stakeholder, i.e., the stakeholder with the smallest
total profit value. An approach based on the linear programming relaxation and
column-generation to solve this max-min type routing problem was developed. Two
cases studies - the planetary surface exploration and the Rome tour cases -
were presented to demonstrate the effectiveness of the proposed problem
formulation and solution methodology.
</dc:description>
 <dc:description>Comment: 33 pages, submitted to Engineering Optimization</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10550</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10551</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Zeroth-order Optimization in High Dimensions</dc:title>
 <dc:creator>Wang, Yining</dc:creator>
 <dc:creator>Du, Simon</dc:creator>
 <dc:creator>Balakrishnan, Sivaraman</dc:creator>
 <dc:creator>Singh, Aarti</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the problem of optimizing a high-dimensional convex function
using stochastic zeroth-order query oracles. Such problems arise naturally in a
variety of practical applications, including optimizing experimental or
simulation parameters with many variables. Under sparsity assumptions on the
gradients or function values, we present a successive component/feature
selection algorithm and a noisy mirror descent algorithm with Lasso gradient
estimates and show that both algorithms have convergence rates depending only
logarithmically on the ambient problem dimension. Empirical results verify our
theoretical findings and suggest that our designed algorithms outperform
classical zeroth-order optimization methods in the high-dimensional setting.
</dc:description>
 <dc:description>Comment: 25 pages, 6 figures</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10551</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10553</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Approach to Artistic Textual Visualization via GAN</dc:title>
 <dc:creator>Ma, Yichi</dc:creator>
 <dc:creator>Ma, Muhan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  While the visualization of statistical data tends to a mature technology, the
visualization of textual data is still in its infancy, especially for the
artistic text. Due to the fact that visualization of artistic text is valuable
and attractive in both art and information science, we attempt to realize this
tentative idea in this article. We propose the Generative Adversarial Network
based Artistic Textual Visualization (GAN-ATV) which can create paintings after
analyzing the semantic content of existing poems. Our GAN-ATV consists of two
main sections: natural language analysis section and visual information
synthesis section. In natural language analysis section, we use Bag-of-Word
(BoW) feature descriptors and a two-layer network to mine and analyze the
high-level semantic information from poems. In visual information synthesis
section, we design a cross-modal semantic understanding module and integrate it
with Generative Adversarial Network (GAN) to create paintings, whose content
are corresponding to the original poems. Moreover, in order to train our
GAN-ATV and verify its performance, we establish a cross-modal artistic dataset
named &quot;Cross-Art&quot;. In the Cross-Art dataset, there are six topics and each
topic has their corresponding paintings and poems. The experimental results on
Cross-Art dataset are shown in this article.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10553</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10555</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complexity Analysis Approach for Prefabricated Construction Products
  Using Uncertain Data Clustering</dc:title>
 <dc:creator>Ji, Wenying</dc:creator>
 <dc:creator>AbouRizk, Simaan M.</dc:creator>
 <dc:creator>Zaiane, Osmar R.</dc:creator>
 <dc:creator>Li, Yitong</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  This paper proposes an uncertain data clustering approach to quantitatively
analyze the complexity of prefabricated construction components through the
integration of quality performance-based measures with associated engineering
design information. The proposed model is constructed in three steps, which (1)
measure prefabricated construction product complexity (hereafter referred to as
product complexity) by introducing a Bayesian-based nonconforming quality
performance indicator; (2) score each type of product complexity by developing
a Hellinger distance-based distribution similarity measurement; and (3) cluster
products into homogeneous complexity groups by using the agglomerative
hierarchical clustering technique. An illustrative example is provided to
demonstrate the proposed approach, and a case study of an industrial company in
Edmonton, Canada, is conducted to validate the feasibility and applicability of
the proposed model. This research inventively defines and investigates product
complexity from the perspective of product quality performance with design
information associated. The research outcomes provide simplified,
interpretable, and informative insights for practitioners to better analyze and
manage product complexity. In addition to this practical contribution, a novel
hierarchical clustering technique is devised. This technique is capable of
clustering uncertain data (i.e., beta distributions) with lower computational
complexity and has the potential to be generalized to cluster all types of
uncertain data.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10555</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10556</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Smooth Sensitivity Based Approach for Differentially Private Principal
  Component Analysis</dc:title>
 <dc:creator>Gonen, Alon</dc:creator>
 <dc:creator>Gilad-Bachrach, Ran</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Currently known methods for this task either employ the computationally
intensive \emph{exponential mechanism} or require an access to the covariance
matrix, and therefore fail to utilize potential sparsity of the data. The
problem of designing simpler and more efficient methods for this task has been
raised as an open problem in \cite{kapralov2013differentially}.
  In this paper we address this problem by employing the output perturbation
mechanism. Despite being arguably the simplest and most straightforward
technique, it has been overlooked due to the large \emph{global sensitivity}
associated with publishing the leading eigenvector. We tackle this issue by
adopting a \emph{smooth sensitivity} based approach, which allows us to
establish differential privacy (in a worst-case manner) and near-optimal sample
complexity results under eigengap assumption. We consider both the pure and the
approximate notions of differential privacy, and demonstrate a tradeoff between
privacy level and sample complexity. We conclude by suggesting how our results
can be extended to related problems.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10556</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10564</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bayesian Data Augmentation Approach for Learning Deep Models</dc:title>
 <dc:creator>Tran, Toan</dc:creator>
 <dc:creator>Pham, Trung</dc:creator>
 <dc:creator>Carneiro, Gustavo</dc:creator>
 <dc:creator>Palmer, Lyle</dc:creator>
 <dc:creator>Reid, Ian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Data augmentation is an essential part of the training process applied to
deep learning models. The motivation is that a robust training process for deep
learning models depends on large annotated datasets, which are expensive to be
acquired, stored and processed. Therefore a reasonable alternative is to be
able to automatically generate new annotated training samples using a process
known as data augmentation. The dominant data augmentation approach in the
field assumes that new training samples can be obtained via random geometric or
appearance transformations applied to annotated training samples, but this is a
strong assumption because it is unclear if this is a reliable generative model
for producing new training samples. In this paper, we provide a novel Bayesian
formulation to data augmentation, where new annotated training points are
treated as missing variables and generated based on the distribution learned
from the training set. For learning, we introduce a theoretically sound
algorithm --- generalised Monte Carlo expectation maximisation, and demonstrate
one possible implementation via an extension of the Generative Adversarial
Network (GAN). Classification results on MNIST, CIFAR-10 and CIFAR-100 show the
better performance of our proposed method compared to the current dominant data
augmentation approach mentioned above --- the results also show that our
approach produces better classification results than similar GAN models.
</dc:description>
 <dc:description>Comment: Accepted to NISP 2017</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10565</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synthetic Iris Presentation Attack using iDCGAN</dc:title>
 <dc:creator>Kohli, Naman</dc:creator>
 <dc:creator>Yadav, Daksha</dc:creator>
 <dc:creator>Vatsa, Mayank</dc:creator>
 <dc:creator>Singh, Richa</dc:creator>
 <dc:creator>Noore, Afzel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Reliability and accuracy of iris biometric modality has prompted its
large-scale deployment for critical applications such as border control and
national ID projects. The extensive growth of iris recognition systems has
raised apprehensions about susceptibility of these systems to various attacks.
In the past, researchers have examined the impact of various iris presentation
attacks such as textured contact lenses and print attacks. In this research, we
present a novel presentation attack using deep learning based synthetic iris
generation. Utilizing the generative capability of deep convolutional
generative adversarial networks and iris quality metrics, we propose a new
framework, named as iDCGAN (iris deep convolutional generative adversarial
network) for generating realistic appearing synthetic iris images. We
demonstrate the effect of these synthetically generated iris images as
presentation attack on iris recognition by using a commercial system. The
state-of-the-art presentation attack detection framework, DESIST is utilized to
analyze if it can discriminate these synthetically generated iris images from
real images. The experimental results illustrate that mitigating the proposed
synthetic presentation attack is of paramount importance.
</dc:description>
 <dc:description>Comment: International Joint Conference on Biometrics 2017</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10565</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10568</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Training of Graph Convolutional Networks</dc:title>
 <dc:creator>Chen, Jianfei</dc:creator>
 <dc:creator>Zhu, Jun</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Graph convolutional networks (GCNs) are powerful deep neural networks for
graph-structured data. However, GCN computes nodes' representation recursively
from their neighbors, making the receptive field size grow exponentially with
the number of layers. Previous attempts on reducing the receptive field size by
subsampling neighbors do not have any convergence guarantee, and their
receptive field size per node is still in the order of hundreds. In this paper,
we develop a preprocessing strategy and two control variate based algorithms to
further reduce the receptive field size. Our algorithms are guaranteed to
converge to GCN's local optimum regardless of the neighbor sampling size.
Empirical results show that our algorithms have a similar convergence speed per
epoch with the exact algorithm even using only two neighbors per node. The time
consumption of our algorithm on the Reddit dataset is only one fifth of
previous neighbor sampling algorithms.
</dc:description>
 <dc:description>Comment: submitted to ICLR2018</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10568</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10570</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weight Initialization of Deep Neural Networks(DNNs) using Data
  Statistics</dc:title>
 <dc:creator>Koturwar, Saiprasad</dc:creator>
 <dc:creator>Merchant, Shabbir</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep neural networks (DNNs) form the backbone of almost every
state-of-the-art technique in the fields such as computer vision, speech
processing, and text analysis. The recent advances in computational technology
have made the use of DNNs more practical. Despite the overwhelming performances
by DNN and the advances in computational technology, it is seen that very few
researchers try to train their models from the scratch. Training of DNNs still
remains a difficult and tedious job. The main challenges that researchers face
during training of DNNs are the vanishing/exploding gradient problem and the
highly non-convex nature of the objective function which has up to million
variables. The approaches suggested in He and Xavier solve the vanishing
gradient problem by providing a sophisticated initialization technique. These
approaches have been quite effective and have achieved good results on standard
datasets, but these same approaches do not work very well on more practical
datasets. We think the reason for this is not making use of data statistics for
initializing the network weights. Optimizing such a high dimensional loss
function requires careful initialization of network weights. In this work, we
propose a data dependent initialization and analyze its performance against the
standard initialization techniques such as He and Xavier. We performed our
experiments on some practical datasets and the results show our algorithm's
superior classification accuracy.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10570</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10571</identifier>
 <datestamp>2018-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Certifiable Distributional Robustness with Principled Adversarial
  Training</dc:title>
 <dc:creator>Sinha, Aman</dc:creator>
 <dc:creator>Namkoong, Hongseok</dc:creator>
 <dc:creator>Duchi, John</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Neural networks are vulnerable to adversarial examples and researchers have
proposed many heuristic attack and defense mechanisms. We take the principled
view of distributionally robust optimization, which guarantees performance
under adversarial input perturbations. By considering a Lagrangian penalty
formulation of perturbation of the underlying data distribution in a
Wasserstein ball, we provide a training procedure that augments model parameter
updates with worst-case perturbations of training data. For smooth losses, our
procedure provably achieves moderate levels of robustness with little
computational or statistical cost relative to empirical risk minimization.
Furthermore, our statistical guarantees allow us to efficiently certify
robustness for the population loss. For imperceptible perturbations, our method
matches or outperforms heuristic approaches.
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:date>2018-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10571</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10574</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Personalized word representations Carrying Personalized Semantics
  Learned from Social Network Posts</dc:title>
 <dc:creator>Lin, Zih-Wei</dc:creator>
 <dc:creator>Sung, Tzu-Wei</dc:creator>
 <dc:creator>Lee, Hung-Yi</dc:creator>
 <dc:creator>Lee, Lin-Shan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Distributed word representations have been shown to be very useful in various
natural language processing (NLP) application tasks. These word vectors learned
from huge corpora very often carry both semantic and syntactic information of
words. However, it is well known that each individual user has his own language
patterns because of different factors such as interested topics, friend groups,
social activities, wording habits, etc., which may imply some kind of
personalized semantics. With such personalized semantics, the same word may
imply slightly differently for different users. For example, the word
&quot;Cappuccino&quot; may imply &quot;Leisure&quot;, &quot;Joy&quot;, &quot;Excellent&quot; for a user enjoying
coffee, by only a kind of drink for someone else. Such personalized semantics
of course cannot be carried by the standard universal word vectors trained with
huge corpora produced by many people. In this paper, we propose a framework to
train different personalized word vectors for different users based on the very
successful continuous skip-gram model using the social network data posted by
many individual users. In this framework, universal background word vectors are
first learned from the background corpora, and then adapted by the personalized
corpus for each individual user to learn the personalized word vectors. We use
two application tasks to evaluate the quality of the personalized word vectors
obtained in this way, the user prediction task and the sentence completion
task. These personalized word vectors were shown to carry some personalized
semantics and offer improved performance on these two evaluation tasks.
</dc:description>
 <dc:description>Comment: Accepted by the 12th biannual IEEE workshop on Automatic Speech
  Recognition and Understanding (ASRU'17)</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10574</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10577</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Examining CNN Representations with respect to Dataset Bias</dc:title>
 <dc:creator>Zhang, Quanshi</dc:creator>
 <dc:creator>Wang, Wenguan</dc:creator>
 <dc:creator>Zhu, Song-Chun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Given a pre-trained CNN without any testing samples, this paper proposes a
simple yet effective method to diagnose feature representations of the CNN. We
aim to discover representation flaws caused by potential dataset bias. More
specifically, when the CNN is trained to estimate image attributes, we mine
latent relationships between representations of different attributes inside the
CNN. Then, we compare the mined attribute relationships with ground-truth
attribute relationships to discover the CNN's blind spots and failure modes due
to dataset bias. In fact, representation flaws caused by dataset bias cannot be
examined by conventional evaluation strategies based on testing images, because
testing images may also have a similar bias. Experiments have demonstrated the
effectiveness of our method.
</dc:description>
 <dc:description>Comment: in AAAI 2018</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:date>2017-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10577</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10583</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secrecy Rate Maximization with Outage Constraint in Multihop Relaying
  Networks</dc:title>
 <dc:creator>Yao, Jianping</dc:creator>
 <dc:creator>Liu, Yuan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study the secure transmission in multihop wireless networks
with randomize-and-forward (RaF) relaying, in the presence of randomly
distributed eavesdroppers. By considering adaptive encoder with on-off
transmission (OFT) scheme, we investigate the optimal design of the wiretap
code and routing strategies to maximize the secrecy rate while satisfying the
secrecy outage probability (SOP) constraint. We derive the exact expressions
for the optimal rate parameters of the wiretap code. Then the secure routing
problem is solved by revising the classical Bellman-Ford algorithm. Simulation
results are conducted to verify our analysis.
</dc:description>
 <dc:description>Comment: 4 pages, 2 figures, 1 table, Accepted for publication at the IEEE
  Communications Letter</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10585</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Path-Based Attention Neural Model for Fine-Grained Entity Typing</dc:title>
 <dc:creator>Zhang, Denghui</dc:creator>
 <dc:creator>Cai, Pengshan</dc:creator>
 <dc:creator>Jia, Yantao</dc:creator>
 <dc:creator>Li, Manling</dc:creator>
 <dc:creator>Wang, Yuanzhuo</dc:creator>
 <dc:creator>Cheng, Xueqi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  Fine-grained entity typing aims to assign entity mentions in the free text
with types arranged in a hierarchical structure. Traditional distant
supervision based methods employ a structured data source as a weak supervision
and do not need hand-labeled data, but they neglect the label noise in the
automatically labeled training corpus. Although recent studies use many
features to prune wrong data ahead of training, they suffer from error
propagation and bring much complexity. In this paper, we propose an end-to-end
typing model, called the path-based attention neural model (PAN), to learn a
noise- robust performance by leveraging the hierarchical structure of types.
Experiments demonstrate its effectiveness.
</dc:description>
 <dc:description>Comment: AAAI 2018</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:date>2018-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10585</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10586</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluation of Automatic Video Captioning Using Direct Assessment</dc:title>
 <dc:creator>Graham, Yvette</dc:creator>
 <dc:creator>Awad, George</dc:creator>
 <dc:creator>Smeaton, Alan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present Direct Assessment, a method for manually assessing the quality of
automatically-generated captions for video. Evaluating the accuracy of video
captions is particularly difficult because for any given video clip there is no
definitive ground truth or correct answer against which to measure. Automatic
metrics for comparing automatic video captions against a manual caption such as
BLEU and METEOR, drawn from techniques used in evaluating machine translation,
were used in the TRECVid video captioning task in 2016 but these are shown to
have weaknesses. The work presented here brings human assessment into the
evaluation by crowdsourcing how well a caption describes a video. We
automatically degrade the quality of some sample captions which are assessed
manually and from this we are able to rate the quality of the human assessors,
a factor we take into account in the evaluation. Using data from the TRECVid
video-to-text task in 2016, we show how our direct assessment method is
replicable and robust and should scale to where there many caption-generation
techniques to be evaluated.
</dc:description>
 <dc:description>Comment: 26 pages, 8 figures</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10586</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10587</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intelligent Interference Exploitation for Heterogeneous Cellular
  Networks against Eavesdropping</dc:title>
 <dc:creator>Zou, Yulong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper explores the co-existence of a macro cell and a small cell for
heterogeneous cellular networks, where a macro-cell base station (MBS) and
small-cell base station (SBS) transmit to respective macro-cell user (MU) and
small-cell user (SU) through their shared spectrum in the face of a common
eavesdropper. We consider two spectrum sharing mechanisms, namely the overlay
spectrum sharing (OSS) and underlay spectrum sharing (USS). In the OSS, MBS and
SBS take turns to access their shared spectrum. By contrast, the USS allows MBS
and SBS to simultaneously transmit over the shared spectrum with the aid of
power control for limiting their mutual interference, thus called
interference-limited USS (IL-USS). We propose an interference-canceled USS
(IC-USS) scheme, where a sophisticatedly-designed signal is emitted at MBS to
cancel out the interference received at MU, which is also beneficial in terms
of defending the common eavesdropper. Closed-form expressions of overall outage
probability and intercept probability are derived for OSS, IL-USS and IC-USS
schemes by taking into account both MBS-MU and SBS-SU transmissions. We prove
that the proposed IC-USS can achieve an absolute security with zero intercept
probability for the MBS-MU transmission. The secrecy diversity analysis is also
carried out by characterizing an asymptotic behavior of the overall outage
probability with a given intercept probability in high signal-to-noise ratio
region. It is shown that the secrecy diversity gains of conventional OSS and
IL-USS are zero, whereas the proposed IC-USS achieves a higher secrecy
diversity gain of one. Additionally, numerical results demonstrate an obvious
advantage of the proposed IC-USS over OSS and IL-USS against eavesdropping.
</dc:description>
 <dc:description>Comment: 12 pages, IEEE Journal on Selected Areas in Communications, 2018</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:date>2018-01-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10587</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10589</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Knee Osteoarthritis Diagnosis from Plain Radiographs: A Deep
  Learning-Based Approach</dc:title>
 <dc:creator>Tiulpin, Aleksei</dc:creator>
 <dc:creator>Thevenot, J&#xe9;r&#xf4;me</dc:creator>
 <dc:creator>Rahtu, Esa</dc:creator>
 <dc:creator>Lehenkari, Petri</dc:creator>
 <dc:creator>Saarakkala, Simo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Knee osteoarthritis (OA) is the most common musculoskeletal disorder. OA
diagnosis is currently conducted by assessing symptoms and evaluating plain
radiographs, but this process suffers from subjectivity. In this study, we
present a new transparent computer-aided diagnosis method based on the Deep
Siamese Convolutional Neural Network to automatically score knee OA severity
according to the Kellgren-Lawrence grading scale. We trained our method using
the data solely from the Multicenter Osteoarthritis Study and validated it on
randomly selected 3,000 subjects (5,960 knees) from Osteoarthritis Initiative
dataset. Our method yielded a quadratic Kappa coefficient of 0.83 and average
multiclass accuracy of 66.71\% compared to the annotations given by a committee
of clinical experts. Here, we also report a radiological OA diagnosis area
under the ROC curve of 0.93. We also present attention maps -- given as a class
probability distribution -- highlighting the radiological features affecting
the network decision. This information makes the decision process transparent
for the practitioner, which builds better trust toward automatic methods. We
believe that our model is useful for clinical decision making and for OA
research; therefore, we openly release our training codes and the data set
created in this study.
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10589</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10592</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Almost Optimal Stochastic Weighted Matching With Few Queries</dc:title>
 <dc:creator>Behnezhad, Soheil</dc:creator>
 <dc:creator>Reyhani, Nima</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the stochastic matching problem. An edge-weighted general graph
$G(V, E)$ is given in the input, where each edge in $E$ is realized
independently with probability $p$. The realization is initially unknown,
however, we are able to query the edges to determine whether they are realized.
The goal is to query only a small number of edges to find a realized matching
that is sufficiently close to the optimum (i.e., the maximum matching among all
realized edges).
  The stochastic matching problem has been studied extensively during the past
decade because of its numerous real-world applications in kidney-exchange,
matchmaking services, online labor markets, advertisement, etc.
  Our main result is an adaptive algorithm that, in expectation, finds a
$(1-\epsilon)$-approximation by querying only $O(1)$ edges per vertex. Prior to
our work, no nontrivial approximation was known for weighted graphs using a
constant per-vertex budget. The only known result for weighted graphs is the
algorithm of Maehara and Yamaguchi~(SODA'18) that achieves a
$(1-\epsilon)$-approximation by querying $\Theta(w\log{n})$ edges per vertex
where $w$ is the maximum edge-weight. Our result is a substantial improvement
over this bound and has an appealing practical message: No matter what the
structure of the input graph is, one can get arbitrarily close to the optimum
solution by querying only a constant number of edges per vertex.
  To obtain our results, we introduce novel properties of weighted augmenting
paths that may be of independent interest in generalizing augmenting path based
techniques to weighted graphs.
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10592</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10595</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Social Welfare Maximization Auction in Edge Computing Resource
  Allocation for Mobile Blockchain</dc:title>
 <dc:creator>Jiao, Yutao</dc:creator>
 <dc:creator>Wang, Ping</dc:creator>
 <dc:creator>Niyato, Dusit</dc:creator>
 <dc:creator>Xiong, Zehui</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Blockchain, an emerging decentralized security system, has been applied in
many applications, such as bitcoin, smart grid, and Internet-of-Things.
However, running the mining process may cost too much energy consumption and
computing resource usage on handheld devices, which restricts the use of
blockchain in mobile environments. In this paper, we consider deploying edge
computing service to support the mobile blockchain. We propose an auction-based
edge computing resource market of the edge computing service provider. Since
there is competition among miners, the allocative externalities (positive and
negative) are taken into account in the model. In our auction mechanism, we
maximize the social welfare while guaranteeing the truthfulness, individual
rationality and computational efficiency. Based on blockchain mining experiment
results, we define a hash power function that characterizes the probability of
successfully mining a block. Through extensive simulations, we evaluate the
performance of our auction mechanism which shows that our edge computing
resources market model can efficiently solve the social welfare maximization
problem for the edge computing service provider.
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:date>2017-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10595</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10598</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Push Recovery of a Position-Controlled Humanoid Robot Based on Capture
  Point Feedback Control</dc:title>
 <dc:creator>Shafiee-Ashtiani, Milad</dc:creator>
 <dc:creator>Yousefi-Koma, Aghil</dc:creator>
 <dc:creator>Mirjalili, Reihaneh</dc:creator>
 <dc:creator>Maleki, Hessam</dc:creator>
 <dc:creator>Karimi, Mojtaba</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this paper, a combination of ankle and hip strategy is used for push
recovery of a position-controlled humanoid robot. Ankle strategy and hip
strategy are equivalent to Center of Pressure (CoP) and Centroidal Moment Pivot
(CMP) regulation respectively. For controlling the CMP and CoP we need a
torque-controlled robot, however most of the conventional humanoid robots are
position controlled. In this regard, we present an efficient way for
implementation of the hip and ankle strategies on a position controlled
humanoid robot. We employ a feedback controller to compensate the capture point
error. Using our scheme, a simple and practical push recovery controller is
designed which can be implemented on the most of the conventional humanoid
robots without the need for torque sensors. The effectiveness of the proposed
approach is verified through push recovery experiments on SURENA-Mini humanoid
robot under severe pushes.
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10598</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10600</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regularization approaches for support vector machines with applications
  to biomedical data</dc:title>
 <dc:creator>Lopez-Martinez, Daniel</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The support vector machine (SVM) is a widely used machine learning tool for
classification based on statistical learning theory. Given a set of training
data, the SVM finds a hyperplane that separates two different classes of data
points by the largest distance. While the standard form of SVM uses L2-norm
regularization, other regularization approaches are particularly attractive for
biomedical datasets where, for example, sparsity and interpretability of the
classifier's coefficient values are highly desired features. Therefore, in this
paper we consider different types of regularization approaches for SVMs, and
explore them in both synthetic and real biomedical datasets.
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10600</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10609</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding Dominant User Utterances And System Responses in Conversations</dc:title>
 <dc:creator>Madan, Dhiraj</dc:creator>
 <dc:creator>Joshi, Sachindra</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  There are several dialog frameworks which allow manual specification of
intents and rule based dialog flow. The rule based framework provides good
control to dialog designers at the expense of being more time consuming and
laborious. The job of a dialog designer can be reduced if we could identify
pairs of user intents and corresponding responses automatically from prior
conversations between users and agents. In this paper we propose an approach to
find these frequent user utterances (which serve as examples for intents) and
corresponding agent responses. We propose a novel SimCluster algorithm that
extends standard K-means algorithm to simultaneously cluster user utterances
and agent utterances by taking their adjacency information into account. The
method also aligns these clusters to provide pairs of intents and response
groups. We compare our results with those produced by using simple Kmeans
clustering on a real dataset and observe upto 10% absolute improvement in
F1-scores. Through our experiments on synthetic dataset, we show that our
algorithm gains more advantage over K-means algorithm when the data has large
variance.
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10609</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10621</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data-Driven Power Flow Linearization: A Regression Approach</dc:title>
 <dc:creator>Liu, Yuxiao</dc:creator>
 <dc:creator>Zhang, Ning</dc:creator>
 <dc:creator>Wang, Yi</dc:creator>
 <dc:creator>Yang, Jingwei</dc:creator>
 <dc:creator>Kang, Chongqing</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The linearization of a power flow (PF) model is an important approach for
simplifying and accelerating the calculation of a power system's control,
operation, and optimization. Traditional model-based methods derive linearized
PF models by making approximations in the analytical PF model according to the
physical characteristics of the power system. Today, more measurements of the
power system are available and thus facilitate data-driven approaches beyond
model-driven approaches. This work studies a linearized PF model through a
data-driven approach. Both a forward regression model ((P, Q) as a function of
(theta, V)) and an inverse regression model ((theta, V) as a function of (P,
Q)) are proposed. Partial least square (PLS)- and Bayesian linear regression
(BLR)-based algorithms are designed to address data collinearity and avoid
overfitting. The proposed approach is tested on a series of IEEE standard
cases, which include both meshed transmission grids and radial distribution
grids, with both Monte Carlo simulated data and public testing data. The
results show that the proposed approach can realize a higher calculation
accuracy than model-based approaches can. The results also demonstrate that the
obtained regression parameter matrices of data-driven models reflect power
system physics by demonstrating similar patterns with some power system
matrices (e.g., the admittance matrix).
</dc:description>
 <dc:description>Comment: 9 pages, 7 figures, 1 table</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10621</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10628</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variational Continual Learning</dc:title>
 <dc:creator>Nguyen, Cuong V.</dc:creator>
 <dc:creator>Li, Yingzhen</dc:creator>
 <dc:creator>Bui, Thang D.</dc:creator>
 <dc:creator>Turner, Richard E.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper develops variational continual learning (VCL), a simple but
general framework for continual learning that fuses online variational
inference (VI) and recent advances in Monte Carlo VI for neural networks. The
framework can successfully train both deep discriminative models and deep
generative models in complex continual learning settings where existing tasks
evolve over time and entirely new tasks emerge. Experimental results show that
variational continual learning outperforms state-of-the-art continual learning
methods on a variety of tasks, avoiding catastrophic forgetting in a fully
automatic way.
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10628</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10629</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dimensionality reduction methods for molecular simulations</dc:title>
 <dc:creator>Doerr, Stefan</dc:creator>
 <dc:creator>Ariz-Extreme, Igor</dc:creator>
 <dc:creator>Harvey, Matthew J.</dc:creator>
 <dc:creator>De Fabritiis, Gianni</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Biomolecules</dc:subject>
 <dc:description>  Molecular simulations produce very high-dimensional data-sets with millions
of data points. As analysis methods are often unable to cope with so many
dimensions, it is common to use dimensionality reduction and clustering methods
to reach a reduced representation of the data. Yet these methods often fail to
capture the most important features necessary for the construction of a Markov
model. Here we demonstrate the results of various dimensionality reduction
methods on two simulation data-sets, one of protein folding and another of
protein-ligand binding. The methods tested include a k-means clustering
variant, a non-linear auto encoder, principal component analysis and tICA. The
dimension-reduced data is then used to estimate the implied timescales of the
slowest process by a Markov state model analysis to assess the quality of the
projection. The projected dimensions learned from the data are visualized to
demonstrate which conformations the various methods choose to represent the
molecular process.
</dc:description>
 <dc:description>Comment: 11 pages, 10 figures</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10629</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10636</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design and Analysis of a Controller Using Quantitative Feedback Theory
  for a Vehicle Air Suspension System</dc:title>
 <dc:creator>Shafiekhani, Ali</dc:creator>
 <dc:creator>Mirsadeghi, Seyed Mehdi</dc:creator>
 <dc:creator>Torabi, Keivan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents the design of a robust controller for a vehicle air
suspension system using Quantitative Feedback Theory (QFT). This study is
primarily focused on control of linearized active air suspension system. For
the purpose of simplicity, the dynamics of the air suspension system is modeled
using a simple 2-DOF quarter car model. Uncertain dynamic system with different
working condition has been considered for the vehicle air suspension system.
</dc:description>
 <dc:description>Comment: 5 pages, 13 figures</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10636</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10639</identifier>
 <datestamp>2017-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>JESC: Japanese-English Subtitle Corpus</dc:title>
 <dc:creator>Pryzant, Reid</dc:creator>
 <dc:creator>Chung, Yongjoo</dc:creator>
 <dc:creator>Jurafsky, Dan</dc:creator>
 <dc:creator>Britz, Denny</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper we describe the Japanese-English Subtitle Corpus (JESC). JESC
is a large Japanese-English parallel corpus covering the underrepresented
domain of conversational dialogue. It consists of more than 3.2 million
examples, making it the largest freely available dataset of its kind. The
corpus was assembled by crawling and aligning subtitles found on the web. The
assembly process incorporates a number of novel preprocessing elements to
ensure high monolingual fluency and accurate bilingual alignments. We summarize
its contents and evaluate its quality using human experts and baseline machine
translation (MT) systems.
</dc:description>
 <dc:description>Comment: To appear at LREC 2018</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:date>2017-12-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10639</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10642</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Homophily of Music Listening in Online Social Networks</dc:title>
 <dc:creator>Zhou, Zhenkun</dc:creator>
 <dc:creator>Xu, Ke</dc:creator>
 <dc:creator>Zhao, Jichang</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Homophily, ranging from demographics to sentiments, breeds connections in
social networks, either offline or online. However, with the prosperous growth
of music streaming service, whether homophily exists in online music listening
remains unclear. In this study, two online social networks of a same group of
active users are established respectively in Netease Music and Weibo. Through
presented multiple similarity measures, it is evidently demonstrated that
homophily does exist in music listening of both online social networks. The
unexpected music similarity in Weibo also implies that knowledge from generic
social networks can be confidently transfered to domain-oriented networks for
context enrichment and algorithm enhancement. Comprehensive factors that might
function in formation of homophily are further probed and many interesting
patterns are profoundly revealed. It is found that female friends are more
homogeneous in music listening and positive and energetic songs significantly
pull users close. Our methodology and findings would shed lights on realistic
applications in online music services.
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10642</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10646</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Consistency of Quick Shift</dc:title>
 <dc:creator>Jiang, Heinrich</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Quick Shift is a popular mode-seeking and clustering algorithm. We present
finite sample statistical consistency guarantees for Quick Shift on mode and
cluster recovery under mild distributional assumptions. We then apply our
results to construct a consistent modal regression algorithm.
</dc:description>
 <dc:description>Comment: Proceedings of 31st Conference on Neural Information Processing
  Systems (NIPS 2017)</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10646</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10648</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using the quantization error from Self-Organized Map (SOM) output for
  detecting critical variability in large bodies of image time series in less
  than a minute</dc:title>
 <dc:creator>Dresp-Langley, Birgitta</dc:creator>
 <dc:creator>Wandeto, John Mwangi</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The quantization error (QE) from SOM applied on time series of spatial
contrast images with variable relative amount of white and dark pixel contents,
as in monochromatic medical images or satellite images, is proven a reliable
indicator of potentially critical changes in image homogeneity. The QE is shown
to increase linearly with the variability in spatial contrast contents across
time when contrast intensity is kept constant.
</dc:description>
 <dc:description>Comment: 12 pages, 10 Figures</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10648</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10654</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Delivery Time Minimization in Edge Caching: Synergistic Benefits of
  Subspace Alignment and Zero Forcing</dc:title>
 <dc:creator>Kakar, Jaber</dc:creator>
 <dc:creator>Alameer, Alaa</dc:creator>
 <dc:creator>Chaaban, Anas</dc:creator>
 <dc:creator>Sezgin, Aydin</dc:creator>
 <dc:creator>Paulraj, Arogyaswami</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  An emerging trend of next generation communication systems is to provide
network edges with additional capabilities such as additional storage resources
in the form of caches to reduce file delivery latency. To investigate this
aspect, we study the fundamental limits of a cache-aided wireless network
consisting of one central base station, $M$ transceivers and $K$ receivers from
a latency-centric perspective. We use the normalized delivery time (NDT) to
capture the per-bit latency for the worst-case file request pattern at high
signal-to-noise ratios (SNR), normalized with respect to a reference
interference-free system with unlimited transceiver cache capabilities. For
various special cases with $M=\{1,2\}$ and $K=\{1,2,3\}$ that satisfy $M+K\leq
4$, we establish the optimal tradeoff between cache storage and latency. This
is facilitated through establishing a novel converse (for arbitrary $M$ and
$K$) and an achievability scheme on the NDT. Our achievability scheme is a
synergistic combination of multicasting, zero-forcing beamforming and
interference alignment.
</dc:description>
 <dc:description>Comment: submitted to ICC 2018; fixed some typos</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10654</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10655</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>If it ain't broke, don't fix it: Sparse metric repair</dc:title>
 <dc:creator>Gilbert, Anna C.</dc:creator>
 <dc:creator>Jain, Lalit</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Many modern data-intensive computational problems either require, or benefit
from distance or similarity data that adhere to a metric. The algorithms run
faster or have better performance guarantees. Unfortunately, in real
applications, the data are messy and values are noisy. The distances between
the data points are far from satisfying a metric. Indeed, there are a number of
different algorithms for finding the closest set of distances to the given ones
that also satisfy a metric (sometimes with the extra condition of being
Euclidean). These algorithms can have unintended consequences, they can change
a large number of the original data points, and alter many other features of
the data.
  The goal of sparse metric repair is to make as few changes as possible to the
original data set or underlying distances so as to ensure the resulting
distances satisfy the properties of a metric. In other words, we seek to
minimize the sparsity (or the $\ell_0$ &quot;norm&quot;) of the changes we make to the
distances subject to the new distances satisfying a metric. We give three
different combinatorial algorithms to repair a metric sparsely. In one setting
the algorithm is guaranteed to return the sparsest solution and in the other
settings, the algorithms repair the metric. Without prior information, the
algorithms run in time proportional to the cube of the number of input data
points and, with prior information we can reduce the running time considerably.
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10655</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10657</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Armed Bandits with Non-Stationary Rewards</dc:title>
 <dc:creator>Cortes, Corinna</dc:creator>
 <dc:creator>DeSalvo, Giulia</dc:creator>
 <dc:creator>Kuznetsov, Vitaly</dc:creator>
 <dc:creator>Mohri, Mehryar</dc:creator>
 <dc:creator>Yang, Scott</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The multi-armed bandit problem where the rewards are realizations of general
non-stationary stochastic processes is a challenging setting which has not been
previously tackled in the bandit literature in its full generality. We present
the first theoretical analysis of this problem by deriving guarantees for both
the path-dependent dynamic pseudo-regret and the standard pseudo-regret that,
remarkably, are both logarithmic in the number of rounds under certain natural
conditions. We describe several UCB-type algorithms based on the notion of
weighted discrepancy, a key measure of non-stationarity for stochastic
processes. We show that discrepancy provides a unified framework for the
analysis of non-stationary rewards. Our experiments demonstrate a significant
improvement in practice compared to standard benchmarks.
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10657</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10660</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Bounds for Testing Forbidden Order Patterns</dc:title>
 <dc:creator>Ben-Eliezer, Omri</dc:creator>
 <dc:creator>Canonne, Cl&#xe9;ment L.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A sequence $f\colon\{1,\dots,n\}\to\mathbb{R}$ contains a permutation $\pi$
of length $k$ if there exist $i_1&lt;\dots&lt;i_k$ such that, for all $x,y$,
$f(i_x)&lt;f(i_y)$ if and only if $\pi(x)&lt;\pi(y)$; otherwise, $f$ is said to be
$\pi$-free. In this work, we consider the problem of testing for $\pi$-freeness
with one-sided error, continuing the investigation of [Newman et al., SODA'17].
  We demonstrate a surprising behavior for non-adaptive tests with one-sided
error: While a trivial sampling-based approach yields an $\varepsilon$-test for
$\pi$-freeness making $\Theta(\varepsilon^{-1/k} n^{1-1/k})$ queries, our lower
bounds imply that this is almost optimal for most permutations! Specifically,
for most permutations $\pi$ of length $k$, any non-adaptive one-sided
$\varepsilon$-test requires
$\varepsilon^{-1/(k-\Theta(1))}n^{1-1/(k-\Theta(1))}$ queries; furthermore, the
permutations that are hardest to test require
$\Theta(\varepsilon^{-1/(k-1)}n^{1-1/(k-1)})$ queries, which is tight in $n$
and $\varepsilon$.
  Additionally, we show two hierarchical behaviors here. First, for any $k$ and
$l\leq k-1$, there exists some $\pi$ of length $k$ that requires
$\tilde{\Theta}_{\varepsilon}(n^{1-1/l})$ non-adaptive queries. Second, we show
an adaptivity hierarchy for $\pi=(1,3,2)$ by proving upper and lower bounds for
(one- and two-sided) testing of $\pi$-freeness with $r$ rounds of adaptivity.
The results answer open questions of Newman et al. and [Canonne and Gur,
CCC'17].
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10662</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Study on Topological Descriptors for the Analysis of 3D Surface
  Texture</dc:title>
 <dc:creator>Zeppelzauer, Matthias</dc:creator>
 <dc:creator>Zielinski, Bartosz</dc:creator>
 <dc:creator>Juda, Mateusz</dc:creator>
 <dc:creator>Seidl, Markus</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Methods from computational topology are becoming more and more popular in
computer vision and have shown to improve the state-of-the-art in several
tasks. In this paper, we investigate the applicability of topological
descriptors in the context of 3D surface analysis for the classification of
different surface textures. We present a comprehensive study on topological
descriptors, investigate their robustness and expressiveness and compare them
with state-of-the-art methods including Convolutional Neural Networks (CNNs).
Results show that class-specific information is reflected well in topological
descriptors. The investigated descriptors can directly compete with
non-topological descriptors and capture complementary information. As a
consequence they improve the state-of-the-art when combined with
non-topological descriptors.
</dc:description>
 <dc:description>Comment: Preprint of Article &quot;A Study on Topological Descriptors for the
  Analysis of 3D Surface Texture&quot; in Elsevier Journal on Computer Vision and
  Image Understanding (CVIU): https://doi.org/10.1016/j.cviu.2017.10.012, 17
  Pages, 19 Figures, 4 Tables</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10662</dc:identifier>
 <dc:identifier>doi:10.1016/j.cviu.2017.10.012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10663</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>List-decodable zero-rate codes</dc:title>
 <dc:creator>Alon, Noga</dc:creator>
 <dc:creator>Bukh, Boris</dc:creator>
 <dc:creator>Polyanskiy, Yury</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>68P30, 05D99, 52C35</dc:subject>
 <dc:description>  We consider list-decoding in the zero-rate regime for two cases: the binary
alphabet and the spherical codes in Euclidean space. Specifically, we study the
maximal $\tau \in [0,1]$ for which there exists an arrangement of $M$ balls of
relative Hamming radius $\tau$ in the binary hypercube (of arbitrary dimension)
with the property that no point of the latter is covered by $L$ or more of
them. As $M\to \infty$ the maximal $\tau$ decreases to a well-known critical
value $\tau_L$. In this work, we prove several results on the rate of this
convergence.
  For the binary case, we show that the rate is $\Theta(M^{-1})$ when $L$ is
even, thus extending the classical results of Plotkin and Levenshtein for
$L=2$. For $L=3$ the rate is shown to be $\Theta(M^{-\tfrac{2}{3}})$.
  For the similar question about spherical codes, we prove the rate is
$\Omega(M^{-1})$ and $O(M^{-\tfrac{2L}{L^2-L+2}})$.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10663</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10669</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wideband Channel Estimation for Hybrid Beamforming Millimeter Wave
  Communication Systems with Low-Resolution ADCs</dc:title>
 <dc:creator>Sung, Junmo</dc:creator>
 <dc:creator>Choi, Jinseok</dc:creator>
 <dc:creator>Evans, Brian L.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A potential tremendous spectrum resource makes millimeter wave (mmWave)
communications a promising technology. High power consumption due to a large
number of antennas and analog-to-digital converters (ADCs) for beamforming to
overcome the large propagation losses is problematic in practice. As a hybrid
beamforming architecture and low-resolution ADCs are considered to reduce power
consumption, estimation of mmWave channels becomes challenging. We evaluate
several channel estimation algorithms for wideband mmWave systems with hybrid
beamforming and low-resolution ADCs. Through simulation, we show that 1)
infinite bit ADCs with least-squares estimation have worse channel estimation
performance than do one-bit ADCs with orthogonal matching pursuit (OMP) in an
SNR range of interest, 2) three- and four-bit quantizers can achieve channel
estimation performance close to the unquantized case when using OMP, 3) a
receiver with a single RF chain can yield better estimates than that with four
RF chains if enough frames are exploited, and 4) for one-bit ADCs, exploitation
of higher transmit power and more frames for performance enhancement adversely
affects estimation performance after a certain point.
</dc:description>
 <dc:description>Comment: 6 pages, 8 figures, submitted to ICC 2018</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10669</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10673</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Narrowband Channel Estimation for Hybrid Beamforming Millimeter Wave
  Communication Systems with One-bit Quantization</dc:title>
 <dc:creator>Sung, Junmo</dc:creator>
 <dc:creator>Choi, Jinseok</dc:creator>
 <dc:creator>Evans, Brian L.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Millimeter wave (mmWave) spectrum has drawn attention due to its tremendous
available bandwidth. The high propagation losses in the mmWave bands
necessitate beamforming with a large number of antennas. Traditionally each
antenna is paired with a high-speed analog-to-digital converter (ADC), which
results in high power consumption. A hybrid beamforming architecture and
one-bit resolution ADCs have been proposed to reduce power consumption.
However, analog beamforming and one-bit quantization make channel estimation
more challenging. In this paper, we propose a narrowband channel estimation
algorithm for mmWave communication systems with one-bit ADCs and hybrid
beamforming based on generalized approximate message passing (GAMP). We show
through simulation that 1) GAMP variants with one-bit ADCs have better
performance than do least-squares estimation methods without quantization, 2)
the proposed one-bit GAMP algorithm achieves the lowest estimation error among
the GAMP variants, and 3) exploiting more frames and RF chains enhances the
channel estimation performance.
</dc:description>
 <dc:description>Comment: 5 pages, 5 figures, submitted to ICASSP 2018</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10673</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10675</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovery Radiomics with CLEAR-DR: Interpretable Computer Aided
  Diagnosis of Diabetic Retinopathy</dc:title>
 <dc:creator>Kumar, Devinder</dc:creator>
 <dc:creator>Taylor, Graham W.</dc:creator>
 <dc:creator>Wong, Alexander</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Objective: Radiomics-driven Computer Aided Diagnosis (CAD) has shown
considerable promise in recent years as a potential tool for improving clinical
decision support in medical oncology, particularly those based around the
concept of Discovery Radiomics, where radiomic sequencers are discovered
through the analysis of medical imaging data. One of the main limitations with
current CAD approaches is that it is very difficult to gain insight or
rationale as to how decisions are made, thus limiting their utility to
clinicians. Methods: In this study, we propose CLEAR-DR, a novel interpretable
CAD system based on the notion of CLass-Enhanced Attentive Response Discovery
Radiomics for the purpose of clinical decision support for diabetic
retinopathy. Results: In addition to disease grading via the discovered deep
radiomic sequencer, the CLEAR-DR system also produces a visual interpretation
of the decision-making process to provide better insight and understanding into
the decision-making process of the system. Conclusion: We demonstrate the
effectiveness and utility of the proposed CLEAR-DR system of enhancing the
interpretability of diagnostic grading results for the application of diabetic
retinopathy grading. Significance: CLEAR-DR can act as a potential powerful
tool to address the uninterpretability issue of current CAD systems, thus
improving their utility to clinicians.
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10675</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10686</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regularization for Deep Learning: A Taxonomy</dc:title>
 <dc:creator>Kuka&#x10d;ka, Jan</dc:creator>
 <dc:creator>Golkov, Vladimir</dc:creator>
 <dc:creator>Cremers, Daniel</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>62M45</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.5</dc:subject>
 <dc:description>  Regularization is one of the crucial ingredients of deep learning, yet the
term regularization has various definitions, and regularization methods are
often studied separately from each other. In our work we present a systematic,
unifying taxonomy to categorize existing methods. We distinguish methods that
affect data, network architectures, error terms, regularization terms, and
optimization procedures. We do not provide all details about the listed
methods; instead, we present an overview of how the methods can be sorted into
meaningful categories and sub-categories. This helps revealing links and
fundamental similarities between them. Finally, we include practical
recommendations both for users and for developers of new regularization
methods.
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10686</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10687</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-Precision Localization Using Ground Texture</dc:title>
 <dc:creator>Zhang, Linguang</dc:creator>
 <dc:creator>Finkelstein, Adam</dc:creator>
 <dc:creator>Rusinkiewicz, Szymon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Location-aware applications play an increasingly critical role in everyday
life. However, the most common global localization technology - GPS - has
limited accuracy and can be unusable in dense urban areas and indoors. We
introduce an image-based global localization system that is accurate to a few
millimeters and performs reliable localization both indoors and outside. The
key idea is to capture and index distinctive local features in ground textures.
This is based on the observation that ground textures including wood, carpet,
tile, concrete, and asphalt may look random and homogeneous, but all contain
cracks, scratches, or unique arrangements of carpet fibers. These imperfections
are persistent, and can serve as local features. Our system incorporates a
downward-facing camera to capture the fine texture of the ground, together with
an image processing pipeline that locates the captured texture patch in a
compact database constructed offline. We demonstrate the capability of our
system to robustly, accurately, and quickly locate test images on various types
of outdoor and indoor ground surfaces.
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10687</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10689</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kernel Graph Convolutional Neural Networks</dc:title>
 <dc:creator>Nikolentzos, Giannis</dc:creator>
 <dc:creator>Meladianos, Polykarpos</dc:creator>
 <dc:creator>Tixier, Antoine Jean-Pierre</dc:creator>
 <dc:creator>Skianis, Konstantinos</dc:creator>
 <dc:creator>Vazirgiannis, Michalis</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Graph kernels have been successfully applied to many graph classification
problems. Typically, a kernel is first designed, and then an SVM classifier is
trained based on the features defined implicitly by this kernel. This two-stage
approach decouples data representation from learning, which is suboptimal. On
the other hand, Convolutional Neural Networks (CNNs) have the capability to
learn their own features directly from the raw data during training.
Unfortunately, they cannot handle irregular data such as graphs. We address
this challenge by using graph kernels to embed meaningful local neighborhoods
of the graphs in a continuous vector space. A set of filters is then convolved
with these patches, pooled, and the output is then passed to a feedforward
network. With limited parameter tuning, our approach outperforms strong
baselines on 7 out of 10 benchmark datasets.
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10689</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10695</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multilinear Class-Specific Discriminant Analysis</dc:title>
 <dc:creator>Tran, Dat Thanh</dc:creator>
 <dc:creator>Gabbouj, Moncef</dc:creator>
 <dc:creator>Iosifidis, Alexandros</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  There has been a great effort to transfer linear discriminant techniques that
operate on vector data to high-order data, generally referred to as Multilinear
Discriminant Analysis (MDA) techniques. Many existing works focus on maximizing
the inter-class variances to intra-class variances defined on tensor data
representations. However, there has not been any attempt to employ
class-specific discrimination criteria for the tensor data. In this paper, we
propose a multilinear subspace learning technique suitable for applications
requiring class-specific tensor models. The method maximizes the discrimination
of each individual class in the feature space while retains the spatial
structure of the input. We evaluate the efficiency of the proposed method on
two problems, i.e. facial image analysis and stock price prediction based on
limit order book data.
</dc:description>
 <dc:description>Comment: accepted in PRL</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10695</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10702</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards A Usability Model for Software Development Process and Practice</dc:title>
 <dc:creator>Fontdevila, Diego</dc:creator>
 <dc:creator>Genero, Marcela</dc:creator>
 <dc:creator>Oliveros, Alejandro</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Context/Background: process and practice adoption is a key element in modern
software process improvement initiatives, and many of them fail. Goal: this
paper presents a preliminary version of a usability model for software
development process and practice. Method: this model integrates different
perspectives, the ISO Standard on Sys- tems and Software Quality Models (ISO
25010) and classic usability literature. For illustrating the feasibility of
the model, two experts applied it to Scrum. Results: metrics values were mostly
positive and consistent between evaluators. Conclusions: we find the model
feasible to use and potentially beneficial.
</dc:description>
 <dc:description>Comment: 6 pages, Profes 2017 The 18th International Conference on
  Product-Focused Software Process Improvement</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10702</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10704</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training Probabilistic Spiking Neural Networks with First-to-spike
  Decoding</dc:title>
 <dc:creator>Bagheri, Alireza</dc:creator>
 <dc:creator>Simeone, Osvaldo</dc:creator>
 <dc:creator>Rajendran, Bipin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Third-generation neural networks, or Spiking Neural Networks (SNNs), aim at
harnessing the energy efficiency of spike-domain processing by building on
computing elements that operate on, and exchange, spikes. In this paper, the
problem of training a two-layer SNNs is studied for the purpose of
classification, under a Generalized Linear Model (GLM) probabilistic neural
model that was previously considered within the computational neuroscience
literature. Conventional classification rules for SNNs operate offline based on
the number of output spikes at each output neuron. In contrast, a novel
training method is proposed here for a first-to-spike decoding rule, whereby
the SNN can perform an early classification decision once spike firing is
detected at an output neuron. Numerical results bring insights into the optimal
parameter selection for the GLM neuron and on the accuracy-complexity trade-off
performance of conventional and first-to-spike decoding.
</dc:description>
 <dc:description>Comment: Submitted for conference publication</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10704</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10706</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Disjunctive bases: normal forms and model theory for modal logics</dc:title>
 <dc:creator>Enqvist, Sebastian</dc:creator>
 <dc:creator>Venema, Yde</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We present the concept of a disjunctive basis as a generic framework for
normal forms in modal logic based on coalgebra. Disjunctive bases were defined
in previous work on completeness for modal fixpoint logics, where they played a
central role in the proof of a generic completeness theorem for coalgebraic
mu-calculi. Believing the concept has a much wider significance, here we
investigate it more thoroughly in its own right. We show that the presence of a
disjunctive basis at the &quot;one-step&quot; level entails a number of good properties
for a coalgebraic mu-calculus, in particular, a simulation theorem showing that
every alternating automaton can be transformed into an equivalent
nondeterministic one. Based on this, we prove a Lyndon theorem for the full
fixpoint logic, its fixpoint-free fragment and its one-step fragment, a Uniform
Interpolation result, for both the full mu-calculus and its fixpoint-free
fragment, and a Janin-Walukiewicz-style characterization theorem for the
mu-calculus under slightly stronger assumptions. We also raise the questions,
when a disjunctive basis exists, and how disjunctive bases are related to Moss'
coalgebraic &quot;nabla&quot; modalities. Nabla formulas provide disjunctive bases for
many coalgebraic modal logics, but there are cases where disjunctive bases give
useful normal forms even when nabla formulas fail to do so, our prime example
being graded modal logic. We also show that disjunctive bases are preserved by
forming sums of coalgebraic modal logics, providing a tool for modular
construction of modal logics admitting disjunctive bases. Finally, we consider
the problem of giving a category-theoretic formulation of disjunctive bases,
and provide a partial solution.
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10706</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10710</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Pre-Trained Image Features and Synthetic Images for Deep Learning</dc:title>
 <dc:creator>Hinterstoisser, Stefan</dc:creator>
 <dc:creator>Lepetit, Vincent</dc:creator>
 <dc:creator>Wohlhart, Paul</dc:creator>
 <dc:creator>Konolige, Kurt</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep Learning methods usually require huge amounts of training data to
perform at their full potential, and often require expensive manual labeling.
Using synthetic images is therefore very attractive to train object detectors,
as the labeling comes for free, and several approaches have been proposed to
combine synthetic and real images for training.
  In this paper, we show that a simple trick is sufficient to train very
effectively modern object detectors with synthetic images only: We freeze the
layers responsible for feature extraction to generic layers pre-trained on real
images, and train only the remaining layers with plain OpenGL rendering. Our
experiments with very recent deep architectures for object recognition
(Faster-RCNN, R-FCN, Mask-RCNN) and image feature extractors (InceptionResnet
and Resnet) show this simple approach performs surprisingly well.
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10710</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10714</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Saak Transform Approach to Efficient, Scalable and Robust Handwritten
  Digits Recognition</dc:title>
 <dc:creator>Chen, Yueru</dc:creator>
 <dc:creator>Xu, Zhuwei</dc:creator>
 <dc:creator>Cai, Shanshan</dc:creator>
 <dc:creator>Lang, Yujian</dc:creator>
 <dc:creator>Kuo, C. -C. Jay</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  An efficient, scalable and robust approach to the handwritten digits
recognition problem based on the Saak transform is proposed in this work.
First, multi-stage Saak transforms are used to extract a family of joint
spatial-spectral representations of input images. Then, the Saak coefficients
are used as features and fed into the SVM classifier for the classification
task. In order to control the size of Saak coefficients, we adopt a lossy Saak
transform that uses the principal component analysis (PCA) to select a smaller
set of transform kernels. The handwritten digits recognition problem is well
solved by the convolutional neural network (CNN) such as the LeNet-5. We
conduct a comparative study on the performance of the LeNet-5 and the
Saak-transform-based solutions in terms of scalability and robustness as well
as the efficiency of lossless and lossy Saak transforms under a comparable
accuracy level.
</dc:description>
 <dc:description>Comment: 5 pages, 5 figures, 5 tables</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10714</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10718</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Coded Multicast in Cache Networks with Arbitrary Content
  Placement</dc:title>
 <dc:creator>Asghari, Seyed Mohammad</dc:creator>
 <dc:creator>Ouyang, Yi</dc:creator>
 <dc:creator>Nayyar, Ashutosh</dc:creator>
 <dc:creator>Avestimehr, A. Salman</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A new class of caching schemes, called coded caching can significantly reduce
the communication bandwidth requirement for satisfying users' demands by
utilizing the multicasting gain among multiple users. Most existing works
assume that the users follow the prescriptions for content placement made by
the system. However, users in practice prefer to decide what files to cache or
discard some part of their caches due to lack of space. In order to address
this issue, we study a caching system where the content placement phase has
been already carried out by the users arbitrarily. More specifically, we
consider a network consisting of a file server connected through a shared link
to $N$ users, each equipped with a cache. Given arbitrary content placement by
the users, the goal is to find a coded multicast strategy for the server that
minimizes the load of the shared link. We first formulate the optimal coded
multicast design problem as an Integer Linear Program (ILP). Using a connection
with the weighted set cover problem, we propose an approximation algorithm for
solving this problem. We show that our proposed algorithm provides $(1 + \log
N)$-approximation for the optimal coded multicast design problem, while the
approximation ratio for the existing coded delivery schemes is linear in $N$.
Numerical simulations show that our proposed algorithm provides a considerable
bandwidth reduction over the existing coded delivery schemes for
uniformly-random generated content placement.
</dc:description>
 <dc:description>Comment: 22 pages, 9 figures</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10723</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simple and Effective Multi-Paragraph Reading Comprehension</dc:title>
 <dc:creator>Clark, Christopher</dc:creator>
 <dc:creator>Gardner, Matt</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We consider the problem of adapting neural paragraph-level question answering
models to the case where entire documents are given as input. Our proposed
solution trains models to produce well calibrated confidence scores for their
results on individual paragraphs. We sample multiple paragraphs from the
documents during training, and use a shared-normalization training objective
that encourages the model to produce globally correct output. We combine this
method with a state-of-the-art pipeline for training models on document QA
data. Experiments demonstrate strong performance on several document QA
datasets. Overall, we are able to achieve a score of 71.3 F1 on the web portion
of TriviaQA, a large improvement from the 56.7 F1 of the previous best system.
</dc:description>
 <dc:description>Comment: 11 pages, updated a reference</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10723</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10724</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BAS: Beetle Antennae Search Algorithm for Optimization Problems</dc:title>
 <dc:creator>Jiang, Xiangyuan</dc:creator>
 <dc:creator>Li, Shuai</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Meta-heuristic algorithms have become very popular because of powerful
performance on the optimization problem. A new algorithm called beetle antennae
search algorithm (BAS) is proposed in the paper inspired by the searching
behavior of longhorn beetles. The BAS algorithm imitates the function of
antennae and the random walking mechanism of beetles in nature, and then two
main steps of detecting and searching are implemented. Finally, the algorithm
is benchmarked on 2 well-known test functions, in which the numerical results
validate the efficacy of the proposed BAS algorithm.
</dc:description>
 <dc:description>Comment: 3 pages, 3 figures</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10724</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10727</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exact Topology and Parameter Estimation in Distribution Grids with
  Minimal Observability</dc:title>
 <dc:creator>Park, Sejun</dc:creator>
 <dc:creator>Deka, Deepjyoti</dc:creator>
 <dc:creator>Chertkov, Michael</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Limited presence of nodal and line meters in distribution grids hinders their
optimal operation and participation in real-time markets. In particular lack of
real-time information on the grid topology and infrequently calibrated line
parameters (impedances) adversely affect the accuracy of any operational power
flow control. This paper suggests a novel algorithm for learning the topology
of distribution grid and estimating impedances of the operational lines with
minimal observational requirements - it provably reconstructs topology and
impedances using voltage and injection measured only at the terminal (end-user)
nodes of the distribution grid. All other (intermediate) nodes in the network
may be unobserved/hidden. Furthermore no additional input (e.g., number of grid
nodes, historical information on injections at hidden nodes) is needed for the
learning to succeed. Performance of the algorithm is illustrated in numerical
experiments on the IEEE and custom power distribution models.
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10727</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10728</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contextual Regression: An Accurate and Conveniently Interpretable
  Nonlinear Model for Mining Discovery from Scientific Data</dc:title>
 <dc:creator>Liu, Chengyu</dc:creator>
 <dc:creator>Wang, Wei</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Machine learning algorithms such as linear regression, SVM and neural network
have played an increasingly important role in the process of scientific
discovery. However, none of them is both interpretable and accurate on
nonlinear datasets. Here we present contextual regression, a method that joins
these two desirable properties together using a hybrid architecture of neural
network embedding and dot product layer. We demonstrate its high prediction
accuracy and sensitivity through the task of predictive feature selection on a
simulated dataset and the application of predicting open chromatin sites in the
human genome. On the simulated data, our method achieved high fidelity recovery
of feature contributions under random noise levels up to 200%. On the open
chromatin dataset, the application of our method not only outperformed the
state of the art method in terms of accuracy, but also unveiled two previously
unfound open chromatin related histone marks. Our method can fill the blank of
accurate and interpretable nonlinear modeling in scientific data mining tasks.
</dc:description>
 <dc:description>Comment: 18 pages of Main Article, 30 pages of Supplementary Material</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10728</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10733</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attacking the Madry Defense Model with $L_1$-based Adversarial Examples</dc:title>
 <dc:creator>Sharma, Yash</dc:creator>
 <dc:creator>Chen, Pin-Yu</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The Madry Lab recently hosted a competition designed to test the robustness
of their adversarially trained MNIST model. Attacks were constrained to perturb
each pixel of the input image by a scaled maximal $L_\infty$ distortion
$\epsilon$ = 0.3. This discourages the use of attacks which are not optimized
on the $L_\infty$ distortion metric. Our experimental results demonstrate that
by relaxing the $L_\infty$ constraint of the competition, the elastic-net
attack to deep neural networks (EAD) can generate transferable adversarial
examples which, despite their high average $L_\infty$ distortion, have minimal
visual distortion. These results call into question the use of $L_\infty$ as a
sole measure for visual distortion, and further demonstrate the power of EAD at
generating robust adversarial examples.
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10733</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10736</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can you find a face in a HEVC bitstream?</dc:title>
 <dc:creator>Alvar, Saeed Ranjbar</dc:creator>
 <dc:creator>Choi, Hyomin</dc:creator>
 <dc:creator>Bajic, Ivan V.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Finding faces in images is one of the most important tasks in computer
vision, with applications in biometrics, surveillance, human-computer
interaction, and other areas. In our earlier work, we demonstrated that it is
possible to tell whether or not an image contains a face by only examining the
HEVC syntax, without fully reconstructing the image. In the present work we
move further in this direction by showing how to localize faces in HEVC-coded
images, without full reconstruction. We also demonstrate the benefits that such
approach can have in privacy-friendly face localization.
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10736</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10737</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linearly convergent stochastic heavy ball method for minimizing
  generalization error</dc:title>
 <dc:creator>Loizou, Nicolas</dc:creator>
 <dc:creator>Richt&#xe1;rik, Peter</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this work we establish the first linear convergence result for the
stochastic heavy ball method. The method performs SGD steps with a fixed
stepsize, amended by a heavy ball momentum term. In the analysis, we focus on
minimizing the expected loss and not on finite-sum minimization, which is
typically a much harder problem. While in the analysis we constrain ourselves
to quadratic loss, the overall objective is not necessarily strongly convex.
</dc:description>
 <dc:description>Comment: NIPS 2017, Workshop on Optimization for Machine Learning (camera
  ready version)</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10737</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10738</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Common neighbor based degree distribution of complex networks</dc:title>
 <dc:creator>Li, Jie</dc:creator>
 <dc:creator>Pu, Cunlai</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Unveiling the general structural properties of various complex networks is
one of the main tasks in network science. We define the degree of a bunch of
nodes as the number of common neighbors they share in the network, namely
common neighbor based degree (CNBD). We provide a general model, namely unified
ring model, which unifies all the ring based models. We propose a general
framework based on the generating function to calculate the CNBD distributions
of complex networks. We find that in the ER network, the CNBD distribution obey
the Poisson law for node sets of any size. We also study the CNBD distribution
for the other types of complex networks including the regular ring lattice,
small-world model, scale-free model, and real-world networks.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10738</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10739</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning neural trans-dimensional random field language models with
  noise-contrastive estimation</dc:title>
 <dc:creator>Wang, Bin</dc:creator>
 <dc:creator>Ou, Zhijian</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Trans-dimensional random field language models (TRF LMs) where sentences are
modeled as a collection of random fields, have shown close performance with
LSTM LMs in speech recognition and are computationally more efficient in
inference. However, the training efficiency of neural TRF LMs is not
satisfactory, which limits the scalability of TRF LMs on large training corpus.
In this paper, several techniques on both model formulation and parameter
estimation are proposed to improve the training efficiency and the performance
of neural TRF LMs. First, TRFs are reformulated in the form of exponential
tilting of a reference distribution. Second, noise-contrastive estimation (NCE)
is introduced to jointly estimate the model parameters and normalization
constants. Third, we extend the neural TRF LMs by marrying the deep
convolutional neural network (CNN) and the bidirectional LSTM into the
potential function to extract the deep hierarchical features and
bidirectionally sequential features. Utilizing all the above techniques enables
the successful and efficient training of neural TRF LMs on a 40x larger
training set with only 1/3 training time and further reduces the WER with
relative reduction of 4.7% on top of a strong LSTM LM baseline.
</dc:description>
 <dc:description>Comment: 5 pages and 2 figures</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10739</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10741</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evolving Deep Convolutional Neural Networks for Image Classification</dc:title>
 <dc:creator>Sun, Yanan</dc:creator>
 <dc:creator>Xue, Bing</dc:creator>
 <dc:creator>Zhang, Mengjie</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Evolutionary computation methods have been successfully applied to neural
networks since two decades ago, while those methods cannot scale well to the
modern deep neural networks due to the complicated architectures and large
quantities of connection weights. In this paper, we propose a new method using
genetic algorithms for evolving the architectures and connection weight
initialization values of a deep convolutional neural network to address image
classification problems. In the proposed algorithm, an efficient
variable-length gene encoding strategy is designed to represent the different
building blocks and the unpredictable optimal depth in convolutional neural
networks. In addition, a new representation scheme is developed for effectively
initializing connection weights of deep convolutional neural networks, which is
expected to avoid networks getting stuck into local minima which is typically a
major issue in the backward gradient-based optimization. Furthermore, a novel
fitness evaluation method is proposed to speed up the heuristic search with
substantially less computational resource. The proposed algorithm is examined
and compared with 22 existing algorithms on nine widely used image
classification tasks, including the state-of-the-art methods. The experimental
results demonstrate the remarkable superiority of the proposed algorithm over
the state-of-the-art algorithms in terms of classification error rate and the
number of parameters (weights).
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10741</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10742</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Implicit Causal Models for Genome-wide Association Studies</dc:title>
 <dc:creator>Tran, Dustin</dc:creator>
 <dc:creator>Blei, David M.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  Progress in probabilistic generative models has accelerated, developing
richer models with neural architectures, implicit densities, and with scalable
algorithms for their Bayesian inference. However, there has been limited
progress in models that capture causal relationships, for example, how
individual genetic factors cause major human diseases. In this work, we focus
on two challenges in particular: How do we build richer causal models, which
can capture highly nonlinear relationships and interactions between multiple
causes? How do we adjust for latent confounders, which are variables
influencing both cause and effect and which prevent learning of causal
relationships? To address these challenges, we synthesize ideas from causality
and modern probabilistic modeling. For the first, we describe implicit causal
models, a class of causal models that leverages neural architectures with an
implicit density. For the second, we describe an implicit causal model that
adjusts for confounders by sharing strength across examples. In experiments, we
scale Bayesian inference on up to a billion genetic measurements. We achieve
state of the art accuracy for identifying causal factors: we significantly
outperform existing genetics methods by an absolute difference of 15-45.3%.
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10742</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10746</identifier>
 <datestamp>2017-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Louvre: Lightweight Ordering Using Versioning for Release Consistency</dc:title>
 <dc:creator>Kumar, Pranith</dc:creator>
 <dc:creator>Gera, Prasun</dc:creator>
 <dc:creator>Kim, Hyojong</dc:creator>
 <dc:creator>Kim, Hyesoon</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Fence instructions are fundamental primitives that ensure consistency in a
weakly consistent shared memory multi-core processor. The execution cost of
these instructions is significant and adds a non-trivial overhead to parallel
programs. In a naive architecture implementation, we track the ordering
constraints imposed by a fence by its entry in the reorder buffer and its
execution overhead entails stalling the processor's pipeline until the store
buffer is drained and also conservatively invalidating speculative loads. These
actions create a cascading effect of increased overhead on the execution of the
following instructions in the program. We find these actions to be overly
restrictive and that they can be further relaxed thereby allowing aggressive
optimizations.
  The current work proposes a lightweight mechanism in which we assign ordering
tags, called versions, to load and store instructions when they reside in the
load/store queues and the write buffer. The version assigned to a memory access
allows us to fully exploit the relaxation allowed by the weak consistency model
and restricts its execution in such a way that the ordering constraints by the
model are satisfied. We utilize the information captured through the assigned
versions to reduce stalls caused by waiting for the store buffer to drain and
to avoid unnecessary squashing of speculative loads, thereby minimizing the
re-execution penalty. This method is particularly effective for the release
consistency model that employs uni-directional fence instructions. We show that
this mechanism reduces the ordering instruction latency by 39.6% and improves
program performance by 11% on average over the baseline implementation.
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:date>2017-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10746</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10748</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How we can control the crack to propagate along the specified path
  feasibly?</dc:title>
 <dc:creator>Cheng, Zhenxing</dc:creator>
 <dc:creator>Wang, Hu</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  A controllable crack propagation (CCP) strategy is suggested. It is well
known that crack always leads the failure by crossing the critical domain in
engineering structure. Therefore, the CCP method is proposed to control the
crack to propagate along the specified path, which is away from the critical
domain. To complete this strategy, two optimization methods are engaged.
Firstly, a back propagation neural network (BPNN) assisted particle swarm
optimization (PSO) is suggested. In this method, to improve the efficiency of
CCP, the BPNN is used to build the metamodel instead of the forward evaluation.
Secondly, the popular PSO is used. Considering the optimization iteration is a
time consuming process, an efficient reanalysis based extended finite element
methods (X-FEM) is used to substitute the complete X-FEM solver to calculate
the crack propagation path. Moreover, an adaptive subdomain partition strategy
is suggested to improve the fitting accuracy between real crack and specified
paths. Several typical numerical examples demonstrate that both optimization
methods can carry out the CCP. The selection of them should be determined by
the tradeoff between efficiency and accuracy.
</dc:description>
 <dc:description>Comment: 17 pages, 29 figures, Crack propagation path, Reanalysis solver, Back
  propagation neural network, Particle swarm optimization, Extended finite
  element method</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10748</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10749</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cascade Region Proposal and Global Context for Deep Object Detection</dc:title>
 <dc:creator>Zhong, Qiaoyong</dc:creator>
 <dc:creator>Li, Chao</dc:creator>
 <dc:creator>Zhang, Yingying</dc:creator>
 <dc:creator>Xie, Di</dc:creator>
 <dc:creator>Yang, Shicai</dc:creator>
 <dc:creator>Pu, Shiliang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep region-based object detector consists of a region proposal step and a
deep object recognition step. In this paper, we make significant improvements
on both of the two steps. For region proposal we propose a novel lightweight
cascade structure which can effectively improve RPN proposal quality. For
object recognition we re-implement global context modeling with a few
modications and obtain a performance boost (4.2% mAP gain on the ILSVRC 2016
validation set). Besides, we apply the idea of pre-training extensively and
show its importance in both steps. Together with common training and testing
tricks, we improve Faster R-CNN baseline by a large margin. In particular, we
obtain 87.9% mAP on the PASCAL VOC 2012 test set, 65.3% on the ILSVRC 2016 test
set and 36.8% on the COCO test-std set.
</dc:description>
 <dc:description>Comment: Preprint to appear in Neurocomputing</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10749</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10753</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Social Choice and Computational Complexity: BFFs?</dc:title>
 <dc:creator>Hemaspaandra, Lane A.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:description>  We discuss the connection between computational social choice (comsoc) and
computational complexity. We stress the work so far on, and urge continued
focus on, two less-recognized aspects of this connection. Firstly, this is very
much a two-way street: Everyone knows complexity classification is used in
comsoc, but we also highlight benefits to complexity that have arisen from its
use in comsoc. Secondly, more subtle, less-known complexity tools often can be
very productively used in comsoc.
</dc:description>
 <dc:description>Comment: A version of this paper will appear in AAAI-18</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:date>2017-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10753</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10754</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stationarity Region of Mm-Wave Channel Based on Outdoor Microcellular
  Measurements at 28 GHz</dc:title>
 <dc:creator>Wang, R.</dc:creator>
 <dc:creator>Bas, C. U.</dc:creator>
 <dc:creator>Sangodoyin, S.</dc:creator>
 <dc:creator>Hur, S.</dc:creator>
 <dc:creator>Park, J.</dc:creator>
 <dc:creator>Zhang, J.</dc:creator>
 <dc:creator>Molisch, A. F.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The stationarity region, i.e., the area in which the statistics of a
propagation channel remain constant, is an important measure of the propagation
channel, and essential for efficient system design. This paper presents what is
to our knowledge the first extensive measurement campaign for measuring the
stationarity region of MIMO mm-wave channels. Using a novel 28 GHz phased-array
sounder with high phase stability, we present results in an urban microcell
LoS, and LOS to NLOS transition region scenario, for the stationarity region of
shadowing, power delay profile, and the angular power spectrum. A comparison to
results at cm-waves shows considerably reduced stationarity region size, which
has an important impact on system design.
</dc:description>
 <dc:description>Comment: 6 pages, 9 figures, conference</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10754</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10755</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling Attention in Panoramic Video: A Deep Reinforcement Learning
  Approach</dc:title>
 <dc:creator>Song, Yuhang</dc:creator>
 <dc:creator>Xu, Mai</dc:creator>
 <dc:creator>Qiao, Minglang</dc:creator>
 <dc:creator>Wang, Jianyi</dc:creator>
 <dc:creator>Huo, Liangyu</dc:creator>
 <dc:creator>Wang, Zulin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Panoramic video provides immersive and interactive experience by enabling
humans to control the field of view (FoV) through head movement (HM). Thus, HM
plays a key role in modeling human attention on panoramic video. This paper
establishes a database collecting subjects' HM positions on panoramic video
sequences. From this database, we find that the HM data are highly consistent
across subjects. Furthermore, we find that deep reinforcement learning (DRL)
can be applied to predict HM positions, via maximizing the reward of imitating
human HM scanpaths through the agent's actions. Based on our findings, we
propose a DRL based HM prediction (DHP) approach with offline and online
versions, called offline-DHP and online-DHP. In offline-DHP, multiple DRL
workflows are run to determine potential HM positions at each panoramic frame.
Then, a heat map of the potential HM positions, named the HM map, is generated
as the output of offline-DHP. In online-DHP, the next HM position of one
subject is estimated given the currently observed HM position, which is
achieved by developing a DRL algorithm upon the learned offline-DHP model.
Finally, the experimental results validate that our approach is effective in
offline and online prediction of HM positions for panoramic video, and that the
learned offline-DHP model can improve the performance of online-DHP.
</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:date>2018-01-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10755</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10756</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fair Termination for Parameterized Probabilistic Concurrent Systems
  (Technical Report)</dc:title>
 <dc:creator>Lengal, Ondrej</dc:creator>
 <dc:creator>Lin, Anthony W.</dc:creator>
 <dc:creator>Majumdar, Rupak</dc:creator>
 <dc:creator>Ruemmer, Philipp</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  We consider the problem of automatically verifying that a parameterized
family of probabilistic concurrent systems terminates with probability one for
all instances against adversarial schedulers. A parameterized family defines an
infinite-state system: for each number n, the family consists of an instance
with n finite-state processes. In contrast to safety, the parameterized
verification of liveness is currently still considered extremely challenging
especially in the presence of probabilities in the model. One major challenge
is to provide a sufficiently powerful symbolic framework. One well-known
symbolic framework for the parameterized verification of non-probabilistic
concurrent systems is regular model checking. Although the framework was
recently extended to probabilistic systems, incorporating fairness in the
framework - often crucial for verifying termination - has been especially
difficult due to the presence of an infinite number of fairness constraints
(one for each process). Our main contribution is a systematic,
regularity-preserving, encoding of finitary fairness (a realistic notion of
fairness proposed by Alur &amp; Henzinger) in the framework of regular model
checking for probabilistic parameterized systems. Our encoding reduces
termination with finitary fairness to verifying parameterized termination
without fairness over probabilistic systems in regular model checking (for
which a verification framework already exists). We show that our algorithm
could verify termination for many interesting examples from distributed
algorithms (Herman's protocol) and evolutionary biology (Moran process, cell
cycle switch), which do not hold under the standard notion of fairness. To the
best of our knowledge, our algorithm is the first fully-automatic method that
can prove termination for these examples.
</dc:description>
 <dc:description>Comment: A technical report of a TACAS'17 paper</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10756</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10766</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PixelDefend: Leveraging Generative Models to Understand and Defend
  against Adversarial Examples</dc:title>
 <dc:creator>Song, Yang</dc:creator>
 <dc:creator>Kim, Taesup</dc:creator>
 <dc:creator>Nowozin, Sebastian</dc:creator>
 <dc:creator>Ermon, Stefano</dc:creator>
 <dc:creator>Kushman, Nate</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Adversarial perturbations of normal images are usually imperceptible to
humans, but they can seriously confuse state-of-the-art machine learning
models. What makes them so special in the eyes of image classifiers? In this
paper, we show empirically that adversarial examples mainly lie in the low
probability regions of the training distribution, regardless of attack types
and targeted models. Using statistical hypothesis testing, we find that modern
neural density models are surprisingly good at detecting imperceptible image
perturbations. Based on this discovery, we devised PixelDefend, a new approach
that purifies a maliciously perturbed image by moving it back towards the
distribution seen in the training data. The purified image is then run through
an unmodified classifier, making our method agnostic to both the classifier and
the attacking method. As a result, PixelDefend can be used to protect already
deployed models and be combined with other model-specific defenses. Experiments
show that our method greatly improves resilience across a wide variety of
state-of-the-art attacking methods, increasing accuracy on the strongest attack
from 63% to 84% for Fashion MNIST and from 32% to 70% for CIFAR-10.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10766</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10769</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communication-Avoiding Optimization Methods for Massive-Scale Graphical
  Model Structure Learning</dc:title>
 <dc:creator>Koanantakool, Penporn</dc:creator>
 <dc:creator>Ali, Alnur</dc:creator>
 <dc:creator>Azad, Ariful</dc:creator>
 <dc:creator>Buluc, Aydin</dc:creator>
 <dc:creator>Morozov, Dmitriy</dc:creator>
 <dc:creator>Oh, Sang-Yun</dc:creator>
 <dc:creator>Oliker, Leonid</dc:creator>
 <dc:creator>Yelick, Katherine</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Undirected graphical models compactly represent the structure of large,
high-dimensional data sets, which are especially important in interpreting
complex scientific data. Some data sets may run to multiple terabytes, and
current methods are intractable in both memory size and running time. We
introduce HP-CONCORD, a highly scalable optimization algorithm to estimate a
sparse inverse covariance matrix based on a regularized pseudolikelihood
framework. Our parallel proximal gradient method runs across a multi-node
cluster and achieves parallel scalability using a novel communication-avoiding
linear algebra algorithm. We demonstrate scalability on problems with 1.28
million dimensions (over 800 billion parameters) and show that it can
outperform a previous method on a single node and scales to 1K nodes (24K
cores). We use HP-CONCORD to estimate the underlying conditional dependency
structure of the brain from fMRI data and use the result to automatically
identify functional regions. The results show good agreement with a
state-of-the-art clustering from the neuroscience literature.
</dc:description>
 <dc:description>Comment: Main paper: 16 pages, appendix: 20 pages</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10769</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10770</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Frank-Wolfe methods for geodesically convex optimization with
  application to the matrix geometric mean</dc:title>
 <dc:creator>Weber, Melanie</dc:creator>
 <dc:creator>Sra, Suvrit</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:subject>46N10, 15A24, 65K10, 49Q99</dc:subject>
 <dc:description>  We consider optimization of geodesically convex objectives over geodesically
convex subsets of the manifold of positive definite matrices. In particular,
for this task, we develop Euclidean and Riemannian Frank-Wolfe (FW) algorithms.
For both settings, we analyze non-asymptotic convergence rates to global
optimality. To our knowledge, these are the first results on Riemannian FW and
its convergence. We specialize our algorithms for the task of computing the
matrix geometric mean, i.e., the Riemannian centroid of a set of positive
definite matrices. For this problem, we provide concrete, closed-form
realizations of the crucial &quot;linear oracle&quot; required by FW that may be of
independent interest. Moreover, under an additional hypothesis, we prove how
Riemannian FW can even attain a linear rate of convergence. Experiments against
recently published methods for the matrix geometric mean substantiate the
competitiveness of the proposed FW algorithms.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10770</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10772</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tensorizing Generative Adversarial Nets</dc:title>
 <dc:creator>Cao, Xingwei</dc:creator>
 <dc:creator>Zhao, Qibin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Generative Adversarial Network (GAN) and its variants demonstrate
state-of-the-art performance in the class of generative models. To capture
higher dimensional distributions, the common learning procedure requires high
computational complexity and large number of parameters. In this paper, we
present a new generative adversarial framework by representing each layer as a
tensor structure connected by multilinear operations, aiming to reduce the
number of model parameters by a large factor while preserving the quality of
generalized performance. To learn the model, we develop an efficient algorithm
by alternating optimization of the mode connections. Experimental results
demonstrate that our model can achieve high compression rate for model
parameters up to 40 times as compared to the existing GAN.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10772</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10774</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequence-to-Sequence ASR Optimization via Reinforcement Learning</dc:title>
 <dc:creator>Tjandra, Andros</dc:creator>
 <dc:creator>Sakti, Sakriani</dc:creator>
 <dc:creator>Nakamura, Satoshi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Despite the success of sequence-to-sequence approaches in automatic speech
recognition (ASR) systems, the models still suffer from several problems,
mainly due to the mismatch between the training and inference conditions. In
the sequence-to-sequence architecture, the model is trained to predict the
grapheme of the current time-step given the input of speech signal and the
ground-truth grapheme history of the previous time-steps. However, it remains
unclear how well the model approximates real-world speech during inference.
Thus, generating the whole transcription from scratch based on previous
predictions is complicated and errors can propagate over time. Furthermore, the
model is optimized to maximize the likelihood of training data instead of error
rate evaluation metrics that actually quantify recognition quality. This paper
presents an alternative strategy for training sequence-to-sequence ASR models
by adopting the idea of reinforcement learning (RL). Unlike the standard
training scheme with maximum likelihood estimation, our proposed approach
utilizes the policy gradient algorithm. We can (1) sample the whole
transcription based on the model's prediction in the training process and (2)
directly optimize the model with negative Levensthein distance as the reward.
Experimental results demonstrate that we significantly improved the performance
compared to a model trained only with maximum likelihood estimation.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10774</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10776</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transfer Learning to Learn with Multitask Neural Model Search</dc:title>
 <dc:creator>Wong, Catherine</dc:creator>
 <dc:creator>Gesmundo, Andrea</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep learning models require extensive architecture design exploration and
hyperparameter optimization to perform well on a given task. The exploration of
the model design space is often made by a human expert, and optimized using a
combination of grid search and search heuristics over a large space of possible
choices. Neural Architecture Search (NAS) is a Reinforcement Learning approach
that has been proposed to automate architecture design. NAS has been
successfully applied to generate Neural Networks that rival the best
human-designed architectures. However, NAS requires sampling, constructing, and
training hundreds to thousands of models to achieve well-performing
architectures. This procedure needs to be executed from scratch for each new
task. The application of NAS to a wide set of tasks currently lacks a way to
transfer generalizable knowledge across tasks. In this paper, we present the
Multitask Neural Model Search (MNMS) controller. Our goal is to learn a
generalizable framework that can condition model construction on successful
model searches for previously seen tasks, thus significantly speeding up the
search for new tasks. We demonstrate that MNMS can conduct an automated
architecture search for multiple tasks simultaneously while still learning
well-performing, specialized models for each task. We then show that
pre-trained MNMS controllers can transfer learning to new tasks. By leveraging
knowledge from previous searches, we find that pre-trained MNMS models start
from a better location in the search space and reduce search time on unseen
tasks, while still discovering models that outperform published human-designed
models.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10776</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10777</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Hidden Memories of Recurrent Neural Networks</dc:title>
 <dc:creator>Ming, Yao</dc:creator>
 <dc:creator>Cao, Shaozu</dc:creator>
 <dc:creator>Zhang, Ruixiang</dc:creator>
 <dc:creator>Li, Zhen</dc:creator>
 <dc:creator>Chen, Yuanzhe</dc:creator>
 <dc:creator>Song, Yangqiu</dc:creator>
 <dc:creator>Qu, Huamin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Recurrent neural networks (RNNs) have been successfully applied to various
natural language processing (NLP) tasks and achieved better results than
conventional methods. However, the lack of understanding of the mechanisms
behind their effectiveness limits further improvements on their architectures.
In this paper, we present a visual analytics method for understanding and
comparing RNN models for NLP tasks. We propose a technique to explain the
function of individual hidden state units based on their expected response to
input texts. We then co-cluster hidden state units and words based on the
expected response and visualize co-clustering results as memory chips and word
clouds to provide more structured knowledge on RNNs' hidden states. We also
propose a glyph-based sequence visualization based on aggregate information to
analyze the behavior of an RNN's hidden state at the sentence-level. The
usability and effectiveness of our method are demonstrated through case studies
and reviews from domain experts.
</dc:description>
 <dc:description>Comment: Published at IEEE Conference on Visual Analytics Science and
  Technology (IEEE VAST 2017)</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10777</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10779</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generative Adversarial Source Separation</dc:title>
 <dc:creator>Subakan, Cem</dc:creator>
 <dc:creator>Smaragdis, Paris</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Generative source separation methods such as non-negative matrix
factorization (NMF) or auto-encoders, rely on the assumption of an output
probability density. Generative Adversarial Networks (GANs) can learn data
distributions without needing a parametric assumption on the output density. We
show on a speech source separation experiment that, a multi-layer perceptron
trained with a Wasserstein-GAN formulation outperforms NMF, auto-encoders
trained with maximum likelihood, and variational auto-encoders in terms of
source to distortion ratio.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10779</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10780</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Vector Coding for Ultra-Reliable and Low Latency Communications</dc:title>
 <dc:creator>Ji, Hyoungju</dc:creator>
 <dc:creator>Park, Sunho</dc:creator>
 <dc:creator>Shim, Byonghyo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Ultra reliable and low latency communication (URLLC) is a newly introduced
service category in 5G to support delay-sensitive applications. In order to
support this new service category, 3rd Generation Partnership Project (3GPP)
sets an aggressive requirement that a packet should be delivered with 10-5
block error rate within 1 msec transmission period. Since the current wireless
standard designed to maximize the coding gain by transmitting capacity
achieving long code-block is not relevant for this purpose, entirely new
strategy is required. In this paper, we propose a new approach to deliver
control information, called sparse vector coding (SVC). Key idea behind the
proposed method is to transmit the control channel information after the sparse
vector transformation. By mapping the control information into the position of
nonzero elements and then transmitting it after the random spreading, we obtain
underdetermined sparse system for which the principle of compressed sensing can
be applied.
</dc:description>
 <dc:description>Comment: This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10780</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10781</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic variance reduced multiplicative update for nonnegative matrix
  factorization</dc:title>
 <dc:creator>Kasai, Hiroyuki</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Nonnegative matrix factorization (NMF), a dimensionality reduction and factor
analysis method, is a special case in which factor matrices have low-rank
nonnegative constraints. Considering the stochastic learning in NMF, we
specifically address the multiplicative update (MU) rule, which is the most
popular, but which has slow convergence property. This present paper introduces
on the stochastic MU rule a variance-reduced technique of stochastic gradient.
Numerical comparisons suggest that our proposed algorithms robustly outperform
state-of-the-art algorithms across different synthetic and real-world datasets.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10781</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10784</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How deep learning works --The geometry of deep learning</dc:title>
 <dc:creator>Dong, Xiao</dc:creator>
 <dc:creator>Wu, Jiasong</dc:creator>
 <dc:creator>Zhou, Ling</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Why and how that deep learning works well on different tasks remains a
mystery from a theoretical perspective. In this paper we draw a geometric
picture of the deep learning system by finding its analogies with two existing
geometric structures, the geometry of quantum computations and the geometry of
the diffeomorphic template matching. In this framework, we give the geometric
structures of different deep learning systems including convolutional neural
networks, residual networks, recursive neural networks, recurrent neural
networks and the equilibrium prapagation framework. We can also analysis the
relationship between the geometrical structures and their performance of
different networks in an algorithmic level so that the geometric framework may
guide the design of the structures and algorithms of deep learning systems.
</dc:description>
 <dc:description>Comment: 16 pages, 13 figures</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10784</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10793</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding GANs: the LQG Setting</dc:title>
 <dc:creator>Feizi, Soheil</dc:creator>
 <dc:creator>Suh, Changho</dc:creator>
 <dc:creator>Xia, Fei</dc:creator>
 <dc:creator>Tse, David</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Generative Adversarial Networks (GANs) have become a popular method to learn
a probability model from data. Many GAN architectures with different
optimization metrics have been introduced recently. Instead of proposing yet
another architecture, this paper aims to provide an understanding of some of
the basic issues surrounding GANs. First, we propose a natural way of
specifying the loss function for GANs by drawing a connection with supervised
learning. Second, we shed light on the generalization peformance of GANs
through the analysis of a simple LQG setting: the generator is Linear, the loss
function is Quadratic and the data is drawn from a Gaussian distribution. We
show that in this setting: 1) the optimal GAN solution converges to population
Principal Component Analysis (PCA) as the number of training samples increases;
2) the number of samples required scales exponentially with the dimension of
the data; 3) the number of samples scales almost linearly if the discriminator
is constrained to be quadratic. Thus, linear generators and quadratic
discriminators provide a good balance for fast learning.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10793</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10796</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Limits of Compressive Sensing Channel Estimation in Dense
  Cloud RAN</dc:title>
 <dc:creator>Stefanatos, Stelios</dc:creator>
 <dc:creator>Wunder, Gerhard</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Towards reducing the training signaling overhead in large scale and dense
cloud radio access networks (CRAN), various approaches have been proposed based
on the channel sparsification assumption, namely, only a small subset of the
deployed remote radio heads (RRHs) are of significance to any user in the
system. Motivated by the potential of compressive sensing (CS) techniques in
this setting, this paper provides a rigorous description of the performance
limits of many practical CS algorithms by considering the performance of the,
so called, oracle estimator, which knows a priori which RRHs are of
significance but not their corresponding channel values. By using tools from
stochastic geometry, a closed form analytical expression of the oracle
estimator performance is obtained, averaged over distribution of RRH positions
and channel statistics. Apart from a bound on practical CS algorithms, the
analysis provides important design insights, e.g., on how the training sequence
length affects performance, and identifies the operational conditions where the
channel sparsification assumption is valid. It is shown that the latter is true
only in operational conditions with sufficiently large path loss exponents.
</dc:description>
 <dc:description>Comment: 6 pages, two-column format</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10796</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10800</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DART: Distribution Aware Retinal Transform for Event-based Cameras</dc:title>
 <dc:creator>Ramesh, Bharath</dc:creator>
 <dc:creator>Yang, Hong</dc:creator>
 <dc:creator>Orchard, Garrick</dc:creator>
 <dc:creator>Thi, Ngoc Anh Le</dc:creator>
 <dc:creator>Xiang, Cheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce a new event-based visual descriptor, termed as distribution
aware retinal transform (DART), for pattern recognition using silicon retina
cameras. The DART descriptor captures the information of the spatio-temporal
distribution of events, and forms a rich structural representation.
Consequently, the event context encoded by DART greatly simplifies the feature
correspondence problem, which is highly relevant to many event-based vision
problems. The proposed descriptor is robust to scale and rotation variations
without the need for spectral analysis. To demonstrate the effectiveness of the
DART descriptors, they are employed as local features in the bag-of-features
classification framework. The proposed framework is tested on the N-MNIST,
MNIST-DVS, CIFAR10-DVS, NCaltech-101 datasets, as well as a new object dataset,
N-SOD (Neuromorphic-Single Object Dataset), collected to test unconstrained
viewpoint recognition. We report a competitive classification accuracy of
97.95% on the N-MNIST and the best classification accuracy compared to existing
works on the MNIST-DVS (99%), CIFAR10-DVS (65.9%) and NCaltech-101 (70.3%).
Using the in-house N-SOD, we demonstrate real-time classification performance
on an Intel Compute Stick directly interfaced to an event camera flying
on-board a quadcopter. In addition, taking advantage of the high-temporal
resolution of event cameras, the classification system is extended to tackle
object tracking. Finally, we demonstrate efficient feature matching for
event-based cameras using kd-trees.
</dc:description>
 <dc:description>Comment: 12 pages, submitted to TPAMI in Oct 2017</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10805</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modular Labelled Sequent Calculi for Abstract Separation Logics</dc:title>
 <dc:creator>H&#xf3;u, Zh&#xe9;</dc:creator>
 <dc:creator>Clouston, Ranald</dc:creator>
 <dc:creator>Gor&#xe9;, Rajeev</dc:creator>
 <dc:creator>Tiu, Alwen</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Abstract separation logics are a family of extensions of Hoare logic for
reasoning about programs that manipulate resources such as memory locations.
These logics are &quot;abstract&quot; because they are independent of any particular
concrete resource model. Their assertion languages, called propositional
abstract separation logics (PASLs), extend the logic of (Boolean) Bunched
Implications (BBI) in various ways. In particular, these logics contain the
connectives $*$ and $-\!*$, denoting the composition and extension of resources
respectively.
  This added expressive power comes at a price since the resulting logics are
all undecidable. Given their wide applicability, even a semi-decision procedure
for these logics is desirable. Although several PASLs and their relationships
with BBI are discussed in the literature, the proof theory and automated
reasoning for these logics were open problems solved by the conference version
of this paper, which developed a modular proof theory for various PASLs using
cut-free labelled sequent calculi. This paper non-trivially improves upon this
previous work by giving a general framework of calculi on which any new axiom
in the logic satisfying a certain form corresponds to an inference rule in our
framework, and the completeness proof is generalised to consider such axioms.
  Our base calculus handles Calcagno et al.'s original logic of separation
algebras by adding sound rules for partial-determinism and cancellativity,
while preserving cut-elimination. We then show that many important properties
in separation logic, such as indivisible unit, disjointness, splittability, and
cross-split, can be expressed in our general axiom form. Thus our framework
offers inference rules and completeness for these properties for free. Finally,
we show how our calculi reduce to calculi with global label substitutions,
enabling more efficient implementation.
</dc:description>
 <dc:description>Comment: Accepted for publication in ACM Transactions on Computational Logic
  (TOCL). arXiv admin note: text overlap with arXiv:1307.5592</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2018-01-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10805</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10807</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Backhaul For Low-Altitude UAVs in Urban Environments</dc:title>
 <dc:creator>Galkin, Boris</dc:creator>
 <dc:creator>Kibi&#x142;da, Jacek</dc:creator>
 <dc:creator>DaSilva, Luiz A.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Unmanned Aerial Vehicles (UAVs) acting as access points in cellular networks
require wireless backhauls to the core network. In this paper we employ
stochastic geometry to carry out an analysis of the UAV backhaul performance
that can be achieved with a network of dedicated ground stations. We provide
analytical expressions for the probability of successfully establishing a
backhaul and the expected data rate over the backhaul link, given either an LTE
or a millimeter-wave backhaul. We demonstrate that increasing the density of
the ground station network gives diminishing returns on the performance of the
UAV backhaul, and that for an LTE backhaul the ground stations can benefit from
being colocated with an existing base station network.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10807</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10811</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reliable Communication under the Influence of a State-Constrained
  Jammer: A Novel Perspective on Receive Diversity</dc:title>
 <dc:creator>Arendt, Christian</dc:creator>
 <dc:creator>N&#xf6;tzel, Janis</dc:creator>
 <dc:creator>Boche, Holger</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The question of robust direct communication in vehicular networks is
discussed. In most state-of-the-art approaches, there is no central entity
controlling channel access, so there may be arbitrary interference from other
parties. Thus, a suitable channel model for Vehicle-to-X (V2X) communication is
the Arbitrarily Varying Channel (AVC). Employing multiple antennas on a vehicle
or sending over multiple frequencies to make use of diversity are promising
approaches to combat interference. In this setup, an important question about
diversity is how many antennas or orthogonal carrier frequencies are necessary
in order to avoid system breakdown due to unknown interference in AVCs. For
Binary Symmetric AVCs (AVBSC) and a physically meaningful identical
state-constrained jammer, the deployment of a third, uncorrelated receiving
antenna or the parallel transmission over three different orthogonal
frequencies avoids symmetrizability and thus ensures positivity of the capacity
of the overall communication channel. Furthermore, the capacity of the
identical state-constrained composite AVBSC is continuous and shows
super-activation, a phenomenon which was hitherto deemed impossible for
classical communication without secrecy constraints. Subsuming, spatial and
frequency diversity are enablers for reliable communication over communication
channels with arbitrarily varying interference.
</dc:description>
 <dc:description>Comment: 29 pages, 4 figures</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10811</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10812</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Analysis of Multi-Service Oriented Multiple Access Under
  General Channel Correlation</dc:title>
 <dc:creator>Ksairi, Nassar</dc:creator>
 <dc:creator>Debbah, M&#xe9;rouane</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this article, we provide both analytical and numerical performance
analysis of multi-service oriented multiple access (MOMA), a recently proposed
non-orthogonal multiple-access scheme for scenarios with a massive number of
concurrent connections originating from separate service classes with diverse
quality-of-service (QoS) profiles and running on both handheld terminals and
Internet-of-Things (IoT) devices. MOMA is based on both class dependent
hierarchical-spreading transmission scheme and per-class reception structure.
The performance analysis presented in this article is based on realistic
channel and signal models for scenarios where the base station is equipped with
a large number of antennas. It provides asymptotically exact approximations of
the ergodic rates achievable by MOMA.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, accepted for publication in GLOBECOM 2017,
  Singapore</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10812</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10814</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hit Song Prediction for Pop Music by Siamese CNN with Ranking Loss</dc:title>
 <dc:creator>Yu, Lang-Chi</dc:creator>
 <dc:creator>Yang, Yi-Hsuan</dc:creator>
 <dc:creator>Hung, Yun-Ning</dc:creator>
 <dc:creator>Chen, Yi-An</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  A model for hit song prediction can be used in the pop music industry to
identify emerging trends and potential artists or songs before they are
marketed to the public. While most previous work formulates hit song prediction
as a regression or classification problem, we present in this paper a
convolutional neural network (CNN) model that treats it as a ranking problem.
Specifically, we use a commercial dataset with daily play-counts to train a
multi-objective Siamese CNN model with Euclidean loss and pairwise ranking loss
to learn from audio the relative ranking relations among songs. Besides, we
devise a number of pair sampling methods according to some empirical
observation of the data. Our experiment shows that the proposed model with a
sampling method called A/B sampling leads to much higher accuracy in hit song
prediction than the baseline regression model. Moreover, we can further improve
the accuracy by using a neural attention mechanism to extract the highlights of
songs and by using a separate CNN model to offer high-level features of songs.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10814</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10824</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rough extreme learning machine: a new classification method based on
  uncertainty measure</dc:title>
 <dc:creator>Xu, Shuliang</dc:creator>
 <dc:creator>Feng, Lin</dc:creator>
 <dc:creator>Wang, Feilong</dc:creator>
 <dc:creator>Liu, Shenglan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Extreme learning machine (ELM) is a new single hidden layer feedback neural
network. The weights of the input layer and the biases of neurons in hidden
layer are randomly generated, the weights of the output layer can be
analytically determined. ELM has been achieved good results for a large number
of classification tasks. In this paper, a new extreme learning machine called
rough extreme learning machine (RELM) was proposed. RELM uses rough set to
divide data into upper approximation set and lower approximation set, and the
two approximation sets are utilized to train upper approximation neurons and
lower approximation neurons. In addition, an attribute reduction is executed in
this algorithm to remove redundant attributes. The experimental results showed,
comparing with the comparison algorithms, RELM can get a better accuracy and
repeatability in most cases, RELM can not only maintain the advantages of fast
speed, but also effectively cope with the classification task for
high-dimensional data.
</dc:description>
 <dc:description>Comment: 23 pages</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10824</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10828</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>2D Unitary ESPRIT Based Super-Resolution Channel Estimation for
  Millimeter-Wave Massive MIMO with Hybrid Precoding</dc:title>
 <dc:creator>Liao, Anwen</dc:creator>
 <dc:creator>Gao, Zhen</dc:creator>
 <dc:creator>Wu, Yongpeng</dc:creator>
 <dc:creator>Wang, Hua</dc:creator>
 <dc:creator>Alouini, Mohamed-Slim</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Millimeter-wave (mmWave) massive multiple-input multiple-output (MIMO) with
hybrid precoding is a promising technique for the future 5G wireless
communications. Due to a large number of antennas but a much smaller number of
radio frequency (RF) chains, estimating the high-dimensional mmWave massive
MIMO channel will bring the large pilot overhead. To overcome this challenge,
this paper proposes a super-resolution channel estimation scheme based on
two-dimensional (2D) u- nitary ESPRIT algorithm. By exploiting the angular
sparsity of mmWave channels, the continuously distributed angle of
arrivals/departures (AoAs/AoDs) can be jointly estimated with high accuracy.
Specifically, by designing the uplink training signals at both base station
(BS) and mobile station (MS), we first use low pilot overhead to estimate a
low-dimensional effective channel, which has the same shift-invariance of array
response as the high-dimensional mmWave MIMO channel to be estimated. From the
low-dimensional effective channel, the super- resolution estimates of AoAs and
AoDs can be jointly obtained by exploiting the 2D unitary ESPRIT channel
estimation algorithm. Furthermore, the associated path gains can be acquired
based on the least squares (LS) criterion. Finally, we can reconstruct the
high-dimensional mmWave MIMO channel according to the obtained AoAs, AoDs, and
path gains. Simulation results have confirmed that the proposed scheme is
superior to conventional schemes with a much lower pilot overhead.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures, to be published in IEEE Access</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10828</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10830</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Framework for Over-the-air Reciprocity Calibration for TDD Massive
  MIMO Systems</dc:title>
 <dc:creator>Jiang, Xiwen</dc:creator>
 <dc:creator>Decurninge, Alexis</dc:creator>
 <dc:creator>Gopala, Kalyana</dc:creator>
 <dc:creator>Kaltenberger, Florian</dc:creator>
 <dc:creator>Guillaud, Maxime</dc:creator>
 <dc:creator>Slock, Dirk</dc:creator>
 <dc:creator>Deneire, Luc</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  One of the biggest challenges in operating massive multiple-input
multiple-output systems is the acquisition of accurate channel state
information at the transmitter. To take up this challenge, time division duplex
is more favorable thanks to its channel reciprocity between downlink and
uplink. However, while the propagation channel over the air is reciprocal, the
radio-frequency front-ends in the transceivers are not. Therefore, calibration
is required to compensate the RF hardware asymmetry.
  Although various over-the-air calibration methods exist to address the above
problem, this paper offers a unified representation of these algorithms,
providing a higher level view on the calibration problem, and introduces
innovations on calibration methods. We present a novel family of calibration
methods, based on antenna grouping, which improve accuracy and speed up the
calibration process compared to existing methods. We then provide the
Cram\'er-Rao bound as the performance evaluation benchmark and compare maximum
likelihood and least squares estimators. We also differentiate between coherent
and non-coherent accumulation of calibration measurements, and point out that
enabling non-coherent accumulation allows the training to be spread in time,
minimizing impact to the data service. Overall, these results have special
value in allowing to design reciprocity calibration techniques that are both
accurate and resource-effective.
</dc:description>
 <dc:description>Comment: This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10830</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10835</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Verification of BSF Parallel Computational Model</dc:title>
 <dc:creator>Ezhova, Nadezhda</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The article is devoted to the verification of the BSF parallel computing
model. The BSF-model is an evolution of the &quot;master-slave&quot; model and
SPMD-model. The BSF-model is oriented to iterative algorithms that are
implemented in cluster computing systems. The article briefly describes the
basics of the BSF-model and its cost metrics. The structure of the BSF program
is shown in the form of a UML activity diagram. The simulator of BSF-programs,
implemented in C++ language using the MPI-library, is described. The results of
computational experiments confirming the adequacy of the cost metrics of the
BSF-model are presented.
</dc:description>
 <dc:description>Comment: Accepted at the 3rd Ural Workshop on Parallel, Distributed, and Cloud
  Computing for Young Scientists (Ural-PDC 2017)</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10836</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An algorithmic approach to handle circular trading in commercial taxing
  system</dc:title>
 <dc:creator>Mathews, Jithin</dc:creator>
 <dc:creator>Mehta, Priya</dc:creator>
 <dc:creator>Rao, S. V. Kasi Visweswara</dc:creator>
 <dc:creator>Babu, Ch. Sobhan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Tax manipulation comes in a variety of forms with different motivations and
of varying complexities. In this paper, we deal with a specific technique used
by tax-evaders known as circular trading. In particular, we define algorithms
for the detection and analysis of circular trade. To achieve this, we have
modelled the whole system as a directed graph with the actors being vertices
and the transactions among them as directed edges. We illustrate the results
obtained after running the proposed algorithm on the commercial tax dataset of
the government of Telangana, India, which contains the transaction details of a
set of participants involved in a known circular trade.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures, 1 table, 3 algorithms</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10836</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10866</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unifying Value Iteration, Advantage Learning, and Dynamic Policy
  Programming</dc:title>
 <dc:creator>Kozuno, Tadashi</dc:creator>
 <dc:creator>Uchibe, Eiji</dc:creator>
 <dc:creator>Doya, Kenji</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Approximate dynamic programming algorithms, such as approximate value
iteration, have been successfully applied to many complex reinforcement
learning tasks, and a better approximate dynamic programming algorithm is
expected to further extend the applicability of reinforcement learning to
various tasks. In this paper we propose a new, robust dynamic programming
algorithm that unifies value iteration, advantage learning, and dynamic policy
programming. We call it generalized value iteration (GVI) and its approximated
version, approximate GVI (AGVI). We show AGVI's performance guarantee, which
includes performance guarantees for existing algorithms, as special cases. We
discuss theoretical weaknesses of existing algorithms, and explain the
advantages of AGVI. Numerical experiments in a simple environment support
theoretical arguments, and suggest that AGVI is a promising alternative to
previous algorithms.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10866</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10881</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Linear Model for Knowledge Graph Embeddings</dc:title>
 <dc:creator>Joulin, Armand</dc:creator>
 <dc:creator>Grave, Edouard</dc:creator>
 <dc:creator>Bojanowski, Piotr</dc:creator>
 <dc:creator>Nickel, Maximilian</dc:creator>
 <dc:creator>Mikolov, Tomas</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper shows that a simple baseline based on a Bag-of-Words (BoW)
representation learns surprisingly good knowledge graph embeddings. By casting
knowledge base completion and question answering as supervised classification
problems, we observe that modeling co-occurences of entities and relations
leads to state-of-the-art performance with a training time of a few minutes
using the open sourced library fastText.
</dc:description>
 <dc:description>Comment: Submitted AKBC 2017</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10881</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10883</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weak Stability of $\ell_1$-minimization Methods in Sparse Data
  Reconstruction</dc:title>
 <dc:creator>Zhao, Yun-Bin</dc:creator>
 <dc:creator>Jiang, Houyuan</dc:creator>
 <dc:creator>Luo, Zhi-Quan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  As one of the most plausible convex optimization methods for sparse data
reconstruction, $\ell_1$-minimization plays a fundamental role in the
development of sparse optimization theory. The stability of this method has
been addressed in the literature under various assumptions such as restricted
isometry property (RIP), null space property (NSP), and mutual coherence. In
this paper, we propose a unified means to develop the so-called weak stability
theory for $\ell_1$-minimization methods under the condition called weak range
space property of a transposed design matrix, which turns out to be a necessary
and sufficient condition for the standard $\ell_1$-minimization method to be
weakly stable in sparse data reconstruction. The reconstruction error bounds
established in this paper are measured by the so-called Robinson's constant.
  We also provide a unified weak stability result for standard
$\ell_1$-minimization under several existing compressed-sensing matrix
properties. In particular, the weak stability of $\ell_1$-minimization under
the constant-free range space property of order $k$ of the transposed design
matrix is established for the first time in this paper. Different from the
existing analysis, we utilize the classic Hoffman's Lemma concerning the error
bound of linear systems as well as the Dudley's theorem concerning the polytope
approximation of the unit $\ell_2$-ball to show that $\ell_1$-minimization is
robustly and weakly stable in recovering sparse data from inaccurate
measurements.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10883</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10888</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rectilinear and $\mathcal{O}$-convex hull with minimum area</dc:title>
 <dc:creator>Alegr&#xed;a-Galicia, Carlos</dc:creator>
 <dc:creator>Orden, David</dc:creator>
 <dc:creator>Seara, Carlos</dc:creator>
 <dc:creator>Urrutia, Jorge</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Let $P$ be a set of $n$ points in the plane and $\mathcal{O}$ be a set of $k$
lines passing through the origin. We show: (1) How to compute the
$\mathcal{O}$-hull of $P$ in $\Theta(n\log n)$ time and $O(n)$ space, (2) how
to compute and maintain the rotated hull $\mathcal{OH}_{\theta}(P)$ for
$\theta\in [0,2\pi)$ in $O(kn\log n)$ time and $O(kn)$ space, and (3) how to
compute in $\Theta(n\log n)$ time and $O(n)$ space a value of $\theta$ for
which the rectilinear convex hull, $\mathcal{RH}_{\theta}(P)$, has minimum
area, thus improving the previously best $O(n^2)$ algorithm presented by Bae et
al. in 2009.
</dc:description>
 <dc:description>Comment: 21 pages, 18 figures</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10888</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10891</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Open Set Logo Detection and Retrieval</dc:title>
 <dc:creator>T&#xfc;zk&#xf6;, Andras</dc:creator>
 <dc:creator>Herrmann, Christian</dc:creator>
 <dc:creator>Manger, Daniel</dc:creator>
 <dc:creator>Beyerer, J&#xfc;rgen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Current logo retrieval research focuses on closed set scenarios. We argue
that the logo domain is too large for this strategy and requires an open set
approach. To foster research in this direction, a large-scale logo dataset,
called Logos in the Wild, is collected and released to the public. A typical
open set logo retrieval application is, for example, assessing the
effectiveness of advertisement in sports event broadcasts. Given a query sample
in shape of a logo image, the task is to find all further occurrences of this
logo in a set of images or videos. Currently, common logo retrieval approaches
are unsuitable for this task because of their closed world assumption. Thus, an
open set logo retrieval method is proposed in this work which allows searching
for previously unseen logos by a single query sample. A two stage concept with
separate logo detection and comparison is proposed where both modules are based
on task specific CNNs. If trained with the Logos in the Wild data, significant
performance improvements are observed, especially compared with
state-of-the-art closed set approaches.
</dc:description>
 <dc:description>Comment: accepted at VISAPP 2018</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10891</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10898</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to solve inverse problems using Wasserstein loss</dc:title>
 <dc:creator>Adler, Jonas</dc:creator>
 <dc:creator>Ringh, Axel</dc:creator>
 <dc:creator>&#xd6;ktem, Ozan</dc:creator>
 <dc:creator>Karlsson, Johan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We propose using the Wasserstein loss for training in inverse problems. In
particular, we consider a learned primal-dual reconstruction scheme for
ill-posed inverse problems using the Wasserstein distance as loss function in
the learning. This is motivated by miss-alignments in training data, which when
using standard mean squared error loss could severely degrade reconstruction
quality. We prove that training with the Wasserstein loss gives a
reconstruction operator that correctly compensates for miss-alignments in
certain cases, whereas training with the mean squared error gives a smeared
reconstruction. Moreover, we demonstrate these effects by training a
reconstruction algorithm using both mean squared error and optimal transport
loss for a problem in computerized tomography.
</dc:description>
 <dc:description>Comment: 11 pages, 3 figures</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10898</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10899</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Massively Parallel Algorithm for the Approximate Calculation of
  Inverse p-th Roots of Large Sparse Matrices</dc:title>
 <dc:creator>Lass, Michael</dc:creator>
 <dc:creator>Mohr, Stephan</dc:creator>
 <dc:creator>K&#xfc;hne, Thomas D.</dc:creator>
 <dc:creator>Plessl, Christian</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  We present the submatrix method, a highly parallelizable method for the
approximate calculation of inverse p-th roots of large sparse symmetric
matrices which are required in different scientific applications such as
electronic structure methods. We follow the idea of Approximate Computing,
allowing imprecision in the final result in order to be able to utilize the
sparsity of the input matrix and to allow massively parallel execution. For an
n x n matrix, the proposed algorithm allows to distribute the calculations over
n nodes with only little communication overhead. The approximate result matrix
exhibits the same sparsity pattern as the input matrix, allowing for efficient
reuse of allocated data structures.
  We evaluate the algorithm with respect to the error that it introduces into
calculated results, as well as its performance and scalability. We demonstrate
that the error is relatively limited for well-conditioned matrices and discuss
the execution time of the algorithm for increasing matrix sizes. Finally, we
present a distributed implementation of the algorithm using MPI and OpenMP and
demonstrate its scalability by running it on a high-performance compute cluster
comprised of 1024 CPU cores.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10899</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10903</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph Attention Networks</dc:title>
 <dc:creator>Veli&#x10d;kovi&#x107;, Petar</dc:creator>
 <dc:creator>Cucurull, Guillem</dc:creator>
 <dc:creator>Casanova, Arantxa</dc:creator>
 <dc:creator>Romero, Adriana</dc:creator>
 <dc:creator>Li&#xf2;, Pietro</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We present graph attention networks (GATs), novel neural network
architectures that operate on graph-structured data, leveraging masked
self-attentional layers to address the shortcomings of prior methods based on
graph convolutions or their approximations. By stacking layers in which nodes
are able to attend over their neighborhoods' features, we enable (implicitly)
specifying different weights to different nodes in a neighborhood, without
requiring any kind of costly matrix operation (such as inversion) or depending
on knowing the graph structure upfront. In this way, we address several key
challenges of spectral-based graph neural networks simultaneously, and make our
model readily applicable to inductive as well as transductive problems. Our GAT
models have achieved or matched state-of-the-art results across four
established transductive and inductive graph benchmarks: the Cora, Citeseer and
Pubmed citation network datasets, as well as a protein-protein interaction
dataset (wherein test graphs remain unseen during training).
</dc:description>
 <dc:description>Comment: Under review as a conference paper at ICLR 2018. 12 pages, 2 figures</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10903</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10904</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An FPTAS of Minimizing Total Weighted Completion Time on Single Machine
  with Position Constraint</dc:title>
 <dc:creator>Calinescu, G.</dc:creator>
 <dc:creator>Jaehn, F.</dc:creator>
 <dc:creator>Li, M.</dc:creator>
 <dc:creator>Wang, K.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  In this paper we study the classical scheduling problem of minimizing the
total weighted completion time on a single machine with the constraint that one
specific job must be scheduled at a specified position. We give dynamic
programs with pseudo-polynomial running time, and a fully polynomial-time
approximation scheme (FPTAS).
</dc:description>
 <dc:description>Comment: 13 pages, The 28th International Symposium on Algorithms and
  Computation (ISAAC)</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10904</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10911</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Device-centric Energy Optimization for Edge Cloud Offloading</dc:title>
 <dc:creator>Tayade, Shreya</dc:creator>
 <dc:creator>Rost, Peter</dc:creator>
 <dc:creator>Maeder, Andreas</dc:creator>
 <dc:creator>Schotten, Hans D.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  A wireless system is considered, where, computationally complex algorithms
are offloaded from user devices to an edge cloud server, for the purpose of
efficient battery usage. The main focus of this paper is to characterize and
analyze, the trade-off between the energy consumed for processing the data
locally, and for offloading. An analytical framework is presented, that
minimizes the in-device energy consumption, by providing an optimal offloading
decision for multiple user devices. A closed form solution is obtained for the
offloading decision. The solution also provides the amount of computational
data that should be offloaded, for the given computational and communication
resources. Consequently, reduction in the energy consumption is observed.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures, Accepted for IEEE Globecom 2017</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10911</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10916</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>StackGAN++: Realistic Image Synthesis with Stacked Generative
  Adversarial Networks</dc:title>
 <dc:creator>Zhang, Han</dc:creator>
 <dc:creator>Xu, Tao</dc:creator>
 <dc:creator>Li, Hongsheng</dc:creator>
 <dc:creator>Zhang, Shaoting</dc:creator>
 <dc:creator>Wang, Xiaogang</dc:creator>
 <dc:creator>Huang, Xiaolei</dc:creator>
 <dc:creator>Metaxas, Dimitris</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Although Generative Adversarial Networks (GANs) have shown remarkable success
in various tasks, they still face challenges in generating high quality images.
In this paper, we propose Stacked Generative Adversarial Networks (StackGAN)
aiming at generating high-resolution photo-realistic images. First, we propose
a two-stage generative adversarial network architecture, StackGAN-v1, for
text-to-image synthesis. The Stage-I GAN sketches the primitive shape and
colors of the object based on given text description, yielding low-resolution
images. The Stage-II GAN takes Stage-I results and text descriptions as inputs,
and generates high-resolution images with photo-realistic details. Second, an
advanced multi-stage generative adversarial network architecture, StackGAN-v2,
is proposed for both conditional and unconditional generative tasks. Our
StackGAN-v2 consists of multiple generators and discriminators in a tree-like
structure; images at multiple scales corresponding to the same scene are
generated from different branches of the tree. StackGAN-v2 shows more stable
training behavior than StackGAN-v1 by jointly approximating multiple
distributions. Extensive experiments demonstrate that the proposed stacked
generative adversarial networks significantly outperform other state-of-the-art
methods in generating photo-realistic images.
</dc:description>
 <dc:description>Comment: 14 pages, 14 figures. arXiv admin note: text overlap with
  arXiv:1612.03242</dc:description>
 <dc:date>2017-10-19</dc:date>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10916</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10924</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rectangle Transformation Problem</dc:title>
 <dc:creator>Wang, Shaojiang</dc:creator>
 <dc:creator>He, Kun</dc:creator>
 <dc:creator>Pan, Yicheng</dc:creator>
 <dc:creator>Xia, Mingji</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  In this paper, we propose the rectangle transformation problem (RTP) and its
variants. RTP asks for a transformation by a rectangle partition between two
rectangles of the same area. We are interested in the minimum RTP which
requires to minimize the partition size. We mainly focus on the strict
rectangle transformation problem (SRTP) in which rotation is not allowed in
transforming. We show that SRTP has no finite solution if the ratio of the two
parallel side lengths of input rectangles is irrational. So we turn to its
complement denoted by SIRTP, in which case all side lengths can be assumed
integral. We give a polynomial time algorithm ALGSIRTP which gives a solution
at most $q/p+O(\sqrt{p})$ to SIRTP$(p,q)$ ($q\geq p$), where $p$ and $q$ are
two integer side lengths of input rectangles $p\times q$ and $q\times p$, and
so ALGSIRTP is a $O(\sqrt{p})$-approximation algorithm for minimum
SIRTP$(p,q)$. On the other hand, we show that there is not constant solution to
SIRTP$(p,q)$ for all integers $p$ and $q$ ($q&gt;p$) even though the ratio $q/p$
is within any constant range. We also raise a series of open questions for the
research along this line.
</dc:description>
 <dc:description>Comment: 22 pages,5 figures</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10924</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10928</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The loss surface and expressivity of deep convolutional neural networks</dc:title>
 <dc:creator>Nguyen, Quynh</dc:creator>
 <dc:creator>Hein, Matthias</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We analyze the expressiveness and loss surface of practical deep
convolutional neural networks (CNNs) with shared weights and max pooling
layers. We show that such CNNs produce linearly independent features at a
&quot;wide&quot; layer which has more neurons than the number of training samples. This
condition holds e.g. for the VGG network. Furthermore, we provide for such wide
CNNs necessary and sufficient conditions for global minima with zero training
error. For the case where the wide layer is followed by a fully connected
layer, we show that almost every critical point of the empirical loss is a
global minimum with zero training error. Our analysis suggests that both depth
and width are very important in deep learning. While depth brings more
representational power and allows the network to learn high level features,
width smoothes the optimization landscape of the loss function in the sense
that a sufficiently wide network has a well-behaved loss surface with
potentially no bad local minima.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10932</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structure-preserving discrete-time optimal maneuvers of a wheeled
  inverted pendulum</dc:title>
 <dc:creator>Phogat, Karmvir Singh</dc:creator>
 <dc:creator>Banavar, Ravi</dc:creator>
 <dc:creator>Chatterjee, Debasish</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The Wheeled Inverted Pendulum (WIP) is a nonholonomic, underactuated
mechanical system, and has been popularized commercially as the {\it Segway}.
Designing optimal control laws for point-to-point state-transfer for this
autonomous mechanical system, while respecting momentum and torque constraints
as well as the underlying manifold, continues to pose challenging problems. In
this article we present a successful effort in this direction: We employ
geometric mechanics to obtain a discrete-time model of the system, followed by
the synthesis of an energy-optimal control based on a discrete-time maximum
principle applicable to mechanical systems whose configuration manifold is a
Lie group. Moreover, we incorporate state and momentum constraints into the
discrete-time control directly at the synthesis stage. The control is
implemented on a WIP with parameters obtained from an existing prototype; the
results are highly encouraging, as demonstrated by numerical experiments.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10932</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10940</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Neural Networks and Signed Particles to Simulate Quantum
  Systems More Efficiently</dc:title>
 <dc:creator>Sellier, Jean Michel</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Recently a new formulation of quantum mechanics has been suggested which
describes systems by means of ensembles of classical particles provided with a
sign. This novel approach mainly consists of two steps: the computation of the
Wigner kernel, a multi-dimensional function describing the effects of the
potential over the system, and the field-less evolution of the particles which
eventually create new signed particles in the process. Although this method has
proved to be extremely advantageous in terms of computational resources - as a
matter of fact it is able to simulate in a time-dependent fashion many- body
systems on relatively small machines - the Wigner kernel can represent the
bottleneck of simulations of certain systems. Moreover, storing the kernel can
be another issue as the amount of memory needed is cursed by the dimensionality
of the system. In this work, we introduce a new technique which drastically
reduces the computation time and memory requirement to simulate time-dependent
quantum systems which is based on the use of an appropriately tailored neural
network combined with the signed particle formalism. In particular, the
suggested neural network is able to compute efficiently and reliably the Wigner
kernel without any training as its entire set of weights and biases is
specified by analytical formulas. As a consequence, the amount of memory for
quantum simulations radically drops since the kernel does not need to be stored
anymore as it is now computed by the neural network itself, only on the cells
of the (discretized) phase-space which are occupied by particles. As its is
clearly shown in the final part of this paper, not only this novel approach
drastically reduces the computational time, it also remains accurate. The
author believes this work opens the way towards effective design of quantum
devices, with incredible practical implications.
</dc:description>
 <dc:date>2017-10-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10940</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10941</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The univalence axiom in cubical sets</dc:title>
 <dc:creator>Bezem, Marc</dc:creator>
 <dc:creator>Coquand, Thierry</dc:creator>
 <dc:creator>Huber, Simon</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In this note we show that Voevodsky's univalence axiom holds in the model of
type theory based on symmetric cubical sets. We will also discuss Swan's
construction of the identity type in this variation of cubical sets. This
proves that we have a model of type theory supporting dependent products,
dependent sums, univalent universes, and identity types with the usual
judgmental equality, and this model is formulated in a constructive metatheory.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10941</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10944</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Supervised STDP-based Training Algorithm for Living Neural Networks</dc:title>
 <dc:creator>Zeng, Yuan</dc:creator>
 <dc:creator>Devincentis, Kevin</dc:creator>
 <dc:creator>Xiao, Yao</dc:creator>
 <dc:creator>Ferdous, Zubayer Ibne</dc:creator>
 <dc:creator>Guo, Xiaochen</dc:creator>
 <dc:creator>Yan, Zhiyuan</dc:creator>
 <dc:creator>Berdichevsky, Yevgeny</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Neural networks have shown great potential in many applications like speech
recognition, drug discovery, image classification, and object detection. Neural
network models are inspired by biological neural networks, but they are
optimized to perform machine learning tasks on digital computers. The proposed
work explores the possibilities of using living neural networks in vitro as
basic computational elements for machine learning applications. A new
supervised STDP-based learning algorithm is proposed in this work, which
considers neuron engineering constrains. A 74.7% accuracy is achieved on the
MNIST benchmark for handwritten digit recognition.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures, submitted to ICASSP 2018</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10944</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10948</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sound Source Localization in a Multipath Environment Using Convolutional
  Neural Networks</dc:title>
 <dc:creator>Ferguson, Eric L.</dc:creator>
 <dc:creator>Williams, Stefan B.</dc:creator>
 <dc:creator>Jin, Craig T.</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  The propagation of sound in a shallow water environment is characterized by
boundary reflections from the sea surface and sea floor. These reflections
result in multiple (indirect) sound propagation paths, which can degrade the
performance of passive sound source localization methods. This paper proposes
the use of convolutional neural networks (CNNs) for the localization of sources
of broadband acoustic radiated noise (such as motor vessels) in shallow water
multipath environments. It is shown that CNNs operating on cepstrogram and
generalized cross-correlogram inputs are able to more reliably estimate the
instantaneous range and bearing of transiting motor vessels when the source
localization performance of conventional passive ranging methods is degraded.
The ensuing improvement in source localization performance is demonstrated
using real data collected during an at-sea experiment.
</dc:description>
 <dc:description>Comment: 5 pages, 5 figures, Final draft of paper submitted to 2018 IEEE
  International Conference on Acoustics, Speech and Signal Processing (ICASSP)
  15-20 April 2018 in Calgary, Alberta, Canada. arXiv admin note: text overlap
  with arXiv:1612.03505</dc:description>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10948</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10951</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SGDLibrary: A MATLAB library for stochastic gradient descent algorithms</dc:title>
 <dc:creator>Kasai, Hiroyuki</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of finding the minimizer of a function $f:
\mathbb{R}^d \rightarrow \mathbb{R}$ of the form $\min f(w) =
\frac{1}{n}\sum_{i}f_i({w})$. This problem has been studied intensively in
recent years in machine learning research field. One typical but promising
approach for large-scale data is stochastic optimization algorithm. SGDLibrary
is a flexible, extensible and efficient pure-Matlab library of a collection of
stochastic optimization algorithms. The purpose of the library is to provide
researchers and implementers a comprehensive evaluation environment of those
algorithms on various machine learning problems.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10951</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10964</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>At the Roots of Dictionary Compression: String Attractors</dc:title>
 <dc:creator>Kempa, Dominik</dc:creator>
 <dc:creator>Prezza, Nicola</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A well-known fact in the field of lossless text compression is that
high-order entropy is a weak model when the input contains long repetitions.
Motivated by this fact, decades of research have generated myriads of so-called
dictionary compressors: algorithms able to reduce the text's size by exploiting
its repetitiveness. Lempel-Ziv 77 is probably one of the most successful and
known tools of this kind, followed by straight-line programs, run-length
Burrows-Wheeler transform, macro schemes, collage systems, and the compact
directed acyclic word graph. In this paper, we show that these techniques are
only different solutions to the same, elegant, combinatorial problem: to find a
small set of positions capturing all distinct text's substrings. We call
\emph{string attractor} such a set. We first show reductions between dictionary
compressors and string attractors. This gives us the approximation ratios of
dictionary compressors with respect to the smallest string attractor and allows
us to solve several open problems related to the asymptotic relations between
the output sizes of different dictionary compressors. We then show that
$k$-attractor problem --- that is, deciding whether a text has a size-$t$ set
of positions capturing all substrings of length at most $k$ --- is NP-complete
for $k\geq 3$. This, in particular, implies the NP-completeness of the full
string attractor problem. We provide several approximation techniques for the
smallest $k$-attractor, show that the problem is APX-complete for constant $k$,
and give strong inapproximability results. To conclude, we provide matching
lower- and upper- bounds for the random access problem on string attractors.
Our data structure matching the lower bound is optimal also for LZ77,
straight-line programs, collage systems, and macro schemes, and therefore
essentially closes the random access problem for all these compressors.
</dc:description>
 <dc:description>Comment: added conclusion</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10964</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10967</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Artificial Intelligence as Structural Estimation: Economic
  Interpretations of Deep Blue, Bonanza, and AlphaGo</dc:title>
 <dc:creator>Igami, Mitsuru</dc:creator>
 <dc:subject>Economics - Econometrics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Artificial intelligence (AI) has achieved superhuman performance in a growing
number of tasks, including the classical games of chess, shogi, and Go, but
understanding and explaining AI remain challenging. This paper studies the
machine-learning algorithms for developing the game AIs, and provides their
structural interpretations. Specifically, chess-playing Deep Blue is a
calibrated value function, whereas shogi-playing Bonanza represents an
estimated value function via Rust's (1987) nested fixed-point method. AlphaGo's
&quot;supervised-learning policy network&quot; is a deep neural network (DNN) version of
Hotz and Miller's (1993) conditional choice probability estimates; its
&quot;reinforcement-learning value network&quot; is equivalent to Hotz, Miller, Sanders,
and Smith's (1994) simulation method for estimating the value function. Their
performances suggest DNNs are a useful functional form when the state space is
large and data are sparse. Explicitly incorporating strategic interactions and
unobserved heterogeneity in the data-generating process would further improve
AIs' explicability.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10967</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10974</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Content-based Representations of audio using Siamese neural networks</dc:title>
 <dc:creator>Manocha, Pranay</dc:creator>
 <dc:creator>Badlani, Rohan</dc:creator>
 <dc:creator>Kumar, Anurag</dc:creator>
 <dc:creator>Shah, Ankit</dc:creator>
 <dc:creator>Elizalde, Benjamin</dc:creator>
 <dc:creator>Raj, Bhiksha</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  In this paper, we focus on the problem of content-based retrieval for audio,
which aims to retrieve all semantically similar audio recordings for a given
audio clip query. We propose a novel approach which encodes the audio into a
vector representation using Siamese Neural Networks. The goal is to obtain an
encoding similar for files belonging to the same audio class, thus allowing
retrieval of semantically similar audio. We used two similarity measures,
Cosine similarity and Euclidean distance, to show that our method is effective
in retrieving files similar in audio content. Our results indicate that our
neural network-based approach is able to retrieve files similar in content and
semantics.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10974</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10977</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integrating Small Satellite Communication in an Autonomous Vehicle
  Network: A Case on Oceanography</dc:title>
 <dc:creator>Guerra, Andr&#xe9; G. C.</dc:creator>
 <dc:creator>Ferreira, Ant&#xf3;nio S&#xe9;rgio</dc:creator>
 <dc:creator>Costa, Maria</dc:creator>
 <dc:creator>Nodar-L&#xf3;pez, Diego</dc:creator>
 <dc:creator>Agelet, Fernando Aguado</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Physics - Applied Physics</dc:subject>
 <dc:subject>Physics - Space Physics</dc:subject>
 <dc:description>  Small satellites and autonomous vehicles have greatly evolved in the last few
decades. Hundreds of small satellites have been launched with increasing
functionalities, in the last few years. Likewise, numerous autonomous vehicles
have been built, with decreasing costs and form-factor payloads. Here we focus
on combining these two multifaceted assets in an incremental way. The first
goal is to create a highly reliable and constantly available communication link
for a network of autonomous vehicles, taking advantage of the small satellite
lower cost, with respect to conventional spacecraft, and its higher
flexibility. We have developed a test platform as a proving ground for this
network, by integrating a satellite software defined radio on an unmanned air
vehicle, creating a system of systems. Several experiments have been run
successfully. After this first step is fully operational, we could, in
practice, move on towards a cooperative network of autonomous vehicles and
small satellites.
</dc:description>
 <dc:description>Comment: 11 pages, 10 figures, 4 tables</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10977</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10979</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding Connected Secluded Subgraphs</dc:title>
 <dc:creator>Golovach, Petr A.</dc:creator>
 <dc:creator>Heggernes, Pinar</dc:creator>
 <dc:creator>Lima, Paloma</dc:creator>
 <dc:creator>Montealegre, Pedro</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Problems related to finding induced subgraphs satisfying given properties
form one of the most studied areas within graph algorithms. Such problems have
given rise to breakthrough results and led to development of new techniques
both within the traditional P vs NP dichotomy and within parameterized
complexity. The \Pi-Subgraph problem asks whether an input graph contains an
induced subgraph on at least k vertices satisfying graph property \Pi. For many
applications, it is desirable that the found subgraph has as few connections to
the rest of the graph as possible, which gives rise to the Secluded
\Pi-Subgraph problem. Here, input k is the size of the desired subgraph, and
input t is a limit on the number of neighbors this subgraph has in the rest of
the graph. This problem has been studied from a parameterized perspective, and
unfortunately it turns out to be W[1]-hard for many graph properties \Pi, even
when parameterized by k+t. We show that the situation changes when we are
looking for a connected induced subgraph satisfying \Pi. In particular, we show
that the Connected \Pi-Secluded Subgraph problem is FPT when parameterized by
just t for many important graph properties \Pi.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10979</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10980</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical validation of financial time series via visibility graph</dc:title>
 <dc:creator>Serafino, Matteo</dc:creator>
 <dc:creator>Gabrielli, Andrea</dc:creator>
 <dc:creator>Caldarelli, Guido</dc:creator>
 <dc:creator>Cimini, Giulio</dc:creator>
 <dc:subject>Quantitative Finance - Risk Management</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  Statistical physics of complex systems exploits network theory not only to
model, but also to effectively extract information from many dynamical
real-world systems. A pivotal case of study is given by financial systems:
market prediction represents an unsolved scientific challenge yet with crucial
implications for society, as financial crises have devastating effects on real
economies. Thus, nowadays the quest for a robust estimator of market efficiency
is both a scientific and institutional priority. In this work we study the
visibility graphs built from the time series of several trade market indices.
We propose a validation procedure for each link of these graphs against a null
hypothesis derived from ARCH-type modeling of such series. Building on this
framework, we devise a market indicator that turns out to be highly correlated
and even predictive of financial instability periods.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10980</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10985</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Taut String Interpretation of the One-dimensional
  Rudin-Osher-Fatemi Model: A New Proof, a Fundamental Estimate and Some
  Applications</dc:title>
 <dc:creator>Overgaard, Niels Chr.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A new proof of the equivalence of the Taut String Algorithm and the
one-dimensional Rudin-Osher-Fatemi model is presented. Based on duality and the
projection theorem in Hilbert space, the proof is strictly elementary.
Existence and uniqueness of solutions to both denoising models follow as
by-products. The standard convergence properties of the denoised signal, as the
regularizing parameter tends to zero, are recalled and efficient proofs
provided. Moreover, a new and fundamental bound on the denoised signal is
derived. This bound implies, among other things, the strong convergence (in the
space of functions of bounded variation) of the denoised signal to the insignal
as the regularization parameter vanishes. The methods developed in the paper
can be modified to cover other interesting applications such as isotonic
regression.
</dc:description>
 <dc:description>Comment: 19 pages, 2 figures, 1 appendix</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10985</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10991</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deciding Confluence and Normal Form Properties of Ground Term Rewrite
  Systems Efficiently</dc:title>
 <dc:creator>Felgenhauer, Bertram</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.2</dc:subject>
 <dc:subject>F.4</dc:subject>
 <dc:description>  It is known that the first-order theory of rewriting is decidable for ground
term rewrite systems, but the general technique uses tree automata and often
takes exponential time. For many properties, including confluence (CR),
uniqueness of normal forms with respect to reductions (UNR) and with respect to
conversions (UNC), polynomial time decision procedures are known for ground
term rewrite systems. However, this is not the case for the normal form
property (NFP). In this work, we present a cubic time algorithm for NFP, an
almost cubic time algorithm for UNR, and an almost linear time algorithm for
UNC, improving previous bounds. We also present a cubic time algorithm for CR.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10991</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10994</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conceptual Text Summarizer: A new model in continuous vector space</dc:title>
 <dc:creator>Khademi, Mohammad Ebrahim</dc:creator>
 <dc:creator>Fakhredanesh, Mohammad</dc:creator>
 <dc:creator>Hoseini, Seyed Mojtaba</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Traditional methods of summarization are not cost-effective and possible
today. Extractive summarization is a process that helps to extract the most
important sentences from a text automatically and generates a short informative
summary. In this work, we propose an unsupervised method to summarize Persian
texts. This method is a novel hybrid approach that clusters the concepts of the
text using deep learning and statistical methods. Although the proposed method
is language independent, we focus on Persian text summarization in this work.
First we produce a word embedding based on Hamshahri2 corpus and a dictionary
of word frequencies. Then the proposed algorithm extracts the keywords of the
document, clusters its concepts, and finally ranks the sentences to produce the
summary. We evaluated the proposed method on Pasokh single document dataset
using the ROUGE evaluation measure. Without using any hand-crafted features,
our proposed method achieves competitive performance. ROUGE-3 recall score for
system summaries generated with 25% compression ratio on Pasokh corpus is 0.27.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10994</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10998</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Social Network De-anonymization: More Adversarial Knowledge, More Users
  Re-Identified?</dc:title>
 <dc:creator>Qian, Jianwei</dc:creator>
 <dc:creator>Li, Xiang-Yang</dc:creator>
 <dc:creator>Wang, Yu</dc:creator>
 <dc:creator>Tang, Shaojie</dc:creator>
 <dc:creator>Jung, Taeho</dc:creator>
 <dc:creator>Fan, Yang</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Following the trend of data trading and data publishing, many online social
networks have enabled potentially sensitive data to be exchanged or shared on
the web. As a result, users' privacy could be exposed to malicious third
parties since they are extremely vulnerable to de-anonymization attacks, i.e.,
the attacker links the anonymous nodes in the social network to their real
identities with the help of background knowledge. Previous work in social
network de-anonymization mostly focuses on designing accurate and efficient
de-anonymization methods. We study this topic from a different perspective and
attempt to investigate the intrinsic relation between the attacker's knowledge
and the expected de-anonymization gain. One common intuition is that the more
auxiliary information the attacker has, the more accurate de-anonymization
becomes. However, their relation is much more sophisticated than that. To
simplify the problem, we attempt to quantify background knowledge and
de-anonymization gain under several assumptions. Our theoretical analysis and
simulations on synthetic and real network data show that more background
knowledge may not necessarily lead to more de-anonymization gain in certain
cases. Though our analysis is based on a few assumptions, the findings still
leave intriguing implications for the attacker to make better use of the
background knowledge when performing de-anonymization, and for the data owners
to better measure the privacy risk when releasing their data to third parties.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.10998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11001</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comprehensive Survey on Fog Computing: State-of-the-art and Research
  Challenges</dc:title>
 <dc:creator>Mouradian, Carla</dc:creator>
 <dc:creator>Naboulsi, Diala</dc:creator>
 <dc:creator>Yangui, Sami</dc:creator>
 <dc:creator>Glitho, Roch H.</dc:creator>
 <dc:creator>Morrow, Monique J.</dc:creator>
 <dc:creator>Polakos, Paul A.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Cloud computing with its three key facets (i.e., IaaS, PaaS, and SaaS) and
its inherent advantages (e.g., elasticity and scalability) still faces several
challenges. The distance between the cloud and the end devices might be an
issue for latency-sensitive applications such as disaster management and
content delivery applications. Service Level Agreements (SLAs) may also impose
processing at locations where the cloud provider does not have data centers.
Fog computing is a novel paradigm to address such issues. It enables
provisioning resources and services outside the cloud, at the edge of the
network, closer to end devices or eventually, at locations stipulated by SLAs.
Fog computing is not a substitute for cloud computing but a powerful
complement. It enables processing at the edge while still offering the
possibility to interact with the cloud. This article presents a comprehensive
survey on fog computing. It critically reviews the state of the art in the
light of a concise set of evaluation criteria. We cover both the architectures
and the algorithms that make fog systems. Challenges and research directions
are also introduced. In addition, the lessons learned are reviewed and the
prospects are discussed in terms of the key role fog is likely to play in
emerging technologies such as Tactile Internet.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11004</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Denoising random forests</dc:title>
 <dc:creator>Hibino, Masaya</dc:creator>
 <dc:creator>Kimura, Akisato</dc:creator>
 <dc:creator>Yamashita, Takayoshi</dc:creator>
 <dc:creator>Yamauchi, Yuji</dc:creator>
 <dc:creator>Fujiyoshi, Hironobu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper proposes a novel type of random forests called a denoising random
forests that are robust against noises contained in test samples. Such
noise-corrupted samples cause serious damage to the estimation performances of
random forests, since unexpected child nodes are often selected and the leaf
nodes that the input sample reaches are sometimes far from those for a clean
sample. Our main idea for tackling this problem originates from a binary
indicator vector that encodes a traversal path of a sample in the forest. Our
proposed method effectively employs this vector by introducing denoising
autoencoders into random forests. A denoising autoencoder can be trained with
indicator vectors produced from clean and noisy input samples, and non-leaf
nodes where incorrect decisions are made can be identified by comparing the
input and output of the trained denoising autoencoder. Multiple traversal paths
with respect to the nodes with incorrect decisions caused by the noises can
then be considered for the estimation.
</dc:description>
 <dc:description>Comment: 20 pages, 10 figures, submitted to Pattern Recognition</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11009</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Artificial-Noise-Aided Secure Scheme for Hybrid Parallel PLC/Wireless
  OFDM Systems</dc:title>
 <dc:creator>Shafie, Ahmed El</dc:creator>
 <dc:creator>Marzban, Mohamed F.</dc:creator>
 <dc:creator>Chabaan, Rakan</dc:creator>
 <dc:creator>Al-Dhahir, Naofal</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We investigate the physical-layer security of indoor hybrid parallel
power-line/wireless orthogonal-frequency division-multiplexing (OFDM)
communication systems. We propose an artificial-noise (AN) aided scheme to
enhance the system's security in the presence of an eavesdropper by exploiting
the decoupled nature of the power-line and wireless communication media. The
proposed scheme does not require the instantaneous channel state information of
the eavesdropper's links to be known at the legitimate nodes. In our proposed
scheme, the legitimate transmitter (Alice) and the legitimate receiver (Bob)
cooperate to secure the hybrid system where an AN signal is shared from Bob to
Alice on the link with the lower channel-to-noise ratio (CNR) while the
information stream in addition to a noisy-amplified version of the received AN
signal is transmitted from Alice to Bob on the link with higher CNR at each
OFDM sub-channel. In addition, we investigate the effect of the transmit power
levels at both Alice and Bob and the power allocation ratio between the data
and AN signals at Alice on the secure throughput. We investigate both
single-link eavesdropping attacks, where only one link is exposed to
eavesdropping attacks, and two-link eavesdropping attacks, where the two links
are exposed to eavesdropping attacks.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11017</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synergy in the Knowledge Base of U.S. Innovation Systems at National,
  State, and Regional Levels: The Contributions of High-Tech Manufacturing and
  Knowledge-Intensive Services</dc:title>
 <dc:creator>Leydesdorff, Loet</dc:creator>
 <dc:creator>Wagner, Caroline S.</dc:creator>
 <dc:creator>Porto-Gomez, Igone</dc:creator>
 <dc:creator>Comins, Jordan A.</dc:creator>
 <dc:creator>Phillips, Fred</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Synergies among technological opportunities, market perspectives, and
geographical endowments can be considered as indicators of systemness. Using
information theory, we propose a measure of synergy among size-classes,
zip-codes, and NACE-codes for 8.5 million American firms. The synergy at the
national level is decomposed at the level of states and Core-Based Statistical
Areas (CBSA) as regions. Thereafter, we zoom in to the state of California and
in even more detail to Silicon Valley. Our results do not support the
assumption of a national system of innovations in the U.S.A. Innovation systems
appear to operate at the level of the states, the CBSA regions are too small,
so that systemness spills across their borders. Decomposition of the sample in
terms of high-tech manufacturing (HTM), medium-high-tech manufacturing (MHTM),
knowledge-intensive services (KIS), and high-tech services (HTKIS) does not
change this pattern, but refines it. The East Coast--New Jersey, Boston, and
New York--and California are the major players, with Texas a third one in the
case of HTKIS. At the regional level, Chicago and industrial centers in the
Midwest also contribute synergy. Within California, Los Angeles and its
environment contribute synergy in the sectors of manufacturing, the San
Francisco area in KIS, and Silicon Valley in both, but with synergy mainly
generated by manufacturing. Knowledge-intensive services in Silicon Valley
spillover to other regions and even globally.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11018</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rate-Splitting for Downlink Multi-User Multi-Antenna Systems: Bridging
  NOMA and Conventional Linear Precoding</dc:title>
 <dc:creator>Mao, Yijie</dc:creator>
 <dc:creator>Clerckx, Bruno</dc:creator>
 <dc:creator>Li, Victor O. K.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The main aim of this work is to bridge two contrasting transmission
strategies used for the multiple-input single-output (MISO) broadcast channel
(BC), namely, non-orthogonal multiple access (NOMA) and multi-user linear
precoding. The former is based on superposition coding with successive
interference cancellation (SC--SIC), and therefore relies on strong users to
fully decode and cancel interference created by messages of weaker users. It is
known to be suitable for degraded channels, e.g. when user channels are
aligned. The latter is more common for multi-user transmission. It is known to
have near optimal performance when the user channels are orthogonal or
semi-orthogonal. We propose the use of rate-splitting (RS), a more general
transmission approach that contains the two aforementioned strategies as
special cases. The key benefit of RS is its ability to partially decode
interference and partially treat interference as noise, therefore bridging the
two extremes of fully decoding interference (as in NOMA) and treating
interference as noise (as in conventional multi-user linear precoding). The
three strategies are compared and numerical results show that RS provides a
smooth transition between NOMA and linear precoding, and outperforms them both
in some scenarios.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11020</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical Significance and Effect Sizes of Differences among Research
  Universities at the Level of Nations and Worldwide based on the Leiden
  Rankings</dc:title>
 <dc:creator>Leydesdorff, Loet</dc:creator>
 <dc:creator>Bornmann, Lutz</dc:creator>
 <dc:creator>Mingers, John</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  One can use the Leiden Rankings for grouping research universities by
considering universities which are not significantly different as a homogeneous
set. Such groupings reduce the complexity of the rankings without losing
information. We pursue this classification using both statistical significance
and effect sizes of differences among 902 universities in 54 countries, we
focus on the UK, Germany, and Brazil as national examples. Although the
groupings remain largely the same using different statistical significance
levels, the resulting classifications are uncorrelated with the ones based on
effect sizes (Cramer's V &lt; .3). Effect sizes for the differences between
universities are small (w &lt;.2). The results based on statistical-significance
testing can be understood intuitively. However, the results based on effect
sizes suggest a division between a North-Atlantic and an Asian-Pacific group.
The more detailed analysis of universities at the country level suggests that
distinctions between more than three groups of universities (high, middle, low)
are not meaningful.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11021</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantitative Analysis of DoS Attacks and Client Puzzles in IoT Systems</dc:title>
 <dc:creator>Arnaboldi, Luca</dc:creator>
 <dc:creator>Morrisset, Charles</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Denial of Service (DoS) attacks constitute a major security threat to today's
Internet. This challenge is especially pertinent to the Internet of Things
(IoT) as devices have less computing power, memory and security mechanisms to
mitigate DoS attacks. This paper presents a model that mimics the unique
characteristics of a network of IoT devices, including components of the system
implementing `Crypto Puzzles' - a DoS mitigation technique. We created an
imitation of a DoS attack on the system, and conducted a quantitative analysis
to simulate the impact such an attack may potentially exert upon the system,
assessing the trade off between security and throughput in the IoT system. We
model this through stochastic model checking in PRISM and provide evidence that
supports this as a valuable method to compare the efficiency of different
implementations of IoT systems, exemplified by a case study.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11021</dc:identifier>
 <dc:identifier>In: Livraga G., Mitchell C. (eds) Security and Trust Management.
  STM 2017. Lecture Notes in Computer Science, vol 10547. Springer, Cham</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-68063-7_16</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11027</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Named Entity Recognition in Twitter using Images and Text</dc:title>
 <dc:creator>Esteves, Diego</dc:creator>
 <dc:creator>Peres, Rafael</dc:creator>
 <dc:creator>Lehmann, Jens</dc:creator>
 <dc:creator>Napolitano, Giulio</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Named Entity Recognition (NER) is an important subtask of information
extraction that seeks to locate and recognise named entities. Despite recent
achievements, we still face limitations with correctly detecting and
classifying entities, prominently in short and noisy text, such as Twitter. An
important negative aspect in most of NER approaches is the high dependency on
hand-crafted features and domain-specific knowledge, necessary to achieve
state-of-the-art results. Thus, devising models to deal with such
linguistically complex contexts is still challenging. In this paper, we propose
a novel multi-level architecture that does not rely on any specific linguistic
resource or encoded rule. Unlike traditional approaches, we use features
extracted from images and text to classify named entities. Experimental tests
against state-of-the-art NER for Twitter on the Ritter dataset present
competitive results (0.59 F-measure), indicating that this approach may lead
towards better NER models.
</dc:description>
 <dc:description>Comment: The 3rd International Workshop on Natural Language Processing for
  Informal Text (NLPIT 2017), 8 pages</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11029</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic gradient descent performs variational inference, converges to
  limit cycles for deep networks</dc:title>
 <dc:creator>Chaudhari, Pratik</dc:creator>
 <dc:creator>Soatto, Stefano</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Stochastic gradient descent (SGD) is widely believed to perform implicit
regularization when used to train deep neural networks, but the precise manner
in which this occurs has thus far been elusive. We prove that SGD minimizes an
average potential over the posterior distribution of weights along with an
entropic regularization term. This potential is however not the original loss
function in general. So SGD does perform variational inference, but for a
different loss than the one used to compute the gradients. Even more
surprisingly, SGD does not even converge in the classical sense: we show that
the most likely trajectories of SGD for deep networks do not behave like
Brownian motion around critical points. Instead, they resemble closed loops
with deterministic components. We prove that such &quot;out-of-equilibrium&quot; behavior
is a consequence of highly non-isotropic gradient noise in SGD; the covariance
matrix of mini-batch gradients for deep networks has a rank as small as 1% of
its dimension. We provide extensive empirical validation of these claims,
proven in the appendix.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11035</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine Translation of Low-Resource Spoken Dialects: Strategies for
  Normalizing Swiss German</dc:title>
 <dc:creator>Honnet, Pierre-Edouard</dc:creator>
 <dc:creator>Popescu-Belis, Andrei</dc:creator>
 <dc:creator>Musat, Claudiu</dc:creator>
 <dc:creator>Baeriswyl, Michael</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The goal of this work is to design a machine translation system for a
low-resource family of dialects, collectively known as Swiss German. We list
the parallel resources that we collected, and present three strategies for
normalizing Swiss German input in order to address the regional and spelling
diversity. We show that character-based neural MT is the best solution for text
normalization and that in combination with phrase-based statistical MT we reach
36% BLEU score. This value, however, is shown to decrease as the testing
dialect becomes more remote from the training one.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11039</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Science: A Powerful Catalyst for Cross-Sector Collaborations to
  Transform the Future of Global Health - Developing a New Interactive
  Relational Mapping Tool</dc:title>
 <dc:creator>Bulc, Barbara</dc:creator>
 <dc:creator>Landers, Cassie</dc:creator>
 <dc:creator>Driscoll, Katherine</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The increasingly complex and rapidly changing global health and
socio-economic landscape requires fundamentally new ways of thinking, acting
and collaborating to solve growing systems challenges. Cross-sectoral
collaborations between governments, businesses, international organizations,
private investors, academia and non-profits are essential for lasting success
in achieving the Sustainable Development Goals (SDGs), and securing a
prosperous future for the health and wellbeing of all people. Our aim is to use
data science and innovative technologies to map diverse stakeholders and their
initiatives around SDGs and specific health targets - with particular focus on
SDG 3 (Good Health &amp; Well Being) and SDG 17 (Partnerships for the Goals) - to
accelerate cross-sector collaborations. Initially, the mapping tool focuses on
Geneva, Switzerland as the world center of global health diplomacy with over 80
key stakeholders and influencers present. As we develop the next level pilot,
we aim to build on users' interests, with a potential focus on non-communicable
diseases (NCDs) as one of the emerging and most pressing global health issues
that requires new collaborative approaches. Building on this pilot, we can
later expand beyond only SDG 3 to other SDGs.
</dc:description>
 <dc:description>Comment: Presented at the Data For Good Exchange 2017</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11039</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11040</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Should a Robot Assess Risk? Towards an Axiomatic Theory of Risk in
  Robotics</dc:title>
 <dc:creator>Majumdar, Anirudha</dc:creator>
 <dc:creator>Pavone, Marco</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Endowing robots with the capability of assessing risk and making risk-aware
decisions is widely considered a key step toward ensuring safety for robots
operating under uncertainty. But, how should a robot quantify risk? A natural
and common approach is to consider the framework whereby costs are assigned to
stochastic outcomes - an assignment captured by a cost random variable.
Quantifying risk then corresponds to evaluating a risk metric, i.e., a mapping
from the cost random variable to a real number. Yet, the question of what
constitutes a &quot;good&quot; risk metric has received little attention within the
robotics community. The goal of this paper is to explore and partially address
this question by advocating axioms that risk metrics in robotics applications
should satisfy in order to be employed as rational assessments of risk. We
discuss general representation theorems that precisely characterize the class
of metrics that satisfy these axioms (referred to as distortion risk metrics),
and provide instantiations that can be used in applications. We further discuss
pitfalls of commonly used risk metrics in robotics, and discuss additional
properties that one must consider in sequential decision making tasks. Our hope
is that the ideas presented here will lead to a foundational framework for
quantifying risk (and hence safety) in robotics applications.
</dc:description>
 <dc:description>Comment: Extended version of paper published in International Symposium on
  Robotics Research (ISRR) 2017</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11040</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11041</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Neural Machine Translation</dc:title>
 <dc:creator>Artetxe, Mikel</dc:creator>
 <dc:creator>Labaka, Gorka</dc:creator>
 <dc:creator>Agirre, Eneko</dc:creator>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In spite of the recent success of neural machine translation (NMT) in
standard benchmarks, the lack of large parallel corpora poses a major practical
problem for many language pairs. There have been several proposals to alleviate
this issue with, for instance, triangulation and semi-supervised learning
techniques, but they still require a strong cross-lingual signal. In this work,
we completely remove the need of parallel data and propose a novel method to
train an NMT system in a completely unsupervised manner, relying on nothing but
monolingual corpora. Our model builds upon the recent work on unsupervised
embedding mappings, and consists of a slightly modified attentional
encoder-decoder model that can be trained on monolingual corpora alone using a
combination of denoising and backtranslation. Despite the simplicity of the
approach, our system obtains 15.56 and 10.21 BLEU points in WMT 2014
French-to-English and German-to-English translation. The model can also profit
from small parallel corpora, and attains 21.81 and 15.24 points when combined
with 100,000 parallel sentences, respectively. Our approach is a breakthrough
in unsupervised NMT, and opens exciting opportunities for future research.
</dc:description>
 <dc:description>Comment: Submitted as a conference paper to ICLR 2018</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11043</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Isolation and connectivity in random geometric graphs with self-similar
  intensity measures</dc:title>
 <dc:creator>Dettmann, Carl P.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  Random geometric graphs consist of randomly distributed nodes (points), with
pairs of nodes within a given mutual distance linked. In the usual model the
distribution of nodes is uniform on a square, and in the limit of infinitely
many nodes and shrinking linking range, the number of isolated nodes is Poisson
distributed, and the probability of no isolated nodes is equal to the
probability the whole graph is connected. Here we examine these properties for
several self-similar node distributions, including smooth and fractal, uniform
and nonuniform, and finitely ramified or otherwise. We show that nonuniformity
can break the Poisson distribution property, but it strengthens the link
between isolation and connectivity. It also stretches out the connectivity
transition. Finite ramification is another mechanism for lack of connectivity.
The same considerations apply to fractal distributions as smooth, with some
technical differences in evaluation of the integrals and analytical arguments.
</dc:description>
 <dc:description>Comment: 18 pages, 7 figures</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11046</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring the Impact of Urban Street Trees on Air Quality and
  Respiratory Illness</dc:title>
 <dc:creator>Lai, Yuan</dc:creator>
 <dc:creator>Kontokosta, Constantine E.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  New streams of data enable us to associate physical objects with rich
multi-dimensional data on the urban environment. This study presents how open
data integration can contribute to deeper insights into urban ecology. We
analyze street trees in New York City (NYC) with cross-domain data integration
methods by combining crowd-sourced tree census data - which includes
geolocation, species, size, and condition of each street tree - with pollen
activity and allergen severity, neighborhood demographics, and spatial-temporal
data on tree condition from NYC 311 complaints. We further integrate historical
data on neighborhood asthma hospitalization rates by Zip Code and in-situ air
quality monitoring data (PM 2.5) to investigate how street trees impact local
air quality and the prevalence of respiratory illnesses. The results indicate
although the number of trees contributes to better air quality, species with
severe allergens may increase local asthma hospitalization rates in vulnerable
populations.
</dc:description>
 <dc:description>Comment: Presented at the Data For Good Exchange 2017</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11047</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hiding in plain sight: insights about health-care trends gained through
  open health data</dc:title>
 <dc:creator>Rao, A. Ravishankar</dc:creator>
 <dc:creator>Clarke, Daniel</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The open data movement constitutes an approach to achieving accountability
for government organizations, and is aligned with one of the sustainable
development goals outlined by the United Nations. In the area of health care,
government agencies at the Federal and State levels have released open health
data consisting of de-identified patient outcomes, costs and ratings. We have
applied big data analytics to understand patterns and trends in open health
data. We envision the use of this data by concerned citizens to understand both
national and local trends in health expenditures. We have built an open-source
tool, BOAT (Big Data Open Source Analytics Tool,
https://github.com/fdudatamining) to facilitate analytical exploration of open
health data sets. We used BOAT to analyze data from the New York Statewide
Planning and Research Cooperative System and determined that there has been a
significant increase (40 percent) in the incidences of mental health issues
amongst adolescents from 2009-2014. Using BOAT we analyzed costs for hip
replacement surgery for 168,676 patients is in New York State, and showed that
88% of these patients had surgery costs of less than \$30,000. This figure
provides a basis to understand the decision by The California Public Employees'
Retirement System to cap hip replacement reimbursements at $30,000, resulting
in significant savings. Our tool could enable researchers, hospitals, insurers
and citizens to obtain an unbiased view on health-care expenditures, costs and
emerging trends. Our tool is especially valuable in the current economic
environment, where a significant amount of reporting is controlled by special
interests groups and lobbies.
</dc:description>
 <dc:description>Comment: Presented at the Data For Good Exchange 2017</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11047</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11048</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Demographics in Social Media Data for Public Health Research: Does it
  matter?</dc:title>
 <dc:creator>Cesare, Nina</dc:creator>
 <dc:creator>Grant, Christan</dc:creator>
 <dc:creator>Hawkins, Jared B.</dc:creator>
 <dc:creator>Brownstein, John S.</dc:creator>
 <dc:creator>Nsoesie, Elaine O.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Social media data provides propitious opportunities for public health
research. However, studies suggest that disparities may exist in the
representation of certain populations (e.g., people of lower socioeconomic
status). To quantify and address these disparities in population
representation, we need demographic information, which is usually missing from
most social media platforms. Here, we propose an ensemble approach for
inferring demographics from social media data.
  Several methods have been proposed for inferring demographic attributes such
as, age, gender and race/ethnicity. However, most of these methods require
large volumes of data, which makes their application to large scale studies
challenging. We develop a scalable approach that relies only on user names to
predict gender. We develop three separate classifiers trained on data
containing the gender labels of 7,953 Twitter users from Kaggle.com. Next, we
combine predictions from the individual classifiers using a stacked
generalization technique and apply the ensemble classifier to a dataset of
36,085 geotagged foodborne illness related tweets from the United States.
  Our ensemble approach achieves an accuracy, precision, recall, and F1 score
of 0.828, 0.851, 0.852 and 0.837, respectively, higher than the individual
machine learning approaches. The ensemble classifier also covers any user with
an alphanumeric name, while the data matching approach, which achieves an
accuracy of 0.917, only covers 67% of users. Application of our method to
reports of foodborne illness in the United States highlights disparities in
tweeting by gender and shows that counties with a high volume of
foodborne-illness related tweets are heavily overrepresented by female Twitter
users.
</dc:description>
 <dc:description>Comment: Presented at the Data For Good Exchange 2017</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11048</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11052</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Connection between Feed-Forward Neural Networks and Probabilistic
  Graphical Models</dc:title>
 <dc:creator>Schlesinger, Dmitrij</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Two of the most popular modelling paradigms in computer vision are
feed-forward neural networks (FFNs) and probabilistic graphical models (GMs).
Various connections between the two have been studied in recent works, such as
e.g. expressing mean-field based inference in a GM as an FFN. This paper
establishes a new connection between FFNs and GMs. Our key observation is that
any FFN implements a certain approximation of a corresponding Bayesian network
(BN). We characterize various benefits of having this connection. In
particular, it results in a new learning algorithm for BNs. We validate the
proposed methods for a classification problem on CIFAR-10 dataset and for
binary image segmentation on Weizmann Horse dataset. We show that statistically
learned BNs improve performance, having at the same time essentially better
generalization capability, than their FFN counterparts.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11054</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Code Repair using Neuro-Symbolic Transformation Networks</dc:title>
 <dc:creator>Devlin, Jacob</dc:creator>
 <dc:creator>Uesato, Jonathan</dc:creator>
 <dc:creator>Singh, Rishabh</dc:creator>
 <dc:creator>Kohli, Pushmeet</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  We study the problem of semantic code repair, which can be broadly defined as
automatically fixing non-syntactic bugs in source code. The majority of past
work in semantic code repair assumed access to unit tests against which
candidate repairs could be validated. In contrast, the goal here is to develop
a strong statistical model to accurately predict both bug locations and exact
fixes without access to information about the intended correct behavior of the
program. Achieving such a goal requires a robust contextual repair model, which
we train on a large corpus of real-world source code that has been augmented
with synthetically injected bugs. Our framework adopts a two-stage approach
where first a large set of repair candidates are generated by rule-based
processors, and then these candidates are scored by a statistical model using a
novel neural network architecture which we refer to as Share, Specialize, and
Compete. Specifically, the architecture (1) generates a shared encoding of the
source code using an RNN over the abstract syntax tree, (2) scores each
candidate repair using specialized network modules, and (3) then normalizes
these scores together so they can compete against one another in comparable
probability space. We evaluate our model on a real-world test set gathered from
GitHub containing four common categories of bugs. Our model is able to predict
the exact correct repair 41\% of the time with a single guess, compared to 13\%
accuracy for an attentional sequence-to-sequence model.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11054</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11057</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Techreport: Time-sensitive probabilistic inference for the edge</dc:title>
 <dc:creator>Weilbach, Christian</dc:creator>
 <dc:creator>Bieniusa, Annette</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In recent years the two trends of edge computing and artificial intelligence
became both crucial for information processing infrastructures. While the
centralized analysis of massive amounts of data seems to be at odds with
computation on the outer edge of distributed systems, we explore the properties
of eventually consistent systems and statistics to identify sound formalisms
for probabilistic inference on the edge. In particular we treat time itself as
a random variable that we incorporate into statistical models through
probabilistic programming.
</dc:description>
 <dc:description>Comment: 11 pages, techreport from research in the Lightkone H2020 Project for
  edge computing</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11057</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11063</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Grad-CAM++: Generalized Gradient-based Visual Explanations for Deep
  Convolutional Networks</dc:title>
 <dc:creator>Chattopadhyay, Aditya</dc:creator>
 <dc:creator>Sarkar, Anirban</dc:creator>
 <dc:creator>Howlader, Prantik</dc:creator>
 <dc:creator>Balasubramanian, Vineeth N</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Over the last decade, Convolutional Neural Network (CNN) models have been
highly successful in solving complex vision based problems. However, deep
models are perceived as &quot;black box&quot; methods considering the lack of
understanding of their internal functioning. There has been a significant
recent interest to develop explainable deep learning models, and this paper is
an effort in this direction. Building on a recently proposed method called
Grad-CAM, we propose Grad-CAM++ to provide better visual explanations of CNN
model predictions (when compared to Grad-CAM), in terms of better localization
of objects as well as explaining occurrences of multiple objects of a class in
a single image. We provide a mathematical explanation for the proposed method,
Grad-CAM++, which uses a weighted combination of the positive partial
derivatives of the last convolutional layer feature maps with respect to a
specific class score as weights to generate a visual explanation for the class
label under consideration. Our extensive experiments and evaluations, both
subjective and objective, on standard datasets showed that Grad-CAM++ indeed
provides better visual explanations for a given CNN architecture when compared
to Grad-CAM.
</dc:description>
 <dc:description>Comment: 14 Pages, 8 Figures, 8 Tables. To be presented at IEEE Winter Conf.
  on Applications of Computer Vision (WACV2018)</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11063</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11064</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotic degree distributions in large homogeneous random networks: A
  little theory and a counterexample</dc:title>
 <dc:creator>Pal, Siddharth</dc:creator>
 <dc:creator>Makowski, Armand M.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  In random graph models, the degree distribution of an {\em individual} node
should be distinguished from the (empirical) degree distribution of the {\em
graph} that records the fractions of nodes with given degree. We introduce a
general framework to explore when these two degree distributions coincide
asymptotically in large homogeneous random networks. The discussion is carried
under three basic statistical assumptions on the degree sequences: (i) a weak
form of distributional homogeneity; (ii) the existence of an asymptotic (nodal)
degree distribution; and (iii) a weak form of asymptotic uncorrelatedness. We
show that this asymptotic equality may fail in homogeneous random networks for
which (i) and (ii) hold but (iii) does not. The counterexample is found in the
class of random threshold graphs. An implication of this finding is that random
threshold graphs cannot be used as a substitute to the Barab\'asi-Albert model
for scale-free network modeling, as has been proposed by some authors.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11064</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11070</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence Rates of Latent Topic Models Under Relaxed Identifiability
  Conditions</dc:title>
 <dc:creator>Wang, Yining</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper we study the frequentist convergence rate for the Latent
Dirichlet Allocation (Blei et al., 2003) topic models. We show that the maximum
likelihood estimator converges to one of the finitely many equivalent
parameters in Wasserstein's distance metric at a rate of $n^{-1/4}$ without
assuming separability or non-degeneracy of the underlying topics and/or the
existence of more than three words per document, thus generalizing the previous
works of Anandkumar et al. (2012, 2014) from an information-theoretical
perspective. We also show that the $n^{-1/4}$ convergence rate is optimal in
the worst case.
</dc:description>
 <dc:description>Comment: 17 pages</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11075</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continuous Authentication Using One-class Classifiers and their Fusion</dc:title>
 <dc:creator>Kumar, Rajesh</dc:creator>
 <dc:creator>Kundu, Partha Pratim</dc:creator>
 <dc:creator>Phoha, Vir V.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>K.6.5</dc:subject>
 <dc:description>  While developing continuous authentication systems (CAS), we generally assume
that samples from both genuine and impostor classes are readily available.
However, the assumption may not be true in certain circumstances. Therefore, we
explore the possibility of implementing CAS using only genuine samples.
Specifically, we investigate the usefulness of four one-class classifiers OCC
(elliptic envelope, isolation forest, local outliers factor, and one-class
support vector machines) and their fusion. The performance of these classifiers
was evaluated on four distinct behavioral biometric datasets, and compared with
eight multi-class classifiers (MCC). The results demonstrate that if we have
sufficient training data from the genuine user the OCC, and their fusion can
closely match the performance of the majority of MCC. Our findings encourage
the research community to use OCC in order to build CAS as they do not require
knowledge of impostor class during the enrollment process.
</dc:description>
 <dc:description>Comment: 2018 IEEE 4th International Conference on Identity, Security, and
  Behavior Analysis (ISBA) 978-1-5386-2248-3/18/$31.00 (c) 2018 IEEE</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11075</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11078</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Virtual Differential Passivity based Control for Tracking of
  Flexible-joints Robots</dc:title>
 <dc:creator>Reyes-B&#xe1;ez, Rodlfo</dc:creator>
 <dc:creator>van der Schaft, Arjan</dc:creator>
 <dc:creator>Jayawardhana, Bayu</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Based on recent advances in contraction methods in systems and control, in
this paper we present the virtual differential passivity based control (v-dPBC)
technique. This is a constructive design method that combines the concept of
virtual systems and of differential passivity. We apply the method to the
tracking control problem of flexible joints robots (FJRs) which are formulated
in the port-Hamiltonian (pH) framework. Simulations on a single flexible joint
link are presented for showing the performance of a controller obtained with
this approach.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures, submitted to Workshop on Lagrangian and
  Hamiltonian Methods in Nonlinear Control 2018</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11080</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A mathematical bridge between discretized gauge theories in quantum
  physics and approximate reasoning in pairwise comparisons</dc:title>
 <dc:creator>Magnot, Jean-Pierre</dc:creator>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Differential Geometry</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>03F25, 70S15, 81T13</dc:subject>
 <dc:description>  We describe a mathematical link between aspects of information theory, called
pairwise comparisons, and discretized gauge theories. The link is made by the
notion of holonomy along the edges of a simplex. This correspondance leads to
open questions in both field.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11080</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11087</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Integrated Approach to Crowd Video Analysis: From Tracking to
  Multi-level Activity Recognition</dc:title>
 <dc:creator>Bhargava, Neha</dc:creator>
 <dc:creator>Chaudhuri, Subhasis</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present an integrated framework for simultaneous tracking, group detection
and multi-level activity recognition in crowd videos. Instead of solving these
problems independently and sequentially, we solve them together in a unified
framework to utilize the strong correlation that exists among individual
motion, groups, and activities. We explore the hierarchical structure hidden in
the video that connects individuals over time to produce tracks, connects
individuals to form groups and also connects groups together to form a crowd.
We show that estimation of this hidden structure corresponds to track
association and group detection. We estimate this hidden structure under a
linear programming formulation. The obtained graphical representation is
further explored to recognize the node values that corresponds to multi-level
activity recognition. This problem is solved under a structured SVM framework.
The results on publicly available dataset show very competitive performance at
all levels of granularity with the state-of-the-art batch processing methods
despite the proposed technique being an online (causal) one.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11087</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11088</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Cooperative Manipulation without Force/Torque Measurements:
  Control Design and Experiments</dc:title>
 <dc:creator>Verginis, Christos K.</dc:creator>
 <dc:creator>Mastellaro, Matteo</dc:creator>
 <dc:creator>Dimarogonas, Dimos V.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents two novel control methodologies for the cooperative
manipulation of an object by N robotic agents. Firstly, we design an adaptive
control protocol which employs quaternion feedback for the object orientation
to avoid potential representation singularities. Secondly, we propose a control
protocol that guarantees predefined transient and steady-state performance for
the object trajectory. Both methodologies are decentralized, since the agents
calculate their own signals without communicating with each other, as well as
robust to external disturbances and model uncertainties. Moreover, we consider
that the grasping points are rigid, and avoid the need for force/torque
measurements. Load sharing coefficients are also introduced to account for
potential differences in the agents' power capabilities. Finally, simulation
and experimental results with two robotic arms verify the theoretical findings.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transaction on Robotics</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11088</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11089</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Eigenoption Discovery through the Deep Successor Representation</dc:title>
 <dc:creator>Machado, Marlos C.</dc:creator>
 <dc:creator>Rosenbaum, Clemens</dc:creator>
 <dc:creator>Guo, Xiaoxiao</dc:creator>
 <dc:creator>Liu, Miao</dc:creator>
 <dc:creator>Tesauro, Gerald</dc:creator>
 <dc:creator>Campbell, Murray</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Options in reinforcement learning allow agents to hierarchically decompose a
task into subtasks, having the potential to speed up learning and planning.
However, autonomously learning effective sets of options is still a major
challenge in the field. In this paper we focus on the recently introduced idea
of using representation learning methods to guide the option discovery process.
Specifically, we look at eigenoptions, options obtained from representations
that encode diffusive information flow in the environment. We extend the
existing algorithms for eigenoption discovery to settings with stochastic
transitions and in which handcrafted features are not available. We propose an
algorithm that discovers eigenoptions while learning non-linear state
representations from raw pixels. It exploits recent successes in the deep
reinforcement learning literature and the equivalence between proto-value
functions and the successor representation. We use traditional tabular domains
to provide intuition about our approach and Atari 2600 games to demonstrate its
potential.
</dc:description>
 <dc:description>Comment: Under review as a conference paper at ICLR 2018</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11089</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11090</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prediction of Satisfied User Ratio for Compressed Video</dc:title>
 <dc:creator>Wang, Haiqiang</dc:creator>
 <dc:creator>Katsavounidis, Ioannis</dc:creator>
 <dc:creator>Huang, Qin</dc:creator>
 <dc:creator>Zhou, Xin</dc:creator>
 <dc:creator>Kuo, C. -C. Jay</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  A large-scale video quality dataset called the VideoSet has been constructed
recently to measure human subjective experience of H.264 coded video in terms
of the just-noticeable-difference (JND). It measures the first three JND points
of 5-second video of resolution 1080p, 720p, 540p and 360p. Based on the
VideoSet, we propose a method to predict the satisfied-user-ratio (SUR) curves
using a machine learning framework. First, we partition a video clip into local
spatial-temporal segments and evaluate the quality of each segment using the
VMAF quality index. Then, we aggregate these local VMAF measures to derive a
global one. Finally, the masking effect is incorporated and the support vector
regression (SVR) is used to predict the SUR curves, from which the JND points
can be derived. Experimental results are given to demonstrate the performance
of the proposed SUR prediction method.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11090</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11093</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Infinite dimensional compressed sensing from anisotropic measurements
  and applications to inverse problems in PDE</dc:title>
 <dc:creator>Alberti, Giovanni S.</dc:creator>
 <dc:creator>Santacesaria, Matteo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:description>  We consider a compressed sensing problem in which both the measurement and
the sparsifying systems are assumed to be frames (not necessarily tight) of the
underlying Hilbert space of signals, which may be finite or infinite
dimensional. The main result gives explicit bounds on the number of
measurements in order to achieve stable recovery, which depends on the mutual
coherence of the two systems. As a simple corollary, we prove the efficiency of
nonuniform sampling strategies in cases when the two systems are not
incoherent, but only asymptotically incoherent, as with the recovery of wavelet
coefficients from Fourier samples. This general framework finds applications to
inverse problems in partial differential equations, where the standard
assumptions of compressed sensing are often not satisfied. Several examples are
discussed, with a special focus on electrical impedance tomography.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11093</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11097</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stable Prehensile Pushing: In-Hand Manipulation with Alternating
  Sticking Contacts</dc:title>
 <dc:creator>Chavan-Dafle, Nikhil</dc:creator>
 <dc:creator>Rodriguez, Alberto</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents an approach to in-hand manipulation planning that
exploits the mechanics of alternating sticking contact. Particularly, we
consider the problem of manipulating a grasped object using external pushes for
which the pusher sticks to the object. Given the physical properties of the
object, frictional coefficients at contacts and a desired regrasp on the
object, we propose a sampling-based planning framework that builds a pushing
strategy concatenating different feasible stable pushes to achieve the desired
regrasp. An efficient dynamics formulation for stable prehensile pushing allows
us to plan in-hand manipulations 100-1000 times faster than our previous work
which builds upon a complementarity formulation. Experimental observations for
the generated plans show very close correspondence to the expected results from
the planner.
  Video Summary -- youtu.be/qOTKRJMx6Ho
</dc:description>
 <dc:description>Comment: IEEE International Conference on Robotics and Automation 2018 (in
  review)</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11097</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11098</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Capacity of Private Computation</dc:title>
 <dc:creator>Sun, Hua</dc:creator>
 <dc:creator>Jafar, Syed A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We introduce the problem of private computation, comprised of $N$ distributed
and non-colluding servers, $K$ independent datasets, and a user who wants to
compute a function of the datasets privately, i.e., without revealing which
function he wants to compute, to any individual server. This private
computation problem is a strict generalization of the private information
retrieval (PIR) problem, obtained by expanding the PIR message set (which
consists of only independent messages) to also include functions of those
messages. The capacity of private computation, $C$, is defined as the maximum
number of bits of the desired function that can be retrieved per bit of total
download from all servers. We characterize the capacity of private computation,
for $N$ servers and $K$ independent datasets that are replicated at each
server, when the functions to be computed are arbitrary linear combinations of
the datasets. Surprisingly, the capacity,
$C=\left(1+1/N+\cdots+1/N^{K-1}\right)^{-1}$, matches the capacity of PIR with
$N$ servers and $K$ messages. Thus, allowing arbitrary linear computations does
not reduce the communication rate compared to pure dataset retrieval. The same
insight is shown to hold even for arbitrary non-linear computations when the
number of datasets $K\rightarrow\infty$.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11098</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11118</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Customized Routing Optimization Based on Gradient Boost Regressor Model</dc:title>
 <dc:creator>Zheng, Chen</dc:creator>
 <dc:creator>Kasprowicz, Clara Grzegorz</dc:creator>
 <dc:creator>Saunders, Carol</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we discussed limitation of current
electronic-design-automoation (EDA) tool and proposed a machine learning
framework to overcome the limitations and achieve better design quality. We
explored how to efficiently extract relevant features and leverage gradient
boost regressor (GBR) model to predict underestimated risky net (URN).
Customized routing optimizations are applied to the URNs and results show clear
timing improvement and trend to converge toward timing closure.
</dc:description>
 <dc:description>Comment: 6 pages, 7 tables, 3 figures</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11118</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11121</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Tumor Segmentation and Brain Mapping for the Tumor Area</dc:title>
 <dc:creator>Manocha, Pranay</dc:creator>
 <dc:creator>Bhasme, Snehal</dc:creator>
 <dc:creator>Gupta, Tanvi</dc:creator>
 <dc:creator>Panigrahi, BK</dc:creator>
 <dc:creator>Gandhi, Tapan K.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Magnetic Resonance Imaging (MRI) is an important diagnostic tool for precise
detection of various pathologies. Magnetic Resonance (MR) is more preferred
than Computed Tomography (CT) due to the high resolution in MR images which
help in better detection of neurological conditions. Graphical user interface
(GUI) aided disease detection has become increasingly useful due to the
increasing workload of doctors. In this proposed work, a novel two steps GUI
technique for brain tumor segmentation as well as Brodmann area detec-tion of
the segmented tumor is proposed. A data set of T2 weighted images of 15
patients is used for validating the proposed method. The patient data
incor-porates variations in ethnicities, gender (male and female) and age
(25-50), thus enhancing the authenticity of the proposed method. The tumors
were segmented using Fuzzy C Means Clustering and Brodmann area detection was
done using a known template, mapping each area to the segmented tumor image.
The proposed method was found to be fairly accurate and robust in detecting
tumor.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11122</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Floor-Level for 911 Calls with Neural Networks and Smartphone
  Sensor Data</dc:title>
 <dc:creator>Falcon, William</dc:creator>
 <dc:creator>Schulzrinne, Henning</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In cities with tall buildings, emergency responders need an accurate floor
level location to find 911 callers quickly. We introduce a system to estimate a
victim's floor level via their mobile device's sensor data in a two-step
process. First, we train a neural network to determine when a smartphone enters
or exits a building via GPS signal changes. Second, we use a barometer equipped
smartphone to measure the change in barometric pressure from the entrance of
the building to the victim's indoor location. Unlike impractical previous
approaches, our system is the first that does not require the use of beacons,
prior knowledge of the building infrastructure, or knowledge of user behavior.
We demonstrate real-world feasibility through 63 experiments across five
different tall buildings throughout New York City where our system predicted
the correct floor level with 100% accuracy.
</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:date>2018-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11151</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High efficiency compression for object detection</dc:title>
 <dc:creator>Choi, Hyomin</dc:creator>
 <dc:creator>Bajic, Ivan V.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image and video compression has traditionally been tailored to human vision.
However, modern applications such as visual analytics and surveillance rely on
computers seeing and analyzing the images before (or instead of) humans. For
these applications, it is important to adjust compression to computer vision.
In this paper we present a bit allocation and rate control strategy that is
tailored to object detection. Using the initial convolutional layers of a
state-of-the-art object detector, we create an importance map that can guide
bit allocation to areas that are important for object detection. The proposed
method enables bit rate savings of 7% or more compared to default HEVC, at the
equivalent object detection rate.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11153</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Onsets and Frames: Dual-Objective Piano Transcription</dc:title>
 <dc:creator>Hawthorne, Curtis</dc:creator>
 <dc:creator>Elsen, Erich</dc:creator>
 <dc:creator>Song, Jialin</dc:creator>
 <dc:creator>Roberts, Adam</dc:creator>
 <dc:creator>Simon, Ian</dc:creator>
 <dc:creator>Raffel, Colin</dc:creator>
 <dc:creator>Engel, Jesse</dc:creator>
 <dc:creator>Oore, Sageev</dc:creator>
 <dc:creator>Eck, Douglas</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of transcribing polyphonic piano music with an
emphasis on generalizing to unseen instruments. We use deep neural networks and
propose a novel approach that predicts onsets and frames using both CNNs and
LSTMs. This model predicts pitch onset events and then uses those predictions
to condition framewise pitch predictions. During inference, we restrict the
predictions from the framewise detector by not allowing a new note to start
unless the onset detector also agrees that an onset for that pitch is present
in the frame. We focus on improving onsets and offsets together instead of
either in isolation as we believe it correlates better with human musical
perception. This technique results in over a 100% relative improvement in note
with offset score on the MAPS dataset.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11153</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11154</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Creation of an Annotated Corpus of Spanish Radiology Reports</dc:title>
 <dc:creator>Cotik, Viviana</dc:creator>
 <dc:creator>Filippo, Dar&#xed;o</dc:creator>
 <dc:creator>Roller, Roland</dc:creator>
 <dc:creator>Uszkoreit, Hans</dc:creator>
 <dc:creator>Xu, Feiyu</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper presents a new annotated corpus of 513 anonymized radiology
reports written in Spanish. Reports were manually annotated with entities,
negation and uncertainty terms and relations. The corpus was conceived as an
evaluation resource for named entity recognition and relation extraction
algorithms, and as input for the use of supervised methods. Biomedical
annotated resources are scarce due to confidentiality issues and associated
costs. This work provides some guidelines that could help other researchers to
undertake similar tasks.
</dc:description>
 <dc:description>Comment: WiNLP Workshop ACL</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11154</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11160</identifier>
 <datestamp>2017-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Super-polynomial and exponential improvements for quantum-enhanced
  reinforcement learning</dc:title>
 <dc:creator>Dunjko, Vedran</dc:creator>
 <dc:creator>Liu, Yi-Kai</dc:creator>
 <dc:creator>Wu, Xingyao</dc:creator>
 <dc:creator>Taylor, Jacob M.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Recent work on quantum machine learning has demonstrated that quantum
computers can offer dramatic improvements over classical devices for data
mining, prediction and classification. However, less is known about the
advantages using quantum computers may bring in the more general setting of
reinforcement learning, where learning is achieved via interaction with a task
environment that provides occasional rewards. Reinforcement learning can
incorporate data-analysis-oriented learning settings as special cases, but also
includes more complex situations where, e.g., reinforcing feedback is delayed.
In a few recent works, Grover-type amplification has been utilized to construct
quantum agents that achieve up-to-quadratic improvements in learning
efficiency. These encouraging results have left open the key question of
whether super-polynomial improvements in learning times are possible for
genuine reinforcement learning problems, that is problems that go beyond the
other more restricted learning paradigms. In this work, we provide a family of
such genuine reinforcement learning tasks. We construct quantum-enhanced
learners which learn super-polynomially, and even exponentially faster than any
classical reinforcement learning model, and we discuss the potential impact our
results may have on future technologies.
</dc:description>
 <dc:description>Comment: 21 pages, 6 figures</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11160</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11169</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Indirect Supervision for Relation Extraction using Question-Answer Pairs</dc:title>
 <dc:creator>Wu, Zeqiu</dc:creator>
 <dc:creator>Ren, Xiang</dc:creator>
 <dc:creator>Xu, Frank F.</dc:creator>
 <dc:creator>Li, Ji</dc:creator>
 <dc:creator>Han, Jiawei</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Automatic relation extraction (RE) for types of interest is of great
importance for interpreting massive text corpora in an efficient manner.
Traditional RE models have heavily relied on human-annotated corpus for
training, which can be costly in generating labeled data and become obstacles
when dealing with more relation types. Thus, more RE extraction systems have
shifted to be built upon training data automatically acquired by linking to
knowledge bases (distant supervision). However, due to the incompleteness of
knowledge bases and the context-agnostic labeling, the training data collected
via distant supervision (DS) can be very noisy. In recent years, as increasing
attention has been brought to tackling question-answering (QA) tasks, user
feedback or datasets of such tasks become more accessible. In this paper, we
propose a novel framework, ReQuest, to leverage question-answer pairs as an
indirect source of supervision for relation extraction, and study how to use
such supervision to reduce noise induced from DS. Our model jointly embeds
relation mentions, types, QA entity mention pairs and text features in two
low-dimensional spaces (RE and QA), where objects with same relation types or
semantically similar question-answer pairs have similar representations. Shared
features connect these two spaces, carrying clearer semantic knowledge from
both sources. ReQuest, then use these learned embeddings to estimate the types
of test relation mentions. We formulate a global objective function and adopt a
novel margin-based QA loss to reduce noise in DS by exploiting semantic
evidence from the QA dataset. Our experimental results achieve an average of
11% improvement in F1 score on two public RE datasets combined with TREC QA
dataset.
</dc:description>
 <dc:description>Comment: 9 pages + 1 page reference. Accepted to WSDM 2018</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11176</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CrescendoNet: A Simple Deep Convolutional Neural Network with Ensemble
  Behavior</dc:title>
 <dc:creator>Zhang, Xiang</dc:creator>
 <dc:creator>Vishwamitra, Nishant</dc:creator>
 <dc:creator>Hu, Hongxin</dc:creator>
 <dc:creator>Luo, Feng</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We introduce a new deep convolutional neural network, CrescendoNet, by
stacking simple building blocks without residual connections. Each Crescendo
block contains independent convolution paths with increased depths. The numbers
of convolution layers and parameters are only increased linearly in Crescendo
blocks. In experiments, CrescendoNet with only 15 layers outperforms almost all
networks without residual connections on benchmark datasets, CIFAR10, CIFAR100,
and SVHN. Given sufficient amount of data as in SVHN dataset, CrescendoNet with
15 layers and 4.1M parameters can match the performance of DenseNet-BC with 250
layers and 15.3M parameters. CrescendoNet provides a new way to construct high
performance deep convolutional neural networks without residual connections.
Moreover, through investigating the behavior and performance of subnetworks in
CrescendoNet, we note that the high performance of CrescendoNet may come from
its implicit ensemble behavior, which differs from the FractalNet that is also
a deep convolutional neural network without residual connections. Furthermore,
the independence between paths in CrescendoNet allows us to introduce a new
path-wise training procedure, which can reduce the memory needed for training.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2018-01-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11176</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11185</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Measurement Policy for Predicting UAV Network Topology</dc:title>
 <dc:creator>Razi, Abolfazl</dc:creator>
 <dc:creator>Afghah, Fatemeh</dc:creator>
 <dc:creator>Chakareski, Jacob</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In recent years, there has been a growing interest in using networks of
Unmanned Aerial Vehicles (UAV) that collectively perform complex tasks for
diverse applications. An important challenge in realizing UAV networks is the
need for a communication platform that accommodates rapid network topology
changes. For instance, a timely prediction of network topology changes can
reduce communication link loss rate by setting up links with prolonged
connectivity.
  In this work, we develop an optimal tracking policy for each UAV to perceive
its surrounding network configuration in order to facilitate more efficient
communication protocols. More specifically, we develop an algorithm based on
particle swarm optimization and Kalman filtering with intermittent observations
to find a set of optimal tracking policies for each UAV under time-varying
channel qualities and constrained tracking resources such that the overall
network estimation error is minimized.
</dc:description>
 <dc:description>Comment: 5 pages, 5 figures, To appear in Asilomar Conference on Signals,
  Systems, and Computers</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11185</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11190</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Manipulation Planning to Keep an Object Stable under a Sequence of
  External Forces</dc:title>
 <dc:creator>Chen, Lipeng</dc:creator>
 <dc:creator>Dogar, Mehmet</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We present a planner for a robot to keep an object stable under a sequence of
external forces. We assume a robot with multiple manipulators, with a gripper
at the end of each manipulator. We make two key contributions: First, given an
external force, we propose a method to check the feasibility of gripper
placements on the object to resist the force. This method takes into account
both the manipulator joint torque limits and the force/torque limits of the
grippers-object system. Second, given a sequence of external forces, we propose
a planner that generates a sequence of gripper placements and manipulator
configurations, along with the motion to move between these configurations. The
planner minimizes the number of different gripper placements required to resist
the forces, resulting in efficient planning and execution. We perform
experiments to verify the predictions of our feasibility checking method and to
measure the performance of our planner.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11190</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11194</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to be Helpful? Implementing Supportive Behaviors for Human-Robot
  Collaboration</dc:title>
 <dc:creator>Mangin, Olivier</dc:creator>
 <dc:creator>Roncone, Alessandro</dc:creator>
 <dc:creator>Scassellati, Brian</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The field of Human-Robot Collaboration (HRC) has seen a considerable amount
of progress in the recent years. Although genuinely collaborative platforms are
far from being deployed in real-world scenarios, advances in control and
perception algorithms have progressively popularized robots in manufacturing
settings, where they work side by side with human peers to achieve shared
tasks. Unfortunately, little progress has been made toward the development of
systems that are proactive in their collaboration, and autonomously take care
of some of the chores that compose most of the collaboration tasks. In this
work, we present a collaborative system capable of assisting the human partner
with a variety of supportive behaviors in spite of its limited perceptual and
manipulation capabilities and incomplete model of the task. Our framework
leverages information from a high-level, hierarchical model of the task. The
model, that is shared between the human and robot, enables transparent
synchronization between the peers and understanding of each other's plan. More
precisely, we derive a partially observable Markov model from the high-level
task representation. We then use an online solver to compute a robot policy,
that is robust to unexpected observations such as inaccuracies of perception,
failures in object manipulations, as well as discovers hidden user preferences.
We demonstrate that the system is capable of robustly providing support to the
human in a furniture construction task.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11194</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11198</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sample-efficient Policy Optimization with Stein Control Variate</dc:title>
 <dc:creator>Liu, Hao</dc:creator>
 <dc:creator>Feng, Yihao</dc:creator>
 <dc:creator>Mao, Yi</dc:creator>
 <dc:creator>Zhou, Dengyong</dc:creator>
 <dc:creator>Peng, Jian</dc:creator>
 <dc:creator>Liu, Qiang</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Policy gradient methods have achieved remarkable successes in solving
challenging reinforcement learning problems. However, it still often suffers
from the large variance issue on policy gradient estimation, which leads to
poor sample efficiency during training. In this work, we propose a control
variate method to effectively reduce variance for policy gradient methods.
Motivated by the Stein's identity, our method extends the previous control
variate methods used in REINFORCE and advantage actor-critic by introducing
more general action-dependent baseline functions. Empirical studies show that
our method significantly improves the sample efficiency of the state-of-the-art
policy gradient approaches.
</dc:description>
 <dc:description>Comment: The first two authors contributed equally. Author ordering determined
  by coin flip over a Google Hangout</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11200</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>VLSI Computational Architectures for the Arithmetic Cosine Transform</dc:title>
 <dc:creator>Rajapaksha, N.</dc:creator>
 <dc:creator>Madanayake, A.</dc:creator>
 <dc:creator>Cintra, R. J.</dc:creator>
 <dc:creator>Adikari, J.</dc:creator>
 <dc:creator>Dimitrov, V. S.</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  The discrete cosine transform (DCT) is a widely-used and important signal
processing tool employed in a plethora of applications. Typical fast algorithms
for nearly-exact computation of DCT require floating point arithmetic, are
multiplier intensive, and accumulate round-off errors. Recently proposed fast
algorithm arithmetic cosine transform (ACT) calculates the DCT exactly using
only additions and integer constant multiplications, with very low area
complexity, for null mean input sequences. The ACT can also be computed
non-exactly for any input sequence, with low area complexity and low power
consumption, utilizing the novel architecture described. However, as a
trade-off, the ACT algorithm requires 10 non-uniformly sampled data points to
calculate the 8-point DCT. This requirement can easily be satisfied for
applications dealing with spatial signals such as image sensors and biomedical
sensor arrays, by placing sensor elements in a non-uniform grid. In this work,
a hardware architecture for the computation of the null mean ACT is proposed,
followed by a novel architectures that extend the ACT for non-null mean
signals. All circuits are physically implemented and tested using the Xilinx
XC6VLX240T FPGA device and synthesized for 45 nm TSMC standard-cell library for
performance assessment.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures, 6 tables</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11200</dc:identifier>
 <dc:identifier>IEEE Transactions on Computers, vol. 64, no. 9, Sep 2015</dc:identifier>
 <dc:identifier>doi:10.1109/TC.2014.2366732</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11201</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep word embeddings for visual speech recognition</dc:title>
 <dc:creator>Stafylakis, Themos</dc:creator>
 <dc:creator>Tzimiropoulos, Georgios</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we present a deep learning architecture for extracting word
embeddings for visual speech recognition. The embeddings summarize the
information of the mouth region that is relevant to the problem of word
recognition, while suppressing other types of variability such as speaker, pose
and illumination. The system is comprised of a spatiotemporal convolutional
layer, a Residual Network and bidirectional LSTMs and is trained on the
Lipreading in-the-wild database. We first show that the proposed architecture
goes beyond state-of-the-art on closed-set word identification, by attaining
11.92% error rate on a vocabulary of 500 words. We then examine the capacity of
the embeddings in modelling words unseen during training. We deploy
Probabilistic Linear Discriminant Analysis (PLDA) to model the embeddings and
perform low-shot learning experiments on words unseen during training. The
experiments demonstrate that word-level visual speech recognition is feasible
even in cases where the target words are not included in the training set.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11201</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11204</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improve SAT-solving with Machine Learning</dc:title>
 <dc:creator>Wu, Haoze</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In this project, we aimed to improve the runtime of Minisat, a
Conflict-Driven Clause Learning (CDCL) solver that solves the Propositional
Boolean Satisfiability (SAT) problem. We first used a logistic regression model
to predict the satisfiability of propositional boolean formulae after fixing
the values of a certain fraction of the variables in each formula. We then
applied the logistic model and added a preprocessing period to Minisat to
determine the preferable initial value (either true or false) of each boolean
variable using a Monte-Carlo approach. Concretely, for each Monte-Carlo trial,
we fixed the values of a certain ratio of randomly selected variables, and
calculated the confidence that the resulting sub-formula is satisfiable with
our logistic regression model. The initial value of each variable was set based
on the mean confidence scores of the trials that started from the literals of
that variable. We were particularly interested in setting the initial values of
the backbone variables correctly, which are variables that have the same value
in all solutions of a SAT formula. Our Monte-Carlo method was able to set 78%
of the backbones correctly. Excluding the preprocessing time, compared with the
default setting of Minisat, the runtime of Minisat for satisfiable formulae
decreased by 23%. However, our method did not outperform vanilla Minisat in
runtime, as the decrease in the conflicts was outweighed by the long runtime of
the preprocessing period.
</dc:description>
 <dc:description>Comment: 2 pages, SIGCSE SRC 2017</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11204</dc:identifier>
 <dc:identifier>In Proceedings of the 2017 ACM SIGCSE Technical Symposium on
  Computer Science Education (SIGCSE '17). ACM, New York, NY, USA, 787-788
  (2017)</dc:identifier>
 <dc:identifier>doi:10.1145/3017680.3022464</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11205</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Critical Points of Neural Networks: Analytical Forms and Landscape
  Properties</dc:title>
 <dc:creator>Zhou, Yi</dc:creator>
 <dc:creator>Liang, Yingbin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Due to the success of deep learning to solving a variety of challenging
machine learning tasks, there is a rising interest in understanding loss
functions for training neural networks from a theoretical aspect. Particularly,
the properties of critical points and the landscape around them are of
importance to determine the convergence performance of optimization algorithms.
In this paper, we provide full (necessary and sufficient) characterization of
the analytical forms for the critical points (as well as global minimizers) of
the square loss functions for various neural networks. We show that the
analytical forms of the critical points characterize the values of the
corresponding loss functions as well as the necessary and sufficient conditions
to achieve global minimum. Furthermore, we exploit the analytical forms of the
critical points to characterize the landscape properties for the loss functions
of these neural networks. One particular conclusion is that: The loss function
of linear networks has no spurious local minimum, while the loss function of
one-hidden-layer nonlinear networks with ReLU activation function does have
local minimum that is not global minimum.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11211</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The HRC Model Set for Human-Robot Collaboration Research</dc:title>
 <dc:creator>Zeylikman, Sofya</dc:creator>
 <dc:creator>Widder, Sarah</dc:creator>
 <dc:creator>Roncone, Alessandro</dc:creator>
 <dc:creator>Mangin, Olivier</dc:creator>
 <dc:creator>Scassellati, and Brian</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this paper, we present a model set for designing human-robot collaboration
(HRC) experiments. It targets a common scenario in HRC, which is the
collaborative assembly of furniture, and it consists of a combination of
standard components and custom designs. With this work, we aim at reducing the
amount of work required to set up and reproduce HRC experiments, and we provide
a unified framework to facilitate the comparison and integration of
contributions to the field. The model set is designed to be modular,
extendable, and easy to distribute. Importantly, it covers the majority of
relevant research in HRC, and it allows tuning of a number of experimental
variables that are particularly valuable to the field. Additionally, we provide
a set of software libraries for perception, control and interaction, with the
goal of encouraging other researchers to proactively contribute to our work.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11213</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prophet Secretary for Combinatorial Auctions and Matroids</dc:title>
 <dc:creator>Ehsani, Soheil</dc:creator>
 <dc:creator>Hajiaghayi, MohammadTaghi</dc:creator>
 <dc:creator>Kesselheim, Thomas</dc:creator>
 <dc:creator>Singla, Sahil</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The secretary and the prophet inequality problems are central to the field of
Stopping Theory. Recently, there has been a lot of work in generalizing these
models to multiple items because of their applications in mechanism design. The
most important of these generalizations are to matroids and to combinatorial
auctions (extends bipartite matching). Kleinberg-Weinberg \cite{KW-STOC12} and
Feldman et al. \cite{feldman2015combinatorial} show that for adversarial
arrival order of random variables the optimal prophet inequalities give a
$1/2$-approximation. For many settings, however, it's conceivable that the
arrival order is chosen uniformly at random, akin to the secretary problem. For
such a random arrival model, we improve upon the $1/2$-approximation and obtain
$(1-1/e)$-approximation prophet inequalities for both matroids and
combinatorial auctions. This also gives improvements to the results of Yan
\cite{yan2011mechanism} and Esfandiari et al. \cite{esfandiari2015prophet} who
worked in the special cases where we can fully control the arrival order or
when there is only a single item.
  Our techniques are threshold based. We convert our discrete problem into a
continuous setting and then give a generic template on how to dynamically
adjust these thresholds to lower bound the expected total welfare.
</dc:description>
 <dc:description>Comment: SODA 2018</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11213</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11214</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Algorithmic Confounding in Recommendation Systems Increases
  Homogeneity and Decreases Utility</dc:title>
 <dc:creator>Chaney, Allison J. B.</dc:creator>
 <dc:creator>Stewart, Brandon M.</dc:creator>
 <dc:creator>Engelhardt, Barbara E.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recommendation systems occupy an expanding role in everyday decision making,
from choice of movies and household goods to consequential medical and legal
decisions. The data used to train and test these systems is algorithmically
confounded in that it is the result of a feedback loop between human choices
and an existing algorithmic recommendation system. Using simulations, we
demonstrate that algorithmic confounding can disadvantage algorithms in
training, bias held-out evaluation, and amplify homogenization of user behavior
without gains in utility.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11214</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11216</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning and Conditional Random Fields-based Depth Estimation and
  Topographical Reconstruction from Conventional Endoscopy</dc:title>
 <dc:creator>Mahmood, Faisal</dc:creator>
 <dc:creator>Durr, Nicholas J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Colorectal cancer is the fourth leading cause of cancer deaths worldwide and
the second leading cause in the United States. The risk of colorectal cancer
can be mitigated by the identification and removal of premalignant lesions
through optical colonoscopy. Unfortunately, conventional colonoscopy misses
more than 20% of the polyps that should be removed, due in part to poor
contrast of lesion topography. Imaging tissue topography during a colonoscopy
is difficult because of the size constraints of the endoscope and the deforming
mucosa. Most existing methods make geometric assumptions or incorporate a
priori information, which limits accuracy and sensitivity. In this paper, we
present a method that avoids these restrictions, using a joint deep
convolutional neural network-conditional random field (CNN-CRF) framework.
Estimated depth is used to reconstruct the topography of the surface of the
colon from a single image. We train the unary and pairwise potential functions
of a CRF in a CNN on synthetic data, generated by developing an endoscope
camera model and rendering over 100,000 images of an anatomically-realistic
colon. We validate our approach with real endoscopy images from a porcine
colon, transferred to a synthetic-like domain, with ground truth from
registered computed tomography measurements. The CNN-CRF approach estimates
depths with a relative error of 0.152 for synthetic endoscopy images and 0.242
for real endoscopy images. We show that the estimated depth maps can be used
for reconstructing the topography of the mucosa from conventional colonoscopy
images. This approach can easily be integrated into existing endoscopy systems
and provides a foundation for improving computer-aided detection algorithms for
detection, segmentation and classification of lesions.
</dc:description>
 <dc:description>Comment: 10 pages, 10 figures</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11216</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11222</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dependability in Edge Computing</dc:title>
 <dc:creator>Wood, Paul</dc:creator>
 <dc:creator>Zhang, Heng</dc:creator>
 <dc:creator>Siddiqui, Muhammad-Bilal</dc:creator>
 <dc:creator>Bagchi, Saurabh</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Edge computing is the practice of placing computing resources at the edges of
the Internet in close proximity to devices and information sources. This, much
like a cache on a CPU, increases bandwidth and reduces latency for applications
but at a potential cost of dependability and capacity. This is because these
edge devices are often not as well maintained, dependable, powerful, or robust
as centralized server-class cloud resources. This article explores
dependability and deployment challenges in the field of edge computing, what
aspects are solvable with today's technology, and what aspects call for new
solutions.
  The first issue addressed is failures, both hard (crash, hang, etc.) and soft
(performance-related), and real-time constraint violation. In this domain, edge
computing bolsters real-time system capacity through reduced end-to-end
latency. However, much like cache misses, overloaded or malfunctioning edge
computers can drive latency beyond tolerable limits. Second, decentralized
management and device tampering can lead to chain of trust and security or
privacy violations. Authentication, access control, and distributed intrusion
detection techniques have to be extended from current cloud deployments and
need to be customized for the edge ecosystem. The third issue deals with
handling multi-tenancy in the typically resource-constrained edge devices and
the need for standardization to allow for interoperability across vendor
products.
  We explore the key challenges in each of these three broad issues as they
relate to dependability of edge computing and then hypothesize about promising
avenues of work in this area.
</dc:description>
 <dc:date>2017-10-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11222</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11223</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast and Scalable Learning of Sparse Changes in High-Dimensional
  Gaussian Graphical Model Structure</dc:title>
 <dc:creator>Wang, Beilun</dc:creator>
 <dc:creator>Sekhon, Arshdeep</dc:creator>
 <dc:creator>Qi, Yanjun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We focus on the problem of estimating the change in the dependency structures
of two $p$-dimensional Gaussian Graphical models (GGMs). Previous studies for
sparse change estimation in GGMs involve expensive and difficult non-smooth
optimization. We propose a novel method, DIFFEE for estimating DIFFerential
networks via an Elementary Estimator under a high-dimensional situation. DIFFEE
is solved through a faster and closed form solution that enables it to work in
large-scale settings. We conduct a rigorous statistical analysis showing that
surprisingly DIFFEE achieves the same asymptotic convergence rates as the
state-of-the-art estimators that are much more difficult to compute. Our
experimental results on multiple synthetic datasets and one real-world data
about brain connectivity show strong performance improvements over baselines,
as well as significant computational benefits.
</dc:description>
 <dc:description>Comment: 20pages, 6 figures, 10 tables</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11223</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11231</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bibliometric-Enhanced Information Retrieval: 5th International BIR
  Workshop</dc:title>
 <dc:creator>Mayr, Philipp</dc:creator>
 <dc:creator>Frommholz, Ingo</dc:creator>
 <dc:creator>Cabanac, Guillaume</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Bibliometric-enhanced Information Retrieval (BIR) workshops serve as the
annual gathering of IR researchers who address various information-related
tasks on scientific corpora and bibliometrics. The workshop features original
approaches to search, browse, and discover value-added knowledge from
scientific documents and related information networks (e.g., terms, authors,
institutions, references). We welcome contributions elaborating on dedicated IR
systems, as well as studies revealing original characteristics on how
scientific knowledge is created, communicated, and used. In this paper we
introduce the BIR workshop series and discuss some selected papers presented at
previous BIR workshops.
</dc:description>
 <dc:description>Comment: 6 pages, workshop paper accepted at 39th European Conference on IR
  Research, ECIR 2017</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11238</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prototype Matching Networks for Large-Scale Multi-label Genomic Sequence
  Classification</dc:title>
 <dc:creator>Lanchantin, Jack</dc:creator>
 <dc:creator>Sekhon, Arshdeep</dc:creator>
 <dc:creator>Singh, Ritambhara</dc:creator>
 <dc:creator>Qi, Yanjun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  One of the fundamental tasks in understanding genomics is the problem of
predicting Transcription Factor Binding Sites (TFBSs). With more than hundreds
of Transcription Factors (TFs) as labels, genomic-sequence based TFBS
prediction is a challenging multi-label classification task. There are two
major biological mechanisms for TF binding: (1) sequence-specific binding
patterns on genomes known as &quot;motifs&quot; and (2) interactions among TFs known as
co-binding effects. In this paper, we propose a novel deep architecture, the
Prototype Matching Network (PMN) to mimic the TF binding mechanisms. Our PMN
model automatically extracts prototypes (&quot;motif&quot;-like features) for each TF
through a novel prototype-matching loss. Borrowing ideas from few-shot matching
models, we use the notion of support set of prototypes and an LSTM to learn how
TFs interact and bind to genomic sequences. On a reference TFBS dataset with
$2.1$ $million$ genomic sequences, PMN significantly outperforms baselines and
validates our design choices empirically. To our knowledge, this is the first
deep learning architecture that introduces prototype learning and considers
TF-TF interactions for large-scale TFBS prediction. Not only is the proposed
architecture accurate, but it also models the underlying biology.
</dc:description>
 <dc:description>Comment: 15 pages, 6 figures, 5 tables</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11238</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11239</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time-lagged autoencoders: Deep learning of slow collective variables for
  molecular kinetics</dc:title>
 <dc:creator>Wehmeyer, Christoph</dc:creator>
 <dc:creator>No&#xe9;, Frank</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Physics - Biological Physics</dc:subject>
 <dc:subject>Physics - Chemical Physics</dc:subject>
 <dc:description>  Inspired by the success of deep learning techniques in the physical and
chemical sciences, we apply a modification of an autoencoder type deep neural
network to the task of dimension reduction of molecular dynamics data. We can
show that our time-lagged autoencoder reliably finds low-dimensional embeddings
for high-dimensional feature spaces which capture the slow dynamics of the
underlying stochastic processes - beyond the capabilities of linear dimension
reduction techniques.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11239</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11240</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine Learning and Cognitive Technology for Intelligent Wireless
  Networks</dc:title>
 <dc:creator>Zhou, Xiangwei</dc:creator>
 <dc:creator>Sun, Mingxuan</dc:creator>
 <dc:creator>Li, Geoffrey Ye</dc:creator>
 <dc:creator>Juang, Biing-Hwang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The ability to dynamically and efficiently allocate resources to meet the
need of growing diversity in services and user behavior marks the future of
wireless networks, giving rise to intelligent processing, which aims at
enabling the system to perceive and assess the available resources, to
autonomously learn to adapt to the perceived wireless environment, and to
reconfigure its operating mode to maximize the utility of the available
resources. The perception capability and reconfigurability are the essential
features of cognitive technology while modern machine learning techniques
project effectiveness in system adaptation. In this paper, we discuss the
development of the cognitive technology and machine learning techniques and
emphasize their roles in improving both spectrum and energy efficiency of the
future wireless networks. We describe in detail the state-of-the-art of
cognitive technology, covering spectrum sensing and access approaches that may
enhance spectrum utilization and curtail energy consumption. We discuss
powerful machine learning algorithms that enable spectrum- and energy-efficient
communications in dynamic wireless environments. We also present practical
applications of these techniques to the existing and future wireless
communication systems, such as heterogeneous networks and device-to-device
communications, and identify some research opportunities and challenges in
cognitive technology and machine learning as applied to future wireless
networks.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11240</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11241</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Theoretical properties of the global optimizer of two layer neural
  network</dc:title>
 <dc:creator>Boob, Digvijay</dc:creator>
 <dc:creator>Lan, Guanghui</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we study the problem of optimizing a two-layer artificial
neural network that best fits a training dataset. We look at this problem in
the setting where the number of parameters is greater than the number of
sampled points. We show that for a wide class of differentiable activation
functions (this class involves &quot;almost&quot; all functions which are not piecewise
linear), we have that first-order optimal solutions satisfy global optimality
provided the hidden layer is non-singular. Our results are easily extended to
hidden layers given by a flat matrix from that of a square matrix. Results are
applicable even if network has more than one hidden layer provided all hidden
layers satisfy non-singularity, all activations are from the given &quot;good&quot; class
of differentiable functions and optimization is only with respect to the last
hidden layer. We also study the smoothness properties of the objective function
and show that it is actually Lipschitz smooth, i.e., its gradients do not
change sharply. We use smoothness properties to guarantee asymptotic
convergence of O(1/number of iterations) to a first-order optimal solution. We
also show that our algorithm will maintain non-singularity of hidden layer for
any finite number of iterations.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11241</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11246</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Dynamic Hash Table for the GPU</dc:title>
 <dc:creator>Ashkiani, Saman</dc:creator>
 <dc:creator>Farach-Colton, Martin</dc:creator>
 <dc:creator>Owens, John D.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We design and implement a fully concurrent dynamic hash table for GPUs with
comparable performance to the state of the art static hash tables. We propose a
warp-cooperative work sharing strategy that reduces branch divergence and
provides an efficient alternative to the traditional way of per-thread (or
per-warp) work assignment and processing. By using this strategy, we build a
dynamic non-blocking concurrent linked list, the slab list, that supports
asynchronous, concurrent updates (insertions and deletions) as well as search
queries. We use the slab list to implement a dynamic hash table with chaining
(the slab hash). On an NVIDIA Tesla K40c GPU, the slab hash performs updates
with up to 512 M updates/s and processes search queries with up to 937 M
queries/s. We also design a warp-synchronous dynamic memory allocator,
SlabAlloc, that suits the high performance needs of the slab hash. SlabAlloc
dynamically allocates memory at a rate of 600 M allocations/s, which is up to
37x faster than alternative methods in similar scenarios.
</dc:description>
 <dc:description>Comment: 10 pages, submitted to the International Parallel and Distributed
  Processing Symposium (IPDPS 2018)</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11246</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11248</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Robust Rewards with Adversarial Inverse Reinforcement Learning</dc:title>
 <dc:creator>Fu, Justin</dc:creator>
 <dc:creator>Luo, Katie</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Reinforcement learning provides a powerful and general framework for decision
making and control, but its application in practice is often hindered by the
need for extensive feature and reward engineering. Deep reinforcement learning
methods can remove the need for explicit engineering of policy or value
features, but still require a manually specified reward function. Inverse
reinforcement learning holds the promise of automatic reward acquisition, but
has proven exceptionally difficult to apply to large, high-dimensional problems
with unknown dynamics. In this work, we propose adverserial inverse
reinforcement learning (AIRL), a practical and scalable inverse reinforcement
learning algorithm based on an adversarial reward learning formulation. We
demonstrate that AIRL is able to recover reward functions that are robust to
changes in dynamics, enabling us to learn policies even under significant
variation in the environment seen during training. Our experiments show that
AIRL greatly outperforms prior methods in these transfer settings.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11248</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11249</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rock-Paper-Scissors, Differential Games and Biological Diversity</dc:title>
 <dc:creator>Mai, Tung</dc:creator>
 <dc:creator>Panageas, Ioannis</dc:creator>
 <dc:creator>Ratcliff, Will</dc:creator>
 <dc:creator>Vazirani, Vijay V.</dc:creator>
 <dc:creator>Yunker, Peter</dc:creator>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  We model a situation in which a collection of species derive their fitnesses
via a rock-paper-scissors-type game; however, the precise payoffs are a
function of the environment. The new aspect of our model lies in adding a
feedback loop: the environment changes according to the relative fitnesses of
the species; in particular, it gives a boost to the species having small
populations. We cast our model in the setting of a differential game and we
show that for a certain setting of parameters, this dynamics cycles. Our model
is a natural one, since depletion of resources used by more frequent species
will shift the payoff matrix towards favoring less frequent ones. Since the
dynamics cycles, no species goes extinct and diversity is maintained.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11250</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reachability Preservers: New Extremal Bounds and Approximation
  Algorithms</dc:title>
 <dc:creator>Abboud, Amir</dc:creator>
 <dc:creator>Bodwin, Greg</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  In this paper we prove new results about the extremal structure of paths in
directed graphs. Say we are given a directed graph $G = (V, E)$ on $n$ nodes, a
set of sources $S \subseteq V$ of size $|S|=n^{1/3}$, and a subset $P \subseteq
S \times V$ of pairs $(s,t)$ where $s \in S$, of size $O(n^{2/3})$, such that
for all pairs $(s,t) \in P$, there is a path from $s$ to $t$. Our goal is to
remove as many edges from $G$ as possible while maintaining the reachability of
all pairs in $P$. How many edges will we have to keep? Can you always go down
to $n^{1+o(1)}$ edges? Or maybe for some nasty graphs $G$ you cannot even go
below the simple bound of $O(n^{4/3})$ edges?
  In this paper, we make polynomial progress in both the upper and lower bounds
for these Reachability Preservers over bounds that were implicit in the
literature. We show that in the above scenario, $O(n)$ edges will always be
sufficient, and in general one is even guaranteed a subgraph on $O(n+\sqrt{n
\cdot |P|\cdot |S|})$ edges that preserves the reachability of all pairs in
$P$. We complement this with a lower bound graph construction, establishing
that the above result fully characterizes the settings in which we are
guaranteed a preserver of size $O(n)$. Moreover, we design an efficient
algorithm that can always compute a preserver of existentially optimal size.
  The second contribution of this paper is a new connection between extremal
graph sparsification results and classical Steiner Network Design problems.
Surprisingly, prior to this work, the osmosis of techniques between these two
fields had been superficial. This allows us to improve the state of the art
approximation algorithms for the most basic Steiner-type problem in directed
graphs from the $O(n^{0.6+\varepsilon})$ of Chlamatac, Dinitz, Kortsarz, and
Laekhanukit (SODA'17) to $O(n^{0.577+\varepsilon})$.
</dc:description>
 <dc:description>Comment: To appear in SODA 2018</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11250</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11252</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Variational Video Prediction</dc:title>
 <dc:creator>Babaeizadeh, Mohammad</dc:creator>
 <dc:creator>Finn, Chelsea</dc:creator>
 <dc:creator>Erhan, Dumitru</dc:creator>
 <dc:creator>Campbell, Roy H.</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Predicting the future in real-world settings, particularly from raw sensory
observations such as images, is exceptionally challenging. Real-world events
can be stochastic and unpredictable, and the high dimensionality and complexity
of natural images requires the predictive model to build an intricate
understanding of the natural world. Many existing methods tackle this problem
by making simplifying assumptions about the environment. One common assumption
is that the outcome is deterministic and there is only one plausible future.
This can lead to low-quality predictions in real-world settings with stochastic
dynamics. In this paper, we develop a stochastic variational video prediction
(SV2P) method that predicts a different possible future for each sample of its
latent variables. To the best of our knowledge, our model is the first to
provide effective stochastic multi-frame prediction for real-world video. We
demonstrate the capability of the proposed method in predicting detailed future
frames of videos on multiple real-world datasets, both action-free and
action-conditioned. We find that our proposed method produces substantially
improved video predictions when compared to the same model without
stochasticity, and to other stochastic video prediction methods. Our SV2P
implementation will be open sourced upon publication.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11252</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11253</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximation Algorithms for $\ell_0$-Low Rank Approximation</dc:title>
 <dc:creator>Bringmann, Karl</dc:creator>
 <dc:creator>Kolev, Pavel</dc:creator>
 <dc:creator>Woodruff, David P.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the $\ell_0$-Low Rank Approximation Problem, where the goal is,
given an $m \times n$ matrix $A$, to output a rank-$k$ matrix $A'$ for which
$\|A'-A\|_0$ is minimized. Here, for a matrix $B$, $\|B\|_0$ denotes the number
of its non-zero entries. This NP-hard variant of low rank approximation is
natural for problems with no underlying metric, and its goal is to minimize the
number of disagreeing data positions. We provide approximation algorithms which
significantly improve the running time and approximation factor of previous
work. For $k &gt; 1$, we show how to find, in poly$(mn)$ time for every $k$, a
rank $O(k \log(n/k))$ matrix $A'$ for which $\|A'-A\|_0 \leq O(k^2 \log(n/k))
\mathrm{OPT}$. To the best of our knowledge, this is the first algorithm with
provable guarantees for the $\ell_0$-Low Rank Approximation Problem for $k &gt;
1$, even for bicriteria algorithms. For the well-studied case when $k = 1$, we
give a $(2+\epsilon)$-approximation in {\it sublinear time}, which is
impossible for other variants of low rank approximation such as for the
Frobenius norm. We strengthen this for the well-studied case of binary matrices
to obtain a $(1+O(\psi))$-approximation in sublinear time, where $\psi =
\mathrm{OPT}/\lVert A\rVert_0$. For small $\psi$, our approximation factor is
$1+o(1)$.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11253</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11268</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Theoretical and Computational Guarantees of Mean Field Variational
  Inference for Community Detection</dc:title>
 <dc:creator>Zhang, Anderson Y.</dc:creator>
 <dc:creator>Zhou, Harrison H.</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The mean field variational Bayes method is becoming increasingly popular in
statistics and machine learning. Its iterative Coordinate Ascent Variational
Inference algorithm has been widely applied to large scale Bayesian inference.
See Blei et al. (2017) for a recent comprehensive review. Despite the
popularity of the mean field method there exist remarkably little fundamental
theoretical justifications. To the best of our knowledge, the iterative
algorithm has never been investigated for any high dimensional and complex
model. In this paper, we study the mean field method for community detection
under the Stochastic Block Model. For an iterative Batch Coordinate Ascent
Variational Inference algorithm, we show that it has a linear convergence rate
and converges to the minimax rate within $\log n$ iterations. This complements
the results of Bickel et al. (2013) which studied the global minimum of the
mean field variational Bayes and obtained asymptotic normal estimation of
global model parameters. In addition, we obtain similar optimality results for
Gibbs sampling and an iterative procedure to calculate maximum likelihood
estimation, which can be of independent interest.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-12-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11268</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11271</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Forgetting the Forgotten with Letheia, Concealing Content Deletion from
  Persistent Observers</dc:title>
 <dc:creator>Minaei, Mohsen</dc:creator>
 <dc:creator>Mondal, Mainack</dc:creator>
 <dc:creator>Loiseau, Patrick</dc:creator>
 <dc:creator>Gummadi, Krishna</dc:creator>
 <dc:creator>Kate, Aniket</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Most people are susceptible to oversharing their personal information
publicly on social platforms today. As a coping strategy, these platforms offer
mechanisms allowing users to delete their posts, and a significant fraction of
users exercise this right to be forgotten. However, ironically, users' attempt
to reduce attention to sensitive posts via deletion, in practice, attracts
unwanted attention from stalkers, curious friends, and even blackmailers
specifically to those (deleted) posts. In fact, multiple third party services
today identify and hoard deleted posts from millions of users. Thus, in
general, deletions may leave users more vulnerable to attacks on their privacy,
and users hoping to make their posts forgotten can face a &quot;damned if I do,
damned if I don't&quot; dilemma.
  In the form of intermittent withdrawals, we propose a rather disruptive
solution (Letheia) to this problem of (really) forgetting the forgotten. If the
platforms are willing to give up the uninterrupted availability of non-deleted
posts by a very small fraction, Letheia provides privacy to the deleted posts
over long durations. With Letheia, an adversarial observer becomes unsure if
some posts are permanently deleted or just temporarily withdrawn; at the same
time, the adversarial observer is overwhelmed by a large number of falsely
flagged undeleted posts. We analyze large-scale data about users' deletion over
Twitter and thoroughly investigate how to choose time duration distributions
for alternating between temporary withdrawals and resurrections of non-deleted
posts. We find a favorable trade-off between privacy, availability and
adversarial overhead in Letheia under different settings. For example, we show
that while maintaining content availability as high as 95%, Letheia offers
deletion privacy for up to 3 months from the time of deletion while still
keeping the adversarial precision to 20%.
</dc:description>
 <dc:description>Comment: 16 pages, 8 figures</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11271</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11272</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Empirical analysis of non-linear activation functions for Deep Neural
  Networks in classification tasks</dc:title>
 <dc:creator>Alcantara, Giovanni</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We provide an overview of several non-linear activation functions in a neural
network architecture that have proven successful in many machine learning
applications. We conduct an empirical analysis on the effectiveness of using
these function on the MNIST classification task, with the aim of clarifying
which functions produce the best results overall. Based on this first set of
results, we examine the effects of building deeper architectures with an
increasing number of hidden layers. We also survey the impact of using, on the
same task, different initialisation schemes for the weights of our neural
network. Using these sets of experiments as a base, we conclude by providing a
optimal neural network architecture that yields impressive results in accuracy
on the MNIST classification task.
</dc:description>
 <dc:description>Comment: 7 pages, 23 figures</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11272</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11276</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synchronization in Networks of Diffusively Coupled Nonlinear Systems:
  Robustness Against Time-Delays</dc:title>
 <dc:creator>Murguia, Carlos</dc:creator>
 <dc:creator>Nijmeijer, Henk</dc:creator>
 <dc:creator>Ruths, Justin</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this manuscript, we study the problem of robust synchronization in
networks of diffusively time-delayed coupled nonlinear systems. In particular,
we prove that, under some mild conditions on the input-output dynamics of the
systems and the network topology, there always exists a unimodal region in the
parameter space (coupling strength versus time-delay), such that if they belong
to this region, the systems synchronize. Moreover, we show how this unimodal
region scales with the network topology, which, in turn, provides useful
insights on how to design the network topology to maximize robustness against
time-delays. The results are illustrated by extensive simulation experiments of
time-delayed coupled Hindmarsh-Rose neural chaotic oscillators.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11276</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11277</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Advantage Actor-Critic Model for Task-Completion Dialogue
  Policy Learning</dc:title>
 <dc:creator>Peng, Baolin</dc:creator>
 <dc:creator>Li, Xiujun</dc:creator>
 <dc:creator>Gao, Jianfeng</dc:creator>
 <dc:creator>Liu, Jingjing</dc:creator>
 <dc:creator>Chen, Yun-Nung</dc:creator>
 <dc:creator>Wong, Kam-Fai</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper presents a new method --- adversarial advantage actor-critic
(Adversarial A2C), which significantly improves the efficiency of dialogue
policy learning in task-completion dialogue systems. Inspired by generative
adversarial networks (GAN), we train a discriminator to differentiate
responses/actions generated by dialogue agents from responses/actions by
experts. Then, we incorporate the discriminator as another critic into the
advantage actor-critic (A2C) framework, to encourage the dialogue agent to
explore state-action within the regions where the agent takes actions similar
to those of the experts. Experimental results in a movie-ticket booking domain
show that the proposed Adversarial A2C can accelerate policy exploration
efficiently.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11277</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11278</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximating Continuous Functions by ReLU Nets of Minimal Width</dc:title>
 <dc:creator>Hanin, Boris</dc:creator>
 <dc:creator>Sellke, Mark</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  This article concerns the expressive power of depth in deep feed-forward
neural nets with ReLU activations. Specifically, we answer the following
question: for a fixed $d\geq 1,$ what is the minimal width $w$ so that neural
nets with ReLU activations, input dimension $d$, hidden layer widths at most
$w,$ and arbitrary depth can approximate any continuous function of $d$
variables arbitrarily well. It turns out that this minimal width is exactly
equal to $d+1.$ That is, if all the hidden layer widths are bounded by $d$,
then even in the infinite depth limit, ReLU nets can only express a very
limited class of functions. On the other hand, we show that any continuous
function on the $d$-dimensional unit cube can be approximated to arbitrary
precision by ReLU nets in which all hidden layers have width exactly $d+1.$ Our
construction gives quantitative depth estimates for such an approximation.
</dc:description>
 <dc:description>Comment: v1. 12p. Comments welcome</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11278</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11298</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effective Tensor Sketching via Sparsification</dc:title>
 <dc:creator>Xia, Dong</dc:creator>
 <dc:creator>Yuan, Ming</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we investigate effective sketching schemes via sparsification
for high dimensional multilinear arrays or tensors. More specifically, we
propose a novel tensor sparsification algorithm that retains a subset of the
entries of a tensor in a judicious way, and prove that it can attain a given
level of approximation accuracy in terms of tensor spectral norm with a much
smaller sample complexity when compared with existing approaches. In
particular, we show that for a $k$th order $d\times\cdots\times d$ cubic tensor
of {\it stable rank} $r_s$, the sample size requirement for achieving a
relative error $\varepsilon$ is, up to a logarithmic factor, of the order
$r_s^{1/2} d^{k/2} /\varepsilon$ when $\varepsilon$ is relatively large, and
$r_s d /\varepsilon^2$ and essentially optimal when $\varepsilon$ is
sufficiently small. It is especially noteworthy that the sample size
requirement for achieving a high accuracy is of an order independent of $k$. To
further demonstrate the utility of our techniques, we also study how higher
order singular value decomposition (HOSVD) of large tensors can be efficiently
approximated via sparsification.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11298</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11301</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A generalized parsing framework for Abstract Grammars</dc:title>
 <dc:creator>Harasim, Daniel</dc:creator>
 <dc:creator>Bruno, Chris</dc:creator>
 <dc:creator>Portelance, Eva</dc:creator>
 <dc:creator>Rohrmeier, Martin</dc:creator>
 <dc:creator>O'Donnell, Timothy J.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  This technical report presents a general framework for parsing a variety of
grammar formalisms. We develop a grammar formalism, called an Abstract Grammar,
which is general enough to represent grammars at many levels of the hierarchy,
including Context Free Grammars, Minimalist Grammars, and Generalized
Context-free Grammars. We then develop a single parsing framework which is
capable of parsing grammars which are at least up to GCFGs on the hierarchy.
Our parsing framework exposes a grammar interface, so that it can parse any
particular grammar formalism that can be reduced to an Abstract Grammar.
</dc:description>
 <dc:description>Comment: Technical Report [v2: added Martin Rohrmeier as author.] [v3: fixed
  error stating that AGs are equivalent to GCFGS. this is in fact not known
  yet. other minor typos fixed.]</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11301</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11303</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithmic learning of probability distributions from random data in
  the limit</dc:title>
 <dc:creator>Barmpalias, George</dc:creator>
 <dc:creator>Stephan, Frank</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the problem of identifying a probability distribution for some given
randomly sampled data in the limit, in the context of algorithmic learning
theory as proposed recently by Vinanyi and Chater. We show that there exists a
computable partial learner for the computable probability measures, while by
Bienvenu, Monin and Shen it is known that there is no computable learner for
the computable probability measures. Our main result is the characterization of
the oracles that compute explanatory learners for the computable (continuous)
probability measures as the high oracles. This provides an analogue of a
well-known result of Adleman and Blum in the context of learning computable
probability distributions. We also discuss related learning notions such as
behaviorally correct learning and orther variations of explanatory learning, in
the context of learning probability distributions from data.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:date>2017-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11303</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11304</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterizing the structural diversity of complex networks across
  domains</dc:title>
 <dc:creator>Ikehara, Kansuke</dc:creator>
 <dc:creator>Clauset, Aaron</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Quantitative Biology - Molecular Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The structure of complex networks has been of interest in many scientific and
engineering disciplines over the decades. A number of studies in the field have
been focused on finding the common properties among different kinds of networks
such as heavy-tail degree distribution, small-worldness and modular structure
and they have tried to establish a theory of structural universality in complex
networks. However, there is no comprehensive study of network structure across
a diverse set of domains in order to explain the structural diversity we
observe in the real-world networks. In this paper, we study 986 real-world
networks of diverse domains ranging from ecological food webs to online social
networks along with 575 networks generated from four popular network models.
Our study utilizes a number of machine learning techniques such as random
forest and confusion matrix in order to show the relationships among network
domains in terms of network structure. Our results indicate that there are some
partitions of network categories in which networks are hard to distinguish
based purely on network structure. We have found that these partitions of
network categories tend to have similar underlying functions, constraints
and/or generative mechanisms of networks even though networks in the same
partition have different origins, e.g., biological processes, results of
engineering by human being, etc. This suggests that the origin of a network,
whether it's biological, technological or social, may not necessarily be a
decisive factor of the formation of similar network structure. Our findings
shed light on the possible direction along which we could uncover the hidden
principles for the structural diversity of complex networks.
</dc:description>
 <dc:description>Comment: 23 pages, 11 figures, 2 tables; originally published as K. Ikehara,
  &quot;The Structure of Complex Networks across Domains.&quot; MS Thesis, University of
  Colorado Boulder (2016)</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11304</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11306</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Exact Solution to Rank-1 L1-norm TUCKER2 Decomposition</dc:title>
 <dc:creator>Markopoulos, Panos P.</dc:creator>
 <dc:creator>Chachlakis, Dimitris G.</dc:creator>
 <dc:creator>Papalexakis, Evangelos E.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study rank-1 {L1-norm-based TUCKER2} (L1-TUCKER2) decomposition of 3-way
tensors, treated as a collection of $N$ $D \times M$ matrices that are to be
jointly decomposed. Our contributions are as follows. i) We prove that the
problem is equivalent to combinatorial optimization over $N$ antipodal-binary
variables. ii) We derive the first two algorithms in the literature for its
exact solution. The first algorithm has cost exponential in $N$; the second one
has cost polynomial in $N$ (under a mild assumption). Our algorithms are
accompanied by formal complexity analysis. iii) We conduct numerical studies to
compare the performance of exact L1-TUCKER2 (proposed) with standard HOSVD,
HOOI, GLRAM, PCA, L1-PCA, and TPCA-L1. Our studies show that L1-TUCKER2
outperforms (in tensor approximation) all the above counterparts when the
processed data are outlier corrupted.
</dc:description>
 <dc:description>Comment: This is a preprint; An edited/finalized version of this manuscript
  has been submitted for publication to IEEE Signal Processing Letters</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11306</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11309</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tumor Classification and Segmentation of MR Brain Images</dc:title>
 <dc:creator>Gupta, Tanvi</dc:creator>
 <dc:creator>Manocha, Pranay</dc:creator>
 <dc:creator>Gandhi, Tapan K.</dc:creator>
 <dc:creator>Gupta, RK</dc:creator>
 <dc:creator>Panigrahi, BK</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The diagnosis and segmentation of tumors using any medical diagnostic tool
can be challenging due to the varying nature of this pathology. Magnetic Reso-
nance Imaging (MRI) is an established diagnostic tool for various diseases and
disorders and plays a major role in clinical neuro-diagnosis. Supplementing
this technique with automated classification and segmentation tools is gaining
importance, to reduce errors and time needed to make a conclusive diagnosis. In
this paper a simple three-step algorithm is proposed; (1) identification of
patients that present with tumors, (2) automatic selection of abnormal slices
of the patients, and (3) segmentation and detection of the tumor. Features were
extracted by using discrete wavelet transform on the normalized images and
classified by support vector machine (for step (1)) and random forest (for step
(2)). The 400 subjects were divided in a 3:1 ratio between training and test
with no overlap. This study is novel in terms of use of data, as it employed
the entire T2 weighted slices as a single image for classification and a unique
combination of contralateral approach with patch thresholding for segmentation,
which does not require a training set or a template as is used by most
segmentation studies. Using the proposed method, the tumors were segmented
accurately with a classification accuracy of 95% with 100% specificity and 90%
sensitivity.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11309</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11310</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Innovations Approach to Viterbi Decoding of Convolutional Codes</dc:title>
 <dc:creator>Tajima, Masato</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We introduce the notion of innovations for Viterbi decoding of convolutional
codes. First we define a kind of innovation corresponding to the received data,
i.e., the input to a Viterbi decoder. Then the structure of a
Scarce-State-Transition (SST) Viterbi decoder is derived in a natural manner.
It is shown that the newly defined innovation is just the input to the main
decoder in an SST Viterbi decoder and generates the same syndrome as the
original received data does. A similar result holds for QLI codes as well. In
this case, however, the precise innovation is not defined. We see that this
innovation-like quantity is related to the linear smoothed estimate of the
information. The essence of innovations approach to a linear filtering problem
is first to whiten the observed data, and then to treat the resulting simpler
white-noise observations problem. In our case, this corresponds to the
reduction of decoding complexity in the main decoder in an SST Viterbi decoder.
We show that the distributions related to the main decoder in an SST Viterbi
decoder (i.e., the input distribution and the state distribution in the code
trellis) are much biased under moderately noisy conditions. Note that the state
distribution in the corresponding error trellis is also biased under the same
channel conditions. These biased distributions enable decoding with remarkably
low average complexity.
</dc:description>
 <dc:description>Comment: 22 pages, 2 figures, 6 tables</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11310</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11311</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Forward and Inverse Perceptual Models for Tracking and Prediction</dc:title>
 <dc:creator>Lambert, Alexander</dc:creator>
 <dc:creator>Shaban, Amirreza</dc:creator>
 <dc:creator>Raj, Amit</dc:creator>
 <dc:creator>Liu, Zhen</dc:creator>
 <dc:creator>Boots, Byron</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the problems of learning forward models that map state to
high-dimensional images and inverse models that map high-dimensional images to
state in robotics. Specifically, we present a perceptual model for generating
video frames from state with deep networks, and provide a framework for its use
in tracking and prediction tasks. We show that our proposed model greatly
outperforms standard deconvolutional methods and GANs for image generation,
producing clear, photo-realistic images. We also develop a convolutional neural
network model for state estimation and compare the result to an Extended Kalman
Filter to estimate robot trajectories. We validate all models on a real robotic
system.
</dc:description>
 <dc:description>Comment: 8 pages, Submitted to International Conference on Robotics and
  Automation (ICRA) 2017</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11311</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11315</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rate-optimal Meta Learning of Classification Error</dc:title>
 <dc:creator>Iranzad, Morteza Noshad</dc:creator>
 <dc:creator>Hero III, Alfred O.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Meta learning of optimal classifier error rates allows an experimenter to
empirically estimate the intrinsic ability of any estimator to discriminate
between two populations, circumventing the difficult problem of estimating the
optimal Bayes classifier. To this end we propose a weighted nearest neighbor
(WNN) graph estimator for a tight bound on the Bayes classification error; the
Henze-Penrose (HP) divergence. Similar to recently proposed HP estimators
[berisha2016], the proposed estimator is non-parametric and does not require
density estimation. However, unlike previous approaches the proposed estimator
is rate-optimal, i.e., its mean squared estimation error (MSEE) decays to zero
at the fastest possible rate of $O(1/M+1/N)$ where $M,N$ are the sample sizes
of the respective populations. We illustrate the proposed WNN meta estimator
for several simulated and real data sets.
</dc:description>
 <dc:description>Comment: Submitted to ICASSP 2017</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11315</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11317</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nebula: F0 Estimation and Voicing Detection by Modeling the Statistical
  Properties of Feature Extractors</dc:title>
 <dc:creator>Hua, Kanru</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  A F0 and voicing status estimation algorithm for speech analysis/synthesis is
proposed. Instead of directly modeling speech signals, the proposed algorithm
models the behavior of feature extractors under additive noise using a bank of
Gaussian mixture models, trained on artificial data generated from Monte-Carlo
simulations. The conditional distributions of F0 predicted by the GMMs are
combined to generate a likelihood map, which is then smoothed by a Viterbi
search to give the final F0 trajectory. The voicing decision is obtained based
on the peak F0 likelihood. The proposed method achieves an average F0 gross
error of 0.30% on CSTR and CMU Arctic speech datasets.
</dc:description>
 <dc:description>Comment: Submitted to ICASSP 2018</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11317</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11319</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Motion Predictors for Smart Wheelchair using Autoregressive
  Sparse Gaussian Process</dc:title>
 <dc:creator>Fan, Zicong</dc:creator>
 <dc:creator>Meng, Lili</dc:creator>
 <dc:creator>Chen, Tian Qi</dc:creator>
 <dc:creator>Li, Jingchun</dc:creator>
 <dc:creator>Mitchell, Ian M.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Constructing a smart wheelchair on a commercially available powered
wheelchair (PWC) platform avoids a host of seating, mechanical design and
reliability issues but requires methods of predicting and controlling the
motion of a device never intended for robotics. Analog joystick inputs are
subject to black-box transformations which may produce intuitive and adaptable
motion control for human operators, but complicate robotic control approaches;
furthermore, installation of standard axle mounted odometers on a commercial
PWC is difficult. In this work, we present an integrated hardware and software
system for predicting the motion of a commercial PWC platform that does not
require any physical or electronic modification of the chair beyond plugging
into an industry standard auxiliary input port. This system uses an RGB-D
camera and an Arduino interface board to capture motion data, including visual
odometry and joystick signals, via ROS communication. Future motion is
predicted using an autoregressive sparse Gaussian process model. We evaluate
the proposed system on real-world short-term path prediction experiments.
Experimental results demonstrate the system's efficacy when compared to a
baseline neural network model.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11319</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11324</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Emergence and Relevance of Criticality in Deep Learning</dc:title>
 <dc:creator>Song, Juyong</dc:creator>
 <dc:creator>Marsili, Matteo</dc:creator>
 <dc:creator>Jo, Junghyo</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  Deep learning has been successfully applied to various tasks, but its
underlying mechanism remains unclear. Neural networks map input data to hidden
states in deep layers. As deeper layers have fewer degrees of freedom, subsets
of data are transformed into identical states in the deep layers. In this
sense, deep learning can be considered as a hierarchical data grouping process.
In this Letter, we discover that deep learning forces the size distributions of
the data clusters to follow power laws with a different power exponent within
each layer. In particular, we identify a critical layer where the cluster size
distribution obeys a reciprocal relationship between rank and frequency, also
known as Zipf's law. Deep learning ensures balanced data grouping by extracting
similarities and differences between data. Furthermore, we verify that the data
structure in the critical layer is most informative to reliably generate
patterns of training data. Therefore, the criticality can explain the
operational excellence of deep learning and provide a useful concept for
probing optimal network architectures.
</dc:description>
 <dc:description>Comment: 3 figures</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11324</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11332</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Social Media Text Summarization by Learning Sentence Weight
  Distribution</dc:title>
 <dc:creator>Xu, Jingjing</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recently, encoder-decoder models are widely used in social media text
summarization. However, these models sometimes select noise words in irrelevant
sentences as part of a summary by error, thus declining the performance. In
order to inhibit irrelevant sentences and focus on key information, we propose
an effective approach by learning sentence weight distribution. In our model,
we build a multi-layer perceptron to predict sentence weights. During training,
we use the ROUGE score as an alternative to the estimated sentence weight, and
try to minimize the gap between estimated weights and predicted weights. In
this way, we encourage our model to focus on the key sentences, which have high
relevance with the summary. Experimental results show that our approach
outperforms baselines on a large-scale social media corpus.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11332</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11334</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shallow Discourse Parsing with Maximum Entropy Model</dc:title>
 <dc:creator>Xu, Jingjing</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In recent years, more research has been devoted to studying the subtask of
the complete shallow discourse parsing, such as indentifying discourse
connective and arguments of connective. There is a need to design a full
discourse parser to pull these subtasks together. So we develop a discourse
parser turning the free text into discourse relations. The parser includes
connective identifier, arguments identifier, sense classifier and non-explicit
identifier, which connects with each other in pipeline. Each component applies
the maximum entropy model with abundant lexical and syntax features extracted
from the Penn Discourse Tree-bank. The head-based representation of the PDTB is
adopted in the arguments identifier, which turns the problem of indentifying
the arguments of discourse connective into finding the head and end of the
arguments. In the non-explicit identifier, the contextual type features like
words which have high frequency and can reflect the discourse relation are
introduced to improve the performance of non-explicit identifier. Compared with
other methods, experimental results achieve the considerable performance.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11334</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11341</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Global Rank Estimation</dc:title>
 <dc:creator>Saxena, Akrati</dc:creator>
 <dc:creator>Iyengar, S. R. S.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  In real world complex networks, the importance of a node depends on two
important parameters: 1. characteristics of the node, and 2. the context of the
given application. The current literature contains several centrality measures
that have been defined to measure the importance of a node based on the given
application requirements. These centrality measures assign a centrality value
to each node that denotes its importance index. But in real life applications,
we are more interested in the relative importance of the node that can be
measured using its centrality rank based on the given centrality measure. To
compute the centrality rank of a node, we need to compute the centrality value
of all the nodes and compare them to get the rank. This process requires the
entire network. So, it is not feasible for real-life applications due to the
large size and dynamic nature of real world networks. In the present project,
we aim to propose fast and efficient methods to estimate the global centrality
rank of a node without computing the centrality value of all nodes. These
methods can be further extended to estimate the rank without having the entire
network. The proposed methods use the structural behavior of centrality
measures, sampling techniques, or the machine learning models. In this work, we
also discuss how to apply these methods for degree and closeness centrality
rank estimation.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11341</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11342</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generating Natural Adversarial Examples</dc:title>
 <dc:creator>Zhao, Zhengli</dc:creator>
 <dc:creator>Dua, Dheeru</dc:creator>
 <dc:creator>Singh, Sameer</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Due to their complex nature, it is hard to characterize the ways in which
machine learning models can misbehave or be exploited when deployed. Recent
work on adversarial examples, i.e. inputs with minor perturbations that result
in substantially different model predictions, is helpful in evaluating the
robustness of these models by exposing the adversarial scenarios where they
fail. However, these malicious perturbations are often unnatural, not
semantically meaningful, and not applicable to complicated domains such as
language. In this paper, we propose a framework to generate natural and legible
adversarial examples by searching in semantic space of dense and continuous
data representation, utilizing the recent advances in generative adversarial
networks. We present generated adversaries to demonstrate the potential of the
proposed approach for black-box classifiers in a wide range of applications
such as image classification, textual entailment, and machine translation. We
include experiments to show that the generated adversaries are natural, legible
to humans, and useful in evaluating and analyzing black-box classifiers.
</dc:description>
 <dc:description>Comment: Under review as a conference paper at ICLR 2018</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11342</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11344</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Sequential Matching Framework for Multi-turn Response Selection in
  Retrieval-based Chatbots</dc:title>
 <dc:creator>Wu, Yu</dc:creator>
 <dc:creator>Wu, Wei</dc:creator>
 <dc:creator>Xing, Chen</dc:creator>
 <dc:creator>Xu, Can</dc:creator>
 <dc:creator>Li, Zhoujun</dc:creator>
 <dc:creator>Zhou, Ming</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We study the problem of response selection for multi-turn conversation in
retrieval-based chatbots. The task requires matching a response candidate with
a conversation context, whose challenges include how to recognize important
parts of the context, and how to model the relationships among utterances in
the context. Existing matching methods may lose important information in
contexts as we can interpret them with a unified framework in which contexts
are transformed to fixed-length vectors without any interaction with responses
before matching. The analysis motivates us to propose a new matching framework
that can sufficiently carry the important information in contexts to matching
and model the relationships among utterances at the same time. The new
framework, which we call a sequential matching framework (SMF), lets each
utterance in a context interacts with a response candidate at the first step
and transforms the pair to a matching vector. The matching vectors are then
accumulated following the order of the utterances in the context with a
recurrent neural network (RNN) which models the relationships among the
utterances. The context-response matching is finally calculated with the hidden
states of the RNN. Under SMF, we propose a sequential convolutional network and
sequential attention network and conduct experiments on two public data sets to
test their performance. Experimental results show that both models can
significantly outperform the state-of-the-art matching methods. We also show
that the models are interpretable with visualizations that provide us insights
on how they capture and leverage the important information in contexts for
matching.
</dc:description>
 <dc:description>Comment: Submitted to Computational Linguistics</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11344</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11345</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tensor Regression Meets Gaussian Processes</dc:title>
 <dc:creator>Yu, Rose</dc:creator>
 <dc:creator>Li, Guangyu</dc:creator>
 <dc:creator>Liu, Yan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Low-rank tensor regression, a new model class that learns high-order
correlation from data, has recently received considerable attention. At the
same time, Gaussian processes (GP) are well-studied machine learning models for
structure learning. In this paper, we demonstrate interesting connections
between the two, especially for multi-way data analysis. We show that low-rank
tensor regression is essentially learning a multi-linear kernel in Gaussian
processes, and the low-rank assumption translates to the constrained Bayesian
inference problem. We prove the oracle inequality and derive the average case
learning curve for the equivalent GP model. Our finding implies that low-rank
tensor regression, though empirically successful, is highly dependent on the
eigenvalues of covariance functions as well as variable correlations.
</dc:description>
 <dc:description>Comment: 17 pages</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11346</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Socialbots supporting human rights</dc:title>
 <dc:creator>Vel&#xe1;zquez, E.</dc:creator>
 <dc:creator>Yazdani, M.</dc:creator>
 <dc:creator>Su&#xe1;rez-Serrato, P.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Socialbots, or non-human/algorithmic social media users, have recently been
documented as competing for information dissemination and disruption on online
social networks. Here we investigate the influence of socialbots in Mexican
Twitter in regards to the &quot;Tanhuato&quot; human rights abuse report. We analyze the
applicability of the BotOrNot API to generalize from English to Spanish tweets
and propose adaptations for Spanish-speaking bot detection. We then use text
and sentiment analysis to compare the differences between bot and human tweets.
Our analysis shows that bots actually aided in information proliferation among
human users. This suggests that taxonomies classifying bots should include
non-adversarial roles as well. Our study contributes to the understanding of
different behaviors and intentions of automated accounts observed in empirical
online social network data. Since this type of analysis is seldom performed in
languages different from English, the proposed techniques we employ here are
also useful for other non-English corpora.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11346</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11350</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Grammar induction for mildly context sensitive languages using
  variational Bayesian inference</dc:title>
 <dc:creator>Portelance, Eva</dc:creator>
 <dc:creator>Bruno, Chris</dc:creator>
 <dc:creator>Harasim, Daniel</dc:creator>
 <dc:creator>Bergen, Leon</dc:creator>
 <dc:creator>O'Donnell, Timothy J.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The following technical report presents a formal approach to probabilistic
minimalist grammar induction. We describe a formalization of a minimalist
grammar. Based on this grammar, we define a generative model for minimalist
derivations. We then present a generalized algorithm for the application of
variational Bayesian inference to lexicalized mildly context sensitive language
grammars which in this paper is applied to the previously defined minimalist
grammar.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2018-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11351</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ChainerMN: Scalable Distributed Deep Learning Framework</dc:title>
 <dc:creator>Akiba, Takuya</dc:creator>
 <dc:creator>Fukuda, Keisuke</dc:creator>
 <dc:creator>Suzuki, Shuji</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  One of the keys for deep learning to have made a breakthrough in various
fields was to utilize high computing powers centering around GPUs. Enabling the
use of further computing abilities by distributed processing is essential not
only to make the deep learning bigger and faster but also to tackle unsolved
challenges. We present the design, implementation, and evaluation of ChainerMN,
the distributed deep learning framework we have developed. We demonstrate that
ChainerMN can scale the learning process of the ResNet-50 model to the ImageNet
dataset up to 128 GPUs with the parallel efficiency of 90%.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11351</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11352</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variations of the cop and robber game on graphs</dc:title>
 <dc:creator>Slettnes, Espen</dc:creator>
 <dc:creator>Quines, Carl Joshua</dc:creator>
 <dc:creator>Tsai, Shen-Fu</dc:creator>
 <dc:creator>Geneson, Jesse</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We prove new theoretical results about several variations of the cop and
robber game on graphs. First, we consider a variation of the cop and robber
game which is more symmetric called the cop and killer game. We prove for all
$c &lt; 1$ that almost all random graphs are stalemate for the cop and killer
game, where each edge occurs with probability $p$ such that $\frac{1}{n^{c}}
\le p \le 1-\frac{1}{n^{c}}$. We prove that a graph can be killer-win if and
only if it has exactly $k\ge 3$ triangles or none at all. We prove that graphs
with multiple cycles longer than triangles permit cop-win and killer-win
graphs. For $\left(m,n\right)\neq\left(1,5\right)$ and $n\geq4$, we show that
there are cop-win and killer-win graphs with $m$ $C_n$s. In addition, we
identify game outcomes on specific graph products.
  Next, we find a generalized version of Dijkstra's algorithm that can be
applied to find the minimal expected capture time and the minimal evasion
probability for the cop and gambler game and other variations of graph pursuit.
  Finally, we consider a randomized version of the killer that is similar to
the gambler. We use the generalization of Dijkstra's algorithm to find optimal
strategies for pursuing the random killer. We prove that if $G$ is a connected
graph with maximum degree $d$, then the cop can win with probability at least
$\frac{\sqrt d}{1+\sqrt d}$ after learning the killer's distribution. In
addition, we prove that this bound is tight only on the
$\left(d+1\right)$-vertex star, where the killer takes the center with
probability $\frac1{1+\sqrt d}$ and each of the other vertices with equal
probabilities.
</dc:description>
 <dc:description>Comment: 20 pages, 9 figures. This paper has resulted from the 2017 CrowdMath
  project on graph algorithms and applications (online at
  http://www.aops.com/polymath/mitprimes2017a)</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11352</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11354</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatio-temporal interaction model for crowd video analysis</dc:title>
 <dc:creator>Bhargava, Neha</dc:creator>
 <dc:creator>Chaudhuri, Subhasis</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present an unsupervised approach to analyze crowd at various levels of
granularity $-$ individual, group and collective. We also propose a motion
model to represent the collective motion of the crowd. The model captures the
spatio-temporal interaction pattern of the crowd from the trajectory data
captured over a time period. Furthermore, we also propose an effective group
detection algorithm that utilizes the eigenvectors of the interaction matrix of
the model. We also show that the eigenvalues of the interaction matrix
characterize various group activities such as being stationary, walking,
splitting and approaching. The algorithm is also extended trivially to
recognize individual activity. Finally, we discover the overall crowd behavior
by classifying a crowd video in one of the eight categories. Since the crowd
behavior is determined by its constituent groups, we demonstrate the usefulness
of group level features during classification. Extensive experimentation on
various datasets demonstrates a superlative performance of our algorithms over
the state-of-the-art methods.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11354</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11359</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Patch Matching Using Convolutional Descriptors with Euclidean
  Distance</dc:title>
 <dc:creator>Melekhov, Iaroslav</dc:creator>
 <dc:creator>Kannala, Juho</dc:creator>
 <dc:creator>Rahtu, Esa</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work we propose a neural network based image descriptor suitable for
image patch matching, which is an important task in many computer vision
applications. Our approach is influenced by recent success of deep
convolutional neural networks (CNNs) in object detection and classification
tasks. We develop a model which maps the raw input patch to a low dimensional
feature vector so that the distance between representations is small for
similar patches and large otherwise. As a distance metric we utilize L2 norm,
i.e. Euclidean distance, which is fast to evaluate and used in most popular
hand-crafted descriptors, such as SIFT. According to the results, our approach
outperforms state-of-the-art L2-based descriptors and can be considered as a
direct replacement of SIFT. In addition, we conducted experiments with batch
normalization and histogram equalization as a preprocessing method of the input
data. The results confirm that these techniques further improve the performance
of the proposed descriptor. Finally, we show promising preliminary results by
appending our CNNs with recently proposed spatial transformer networks and
provide a visualisation and interpretation of their impact.
</dc:description>
 <dc:description>Comment: The paper was published in ACCV 2016 Workshops proceedings (Workshop
  on Interpretation and Visualization of Deep Neural Nets)</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11359</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11370</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capacity-Achieving PIR Schemes with Optimal Sub-Packetization</dc:title>
 <dc:creator>Zhang, Zhifang</dc:creator>
 <dc:creator>Xu, Jingke</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Suppose a database containing $M$ records is replicated across $N$ servers,
and a user wants to privately retrieve one record by accessing the servers such
that identity of the retrieved record is secret against any up to $T$ servers.
A scheme designed for this purpose is called a private information retrieval
(PIR) scheme. In practice, capacity-achieving and small sub-packetization are
both desired for PIR schemes, because the former implies the highest download
rate and the latter usually means simple realization.
  For general values of $N,T,M$, the only known capacity-achieving PIR scheme
was designed by Sun and Jafar in 2016 with sub-packetization $N^M$. In this
paper, we design a linear capacity-achieving PIR scheme with much smaller
sub-packetization $dn^{M-1}$, where $d={\rm gcd}(N,T)$ and $n=N/d$.
Furthermore, we prove that for any linear capacity-achieving PIR scheme it must
have sub-packetization no less than $dn^{M-1}$, implying our scheme has the
optimal sub-packetization. Moreover, comparing with Sun and Jafar's scheme, our
scheme reduces the field size by a factor of $\frac{1}{Nd^{M-2}}$.
</dc:description>
 <dc:description>Comment: 16pages</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11370</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11374</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Computer Vision System to Localize and Classify Wastes on the Streets</dc:title>
 <dc:creator>Rad, Mohammad Saeed</dc:creator>
 <dc:creator>von Kaenel, Andreas</dc:creator>
 <dc:creator>Droux, Andre</dc:creator>
 <dc:creator>Tieche, Francois</dc:creator>
 <dc:creator>Ouerhani, Nabil</dc:creator>
 <dc:creator>Ekenel, Hazim Kemal</dc:creator>
 <dc:creator>Thiran, Jean-Philippe</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Littering quantification is an important step for improving cleanliness of
cities. When human interpretation is too cumbersome or in some cases
impossible, an objective index of cleanliness could reduce the littering by
awareness actions. In this paper, we present a fully automated computer vision
application for littering quantification based on images taken from the streets
and sidewalks. We have employed a deep learning based framework to localize and
classify different types of wastes. Since there was no waste dataset available,
we built our acquisition system mounted on a vehicle. Collected images
containing different types of wastes. These images are then annotated for
training and benchmarking the developed system. Our results on real case
scenarios show accurate detection of littering on variant backgrounds.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11374</dc:identifier>
 <dc:identifier>Liu M., Chen H., Vincze M. (eds) Computer Vision Systems. pp
  195-204. ICVS 2017. Lecture Notes in Computer Science, vol 10528. Springer,
  Cham</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-68345-4_18</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11376</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Cache Resource Allocation and Request Routing for In-network
  Caching Services</dc:title>
 <dc:creator>Chu, Weibo</dc:creator>
 <dc:creator>Dehghan, Mostafa</dc:creator>
 <dc:creator>Lui, John C. S.</dc:creator>
 <dc:creator>Towsley, Don</dc:creator>
 <dc:creator>Zhang, Zhi-Li</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In-network caching is recognized as an effective solution to offload content
servers and the network. A cache service provider (SP) always has incentives to
better utilize its cache resources by taking into account diverse roles that
content providers (CPs) play, e.g., their business models, traffic
characteristics, preferences. In this paper, we study the cache resource
allocation problem in a Multi-Cache Multi-CP environment. We propose a cache
partitioning approach, where each cache can be partitioned into slices with
each slice dedicated to a content provider. We propose a content-oblivious
request routing algorithm, to be used by individual caches, that optimizes the
routing strategy for each CP. We associate with each content provider a utility
that is a function of its content delivery performance, and formulate an
optimization problem with the objective to maximize the sum of utilities over
all content providers. We establish the biconvexity of the problem, and develop
decentralized (online) algorithms based on convexity of the subproblem. The
proposed model is further extended to bandwidth-constrained and minimum-delay
scenarios, for which we prove fundamental properties, and develop efficient
algorithms. Finally, we present numerical results to show the efficacy of our
mechanism and the convergence of our algorithms.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2017-12-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11376</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11381</identifier>
 <datestamp>2018-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Interpolation in Implicit Models</dc:title>
 <dc:creator>Kilcher, Yannic</dc:creator>
 <dc:creator>Lucchi, Aurelien</dc:creator>
 <dc:creator>Hofmann, Thomas</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In implicit models, one often interpolates between sampled points in latent
space. As we show in this paper, care needs to be taken to match-up the
distributional assumptions on code vectors with the geometry of the
interpolating paths. Otherwise, typical assumptions about the quality and
semantics of in-between points may not be justified. Based on our analysis we
propose to modify the prior code distribution to put significantly more
probability mass closer to the origin. As a result, linear interpolation paths
are not only shortest paths, but they are also guaranteed to pass through
high-density regions, irrespective of the dimensionality of the latent space.
Experiments on standard benchmark image datasets demonstrate clear visual
improvements in the quality of the generated samples and exhibit more
meaningful interpolation paths.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2018-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11383</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flexible Prior Distributions for Deep Generative Models</dc:title>
 <dc:creator>Kilcher, Yannic</dc:creator>
 <dc:creator>Lucchi, Aurelien</dc:creator>
 <dc:creator>Hofmann, Thomas</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of training generative models with deep neural
networks as generators, i.e. to map latent codes to data points. Whereas the
dominant paradigm combines simple priors over codes with complex deterministic
models, we argue that it might be advantageous to use more flexible code
distributions. We demonstrate how these distributions can be induced directly
from the data. The benefits include: more powerful generative models, better
modeling of latent structure and explicit control of the degree of
generalization.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1707.09241</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2018-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11385</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Audio style transfer</dc:title>
 <dc:creator>Grinstein, Eric</dc:creator>
 <dc:creator>Duong, Ngoc</dc:creator>
 <dc:creator>Ozerov, Alexey</dc:creator>
 <dc:creator>Perez, Patrick</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  &quot;Style transfer&quot; among images has recently emerged as a very active research
topic, fuelled by the power of convolution neural networks (CNNs), and has
become fast a very popular technology in social media. This paper investigates
the analogous problem in the audio domain: How to transfer the style of a
reference audio signal to a target audio content? We propose a flexible
framework for the task, which uses a sound texture model to extract statistics
characterizing the reference audio style, followed by an optimization-based
audio texture synthesis to modify the target content. In contrast to mainstream
optimization-based visual transfer method, the proposed process is initialized
by the target content instead of random noise and the optimized loss is only
about texture, not structure. These differences proved key for audio style
transfer in our experiments. In order to extract features of interest, we
investigate different architectures, whether pre-trained on other tasks, as
done in image style transfer, or engineered based on the human auditory system.
Experimental results on different types of audio signal confirm the potential
of the proposed approach.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11385</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11386</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parametrizing filters of a CNN with a GAN</dc:title>
 <dc:creator>Kilcher, Yannic</dc:creator>
 <dc:creator>Becigneul, Gary</dc:creator>
 <dc:creator>Hofmann, Thomas</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  It is commonly agreed that the use of relevant invariances as a good
statistical bias is important in machine-learning. However, most approaches
that explicitly incorporate invariances into a model architecture only make use
of very simple transformations, such as translations and rotations. Hence,
there is a need for methods to model and extract richer transformations that
capture much higher-level invariances. To that end, we introduce a tool
allowing to parametrize the set of filters of a trained convolutional neural
network with the latent space of a generative adversarial network. We then show
that the method can capture highly non-linear invariances of the data by
visualizing their effect in the data space.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11395</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Slashdot Zoo: Mining a Social Network with Negative Edges</dc:title>
 <dc:creator>Kunegis, J&#xe9;r&#xf4;me</dc:creator>
 <dc:creator>Lommatzsch, Andreas</dc:creator>
 <dc:creator>Bauckhage, Christian</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>H.4.0</dc:subject>
 <dc:description>  We analyse the corpus of user relationships of the Slashdot technology news
site. The data was collected from the Slashdot Zoo feature where users of the
website can tag other users as friends and foes, providing positive and
negative endorsements. We adapt social network analysis techniques to the
problem of negative edge weights. In particular, we consider signed variants of
global network characteristics such as the clustering coefficient, node-level
characteristics such as centrality and popularity measures, and link-level
characteristics such as distances and similarity measures. We evaluate these
measures on the task of identifying unpopular users, as well as on the task of
predicting the sign of links and show that the network exhibits multiplicative
transitivity which allows algebraic methods based on matrix multiplication to
be used. We compare our methods to traditional methods which are only suitable
for positively weighted edges.
</dc:description>
 <dc:description>Comment: 10 pages, color, accepted at WWW 2009</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11395</dc:identifier>
 <dc:identifier>Proc. WWW 2009</dc:identifier>
 <dc:identifier>doi:10.1145/1526709.1526809</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11397</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Updating the VESICLE-CNN Synapse Detector</dc:title>
 <dc:creator>Warrington, Andrew</dc:creator>
 <dc:creator>Wood, Frank</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present an updated version of the VESICLE-CNN algorithm presented by
Roncal et al. (2014). The original implementation makes use of a patch-based
approach. This methodology is known to be slow due to repeated computations. We
update this implementation to be fully convolutional through the use of dilated
convolutions, recovering the expanded field of view achieved through the use of
strided maxpools, but without a degradation of spatial resolution. This updated
implementation performs as well as the original implementation, but with a
$600\times$ speedup at test time. We release source code and data into the
public domain.
</dc:description>
 <dc:description>Comment: Submitted as two side extended abstract to NIPS 2017 workshop:
  BigNeuro 2017: Analyzing brain data from nano to macroscale</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11397</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11403</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collaborative Spatial Reuse in Wireless Networks via Selfish Multi-Armed
  Bandits</dc:title>
 <dc:creator>Wilhelmi, Francesc</dc:creator>
 <dc:creator>Cano, Cristina</dc:creator>
 <dc:creator>Neu, Gergely</dc:creator>
 <dc:creator>Bellalta, Boris</dc:creator>
 <dc:creator>Jonsson, Anders</dc:creator>
 <dc:creator>Barrachina-Mu&#xf1;oz, Sergio</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Next-generation wireless deployments are characterized by being dense and
uncoordinated, which often leads to inefficient use of resources and poor
performance. To solve this, we envision the utilization of completely
decentralized mechanisms that enhance Spatial Reuse (SR). In particular, we
concentrate in Reinforcement Learning (RL), and more specifically, in
Multi-Armed Bandits (MABs), to allow networks to modify both their transmission
power and channel based on their experienced throughput. In this work, we study
the exploration-exploitation trade-off by means of the $\varepsilon$-greedy,
EXP3, UCB and Thompson sampling action-selection strategies. Our results show
that optimal proportional fairness can be achieved, even if no information
about neighboring networks is available to the learners and WNs operate
selfishly. However, there is high temporal variability in the throughput
experienced by the individual networks, specially for $\varepsilon$-greedy and
EXP3. We identify the cause of this variability to be the adversarial setting
of our setup in which the set of most played actions provide intermittent
good/poor performance depending on the neighboring decisions. We also show that
this variability is reduced using UCB and Thompson sampling, which are
parameter-free policies that perform exploration according to the reward
distribution of each action.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11403</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11404</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reshaping Cellular Networks for the Sky: The Major Factors and
  Feasibility</dc:title>
 <dc:creator>Azari, Mohammad Mahdi</dc:creator>
 <dc:creator>Rosas, Fernando</dc:creator>
 <dc:creator>Pollin, Sofie</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we investigate the feasibility of using the existing cellular
infrastructure for drone operations. To this end, we derive an exact expression
for the coverage probability of the ground and drone users by considering a
practical cell association strategy. Our analytical framework includes base
station (BS) height and antenna radiation pattern, drone antenna directivity,
and the impact of various propagation environments. We identify several of the
system factors that play major and minor roles. Our results show that in
contrast to the ground users, the impact of noise and non-line-of-sight (NLoS)
components for the evaluation of drone performance are negligible and hence the
coverage probability can be significantly simplified. We investigate trade-offs
resulted from altitude-dependent variation in the aggregate interference, the
BSs antenna gain, and the number of LoS BSs seen by a drone. Finally, the
impact of network densification is studied which shows the coverage performance
of a drone converges to zero considerably faster than that of a ground user,
however, lowering the drone flying altitude significantly improves its
performance in a very dense network.
</dc:description>
 <dc:description>Comment: Related Works: 1- arXiv:1710.03103, 2- arXiv:1708.06598</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11404</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11408</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Scaled Smart City for Experimental Validation of Connected and
  Automated Vehicles</dc:title>
 <dc:creator>Stager, Adam</dc:creator>
 <dc:creator>Bhan, Luke</dc:creator>
 <dc:creator>Malikopoulos, Andreas</dc:creator>
 <dc:creator>Zhao, Liuhui</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The common thread that characterizes energy efficient mobility systems for
smart cities is their interconnectivity which enables the exchange of massive
amounts of data; this, in turn, provides the opportunity to develop a
decentralized framework to process this information and deliver real-time
control actions that optimize energy consumption and other associated benefits.
To seize these opportunities, this paper describes the development of a scaled
smart city providing a glimpse that bridges the gap between simulation and full
scale implementation of energy efficient mobility systems. Using this testbed,
we can quickly, safely, and affordably experimentally validate control concepts
aimed at enhancing our understanding of the implications of next generation
mobility systems.
</dc:description>
 <dc:description>Comment: Submitted to 2018 IFAC CTS</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11408</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11414</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Bounds for Online Dominating Sets of Trees</dc:title>
 <dc:creator>Kobayashi, Koji M.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The online dominating set problem is an online variant of the minimum
dominating set problem, which is one of the most important NP-hard problems on
graphs. This problem is defined as follows: Given an undirected graph $G = (V,
E)$, in which $V$ is a set of vertices and $E$ is a set of edges. We say that a
set $D \subseteq V$ of vertices is a {\em dominating set} of $G$ if for each $v
\in V \setminus D$, there exists a vertex $u \in D$ such that $\{ u, v \} \in
E$. The vertices are revealed to an online algorithm one by one over time. When
a vertex is revealed, edges between the vertex and vertices revealed in the
past are also revealed. A revelaed subtree is connected at any time.
Immediately after the revelation of each vertex, an online algorithm can choose
vertices which were already revealed irrevocably and must maintain a dominating
set of a graph revealed so far. The cost of an algorithm on a given tree is the
number of vertices chosen by it, and its objective is to minimize the cost.
Eidenbenz (Technical report, Institute of Theoretical Computer Science, ETH
Z\&quot;{u}rich, 2002) and Boyar et al.\ (SWAT 2016) studied the case in which given
graphs are trees. They designed a deterministic online algorithm whose
competitive ratio is at most three, and proved that a lower bound on the
competitive ratio of any deterministic algorithm is two. In this paper, we also
focus on trees. We establish a matching lower bound for any deterministic
algorithm. Moreover, we design a randomized online algorithm whose competitive
ratio is at most $5/2 = 2.5$, and show that the competitive ratio of any
randomized algorithm is at least $4/3 \approx 1.333$.
</dc:description>
 <dc:description>Comment: An extended abstract of this paper appears in Proc. of ISAAC 2017</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11414</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11417</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TreeQN and ATreeC: Differentiable Tree Planning for Deep Reinforcement
  Learning</dc:title>
 <dc:creator>Farquhar, Gregory</dc:creator>
 <dc:creator>Rockt&#xe4;schel, Tim</dc:creator>
 <dc:creator>Igl, Maximilian</dc:creator>
 <dc:creator>Whiteson, Shimon</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Combining deep model-free reinforcement learning with on-line planning is a
promising approach to building on the successes of deep RL. On-line planning
with look-ahead trees has proven successful in environments where transition
models are known a priori. However, in complex environments where transition
models need to be learned from data, the deficiencies of learned models have
limited their utility for planning. To address these challenges, we propose
TreeQN, a differentiable, recursive, tree-structured model that serves as a
drop-in replacement for any value function network in deep RL with discrete
actions. TreeQN dynamically constructs a tree by recursively applying a
transition model in a learned abstract state space and then aggregating
predicted rewards and state-values using a tree backup to estimate Q-values. We
also propose ATreeC, an actor-critic variant that augments TreeQN with a
softmax layer to form a stochastic policy network. Both approaches are trained
end-to-end, such that the learned model is optimised for its actual use in the
planner. We show that TreeQN and ATreeC outperform n-step DQN and A2C on a
box-pushing task, as well as n-step DQN and value prediction networks (Oh et
al., 2017) on multiple Atari games, with deeper trees often outperforming
shallower ones. We also present a qualitative analysis that sheds light on the
trees learned by TreeQN.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11417</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11418</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A SeqGAN for Polyphonic Music Generation</dc:title>
 <dc:creator>Lee, Sang-gil</dc:creator>
 <dc:creator>Hwang, Uiwon</dc:creator>
 <dc:creator>Min, Seonwoo</dc:creator>
 <dc:creator>Yoon, Sungroh</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  We propose an application of SeqGAN, generative adversarial networks for
discrete sequence generation, for creating polyphonic musical sequences.
Instead of monophonic melody generation suggested in the original work, we
present an efficient representation of polyphony MIDI file that captures chords
and melodies with dynamic timings simultaneously. The network can create
sequences that are musically coherent. We also report that careful tuning of
reinforcement learning signals of the model is crucial for general application.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11418</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11420</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Cooperative Computation and Interactive Communication for
  Relay-Assisted Mobile Edge Computing</dc:title>
 <dc:creator>Chen, Xihan</dc:creator>
 <dc:creator>Shi, Qingjiang</dc:creator>
 <dc:creator>Cai, Yunlong</dc:creator>
 <dc:creator>Zhao, Minjian</dc:creator>
 <dc:creator>Zhao, Mingjie</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  To realize cooperative computation and communication in a relay mobile edge
computing system, we develop a hybrid relay forward protocol, where we seek to
balance the execution delay and network energy consumption. The problem is
formulated as a nondifferentible optimization problem which is nonconvex with
highly coupled constraints. By exploiting the problem structure, we propose a
lightweight algorithm based on inexact block coordinate descent method. Our
results show that the proposed algorithm exhibits much faster convergence as
compared with the popular concave-convex procedure based algorithm, while
achieving good performance.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11423</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DynSGX: A Privacy Preserving Toolset for Dynamically Loading Functions
  into Intel(R) SGX Enclaves</dc:title>
 <dc:creator>Silva, Rodolfo</dc:creator>
 <dc:creator>Barbosa, Pedro</dc:creator>
 <dc:creator>Brito, Andrey</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Intel(R) Software Guard eXtensions (SGX) is a hardware-based technology for
ensuring security of sensitive data from disclosure or modification that
enables user-level applications to allocate protected areas of memory called
enclaves. Such memory areas are cryptographically protected even from code
running with higher privilege levels. This memory protection can be used to
develop secure and dependable applications, but the technology has some
limitations: ($i$) the code of an enclave is visible at load time, ($ii$)
libraries used by the code must be statically linked, and ($iii$) the protected
memory size is limited, demanding page swapping to be done when this limit is
exceeded. We present DynSGX, a privacy preserving tool that enables users and
developers to dynamically load and unload code to be executed inside SGX
enclaves. Such a technology makes possible that developers use public cloud
infrastructures to run applications based on sensitive code and data. Moreover,
we present a series of experiments that assess how applications dynamically
loaded by DynSGX perform in comparison to statically linked applications that
disregard privacy of the enclave code at load time.
</dc:description>
 <dc:description>Comment: Paper accepted on CloudCom 2017</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11423</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11424</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regret Minimization for Partially Observable Deep Reinforcement Learning</dc:title>
 <dc:creator>Jin, Peter H.</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:creator>Keutzer, Kurt</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Deep reinforcement learning algorithms that estimate state and state-action
value functions have been shown to be effective in a variety of challenging
domains, including learning control strategies from raw image pixels. However,
algorithms that estimate state and state-action value functions typically
assume a fully observed state and must compensate for partial or non-Markovian
observations by using finite-length frame-history observations or recurrent
networks. In this work, we propose a new deep reinforcement learning algorithm
based on counterfactual regret minimization that iteratively updates an
approximation to a cumulative clipped advantage function and is robust to
partially observed state. We demonstrate that on several partially observed
reinforcement learning tasks, this new class of algorithms can substantially
outperform strong baseline methods: on Pong with single-frame observations, and
on the challenging Doom (ViZDoom) and Minecraft (Malm\&quot;o) first-person
navigation benchmarks.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11424</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11428</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SVSGAN: Singing Voice Separation via Generative Adversarial Network</dc:title>
 <dc:creator>Fan, Zhe-Cheng</dc:creator>
 <dc:creator>Lai, Yen-Lin</dc:creator>
 <dc:creator>Jang, Jyh-Shing Roger</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Separating two sources from an audio mixture is an important task with many
applications. It is a challenging problem since only one signal channel is
available for analysis. In this paper, we propose a novel framework for singing
voice separation using the generative adversarial network (GAN) with a
time-frequency masking function. The mixture spectra is considered to be a
distribution and is mapped to the clean spectra which is also considered a
distribtution. The approximation of distributions between mixture spectra and
clean spectra is performed during the adversarial training process. In contrast
with current deep learning approaches for source separation, the parameters of
the proposed framework are first initialized in a supervised setting and then
optimized by the training procedure of GAN in an unsupervised setting.
Experimental results on three datasets (MIR-1K, iKala and DSD100) show that
performance can be improved by the proposed framework consisting of
conventional networks.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures, 1 table. Demo website:
  http://mirlab.org/demo/svsgan</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11428</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11429</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Behavioural Change Support Intelligent Transportation Applications</dc:title>
 <dc:creator>Bothos, Efthimios</dc:creator>
 <dc:creator>Magoutas, Babis</dc:creator>
 <dc:creator>Caulfield, Brian</dc:creator>
 <dc:creator>Tsirimpa, Athena</dc:creator>
 <dc:creator>Kamargianni, Maria</dc:creator>
 <dc:creator>Georgakis, Panagiotis</dc:creator>
 <dc:creator>Mentzas, Gregoris</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  This workshop invites researchers and practitioners to participate in
exploring behavioral change support intelligent transportation applications. We
welcome submissions that explore intelligent transportation systems (ITS),
which interact with travelers in order to persuade them or nudge them towards
sustainable transportation behaviors and decisions. Emerging opportunities
including the use of data and information generated by ITS and users' mobile
devices in order to render personalized, contextualized and timely transport
behavioral change interventions are in our focus. We invite submissions and
ideas from domains of ITS including, but not limited to, multi-modal journey
planners, advanced traveler information systems and in-vehicle systems. The
expected outcome will be a deeper understanding of the challenges and future
research directions with respect to behavioral change support through ITS.
</dc:description>
 <dc:description>Comment: Intelligent Transportation Systems Conference (ITSC) 2017 Workshop</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11429</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11431</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Physics-guided Neural Networks (PGNN): An Application in Lake
  Temperature Modeling</dc:title>
 <dc:creator>Karpatne, Anuj</dc:creator>
 <dc:creator>Watkins, William</dc:creator>
 <dc:creator>Read, Jordan</dc:creator>
 <dc:creator>Kumar, Vipin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper introduces a novel framework for learning data science models by
using the scientific knowledge encoded in physics-based models. This framework,
termed as physics-guided neural network (PGNN), leverages the output of
physics-based model simulations along with observational features to generate
predictions using a neural network architecture. Further, we present a novel
class of learning objective for training neural networks, which ensures that
the model predictions not only show lower errors on the training data but are
also \emph{consistent} with the known physics. We illustrate the effectiveness
of PGNN for the problem of lake temperature modeling, where physical
relationships between the temperature, density, and depth of water are used in
the learning of neural network model parameters. By using scientific knowledge
to guide the construction and learning of neural networks, we are able to show
that the proposed framework ensures better generalizability as well as physical
consistency of results.
</dc:description>
 <dc:description>Comment: submitted to SIAM International Conference on Data Mining 2018</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11431</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11438</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Neural Representations of Human Cognition across Many fMRI
  Studies</dc:title>
 <dc:creator>Mensch, Arthur</dc:creator>
 <dc:creator>Mairal, Julien</dc:creator>
 <dc:creator>Bzdok, Danilo</dc:creator>
 <dc:creator>Thirion, Bertrand</dc:creator>
 <dc:creator>Varoquaux, Ga&#xeb;l</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Cognitive neuroscience is enjoying rapid increase in extensive public
brain-imaging datasets. It opens the door to large-scale statistical models.
Finding a unified perspective for all available data calls for scalable and
automated solutions to an old challenge: how to aggregate heterogeneous
information on brain function into a universal cognitive system that relates
mental operations/cognitive processes/psychological tasks to brain networks? We
cast this challenge in a machine-learning approach to predict conditions from
statistical brain maps across different studies. For this, we leverage
multi-task learning and multi-scale dimension reduction to learn
low-dimensional representations of brain images that carry cognitive
information and can be robustly associated with psychological stimuli. Our
multi-dataset classification model achieves the best prediction performance on
several large reference datasets, compared to models without cognitive-aware
low-dimension representations, it brings a substantial performance boost to the
analysis of small datasets, and can be introspected to identify universal
template cognitive concepts.
</dc:description>
 <dc:description>Comment: Advances in Neural Information Processing Systems, Dec 2017, Long
  Beach, United States. 2017</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11438</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11439</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical Speech Enhancement Based on Probabilistic Integration of
  Variational Autoencoder and Non-Negative Matrix Factorization</dc:title>
 <dc:creator>Bando, Yoshiaki</dc:creator>
 <dc:creator>Mimura, Masato</dc:creator>
 <dc:creator>Itoyama, Katsutoshi</dc:creator>
 <dc:creator>Yoshii, Kazuyoshi</dc:creator>
 <dc:creator>Kawahara, Tatsuya</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper presents a statistical method of single-channel speech enhancement
that uses a variational autoencoder (VAE) as a prior distribution on clean
speech. A standard approach to speech enhancement is to train a deep neural
network (DNN) to take noisy speech as input and output clean speech. Although
this supervised approach requires a very large amount of pair data for
training, it is not robust against unknown environments. Another approach is to
use non-negative matrix factorization (NMF) based on basis spectra trained on
clean speech in advance and those adapted to noise on the fly. This
semi-supervised approach, however, causes considerable signal distortion in
enhanced speech due to the unrealistic assumption that speech spectrograms are
linear combinations of the basis spectra. Replacing the poor linear generative
model of clean speech in NMF with a VAE---a powerful nonlinear deep generative
model---trained on clean speech, we formulate a unified probabilistic
generative model of noisy speech. Given noisy speech as observed data, we can
sample clean speech from its posterior distribution. The proposed method
outperformed the conventional DNN-based method in unseen noisy environments.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures, version that Eqs. (9), (19), and (20) in v2
  (submitted to ICASSP 2018) are corrected. Samples available here:
  http://sap.ist.i.kyoto-u.ac.jp/members/yoshiaki/demo/vae-nmf/</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11439</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11442</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Model-Based Approach to Security Analysis for Cyber-Physical Systems</dc:title>
 <dc:creator>Bakirtzis, Georgios</dc:creator>
 <dc:creator>Carter, Bryan T.</dc:creator>
 <dc:creator>Elks, Carl R.</dc:creator>
 <dc:creator>Fleming, Cody H.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Evaluating the security of cyber-physical systems throughout their life cycle
is necessary to assure that they can be deployed and operated in
safety-critical applications, such as infrastructure, military, and
transportation. Most safety and security decisions that can have major effects
on mitigation strategy options after deployment are made early in the system's
life cycle. To allow for a cyber-vulnerability analysis before deployment, a
sufficient well-formed model has to be constructed. To construct such a model
we produce a taxonomy of attributes, that is, a generalized schema for system
attributes. This schema allows to capture the necessary specificity so that it
characterizes a possible but real system and can also map to the attack vector
space associated with the model's attributes. In this way, we can match
possible attack vectors and provide architectural mitigation at the design
phase. We present a model of a flight control system encoded in the Systems
Modeling Language, commonly known as SysML, and show agnosticism with respect
to the modeling language or tool used.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures, conference</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11442</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11445</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Hashing with Triplet Quantization Loss</dc:title>
 <dc:creator>Zhou, Yuefu</dc:creator>
 <dc:creator>Huang, Shanshan</dc:creator>
 <dc:creator>Zhang, Ya</dc:creator>
 <dc:creator>Wang, Yanfeng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  With the explosive growth of image databases, deep hashing, which learns
compact binary descriptors for images, has become critical for fast image
retrieval. Many existing deep hashing methods leverage quantization loss,
defined as distance between the features before and after quantization, to
reduce the error from binarizing features. While minimizing the quantization
loss guarantees that quantization has minimal effect on retrieval accuracy, it
unfortunately significantly reduces the expressiveness of features even before
the quantization. In this paper, we show that the above definition of
quantization loss is too restricted and in fact not necessary for maintaining
high retrieval accuracy. We therefore propose a new form of quantization loss
measured in triplets. The core idea of the triplet quantization loss is to
learn discriminative real-valued descriptors which lead to minimal loss on
retrieval accuracy after quantization. Extensive experiments on two widely used
benchmark data sets of different scales, CIFAR-10 and In-shop, demonstrate that
the proposed method outperforms the state-of-the-art deep hashing methods.
Moreover, we show that the compact binary descriptors obtained with triplet
quantization loss lead to very small performance drop after quantization.
</dc:description>
 <dc:description>Comment: 4 pages, to be presented at IEEE VCIP 2017</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11445</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11446</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Clothing Retrieval with Visual Attention Model</dc:title>
 <dc:creator>Wang, Zhonghao</dc:creator>
 <dc:creator>Gu, Yujun</dc:creator>
 <dc:creator>Zhang, Ya</dc:creator>
 <dc:creator>Zhou, Jun</dc:creator>
 <dc:creator>Gu, Xiao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Clothing retrieval is a challenging problem in computer vision. With the
advance of Convolutional Neural Networks (CNNs), the accuracy of clothing
retrieval has been significantly improved. FashionNet[1], a recent study,
proposes to employ a set of artificial features in the form of landmarks for
clothing retrieval, which are shown to be helpful for retrieval. However, the
landmark detection module is trained with strong supervision which requires
considerable efforts to obtain. In this paper, we propose a self-learning
Visual Attention Model (VAM) to extract attention maps from clothing images.
The VAM is further connected to a global network to form an end-to-end network
structure through Impdrop connection which randomly Dropout on the feature maps
with the probabilities given by the attention map. Extensive experiments on
several widely used benchmark clothing retrieval data sets have demonstrated
the promise of the proposed method. We also show that compared to the trivial
Product connection, the Impdrop connection makes the network structure more
robust when training sets of limited size are used.
</dc:description>
 <dc:description>Comment: 4 pages, to be presented at IEEE VCIP 2017</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11446</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11453</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Traffic Splitting Policy in LTE-based Heterogeneous Network</dc:title>
 <dc:creator>Taksande, Pradnya Kiri</dc:creator>
 <dc:creator>Roy, Arghyadip</dc:creator>
 <dc:creator>Karandikar, Abhay</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Dual Connectivity (DC) is a technique proposed to address the problem of
increased handovers in heterogeneous networks. In DC, a foreground User
Equipment (UE) with multiple transceivers has a possibility to connect to a
Macro eNodeB (MeNB) and a Small cell eNodeB (SeNB) simultaneously. In downlink
split bearer architecture of DC, a data radio bearer at MeNB gets divided into
two; one part is forwarded to the SeNB through a non-ideal backhaul link to the
UE, and the other part is forwarded by the MeNB. This may lead to an increase
in the total delay at the UE since different packets corresponding to a single
transmission may incur varying amounts of delays in the two different paths.
Since the resources in the MeNB are shared by background legacy users and
foreground users, DC may increase the blocking probability of background users.
Moreover, single connectivity to the small cell may increase the blocking
probability of foreground users. Therefore, we target to minimize the average
delay of the system subject to a constraint on the blocking probability of
background and foreground users. The optimal policy is computed and observed to
contain a threshold structure. The variation of average system delay is studied
for changes in different system parameters.
</dc:description>
 <dc:description>Comment: Conference</dc:description>
 <dc:date>2017-10-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11453</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11454</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Resource Allocation in Distributed Broadband Wireless
  Communication Systems</dc:title>
 <dc:creator>Yao, Yao</dc:creator>
 <dc:creator>Ali, Mustafa Mehmet</dc:creator>
 <dc:creator>Vakilinia, Shahin</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper is concerned with optimization of distributed broadband wireless
communication (BWC) systems. BWC systems contain a distributed antenna system
(DAS) connected to a base station with optical fiber. Distributed BWC systems
have been proposed as a solution to the power constraint problem in traditional
cellular networks. So far, the research on BWC systems have advanced on two
separate tracks, the design of the system to meet the quality of service
requirements (QoS) and optimization of the location of the DAS. In this paper,
we consider a combined optimization of BWC systems. We consider uplink
communications in distributed BWC systems with multiple levels of priority
traffic with arrivals and departures forming renewal processes. We develop an
analysis that determines packet delay violation probability for each priority
level as a function of the outage probability of the DAS through the
application of results from renewal theory. Then, we determine the optimal
locations of the antennas that minimize the antenna outage probability. We also
study the tradeoff between the packet delay violation probability and packet
loss probability. This work will be helpful in the designing of the distributed
BWC systems.
</dc:description>
 <dc:date>2017-10-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11454</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11455</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Energy-Aware WLAN Discovery Scheme for LTE HetNet</dc:title>
 <dc:creator>Deogun, Pravjyot Singh</dc:creator>
 <dc:creator>Roy, Arghyadip</dc:creator>
 <dc:creator>Karandikar, Abhay</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Recently, there has been significant interest in the integration and
co-existence of Third Generation Partnership Project (3GPP) Long Term Evolution
(LTE) with other Radio Access Technologies, like IEEE 802.11 Wireless Local
Area Networks (WLANs). Although, the inter-working of IEEE 802.11 WLANs with
3GPP LTE has indicated enhanced network performance in the context of capacity
and load balancing, the WLAN discovery scheme implemented in most of the
commercially available smartphones is very inefficient and results in high
battery drainage. In this paper, we have proposed an energy efficient WLAN
discovery scheme for 3GPP LTE and IEEE 802.11 WLAN inter-working scenario. User
Equipment (UE), in the proposed scheme, uses 3GPP network assistance along with
the results of past channel scans, to optimally select the next channels to
scan. Further, we have also developed an algorithm to accurately estimate the
UE's mobility state, using 3GPP network signal strength patterns. We have
implemented various discovery schemes in Android framework, to evaluate the
performance of our proposed scheme against other solutions in the literature.
Since, Android does not support selective scanning mode, we have implemented
modules in Android to enable selective scanning. Further, we have also used
simulation studies and justified the results using power consumption modeling.
The results from the field experiments and simulations have shown high power
savings using the proposed scanning scheme without any discovery performance
deterioration.
</dc:description>
 <dc:date>2017-10-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11455</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11458</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Breaking the Interference Barrier in Dense Wireless Networks with
  Interference Alignment</dc:title>
 <dc:creator>Dovelos, Konstantinos</dc:creator>
 <dc:creator>Bellalta, Boris</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A fundamental problem arising in dense wireless networks is the high
co-channel interference. Interference alignment (IA) was recently proposed as
an effective way to combat interference in wireless networks. The concept of
IA, though, is originated by the capacity study of interference channels and as
such, its performance is mainly gauged under ideal assumptions, such as
instantaneous and perfect channel state information (CSI) at all nodes, and
homogeneous signal-to-noise ratio (SNR) users, i.e., each user has the same
average SNR. Consequently, the performance of IA under realistic conditions has
not been completely investigated yet. In this paper, we aim at filling this gap
by providing a performance assessment of spatial IA in practical systems.
Specifically, we derive a closed-form expression for the IA average sum-rate
when CSI is acquired through training and users have heterogeneous SNR. A main
insight from our analysis is that IA can indeed provide significant spectral
efficiency gains over traditional approaches in a wide range of dense network
scenarios. To demonstrate this, we consider the examples of linear, grid and
random network topologies.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2017-12-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11458</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11460</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Investigating the effect of social groups in uni-directional pedestrian
  flow</dc:title>
 <dc:creator>Crociani, Luca</dc:creator>
 <dc:creator>Zeng, Yiping</dc:creator>
 <dc:creator>Gorrini, Andrea</dc:creator>
 <dc:creator>Vizzari, Giuseppe</dc:creator>
 <dc:creator>Song, Weiguo</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The influence of cohesion among members of dyads is investigated in scenarios
characterized by uni-directional flow by means of a discrete model: a corridor
and the egress from a room with a bottleneck of varying width are simulated.
The model manages the dynamics of simulated group members with an adaptive
mechanism, balancing the probability of movement according to the dispersion of
the group; the cohesion mechanism is calibrated through the parameters
$\kappa_c$ and $\delta$. All scenarios are simulated with two procedures:
(Proc. 1) population composed of individual pedestrians, in order to validate
the simulation model and to provide baseline data; (Proc. 2) population
including dyads (50% of the simulated pedestrians), in order to verify their
impact. In the corridor scenario, the presence of dyads causes a reduction of
the velocities and specific flow at medium-high densities. Egress from a square
room with a unique central exit produces results in line with recent studies in
the literature, but also shows that the dyads negatively affect the dynamics,
leading generally to a slower walking speed and a lower pedestrian flow.
Ignoring the presence of dyads would lead to an overestimation of egress flows.
</dc:description>
 <dc:description>Comment: Pre-print of a paper presented at the 12th International Conference
  on Traffic and Granular Flow - TGF 2017, 19-22 July 2017, Washington DC, USA
  (2017)</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11460</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11462</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Manipulation Strategies for the Rank Maximal Matching Problem</dc:title>
 <dc:creator>Ghosal, Pratik</dc:creator>
 <dc:creator>Paluch, Katarzyna</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider manipulation strategies for the rank-maximal matching problem. In
the rank-maximal matching problem we are given a bipartite graph $G = (A \cup
P, E)$ such that $A$ denotes a set of applicants and $P$ a set of posts. Each
applicant $a \in A$ has a preference list over the set of his neighbours in
$G$, possibly involving ties. Preference lists are represented by ranks on the
edges - an edge $(a,p)$ has rank $i$, denoted as $rank(a,p)=i$, if post $p$
belongs to one of $a$'s $i$-th choices. A rank-maximal matching is one in which
the maximum number of applicants is matched to their rank one posts and subject
to this condition, the maximum number of applicants is matched to their rank
two posts, and so on. A rank-maximal matching can be computed in $O(\min(c
\sqrt{n},n) m)$ time, where $n$ denotes the number of applicants, $m$ the
number of edges and $c$ the maximum rank of an edge in an optimal solution.
  A central authority matches applicants to posts. It does so using one of the
rank-maximal matchings. Since there may be more than one rank- maximal matching
of $G$, we assume that the central authority chooses any one of them randomly.
Let $a_1$ be a manipulative applicant, who knows the preference lists of all
the other applicants and wants to falsify his preference list so that he has a
chance of getting better posts than if he were truthful. In the first problem
addressed in this paper the manipulative applicant $a_1$ wants to ensure that
he is never matched to any post worse than the most preferred among those of
rank greater than one and obtainable when he is truthful. In the second problem
the manipulator wants to construct such a preference list that the worst post
he can become matched to by the central authority is best possible or in other
words, $a_1$ wants to minimize the maximal rank of a post he can become matched
to.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11462</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11469</identifier>
 <datestamp>2017-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Grouping-By-ID: Guarding Against Adversarial Domain Shifts</dc:title>
 <dc:creator>Heinze-Deml, Christina</dc:creator>
 <dc:creator>Meinshausen, Nicolai</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  When training a deep network for image classification, one can broadly
distinguish between two types of latent features that will drive the
classification. Following Gong et al. (2016), we can divide features into (i)
&quot;core&quot; features $X^{ci}$ whose distribution $P(X^{ci} | Y)$ does not change
substantially across domains and (ii) &quot;style&quot; or &quot;orthogonal&quot; features
$X^\perp$ whose distribution $P(X^\perp | Y)$ can change substantially across
domains. These latter orthogonal features would generally include features such
as position or brightness but also more complex ones like hair color or posture
for images of persons. We try to guard against future adversarial domain shifts
by ideally just using the &quot;core&quot; features for classification. In contrast to
previous work, we assume that the domain itself is not observed and hence a
latent variable, i.e. we cannot directly see the distributional change of
features across different domains. We do assume, however, that we can sometimes
observe a so-called ID variable. E.g. we might know that two images show the
same person, with ID referring to the identity of the person. The method
requires only a small fraction of images to have an ID variable. We provide a
causal framework for the problem by adding the ID variable to the model of Gong
et al. (2016). If two or more samples share the same class and identifier, then
we treat those samples as counterfactuals under different interventions on the
orthogonal features. Using this grouping-by-ID approach, we regularize the
network to provide near constant output across samples that share the same ID
by penalizing with an appropriate graph Laplacian. This substantially improves
performance in settings where domains change in terms of image quality,
brightness, color or posture and movement. We show links to questions of
interpretability, fairness, transfer learning and adversarial examples.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2017-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11469</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11471</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Server Allocation for Content Delivery Networks</dc:title>
 <dc:creator>Pattathil, Sarath</dc:creator>
 <dc:creator>Borkar, Vivek S.</dc:creator>
 <dc:creator>Kasbekar, Gaurav S.</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We propose a dynamic formulation of file-sharing networks in terms of an
average cost Markov decision process with constraints. By analyzing a
Whittle-like relaxation thereof, we propose an index policy in the spirit of
Whittle and compare it by simulations with other natural heuristics.
</dc:description>
 <dc:description>Comment: 25 pages, 10 figures</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:date>2017-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11471</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11473</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Resolution Fully Convolutional Neural Networks for Monaural Audio
  Source Separation</dc:title>
 <dc:creator>Grais, Emad M.</dc:creator>
 <dc:creator>Wierstorf, Hagen</dc:creator>
 <dc:creator>Ward, Dominic</dc:creator>
 <dc:creator>Plumbley, Mark D.</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>68T01</dc:subject>
 <dc:subject>H.5.5</dc:subject>
 <dc:subject>I.5</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.4.3</dc:subject>
 <dc:subject>I.4</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:description>  In deep neural networks with convolutional layers, each layer typically has
fixed-size/single-resolution receptive field (RF). Convolutional layers with a
large RF capture global information from the input features, while layers with
small RF size capture local details with high resolution from the input
features. In this work, we introduce novel deep multi-resolution fully
convolutional neural networks (MR-FCNN), where each layer has different RF
sizes to extract multi-resolution features that capture the global and local
details information from its input features. The proposed MR-FCNN is applied to
separate a target audio source from a mixture of many audio sources.
Experimental results show that using MR-FCNN improves the performance compared
to feedforward deep neural networks (DNNs) and single resolution deep fully
convolutional neural networks (FCNNs) on the audio source separation problem.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1703.08019</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11473</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11475</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Neural-Symbolic Approach to Natural Language Tasks</dc:title>
 <dc:creator>Huang, Qiuyuan</dc:creator>
 <dc:creator>Smolensky, Paul</dc:creator>
 <dc:creator>He, Xiaodong</dc:creator>
 <dc:creator>Deng, Li</dc:creator>
 <dc:creator>Wu, Dapeng</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Deep learning (DL) has in recent years been widely used in natural language
processing (NLP) applications due to its superior performance. However, while
natural languages are rich in grammatical structure, DL has not been able to
explicitly represent and enforce such structures. This paper proposes a new
architecture to bridge this gap by exploiting tensor product representations
(TPR), a structured neural-symbolic framework developed in cognitive science
over the past 20 years, with the aim of integrating DL with explicit language
structures and rules. We call it the Tensor Product Generation Network (TPGN),
and apply it to 1) image captioning, 2) classification of the part of speech of
a word, and 3) identification of the phrase structure of a sentence. The key
ideas of TPGN are: 1) unsupervised learning of role-unbinding vectors of words
via a TPR-based deep neural network, and 2) integration of TPR with typical DL
architectures including Long Short-Term Memory (LSTM) models. The novelty of
our approach lies in its ability to generate a sentence and extract partial
grammatical structure of the sentence by using role-unbinding vectors, which
are obtained in an unsupervised manner. Experimental results demonstrate the
effectiveness of the proposed approach.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1709.09118</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11475</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11478</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Convergent Algorithm for Bi-orthogonal Nonnegative Matrix
  Tri-Factorization</dc:title>
 <dc:creator>Mirzal, Andri</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We extend our previous work on a convergent algorithm for uni-orthogonal
nonnegative matrix factorization (UNMF) to the case where the data matrix is
decomposed into three factors with two of them are constrained orthogonally and
the third one is used to absorb the approximation error. Due to the way the
factorization is performed, we name it as bi-orthogonal nonnegative matrix
tri-factorization, i.e., BNMtF. This factorization was first introduced by Ding
et al. (2006) with intent to further improve clustering capability of their
version of UNMF. However, as shown in this paper, not only their BNMtF
algorithm does not have convergent property but also it does not minimize the
objective function it intends to minimize. We tackle this problem by utilizing
a technique presented in our previous work and prove that our algorithm
converges to a stationary point inside the solution space. As a practical
demonstration, the proposed algorithm is utilized for clustering a text corpus;
however, contrary to the claim in the original work, both BNMtF algorithms (the
original one by Ding et al. (2006) and our proposed algorithm) perform poorly
compared to the standard NMF algorithm by Lee &amp; Seung (2000) and our UNMF
algorithm based on multiplicative update rules. This implies that the
additional complexity introduced by BNMtF which was originally intended to
improve UNMF clustering capability probably is not necessary.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1010.5290</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11478</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11486</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Path Cooperative Communications Networks for Augmented and Virtual
  Reality Transmission</dc:title>
 <dc:creator>Ge, Xiaohu</dc:creator>
 <dc:creator>Pan, Linghui</dc:creator>
 <dc:creator>Li, Qiang</dc:creator>
 <dc:creator>Mao, Guoqiang</dc:creator>
 <dc:creator>Tu, Song</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Augmented and/or virtual reality (AR/VR) are emerging as one of the main
applications in future fifth generation (5G) networks. To meet the requirements
of lower latency and massive data transmission in AR/VR applications, a
solution with software-defined networking (SDN) architecture is proposed for 5G
small cell networks. On this basis, a multi-path cooperative route (MCR) scheme
is proposed to facilitate the AR/VR wireless transmissions in 5G small cell
networks, in which the delay of MCR scheme is analytically studied.
Furthermore, a service effective energy optimal (SEEO) algorithm is developed
for AR/VR wireless transmission in 5G small cell networks. Simulation results
indicate that both the delay and service effective energy (SEE) of the proposed
MCR scheme outperform the delay and SEE of the conventional single path route
scheme in 5G small cell networks.
</dc:description>
 <dc:description>Comment: 30 pages, 10 figures</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11486</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11500</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The equational theory of the natural join and inner union is decidable</dc:title>
 <dc:creator>Santocanale, Luigi</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  The natural join and the inner union operations combine relations of a
database. Tropashko and Spight [24] realized that these two operations are the
meet and join operations in a class of lattices, known by now as the relational
lattices. They proposed then lattice theory as an algebraic approach to the
theory of databases, alternative to the relational algebra. Previous works [17,
22] proved that the quasiequational theory of these lattices-that is, the set
of definite Horn sentences valid in all the relational lattices-is undecidable,
even when the signature is restricted to the pure lattice signature. We prove
here that the equational theory of relational lattices is decidable. That, is
we provide an algorithm to decide if two lattice theoretic terms t, s are made
equal under all intepretations in some relational lattice. We achieve this goal
by showing that if an inclusion t $\le$ s fails in any of these lattices, then
it fails in a relational lattice whose size is bound by a triple exponential
function of the sizes of t and s.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1607.02988</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11500</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11507</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-scale study of social network structure and team performance in a
  multiplayer online game</dc:title>
 <dc:creator>Ukkonen, Antti</dc:creator>
 <dc:creator>Hamari, Juho</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  A question of interest in both theory and practice is if and how familiarity
between members of a team, expressed in terms of social network structure,
relates to the success of the team in a given task. In this paper we revisit
this important question in a novel manner by employing game outcome statistics
from Dota 2, a popular team-based multiplayer online game, combined with
network data from Steam Community, a social networking service for gamers. We
conduct a large-scale analysis of 4168 teams to study how network density, and
the minimum and maximum degree of the within-team social network are associated
with team performance, and determine how this association is moderated by team
skill. We observe that minimum degree is strongly associated with good
performance, especially in teams with lower skill. Together with previous
results on network density that we corroborate in this paper, our findings
suggest that a successful team is not only moderately connected overall, but
its members should also individually have not too few nor too many within team
connections.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11507</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11510</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A multi-layer network based on Sparse Ternary Codes for universal vector
  compression</dc:title>
 <dc:creator>Ferdowsi, Sohrab</dc:creator>
 <dc:creator>Voloshynovskiy, Slava</dc:creator>
 <dc:creator>Kostadinov, Dimche</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We present the multi-layer extension of the Sparse Ternary Codes (STC) for
fast similarity search where we focus on the reconstruction of the database
vectors from the ternary codes. To consider the trade-offs between the
compactness of the STC and the quality of the reconstructed vectors, we study
the rate-distortion behavior of these codes under different setups. We show
that a single-layer code cannot achieve satisfactory results at high rates.
Therefore, we extend the concept of STC to multiple layers and design the
ML-STC, a codebook-free system that successively refines the reconstruction of
the residuals of previous layers. While the ML-STC keeps the sparse ternary
structure of the single-layer STC and hence is suitable for fast similarity
search in large-scale databases, we show its superior rate-distortion
performance on both model-based synthetic data and public large-scale
databases, as compared to several binary hashing methods.
</dc:description>
 <dc:description>Comment: Submitted to ICASSP 2018</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11510</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11513</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Designing RNA Secondary Structures is Hard</dc:title>
 <dc:creator>Bonnet, &#xc9;douard</dc:creator>
 <dc:creator>Rz&#x105;&#x17c;ewski, Pawe&#x142;</dc:creator>
 <dc:creator>Sikora, Florian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Quantitative Biology - Biomolecules</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  An RNA sequence is a word over an alphabet on four elements $\{A,C,G,U\}$
called bases. RNA sequences fold into secondary structures where some bases
match one another while others remain unpaired. Pseudoknot-free secondary
structures can be represented as well-parenthesized expressions with additional
dots, where pairs of matching parentheses symbolize paired bases and dots,
unpaired bases. The two fundamental problems in RNA algorithmic are to predict
how sequences fold within some model of energy and to design sequences of bases
which will fold into targeted secondary structures. Predicting how a given RNA
sequence folds into a pseudoknot-free secondary structure is known to be
solvable in cubic time since the eighties and in truly subcubic time by a
recent result of Bringmann et al. (FOCS 2016). As a stark contrast, it is
unknown whether or not designing a given RNA secondary structure is a tractable
task; this has been raised as a challenging open question by Anne Condon (ICALP
2003). Because of its crucial importance in a number of fields such as
pharmaceutical research and biochemistry, there are dozens of heuristics and
software libraries dedicated to RNA secondary structure design. It is therefore
rather surprising that the computational complexity of this central problem in
bioinformatics has been unsettled for decades.
  In this paper we show that, in the simplest model of energy which is the
Watson-Crick model the design of secondary structures is NP-complete if one
adds natural constraints of the form: index $i$ of the sequence has to be
labeled by base $b$. This negative result suggests that the same lower bound
holds for more realistic models of energy. It is noteworthy that the additional
constraints are by no means artificial: they are provided by all the RNA design
pieces of software and they do correspond to the actual practice.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11513</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11516</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the List-Decodability of Random Linear Rank-Metric Codes</dc:title>
 <dc:creator>Guruswami, Venkatesan</dc:creator>
 <dc:creator>Resch, Nicolas</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The list-decodability of random linear rank-metric codes is shown to match
that of random rank-metric codes. Specifically, an $\mathbb{F}_q$-linear
rank-metric code over $\mathbb{F}_q^{m \times n}$ of rate $R =
(1-\rho)(1-\frac{n}{m}\rho)-\varepsilon$ is shown to be (with high probability)
list-decodable up to fractional radius $\rho \in (0,1)$ with lists of size at
most $\frac{C_{\rho,q}}{\varepsilon}$, where $C_{\rho,q}$ is a constant
depending only on $\rho$ and $q$. This matches the bound for random rank-metric
codes (up to constant factors). The proof adapts the approach of Guruswami,
H\aa stad, Kopparty (STOC 2010), who established a similar result for the
Hamming metric case, to the rank-metric setting.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11516</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11523</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy Efficiency of Multi-user Multi-antenna Random Cellular Networks
  with Minimum Distance Constraints</dc:title>
 <dc:creator>Ge, Xiaohu</dc:creator>
 <dc:creator>Du, Bangzheng</dc:creator>
 <dc:creator>Li, Qiang</dc:creator>
 <dc:creator>Michalopoulos, Diomidis S.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Compared with conventional regular hexagonal cellular models, random cellular
network models resemble real cellular networks much more closely. However, most
studies of random cellular networks are based on the Poisson point process and
do not take into account the fact that adjacent base stations (BSs) should be
separated with a minimum distance to avoid strong interference among each
other. In this paper, based on the hard core point process (HCPP), we propose a
multi-user multi-antenna random cellular network model with the aforementioned
minimum distance constraint for adjacent BSs. Taking into account the effects
of small scale fading and shadowing, interference and capacity models are
derived for the multi-user multi-antenna HCPP random cellular networks.
Furthermore, a spectrum efficiency model as well as an energy efficiency model
is presented, based on which, the maximum achievable energy efficiency of the
considered multi-user multiantenna HCPP random cellular networks is
investigated. Simulation results demonstrate that the energy efficiency of
conventional Poison point process (PPP) cellular networks is underestimated
when the minimum distance between adjacent BSs is ignored.
</dc:description>
 <dc:description>Comment: 13 pages, 11 figures</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11523</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11527</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>5G Ultra-dense networks with non-uniform Distributed Users</dc:title>
 <dc:creator>Ye, Junliang</dc:creator>
 <dc:creator>Ge, Xiaohu</dc:creator>
 <dc:creator>Mao, Guoqiang</dc:creator>
 <dc:creator>Zhong, Yi</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  User distribution in ultra-dense networks (UDNs) plays a crucial role in
affecting the performance of UDNs due to the essential coupling between the
traffic and the service provided by the networks. Existing studies are mostly
based on the assumption that users are uniformly distributed in space. The
non-uniform user distribution has not been widely considered despite that it is
much closer to the real scenario. In this paper, Radiation and Absorbing model
(R&amp;A model) is first adopted to analyze the impact of the non-uniformly
distributed users on the performance of 5G UDNs. Based on the R&amp;A model and
queueing network theory, the stationary user density in each hot area is
investigated. Furthermore, the coverage probability, network throughput and
energy efficiency are derived based on the proposed theoretical model. Compared
with the uniformly distributed assumption, it is shown that non-uniform user
distribution has a significant impact on the performance of UDNs.
</dc:description>
 <dc:description>Comment: 14 pages, 10 figures</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11527</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11528</identifier>
 <datestamp>2017-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extracting Syntactic Patterns from Databases</dc:title>
 <dc:creator>Ilyas, Andrew</dc:creator>
 <dc:creator>da Trindade, Joana M. F.</dc:creator>
 <dc:creator>Fernandez, Raul Castro</dc:creator>
 <dc:creator>Madden, Samuel</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Many database columns contain string or numerical data that conforms to a
pattern, such as phone numbers, dates, addresses, product identifiers, and
employee ids. These patterns are useful in a number of data processing
applications, including understanding what a specific field represents when
field names are ambiguous, identifying outlier values, and finding similar
fields across data sets. One way to express such patterns would be to learn
regular expressions for each field in the database. Unfortunately, exist- ing
techniques on regular expression learning are slow, taking hundreds of seconds
for columns of just a few thousand values. In contrast, we develop XSystem, an
efficient method to learn patterns over database columns in significantly less
time. We show that these patterns can not only be built quickly, but are
expressive enough to capture a number of key applications, including detecting
outliers, measuring column similarity, and assigning semantic labels to columns
(based on a library of regular expressions). We evaluate these applications
with datasets that range from chemical databases (based on a collaboration with
a pharmaceutical company), our university data warehouse, and open data from
MassData.gov.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2017-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11528</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11531</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SemTK: An Ontology-first, Open Source Semantic Toolkit for Managing and
  Querying Knowledge Graphs</dc:title>
 <dc:creator>Cuddihy, Paul</dc:creator>
 <dc:creator>McHugh, Justin</dc:creator>
 <dc:creator>Williams, Jenny Weisenberg</dc:creator>
 <dc:creator>Mulwad, Varish</dc:creator>
 <dc:creator>Aggour, Kareem S.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The relatively recent adoption of Knowledge Graphs as an enabling technology
in multiple high-profile artificial intelligence and cognitive applications has
led to growing interest in the Semantic Web technology stack. Many
semantics-related tools, however, are focused on serving experts with a deep
understanding of semantic technologies. For example, triplification of
relational data is available but there is no open source tool that allows a
user unfamiliar with OWL/RDF to import data into a semantic triple store in an
intuitive manner. Further, many tools require users to have a working
understanding of SPARQL to query data. Casual users interested in benefiting
from the power of Knowledge Graphs have few tools available for exploring,
querying, and managing semantic data. We present SemTK, the Semantics Toolkit,
a user-friendly suite of tools that allow both expert and non-expert semantics
users convenient ingestion of relational data, simplified query generation, and
more. The exploration of ontologies and instance data is performed through
SPARQLgraph, an intuitive web-based user interface in SemTK understandable and
navigable by a lay user. The open source version of SemTK is available at
http://semtk.research.ge.com.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11531</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11539</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Core Members Aided Community Structure Detection</dc:title>
 <dc:creator>Fan, Xiaoping</dc:creator>
 <dc:creator>Chen, Zhijie</dc:creator>
 <dc:creator>Cai, Fei</dc:creator>
 <dc:creator>Wu, Jinsong</dc:creator>
 <dc:creator>Liu, Shengzong</dc:creator>
 <dc:creator>Liao, Zhining</dc:creator>
 <dc:creator>Liao, Zhifang</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The relationship of friends in social networks can be strong or weak. Some
research works have shown that a close relationship between friends conducts
good community structure. Based on this result, we propose an effective method
in detecting community structure in social networks based on the closeness of
relations among neighbors. This method calculates the gravity between each
neighbor node to core nodes, then makes judgement if the node should be
classified in the community or not, and finally form the process of community
detection. The experimental results show that the proposed method can mine the
social structure efficiently with a low computational complexity
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11539</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11540</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Prediction Model of the Project Life-span in Open Source Software
  Ecosystem</dc:title>
 <dc:creator>Liao, Zhifang</dc:creator>
 <dc:creator>Zhao, Benhong</dc:creator>
 <dc:creator>Liu, Shengzong</dc:creator>
 <dc:creator>Jin, Haozhi</dc:creator>
 <dc:creator>He, Dayu</dc:creator>
 <dc:creator>Yang, Liu</dc:creator>
 <dc:creator>Wu, Jinsong</dc:creator>
 <dc:creator>Zhang, Yan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In nature ecosystems, animal life-spans are determined by genes and some
other biological characteristics. Similarly, the software project life-spans
are related to some internal or external characteristics. Analyzing the
relations between these characteristics and the project life-span, may help
developers, investors, and contributors to control the development cycle of the
software project. The paper provides an insight on the project life-span for a
free open source software ecosystem. The statistical analysis of some project
characteristics in GitHub is presented, and we find that the choices of
programming languages, the number of files, the label format of the project,
and the relevant membership expressions can impact the life-span of a project.
Based on these discovered characteristics, we also propose a prediction model
to estimate the project life-span in open source software ecosystems. These
results may help developers reschedule the project in open source software
ecosystem.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11540</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11547</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compact Multi-Class Boosted Trees</dc:title>
 <dc:creator>Ponomareva, Natalia</dc:creator>
 <dc:creator>Colthurst, Thomas</dc:creator>
 <dc:creator>Hendry, Gilbert</dc:creator>
 <dc:creator>Haykal, Salem</dc:creator>
 <dc:creator>Radpour, Soroush</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Gradient boosted decision trees are a popular machine learning technique, in
part because of their ability to give good accuracy with small models. We
describe two extensions to the standard tree boosting algorithm designed to
increase this advantage. The first improvement extends the boosting formalism
from scalar-valued trees to vector-valued trees. This allows individual trees
to be used as multiclass classifiers, rather than requiring one tree per class,
and drastically reduces the model size required for multiclass problems. We
also show that some other popular vector-valued gradient boosted trees
modifications fit into this formulation and can be easily obtained in our
implementation. The second extension, layer-by-layer boosting, takes smaller
steps in function space, which is empirically shown to lead to a faster
convergence and to a more compact ensemble. We have added both improvements to
the open-source TensorFlow Boosted trees (TFBT) package, and we demonstrate
their efficacy on a variety of multiclass datasets. We expect these extensions
will be of particular interest to boosted tree applications that require small
models, such as embedded devices, applications requiring fast inference, or
applications desiring more interpretable models.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE Big Data 2017
  http://cci.drexel.edu/bigdata/bigdata2017/AcceptedPapers.html</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11548</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complex Systems Science meets 5G and IoT</dc:title>
 <dc:creator>Marchetti, Nicola</dc:creator>
 <dc:creator>Macaluso, Irene</dc:creator>
 <dc:creator>Kaminski, Nicholas</dc:creator>
 <dc:creator>Dzaferagic, Merim</dc:creator>
 <dc:creator>Butt, M. Majid</dc:creator>
 <dc:creator>Ruffini, Marco</dc:creator>
 <dc:creator>Friedner, Saul</dc:creator>
 <dc:creator>Bradford, Julie</dc:creator>
 <dc:creator>Zanella, Andrea</dc:creator>
 <dc:creator>Zorzi, Michele</dc:creator>
 <dc:creator>Doyle, Linda</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We propose a new paradigm for telecommunications, and develop a framework
drawing on concepts from information (i.e., different metrics of complexity)
and computational (i.e., agent based modeling) theory, adapted from complex
system science. We proceed in a systematic fashion by dividing network
complexity understanding and analysis into different layers. Modelling layer
forms the foundation of the proposed framework, supporting analysis and tuning
layers. The modelling layer aims at capturing the significant attributes of
networks and the interactions that shape them, through the application of tools
such as agent-based modelling and graph theoretical abstractions, to derive new
metrics that holistically describe a network. The analysis phase completes the
core functionality of the framework by linking our new metrics to the overall
network performance. The tuning layer augments this core with algorithms that
aim at automatically guiding networks toward desired conditions. In order to
maximize the impact of our ideas, the proposed approach is rooted in relevant,
near-future architectures and use cases in 5G networks, i.e., Internet of
Things (IoT) and self-organizing cellular networks.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11548</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11549</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Melody Generation for Pop Music via Word Representation of Musical
  Properties</dc:title>
 <dc:creator>Shin, Andrew</dc:creator>
 <dc:creator>Crestel, Leopold</dc:creator>
 <dc:creator>Kato, Hiroharu</dc:creator>
 <dc:creator>Saito, Kuniaki</dc:creator>
 <dc:creator>Ohnishi, Katsunori</dc:creator>
 <dc:creator>Yamaguchi, Masataka</dc:creator>
 <dc:creator>Nakawaki, Masahiro</dc:creator>
 <dc:creator>Ushiku, Yoshitaka</dc:creator>
 <dc:creator>Harada, Tatsuya</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Automatic melody generation for pop music has been a long-time aspiration for
both AI researchers and musicians. However, learning to generate euphonious
melody has turned out to be highly challenging due to a number of factors.
Representation of multivariate property of notes has been one of the primary
challenges. It is also difficult to remain in the permissible spectrum of
musical variety, outside of which would be perceived as a plain random play
without auditory pleasantness. Observing the conventional structure of pop
music poses further challenges. In this paper, we propose to represent each
note and its properties as a unique `word,' thus lessening the prospect of
misalignments between the properties, as well as reducing the complexity of
learning. We also enforce regularization policies on the range of notes, thus
encouraging the generated melody to stay close to what humans would find easy
to follow. Furthermore, we generate melody conditioned on song part
information, thus replicating the overall structure of a full song.
Experimental results demonstrate that our model can generate auditorily
pleasant songs that are more indistinguishable from human-written ones than
previous models.
</dc:description>
 <dc:description>Comment: submitted to ICLR 2018</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11549</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11550</identifier>
 <datestamp>2018-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings of the Data For Good Exchange 2017</dc:title>
 <dc:creator>Meerkamp, Philipp</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  These are the proceedings of the Data For Good Exchange 2017, which was held
in New York, NY, on September 24th 2017.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2018-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11550</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11553</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sturmian numeration systems and decompositions to palindromes</dc:title>
 <dc:creator>Frid, Anna</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>68R15</dc:subject>
 <dc:description>  We extend the classical Ostrowski numeration systems, closely related to
Sturmian words, by allowing a wider range of coefficients, so that possible
representations of a number $n$ better reflect the structure of the associated
Sturmian word. In particular, this extended numeration system helps to catch
occurrences of palindromes in a characteristic Sturmian word and thus to prove
for Sturmian words the following conjecture stated in 2013 by Puzynina, Zamboni
and the author: If a word is not periodic, then for every $Q&gt;0$ it has a prefix
which cannot be decomposed to a concatenation of at most $Q$ palindromes.
</dc:description>
 <dc:description>Comment: Submitted to European Journal of Combinatorics</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11553</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11555</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TF Boosted Trees: A scalable TensorFlow based framework for gradient
  boosting</dc:title>
 <dc:creator>Ponomareva, Natalia</dc:creator>
 <dc:creator>Radpour, Soroush</dc:creator>
 <dc:creator>Hendry, Gilbert</dc:creator>
 <dc:creator>Haykal, Salem</dc:creator>
 <dc:creator>Colthurst, Thomas</dc:creator>
 <dc:creator>Mitrichev, Petr</dc:creator>
 <dc:creator>Grushetsky, Alexander</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  TF Boosted Trees (TFBT) is a new open-sourced frame-work for the distributed
training of gradient boosted trees. It is based on TensorFlow, and its
distinguishing features include a novel architecture, automatic loss
differentiation, layer-by-layer boosting that results in smaller ensembles and
faster prediction, principled multi-class handling, and a number of
regularization techniques to prevent overfitting.
</dc:description>
 <dc:description>Comment: European Conference on Machine Learning and Principles and Practice
  of Knowledge Discovery in Databases (ECML PKDD 2017). The final publication
  will be available at link.springer.com and is available on ECML website
  http://ecmlpkdd2017.ijs.si/papers/paperID705.pdf</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11555</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11557</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>First Programming Language: Visual or Textual?</dc:title>
 <dc:creator>Noone, Mark</dc:creator>
 <dc:creator>Mooney, Aidan</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  In modern day society, the ability to code is a highly desirable skill. So
much so that the current supply from third level institutes across the world
does not meet the high demands of industry. One of the major issues is the low
progression rates from first to second year in third level Computer Science
courses with introductory programming courses proving to be a high contributing
factor. This is something that needs to be addressed. One such way to address
the issue is to get children involved and engaged with computing at young ages.
  This paper describes a study undertaken that is the first step in a body of
work that aims to garner the interest of potential Computer Science students at
an early age. The study involves a comparison of two short courses; one based
in Java and one based in Snap. The goal is to determine whether either of these
languages is a better first programming language for students than the other,
or if both are viable. These languages were chosen to allow for a comparison
between a Visual Programming Language and a Textual Programming Language.
  Feedback in the form of a survey will be used to gather the opinions of the
students. This will provide data on issues such as which language was easier to
learn and which language was preferred amongst others. Based on the outcomes of
this study, a full-scale curriculum will be developed in the coming year. The
outcomes of this study will help to establish which is the best programming
language to suit the learning needs of students.
</dc:description>
 <dc:description>Comment: 14 pages including 1 page Appendix, 8 figures</dc:description>
 <dc:date>2017-10-24</dc:date>
 <dc:date>2017-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11557</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11559</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Implicit Theories and Self-efficacy in an Introductory Programming
  Course</dc:title>
 <dc:creator>Tek, F. Boray</dc:creator>
 <dc:creator>Benli, Kristin S.</dc:creator>
 <dc:creator>Deveci, Ezgi</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Contribution: This study examined student effort and performance in an
introductory programming course with respect to student-held implicit theories
and self-efficacy. Background: Implicit theories and self-efficacy shed a light
into understanding academic success, which must be considered when developing
effective learning strategies for programming. Research Questions: Are implicit
theories of intelligence and programming, and programming-efficacy related to
each other and student success in programming? Is it possible to predict
student course performance using a subset of these constructs? Methodology: Two
consecutive surveys (N=100 and N=81) were administered to non-CS engineering
students in I\c{s}{\i}k University. Findings: Implicit theories and
self-beliefs are interrelated and correlated with effort, performance, and
previous failures in the course and students explain failure in programming
course with &quot;programming-aptitude is fixed&quot; theory, and also that programming
is a difficult task for themselves.
</dc:description>
 <dc:description>Comment: Programming Education. 8 pages</dc:description>
 <dc:date>2017-10-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11559</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11564</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cyber-Automotive Simulation and Evaluation Platform for Vehicular Value
  Added Services</dc:title>
 <dc:creator>Sattiraju, Raja</dc:creator>
 <dc:creator>Chakraborty, Pratip</dc:creator>
 <dc:creator>Schotten, Hans D.</dc:creator>
 <dc:creator>Lin, Xiaohai</dc:creator>
 <dc:creator>G&#xf6;rges, Daniel</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  An easily moving and safe transportation is an indicator in any country in
the world of economic growth and well-being. For the past 100 years, innovation
within the automotive sector has brought major technological advances leading
to safer, cleaner and more affordable vehicles. But for the most time since the
inception of the moving assembly line for vehicle production by Henry Ford, the
changes have been incremental / evolutionary. Thanks to the new possibilities
due to the IT / wireless revolution, the automotive industry appears to be on
the cusp of revolutionary change with potential to dramatically reshape not
just the competitive landscape but also the way we interact with vehicles, and
indeed the future design of our roads and cities. Apart from connected personal
mobility, vehicles are also envisioned to provide Value Added Services (VAS)
such as autonomous driving via Vehicle-to-Vehicle (V2V) and
Vehicle-to-infrastructure (V2I), electric load balancing via Vehicle-to-Grid
(V2G) solutions, communication solutions using Visible Light Communications
(VLC) etc. The development and evaluation of vehicular VAS requires a modular
and scalable multidisciplinary simulation platform. In this paper we propose a
novel simulation platform named Cyber-Automotive Simulation \&amp; Evaluation
Platform (CASEP). The purpose of CASEP is to evaluate and visualize the gains
of various vehicular VAS with special emphasis on commercial vehicle VAS. The
use cases are evaluated with respect to the mission-specific performance
indicators, thereby providing usable metrics for optimization. The
visualization platform is being developed using the UNITY 3D engine, thereby
enabling intuitive interaction as in real physics-based games
</dc:description>
 <dc:description>Comment: published in the Commercial Vehicle Technology Symposium 2016</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11571</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploratory Study of the Privacy Extension for System Theoretic Process
  Analysis (STPA-Priv) to elicit Privacy Risks in eHealth</dc:title>
 <dc:creator>Mindermann, Kai</dc:creator>
 <dc:creator>Riedel, Frederik</dc:creator>
 <dc:creator>Abdulkhaleq, Asim</dc:creator>
 <dc:creator>Stach, Christoph</dc:creator>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Context: System Theoretic Process Analysis for Privacy (STPA-Priv) is a novel
privacy risk elicitation method using a top down approach. It has not gotten
very much attention but may offer a convenient structured approach and
generation of additional artifacts compared to other methods. Aim: The aim of
this exploratory study is to find out what benefits the privacy risk
elicitation method STPA-Priv has and to explain how the method can be used.
Method: Therefore we apply STPA-Priv to a real world health scenario that
involves a smart glucose measurement device used by children. Different kinds
of data from the smart device including location data should be shared with the
parents, physicians, and urban planners. This makes it a sociotechnical system
that offers adequate and complex privacy risks to be found. Results: We find
out that STPA-Priv is a structured method for privacy analysis and finds
complex privacy risks. The method is supported by a tool called XSTAMPP which
makes the analysis and its results more profound. Additionally, we learn that
an iterative application of the steps might be necessary to find more privacy
risks when more information about the system is available later. Conclusions:
STPA-Priv helps to identify complex privacy risks that are derived from
sociotechnical interactions in a system. It also outputs privacy constraints
that are to be enforced by the system to ensure privacy.
</dc:description>
 <dc:description>Comment: author's post-print</dc:description>
 <dc:date>2017-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11571</dc:identifier>
 <dc:identifier>2017 IEEE 25th International Requirements Engineering Conference
  Workshops (REW), 2017, 90-96</dc:identifier>
 <dc:identifier>doi:10.1109/REW.2017.30</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11573</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning as a Mixed Convex-Combinatorial Optimization Problem</dc:title>
 <dc:creator>Friesen, Abram L.</dc:creator>
 <dc:creator>Domingos, Pedro</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  As neural networks grow deeper and wider, learning networks with
hard-threshold activations is becoming increasingly important, both for network
quantization, which can drastically reduce time and energy requirements, and
for creating large integrated systems of deep networks, which may have
non-differentiable components and must avoid vanishing and exploding gradients
for effective learning. However, since gradient descent is not applicable to
hard-threshold functions, it is not clear how to learn them in a principled
way. We address this problem by observing that setting targets for
hard-threshold hidden units in order to minimize loss is a discrete
optimization problem, and can be solved as such. The discrete optimization goal
is to find a set of targets such that each unit, including the output, has a
linearly separable problem to solve. Given these targets, the network
decomposes into individual perceptrons, which can then be learned with standard
convex approaches. Based on this, we develop a recursive mini-batch algorithm
for learning deep hard-threshold networks that includes the popular but poorly
justified straight-through estimator as a special case. Empirically, we show
that our algorithm improves classification accuracy in a number of settings,
including for AlexNet and ResNet-18 on ImageNet, when compared to the
straight-through estimator.
</dc:description>
 <dc:description>Comment: 14 pages (9 body, 5 pages of references and appendices)</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11573</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11577</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Graph Convolution Filters from Data Manifold</dc:title>
 <dc:creator>Lai, Guokun</dc:creator>
 <dc:creator>Liu, Hanxiao</dc:creator>
 <dc:creator>Yang, Yiming</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Convolution Neural Network (CNN) has gained tremendous success in computer
vision tasks with its outstanding ability to capture the local latent features.
Recently, there has been an increasing interest in extending CNNs to the
general spatial domain. Although various types of graph and geometric
convolution methods have been proposed, their connections to traditional
2D-convolution are not well-understood. In this paper, we show that depthwise
separable convolution is the key to close the gap, based on which we derive a
novel Depthwise Separable Graph Convolution that subsumes existing graph
convolution methods as special cases of our formulation. Experiments show that
the proposed approach consistently outperforms other graph and geometric
convolution baselines on benchmark datasets in multiple domains.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11577</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11583</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Why (and How) Networks Should Run Themselves</dc:title>
 <dc:creator>Feamster, Nick</dc:creator>
 <dc:creator>Rexford, Jennifer</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The proliferation of networked devices, systems, and applications that we
depend on every day makes managing networks more important than ever. The
increasing security, availability, and performance demands of these
applications suggest that these increasingly difficult network management
problems be solved in real time, across a complex web of interacting protocols
and systems. Alas, just as the importance of network management has increased,
the network has grown so complex that it is seemingly unmanageable. In this new
era, network management requires a fundamentally new approach. Instead of
optimizations based on closed-form analysis of individual protocols, network
operators need data-driven, machine-learning-based models of end-to-end and
application performance based on high-level policy goals and a holistic view of
the underlying components. Instead of anomaly detection algorithms that operate
on offline analysis of network traces, operators need classification and
detection algorithms that can make real-time, closed-loop decisions. Networks
should learn to drive themselves. This paper explores this concept, discussing
how we might attain this ambitious goal by more closely coupling measurement
with real-time control and by relying on learning for inference and prediction
about a networked application or system, as opposed to closed-form analysis of
individual protocols.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11590</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-Aware Virtual Network Embedding Approach for Distributed Cloud</dc:title>
 <dc:creator>Alzahrani, Amal S.</dc:creator>
 <dc:creator>Shahin, Ashraf A.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Network virtualization has caught the attention of many researchers in recent
years. It facilitates the process of creating several virtual networks over a
single physical network. Despite this advantage, however, network
virtualization suffers from the problem of mapping virtual links and nodes to
physical network in most efficient way. This problem is called virtual network
embedding (&quot;VNE&quot;). Many researches have been proposed in an attempt to solve
this problem, which have many optimization aspects, such as improving embedding
strategies in a way that preserves energy, reducing embedding cost and
increasing embedding revenue. Moreover, some researchers have extended their
algorithms to be more compatible with the distributed clouds instead of a
single infrastructure provider (&quot;ISP&quot;). This paper proposes energy aware
particle swarm optimization algorithm for distributed clouds. This algorithm
aims to partition each virtual network request (&quot;VNR&quot;) to subgraphs, using the
Heavy Clique Matching technique (&quot;HCM&quot;) to generate a coarsened graph. Each
coarsened node in the coarsened graph is assigned to a suitable data center
(&quot;DC&quot;). Inside each DC, a modified particle swarm optimization algorithm is
initiated to find the near optimal solution for the VNE problem. The proposed
algorithm was tested and evaluated against existing algorithms using extensive
simulations, which shows that the proposed algorithm outperforms other
algorithms.
</dc:description>
 <dc:description>Comment: International Journal of Advanced Computer Science and
  Applications(IJACSA)</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11590</dc:identifier>
 <dc:identifier>International Journal of Advanced Computer Science and
  Applications(IJACSA), 8(10), 2017</dc:identifier>
 <dc:identifier>doi:10.14569/IJACSA.2017.081031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11592</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Learning Mixtures of Well-Separated Gaussians</dc:title>
 <dc:creator>Regev, Oded</dc:creator>
 <dc:creator>Vijayaraghavan, Aravindan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We consider the problem of efficiently learning mixtures of a large number of
spherical Gaussians, when the components of the mixture are well separated. In
the most basic form of this problem, we are given samples from a uniform
mixture of $k$ standard spherical Gaussians, and the goal is to estimate the
means up to accuracy $\delta$ using $poly(k,d, 1/\delta)$ samples.
  In this work, we study the following question: what is the minimum separation
needed between the means for solving this task? The best known algorithm due to
Vempala and Wang [JCSS 2004] requires a separation of roughly
$\min\{k,d\}^{1/4}$. On the other hand, Moitra and Valiant [FOCS 2010] showed
that with separation $o(1)$, exponentially many samples are required. We
address the significant gap between these two bounds, by showing the following
results.
  1. We show that with separation $o(\sqrt{\log k})$, super-polynomially many
samples are required. In fact, this holds even when the $k$ means of the
Gaussians are picked at random in $d=O(\log k)$ dimensions.
  2. We show that with separation $\Omega(\sqrt{\log k})$, $poly(k,d,1/\delta)$
samples suffice. Note that the bound on the separation is independent of
$\delta$. This result is based on a new and efficient &quot;accuracy boosting&quot;
algorithm that takes as input coarse estimates of the true means and in time
$poly(k,d, 1/\delta)$ outputs estimates of the means up to arbitrary accuracy
$\delta$ assuming the separation between the means is $\Omega(\min\{\sqrt{\log
k},\sqrt{d}\})$ (independently of $\delta$).
  We also present a computationally efficient algorithm in $d=O(1)$ dimensions
with only $\Omega(\sqrt{d})$ separation. These results together essentially
characterize the optimal order of separation between components that is needed
to learn a mixture of $k$ spherical Gaussians with polynomial samples.
</dc:description>
 <dc:description>Comment: Appeared in FOCS 2017. 55 pages, 1 figure</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11592</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11595</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Partial Least Squares Random Forest Ensemble Regression as a Soft Sensor</dc:title>
 <dc:creator>Kneale, Casey</dc:creator>
 <dc:creator>Brown, Steven</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  Six simple, dynamic soft sensor methodologies with two update conditions were
compared on two experimentally-obtained datasets and one simulated dataset. The
soft sensors investigated were: moving window partial least squares regression
(and a recursive variant), moving window random forest regression, feedforward
neural networks, mean moving window, and a novel random forest partial least
squares regression ensemble (RF-PLS). We found that, on two of the datasets
studied, very small window sizes (4 samples) led to the lowest prediction
errors. The RF-PLS method offered the lowest one-step-ahead prediction errors
compared to those of the other methods, and demonstrated greater stability at
larger time lags than moving window PLS alone. We found that this method most
adequately modeled the datasets that did not feature purely monotonic increases
in property values. In general, we observed that linear models deteriorated
most rapidly at more delayed model update conditions while nonlinear methods
tended to provide predictions that approached those from a simple mean moving
window. Other data dependent findings are presented and discussed.
</dc:description>
 <dc:description>Comment: Rough draft</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11595</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11597</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sentiment Protocol: A Decentralized Protocol Leveraging Crowd Sourced
  Wisdom</dc:title>
 <dc:creator>Muehlemann, Anton</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The wisdom of the crowd is a valuable asset in today's society. It is not
only important in predicting elections but plays also an essential role in
marketing and the financial industry. Having a trustworthy source of opinion
can make forecasts more accurate and markets predictable. Until now, a
fundamental problem of surveys is the lack of incentives for participants to
provide accurate information. Classical solutions like small monetary rewards
or the chance of winning a prize are often not very attractive and also do not
prevent multiple entries or randomly filling in answers. In this work, we
present a framework that solves both problems via a customizable
incentivization framework.
</dc:description>
 <dc:description>Comment: 13 pages, 3 figures</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11597</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11599</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiple Instance Hybrid Estimator for Hyperspectral Target
  Characterization and Sub-pixel Target Detection</dc:title>
 <dc:creator>Jiao, Changzhe</dc:creator>
 <dc:creator>Zare, Alina</dc:creator>
 <dc:creator>McGarvey, Ronald G.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The Multiple Instance Hybrid Estimator for discriminative target
characterization from imprecisely labeled hyperspectral data is presented. In
many hyperspectral target detection problems, acquiring accurately labeled
training data is difficult. Furthermore, each pixel containing target is likely
to be a mixture of both target and non-target signatures (i.e., sub-pixel
targets), making extracting a pure prototype signature for the target class
from the data extremely difficult. The proposed approach addresses these
problems by introducing a data mixing model and optimizing the response of the
hybrid sub-pixel detector within a multiple instance learning framework. The
proposed approach iterates between estimating a set of discriminative target
and non-target signatures and solving a sparse unmixing problem. After learning
target signatures, a signature based detector can then be applied on test data.
Both simulated and real hyperspectral target detection experiments show the
proposed algorithm is effective at learning discriminative target signatures
and achieves superior performance over state-of-the-art comparison algorithms.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11599</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11601</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Whodunnit? Crime Drama as a Case for Natural Language Understanding</dc:title>
 <dc:creator>Frermann, Lea</dc:creator>
 <dc:creator>Cohen, Shay B.</dc:creator>
 <dc:creator>Lapata, Mirella</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we argue that crime drama exemplified in television programs
such as CSI:Crime Scene Investigation is an ideal testbed for approximating
real-world natural language understanding and the complex inferences associated
with it. We propose to treat crime drama as a new inference task, capitalizing
on the fact that each episode poses the same basic question (i.e., who
committed the crime) and naturally provides the answer when the perpetrator is
revealed. We develop a new dataset based on CSI episodes, formalize perpetrator
identification as a sequence labeling problem, and develop an LSTM-based model
which learns from multi-modal data. Experimental results show that an
incremental inference strategy is key to making accurate guesses as well as
learning from representations fusing textual, visual, and acoustic input.
</dc:description>
 <dc:description>Comment: To appear in Transactions of the Association for Computational
  Linguistics (TACL)</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11619</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cellular-Enabled UAV Communication: Trajectory Optimization Under
  Connectivity Constraint</dc:title>
 <dc:creator>Zhang, Shuowen</dc:creator>
 <dc:creator>Zeng, Yong</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study a cellular-enabled unmanned aerial vehicle (UAV)
communication system consisting of one UAV and multiple ground base stations
(GBSs). The UAV has a mission of flying from an initial location to a final
location, during which it needs to maintain reliable wireless connection with
the cellular network by associating with one of the GBSs at each time instant.
We aim to minimize the UAV mission completion time by optimizing its
trajectory, subject to a quality of connectivity constraint of the GBS-UAV link
specified by a minimum received signal-to-noise ratio (SNR) target, which needs
to be satisfied throughout the mission. This problem is non-convex and
difficult to be optimally solved. We first propose an effective approach to
check its feasibility based on graph connectivity verification. Then, by
examining the GBS-UAV association sequence during the UAV mission, we obtain
useful insights on the optimal UAV trajectory, based on which an efficient
algorithm is proposed to find an approximate solution to the trajectory
optimization problem by leveraging techniques in convex optimization and graph
theory. Numerical results show that our proposed trajectory design achieves
near-optimal performance.
</dc:description>
 <dc:description>Comment: submitted for possible conference publication</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11622</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Meta-Learning and Universality: Deep Representations and Gradient
  Descent can Approximate any Learning Algorithm</dc:title>
 <dc:creator>Finn, Chelsea</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Learning to learn is a powerful paradigm for enabling models to learn from
data more effectively and efficiently. A popular approach to meta-learning is
to train a recurrent model to read in a training dataset as input and output
the parameters of a learned model, or output predictions for new test inputs.
Alternatively, a more recent approach to meta-learning aims to acquire deep
representations that can be effectively fine-tuned, via standard gradient
descent, to new tasks. In this paper, we consider the meta-learning problem
from the perspective of universality, formalizing the notion of learning
algorithm approximation and comparing the expressive power of the
aforementioned recurrent models to the more recent approaches that embed
gradient descent into the meta-learner. In particular, we seek to answer the
following question: does deep representation combined with standard gradient
descent have sufficient capacity to approximate any learning algorithm? We find
that this is indeed true, and further find, in our experiments, that
gradient-based meta-learning consistently leads to learning strategies that
generalize more widely compared to those represented by recurrent models.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.11622</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00001</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gene Ontology (GO) Prediction using Machine Learning Methods</dc:title>
 <dc:creator>Wu, Haoze</dc:creator>
 <dc:creator>Zhou, Yangyu</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We applied machine learning to predict whether a gene is involved in axon
regeneration. We extracted 31 features from different databases and trained
five machine learning models. Our optimal model, a Random Forest Classifier
with 50 submodels, yielded a test score of 85.71%, which is 4.1% higher than
the baseline score. We concluded that our models have some predictive
capability. Similar methodology and features could be applied to predict other
Gene Ontology (GO) terms.
</dc:description>
 <dc:description>Comment: 14 pages, 8 figures, 3 tables</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00002</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Log-DenseNet: How to Sparsify a DenseNet</dc:title>
 <dc:creator>Hu, Hanzhang</dc:creator>
 <dc:creator>Dey, Debadeepta</dc:creator>
 <dc:creator>Del Giorno, Allison</dc:creator>
 <dc:creator>Hebert, Martial</dc:creator>
 <dc:creator>Bagnell, J. Andrew</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Skip connections are increasingly utilized by deep neural networks to improve
accuracy and cost-efficiency. In particular, the recent DenseNet is efficient
in computation and parameters, and achieves state-of-the-art predictions by
directly connecting each feature layer to all previous ones. However,
DenseNet's extreme connectivity pattern may hinder its scalability to high
depths, and in applications like fully convolutional networks, full DenseNet
connections are prohibitively expensive. This work first experimentally shows
that one key advantage of skip connections is to have short distances among
feature layers during backpropagation. Specifically, using a fixed number of
skip connections, the connection patterns with shorter backpropagation distance
among layers have more accurate predictions. Following this insight, we propose
a connection template, Log-DenseNet, which, in comparison to DenseNet, only
slightly increases the backpropagation distances among layers from 1 to ($1 +
\log_2 L$), but uses only $L\log_2 L$ total connections instead of $O(L^2)$.
Hence, Log-DenseNets are easier than DenseNets to implement and to scale. We
demonstrate the effectiveness of our design principle by showing better
performance than DenseNets on tabula rasa semantic segmentation, and
competitive results on visual recognition.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00003</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Common Representation Learning Using Step-based Correlation Multi-Modal
  CNN</dc:title>
 <dc:creator>Bhatt, Gaurav</dc:creator>
 <dc:creator>Jha, Piyush</dc:creator>
 <dc:creator>Raman, Balasubramanian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep learning techniques have been successfully used in learning a common
representation for multi-view data, wherein the different modalities are
projected onto a common subspace. In a broader perspective, the techniques used
to investigate common representation learning falls under the categories of
canonical correlation-based approaches and autoencoder based approaches. In
this paper, we investigate the performance of deep autoencoder based methods on
multi-view data. We propose a novel step-based correlation multi-modal CNN
(CorrMCNN) which reconstructs one view of the data given the other while
increasing the interaction between the representations at each hidden layer or
every intermediate step. Finally, we evaluate the performance of the proposed
model on two benchmark datasets - MNIST and XRMB. Through extensive
experiments, we find that the proposed model achieves better performance than
the current state-of-the-art techniques on joint common representation learning
and transfer learning tasks.
</dc:description>
 <dc:description>Comment: Accepted in Asian Conference of Pattern Recognition (ACPR-2017)</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00004</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerate RNN-based Training with Importance Sampling</dc:title>
 <dc:creator>Wang, Fei</dc:creator>
 <dc:creator>Gao, Xiaofeng</dc:creator>
 <dc:creator>Chen, Guihai</dc:creator>
 <dc:creator>Ye, Jun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Importance sampling (IS) as an elegant and efficient variance reduction (VR)
technique for the acceleration of stochastic optimization problems has
attracted many researches recently. Unlike commonly adopted stochastic uniform
sampling in stochastic optimizations, IS-integrated algorithms sample training
data at each iteration with respect to a weighted sampling probability
distribution $P$, which is constructed according to the precomputed importance
factors. Previous experimental results show that IS has achieved remarkable
progresses in the acceleration of training convergence. Unfortunately, the
calculation of the sampling probability distribution $P$ causes a major
limitation of IS: it requires the input data to be well-structured, i.e., the
feature vector is properly defined. Consequently, recurrent neural networks
(RNN) as a popular learning algorithm is not able to enjoy the benefits of IS
due to the fact that its raw input data, i.e., the training sequences, are
often unstructured which makes calculation of $P$ impossible. In considering of
the the popularity of RNN-based learning applications and their relative long
training time, we are interested in accelerating them through IS. This paper
propose a novel Fast-Importance-Mining algorithm to calculate the importance
factor for unstructured data which makes the application of IS in RNN-based
applications possible. Our experimental evaluation on popular open-source
RNN-based learning applications validate the effectiveness of IS in improving
the convergence rate of RNNs.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00005</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Optimization and Parallelization of a Parabolic Equation
  Solver in Computational Ocean Acoustics on Modern Many-core Computer</dc:title>
 <dc:creator>Xu, Min</dc:creator>
 <dc:creator>Wang, Yongxian</dc:creator>
 <dc:creator>Chronopoulos, Anthony Theodore</dc:creator>
 <dc:creator>Yue, Hao</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  As one of open-source codes widely used in computational ocean acoustics,
FOR3D can provide a very good estimate for underwater acoustic propagation. In
this paper, we propose a performance optimization and parallelization to speed
up the running of FOR3D. We utilized a variety of methods to enhance the entire
performance, such as using a multi-threaded programming model to exploit the
potential capability of the many-core node of high-performance computing (HPC)
system, tuning compile options, using efficient tuned mathematical library and
utilizing vectorization optimization instruction. In addition, we extended the
application from single-frequency calculation to multi-frequency calculation
successfully by using OpenMP+MPI hybrid programming techniques on the
mainstream HPC platform. A detailed performance evaluation was performed and
the results showed that the proposed parallelization obtained good accelerated
effect of 25.77X when testing a typical three-dimensional medium-sized case on
Tianhe-2 supercomputer. It also showed that the tuned parallel version has a
weak-scalability. The speed of calculation of underwater sound field can be
greatly improved by the strategy mentioned in this paper. The method used in
this paper is not only applicable to other similar computing models in
computational ocean acoustics but also a guideline of performance enhancement
for scientific and engineering application running on modern
many-core-computing platform.
</dc:description>
 <dc:description>Comment: 9 pages, 8 figures, 3 tables. preprint for the International
  Conference on Computer Science and Application Engineering (CSAE2017).
  2017.10.21-23, Shanghai, China</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00028</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hack Weeks as a model for Data Science Education and Collaboration</dc:title>
 <dc:creator>Huppenkothen, Daniela</dc:creator>
 <dc:creator>Arendt, Anthony</dc:creator>
 <dc:creator>Hogg, David W.</dc:creator>
 <dc:creator>Ram, Karthik</dc:creator>
 <dc:creator>VanderPlas, Jake</dc:creator>
 <dc:creator>Rokem, Ariel</dc:creator>
 <dc:subject>Physics - Physics Education</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Across almost all scientific disciplines, the instruments that record our
experimental data and the methods required for storage and data analysis are
rapidly increasing in complexity. This gives rise to the need for scientific
communities to adapt on shorter time scales than traditional university
curricula allow for, and therefore requires new modes of knowledge transfer.
The universal applicability of data science tools to a broad range of problems
has generated new opportunities to foster exchange of ideas and computational
workflows across disciplines. In recent years, hack weeks have emerged as an
effective tool for fostering these exchanges by providing training in modern
data analysis workflows. While there are variations in hack week
implementation, all events consist of a common core of three components:
tutorials in state-of-the-art methodology, peer-learning and project work in a
collaborative environment. In this paper, we present the concept of a hack week
in the larger context of scientific meetings and point out similarities and
differences to traditional conferences. We motivate the need for such an event
and present in detail its strengths and challenges. We find that hack weeks are
successful at cultivating collaboration and the exchange of knowledge.
Participants self-report that these events help them both in their day-to-day
research as well as their careers. Based on our results, we conclude that hack
weeks present an effective, easy-to-implement, fairly low-cost tool to
positively impact data analysis literacy in academic disciplines, foster
collaboration and cultivate best practices.
</dc:description>
 <dc:description>Comment: 15 pages, 2 figures, submitted to PNAS, all relevant code available
  at https://github.com/uwescience/HackWeek-Writeup</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00043</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Machine Translation Using Monolingual Corpora Only</dc:title>
 <dc:creator>Lample, Guillaume</dc:creator>
 <dc:creator>Denoyer, Ludovic</dc:creator>
 <dc:creator>Ranzato, Marc'Aurelio</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Machine translation has recently achieved impressive performance thanks to
recent advances in deep learning and the availability of large-scale parallel
corpora. There have been numerous attempts to extend these successes to
low-resource language pairs, yet requiring tens of thousands of parallel
sentences. In this work, we take this research direction to the extreme and
investigate whether it is possible to learn to translate even without any
parallel data. We propose a model that takes sentences from monolingual corpora
in two different languages and maps them into the same latent space. By
learning to reconstruct in both languages from this shared feature space, the
model effectively learns to translate without using any labeled data. We
demonstrate our model on two widely used datasets and two language pairs,
reporting BLEU scores up to 32.8, without using even a single parallel sentence
at training time.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00044</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>$K$-User Symmetric M$\times$N MIMO Interference Channel under Finite
  Precision CSIT: A GDoF perspective</dc:title>
 <dc:creator>Davoodi, Arash Gholami</dc:creator>
 <dc:creator>Jafar, Syed Ali</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Generalized Degrees of Freedom (GDoF) are characterized for the symmetric
$K$-user Multiple Input Multiple Output (MIMO) Interference Channel (IC) under
the assumption that the channel state information at the transmitters (CSIT) is
limited to finite precision. In this symmetric setting, each transmitter is
equipped with $M$ antennas, each receiver is equipped with $N$ antennas, each
desired channel (i.e., a channel between a transmit antenna and a receive
antenna belonging to the same user) has strength $\sim P$, while each undesired
channel has strength $\sim P^\alpha$, where $P$ is a nominal SNR parameter. The
result generalizes a previous GDoF characterization for the SISO setting
$(M=N=1)$ and is enabled by a significant extension of the Aligned Image Sets
bound that is broadly useful. GDoF per user take the form of a $W$-curve with
respect to $\alpha$ for fixed values of $M$ and $N$. Under finite precision
CSIT, in spite of the presence of multiple antennas, all the benefits of
interference alignment are lost.
</dc:description>
 <dc:description>Comment: 22 pages, 4 figures</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00046</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Replace or Retrieve Keywords In Documents at Scale</dc:title>
 <dc:creator>Singh, Vikash</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper we introduce, the FlashText algorithm for replacing keywords or
finding keywords in a given text. FlashText can search or replace keywords in
one pass over a document. The time complexity of this algorithm is not
dependent on the number of terms being searched or replaced. For a document of
size N (characters) and a dictionary of M keywords, the time complexity will be
O(N). This algorithm is much faster than Regex, because regex time complexity
is O(MxN). It is also different from Aho Corasick Algorithm, as it doesn't
match substrings. FlashText is designed to only match complete words (words
with boundary characters on both sides). For an input dictionary of {Apple},
this algorithm won't match it to 'I like Pineapple'. This algorithm is also
designed to go for the longest match first. For an input dictionary {Machine,
Learning, Machine learning} on a string 'I like Machine learning', it will only
consider the longest match, which is Machine Learning. We have made python
implementation of this algorithm available as open-source on GitHub, released
under the permissive MIT License.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00048</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Semi-Supervised Audio Source Separation applied to Singing
  Voice Extraction</dc:title>
 <dc:creator>Stoller, Daniel</dc:creator>
 <dc:creator>Ewert, Sebastian</dc:creator>
 <dc:creator>Dixon, Simon</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>H.5.5</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  The state of the art in music source separation employs neural networks
trained in a supervised fashion on multi-track databases to estimate the
sources from a given mixture. With only few datasets available, often extensive
data augmentation is used to combat overfitting. Mixing random tracks, however,
can even reduce separation performance as instruments in real music are
strongly correlated. The key concept in our approach is that source estimates
of an optimal separator should be indistinguishable from real source signals.
Based on this idea, we drive the separator towards outputs deemed as realistic
by discriminator networks that are trained to tell apart real from separator
samples. This way, we can also use unpaired source and mixture recordings
without the drawbacks of creating unrealistic music mixtures. Our framework is
widely applicable as it does not assume a specific network architecture or
number of sources. To our knowledge, this is the first adoption of adversarial
training for music source separation. In a prototype experiment for singing
voice separation, separation performance increases with our approach compared
to purely supervised training.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures, 1 table. Implementation will be published at a
  later date</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00048</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00049</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Medical Image Segmentation Based on Multi-Modal Convolutional Neural
  Network: Study on Image Fusion Schemes</dc:title>
 <dc:creator>Guo, Zhe</dc:creator>
 <dc:creator>Li, Xiang</dc:creator>
 <dc:creator>Huang, Heng</dc:creator>
 <dc:creator>Guo, Ning</dc:creator>
 <dc:creator>Li, Quanzheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Image analysis using more than one modality (i.e. multi-modal) has been
increasingly applied in the field of biomedical imaging. One of the challenges
in performing the multimodal analysis is that there exist multiple schemes for
fusing the information from different modalities, where such schemes are
application-dependent and lack a unified framework to guide their designs. In
this work we firstly propose a conceptual architecture for the image fusion
schemes in supervised biomedical image analysis: fusing at the feature level,
fusing at the classifier level, and fusing at the decision-making level.
Further, motivated by the recent success in applying deep learning for natural
image analysis, we implement the three image fusion schemes above based on the
Convolutional Neural Network (CNN) with varied structures, and combined into a
single framework. The proposed image segmentation framework is capable of
analyzing the multi-modality images using different fusing schemes
simultaneously. The framework is applied to detect the presence of soft tissue
sarcoma from the combination of Magnetic Resonance Imaging (MRI), Computed
Tomography (CT) and Positron Emission Tomography (PET) images. It is found from
the results that while all the fusion schemes outperform the single-modality
schemes, fusing at the feature level can generally achieve the best performance
in terms of both accuracy and computational cost, but also suffers from the
decreased robustness in the presence of large errors in any image modalities.
</dc:description>
 <dc:description>Comment: Zhe Guo and Xiang Li contribute equally to this work</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00054</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Abnormal Spatial-Temporal Pattern Analysis for Niagara Frontier Border
  Wait Times</dc:title>
 <dc:creator>Zhang, Zhenhua</dc:creator>
 <dc:creator>Lin, Lei</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Border crossing delays cause problems like huge economics loss and heavy
environmental pollutions. To understand more about the nature of border
crossing delay, this study applies a dictionary-based compression algorithm to
process the historical Niagara Frontier border wait times data. It can identify
the abnormal spatial-temporal patterns for both passenger vehicles and trucks
at three bridges connecting US and Canada. Furthermore, it provides a
quantitate anomaly score to rank the wait times patterns across the three
bridges for each vehicle type and each direction. By analyzing the top three
most abnormal patterns, we find that there are at least two factors
contributing the anomaly of the patterns. The weekends and holidays may cause
unusual heave congestions at the three bridges at the same time, and the
freight transportation demand may be uneven from Canada to the USA at Peace
Bridge and Lewiston-Queenston Bridge, which may lead to a high anomaly score.
By calculating the frequency of the top 5% abnormal patterns by hour of the
day, the results show that for cars from the USA to Canada, the frequency of
abnormal waiting time patterns is the highest during noon while for trucks in
the same direction, it is the highest during the afternoon peak hours. For
Canada to US direction, the frequency of abnormal border wait time patterns for
both cars and trucks reaches to the peak during the afternoon. The analysis of
abnormal spatial-temporal wait times patterns is promising to improve the
border crossing management
</dc:description>
 <dc:description>Comment: submitted to ITS World Congress 2017 Montreal</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00054</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00064</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Calibration for Stratified Classification Models</dc:title>
 <dc:creator>Zuo, Chandler</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In classification problems, sampling bias between training data and testing
data is critical to the ranking performance of classification scores. Such bias
can be both unintentionally introduced by data collection and intentionally
introduced by the algorithm, such as under-sampling or weighting techniques
applied to imbalanced data. When such sampling bias exists, using the raw
classification score to rank observations in the testing data can lead to
suboptimal results. In this paper, I investigate the optimal calibration
strategy in general settings, and develop a practical solution for one specific
sampling bias case, where the sampling bias is introduced by stratified
sampling. The optimal solution is developed by analytically solving the problem
of optimizing the ROC curve. For practical data, I propose a ranking algorithm
for general classification models with stratified data. Numerical experiments
demonstrate that the proposed algorithm effectively addresses the stratified
sampling bias issue. Interestingly, the proposed method shows its potential
applicability in two other machine learning areas: unsupervised learning and
model ensembling, which can be future research topics.
</dc:description>
 <dc:description>Comment: 14 pages, 12 figures</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00064</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00066</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fraternal Dropout</dc:title>
 <dc:creator>Zolna, Konrad</dc:creator>
 <dc:creator>Arpit, Devansh</dc:creator>
 <dc:creator>Suhubdy, Dendi</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recurrent neural networks (RNNs) are important class of architectures among
neural networks useful for language modeling and sequential prediction.
However, optimizing RNNs is known to be harder compared to feed-forward neural
networks. A number of techniques have been proposed in literature to address
this problem. In this paper we propose a simple technique called fraternal
dropout that takes advantage of dropout to achieve this goal. Specifically, we
propose to train two identical copies of an RNN (that share parameters) with
different dropout masks while minimizing the difference between their
(pre-softmax) predictions. In this way our regularization encourages the
representations of RNNs to be invariant to dropout mask, thus being robust. We
show that our regularization term is upper bounded by the expectation-linear
dropout objective which has been shown to address the gap due to the difference
between the train and inference phases of dropout. We evaluate our model and
achieve state-of-the-art results in sequence modeling tasks on two benchmark
datasets - Penn Treebank and Wikitext-2. We also show that our approach leads
to performance improvement by a significant margin in image captioning
(Microsoft COCO) and semi-supervised (CIFAR-10) tasks.
</dc:description>
 <dc:description>Comment: Added official GitHub code for replication. Added references.
  Corrected typos</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00066</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00068</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Stretch Factor of Hexagon-Delaunay Triangulations</dc:title>
 <dc:creator>Dennis, Michael</dc:creator>
 <dc:creator>Perkovi&#x107;, Ljubomir</dc:creator>
 <dc:creator>T&#xfc;rko&#x11f;lu, Duru</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  The problem of computing the exact stretch factor (i.e., the tight bound on
the worst case stretch factor) of a Delaunay triangulation has been open for
more than three decades. Over the years, a series of upper and lower bounds on
the exact stretch factor have been obtained but the gap between them is still
large. An alternative approach to solving the problem is to develop techniques
for computing the exact stretch factor of &quot;easier&quot; types of Delaunay
triangulations, in particular those defined using regular-polygons instead of a
circle. Tight bounds exist for Delaunay triangulations defined using an
equilateral triangle and a square. In this paper, we determine the exact
stretch factor of Delaunay triangulations defined using a hexagon instead of a
circle: It is 2. We think that the techniques we have developed may prove
useful in future work on computing the exact stretch factor of classical
Delaunay triangulations.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00068</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00073</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Long-term Forecasting using Tensor-Train RNNs</dc:title>
 <dc:creator>Yu, Rose</dc:creator>
 <dc:creator>Zheng, Stephan</dc:creator>
 <dc:creator>Anandkumar, Anima</dc:creator>
 <dc:creator>Yue, Yisong</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present Tensor-Train RNN (TT-RNN), a novel family of neural sequence
architectures for multivariate forecasting in environments with nonlinear
dynamics. Long-term forecasting in such systems is highly challenging, since
there exist long-term temporal dependencies, higher-order correlations and
sensitivity to error propagation. Our proposed tensor recurrent architecture
addresses these issues by learning the nonlinear dynamics directly using higher
order moments and high-order state transition functions. Furthermore, we
decompose the higher-order structure using the tensor-train (TT) decomposition
to reduce the number of parameters while preserving the model performance. We
theoretically establish the approximation properties of Tensor-Train RNNs for
general sequence inputs, and such guarantees are not available for usual RNNs.
We also demonstrate significant long-term prediction improvements over general
RNN and LSTM architectures on a range of simulated environments with nonlinear
dynamics, as well on real-world climate and traffic data.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00073</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00081</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximating the $2$-Machine Flow Shop Problem with Exact Delays Taking
  Two Values</dc:title>
 <dc:creator>Ageev, Alexander</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>68Q17</dc:subject>
 <dc:description>  In the $2$-Machine Flow Shop problem with exact delays the operations of each
job are separated by a given time lag (delay). Leung et al. (2007) established
that the problem is strongly NP-hard when the delays may have at most two
different values. We present further results for this case: we prove that the
existence of $(1.25-\varepsilon)$-approximation implies P$=$NP and present a
$2$-approximation algorithm.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00088</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Image Retrieval via Active Grounding of Visual Situations</dc:title>
 <dc:creator>Quinn, Max H.</dc:creator>
 <dc:creator>Conser, Erik</dc:creator>
 <dc:creator>Witte, Jordan M.</dc:creator>
 <dc:creator>Mitchell, Melanie</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We describe a novel architecture for semantic image retrieval---in
particular, retrieval of instances of visual situations. Visual situations are
concepts such as &quot;a boxing match,&quot; &quot;walking the dog,&quot; &quot;a crowd waiting for a
bus,&quot; or &quot;a game of ping-pong,&quot; whose instantiations in images are linked more
by their common spatial and semantic structure than by low-level visual
similarity. Given a query situation description, our architecture---called
Situate---learns models capturing the visual features of expected objects as
well the expected spatial configuration of relationships among objects. Given a
new image, Situate uses these models in an attempt to ground (i.e., to create a
bounding box locating) each expected component of the situation in the image
via an active search procedure. Situate uses the resulting grounding to compute
a score indicating the degree to which the new image is judged to contain an
instance of the situation. Such scores can be used to rank images in a
collection as part of a retrieval system. In the preliminary study described
here, we demonstrate the promise of this system by comparing Situate's
performance with that of two baseline methods, as well as with a related
semantic image-retrieval system based on &quot;scene graphs.&quot;
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00088</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00092</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Summarizing Dialogic Arguments from Social Media</dc:title>
 <dc:creator>Misra, Amita</dc:creator>
 <dc:creator>Oraby, Shereen</dc:creator>
 <dc:creator>Tandon, Shubhangi</dc:creator>
 <dc:creator>TS, Sharath</dc:creator>
 <dc:creator>Anand, Pranav</dc:creator>
 <dc:creator>Walker, Marilyn</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Online argumentative dialog is a rich source of information on popular
beliefs and opinions that could be useful to companies as well as governmental
or public policy agencies. Compact, easy to read, summaries of these dialogues
would thus be highly valuable. A priori, it is not even clear what form such a
summary should take. Previous work on summarization has primarily focused on
summarizing written texts, where the notion of an abstract of the text is well
defined. We collect gold standard training data consisting of five human
summaries for each of 161 dialogues on the topics of Gay Marriage, Gun Control
and Abortion. We present several different computational models aimed at
identifying segments of the dialogues whose content should be used for the
summary, using linguistic features and Word2vec features with both SVMs and
Bidirectional LSTMs. We show that we can identify the most important arguments
by using the dialog context with a best F-measure of 0.74 for gun control, 0.71
for gay marriage, and 0.67 for abortion.
</dc:description>
 <dc:description>Comment: Proceedings of the 21th Workshop on the Semantics and Pragmatics of
  Dialogue (SemDial 2017)</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00092</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00096</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pattern Recognition Techniques for the Identification of Activities of
  Daily Living using Mobile Device Accelerometer</dc:title>
 <dc:creator>Pires, Ivan Miguel</dc:creator>
 <dc:creator>Garcia, Nuno M.</dc:creator>
 <dc:creator>Pombo, Nuno</dc:creator>
 <dc:creator>Fl&#xf3;rez-Revuelta, Francisco</dc:creator>
 <dc:creator>Spinsante, Susanna</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  This paper focuses on the recognition of Activities of Daily Living (ADL)
applying pattern recognition techniques to the data acquired by the
accelerometer available in the mobile devices. The recognition of ADL is
composed by several stages, including data acquisition, data processing, and
artificial intelligence methods. The artificial intelligence methods used are
related to pattern recognition, and this study focuses on the use of Artificial
Neural Networks (ANN). The data processing includes data cleaning, and the
feature extraction techniques to define the inputs for the ANN. Due to the low
processing power and memory of the mobile devices, they should be mainly used
to acquire the data, applying an ANN previously trained for the identification
of the ADL. The main purpose of this paper is to present a new method
implemented with ANN for the identification of a defined set of ADL with a
reliable accuracy. This paper also presents a comparison of different types of
ANN in order to choose the type for the implementation of the final method.
Results of this research probes that the best accuracies are achieved with Deep
Learning techniques with an accuracy higher than 80%.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00096</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00100</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Utilization-Based Scheduling of Flexible Mixed-Criticality Real-Time
  Tasks</dc:title>
 <dc:creator>Chen, Gang</dc:creator>
 <dc:creator>Guan, Nan</dc:creator>
 <dc:creator>Liu, Di</dc:creator>
 <dc:creator>He, Qingqiang</dc:creator>
 <dc:creator>Huang, Kai</dc:creator>
 <dc:creator>Stefanov, Todor</dc:creator>
 <dc:creator>Yi, Wang</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Mixed-criticality models are an emerging paradigm for the design of real-time
systems because of their significantly improved resource efficiency. However,
formal mixed-criticality models have traditionally been characterized by two
impractical assumptions: once \textit{any} high-criticality task overruns,
\textit{all} low-criticality tasks are suspended and \textit{all other}
high-criticality tasks are assumed to exhibit high-criticality behaviors at the
same time. In this paper, we propose a more realistic mixed-criticality model,
called the flexible mixed-criticality (FMC) model, in which these two issues
are addressed in a combined manner. In this new model, only the overrun task
itself is assumed to exhibit high-criticality behavior, while other
high-criticality tasks remain in the same mode as before. The guaranteed
service levels of low-criticality tasks are gracefully degraded with the
overruns of high-criticality tasks. We derive a utilization-based technique to
analyze the schedulability of this new mixed-criticality model under EDF-VD
scheduling. During runtime, the proposed test condition serves an important
criterion for dynamic service level tuning, by means of which the maximum
available execution budget for low-criticality tasks can be directly determined
with minimal overhead while guaranteeing mixed-criticality schedulability.
Experiments demonstrate the effectiveness of the FMC scheme compared with
state-of-the-art techniques.
</dc:description>
 <dc:description>Comment: This paper has been submitted to IEEE Transaction on Computers (TC)
  on Sept-09th-2016</dc:description>
 <dc:date>2017-09-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00103</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scheduling Monotone Moldable Jobs in Linear Time</dc:title>
 <dc:creator>Jansen, Klaus</dc:creator>
 <dc:creator>Land, Felix</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A moldable job is a job that can be executed on an arbitrary number of
processors, and whose processing time depends on the number of processors
allotted to it. A moldable job is monotone if its work doesn't decrease for an
increasing number of allotted processors. We consider the problem of scheduling
monotone moldable jobs to minimize the makespan.
  We argue that for certain compact input encodings a polynomial algorithm has
a running time polynomial in n and log(m), where n is the number of jobs and m
is the number of machines. We describe how monotony of jobs can be used to
counteract the increased problem complexity that arises from compact encodings,
and give tight bounds on the approximability of the problem with compact
encoding: it is NP-hard to solve optimally, but admits a PTAS.
  The main focus of this work are efficient approximation algorithms. We
describe different techniques to exploit the monotony of the jobs for better
running times, and present a (3/2+{\epsilon})-approximate algorithm whose
running time is polynomial in log(m) and 1/{\epsilon}, and only linear in the
number n of jobs.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2018-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00103</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00104</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Multiple Source Framework for the Identification of Activities of
  Daily Living Based on Mobile Device Data</dc:title>
 <dc:creator>Pires, Ivan Miguel</dc:creator>
 <dc:creator>Garcia, Nuno M.</dc:creator>
 <dc:creator>Pombo, Nuno</dc:creator>
 <dc:creator>Fl&#xf3;rez-Revuelta, Francisco</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  The monitoring of the lifestyles may be performed based on a system for the
recognition of Activities of Daily Living (ADL) and their environments,
combining the results obtained with the user agenda. The system may be
developed with the use of the off-the-shelf mobile devices commonly used,
because they have several types of sensors available, including motion,
magnetic, acoustic, and location sensors. Data acquisition, data processing,
data fusion, and artificial intelligence methods are applied in different
stages of the system developed, which recognizes the ADL with pattern
recognition methods. The motion and magnetic sensors allow the recognition of
activities with movement, but the acoustic sensors allow the recognition of the
environments. The fusion of the motion, magnetic and acoustic sensors allows
the differentiation of other ADL. On the other hand, the location sensors
allows the recognition of ADL with large movement, and the combination of these
sensors with the other sensors increases the number of ADL recognized by the
system. This study consists on the comparison of different types of ANN for
choosing the best methods for the recognition of several ADL, which they are
implemented in a system for the recognition of ADL that combines the sensors
data with the users agenda for the monitoring of the lifestyles. Conclusions
point to the use of Deep Neural Networks (DNN) with normalized data for the
identification of ADL with 85.89% of accuracy, the use of Feedforward neural
networks with non-normalized data for the identification of the environments
with 86.50% of accuracy, and the use of DNN with normalized data for the
identification of standing activities with 100% of accuracy, proving the
reliability of the framework presented in this study.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00106</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DCN+: Mixed Objective and Deep Residual Coattention for Question
  Answering</dc:title>
 <dc:creator>Xiong, Caiming</dc:creator>
 <dc:creator>Zhong, Victor</dc:creator>
 <dc:creator>Socher, Richard</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Traditional models for question answering optimize using cross entropy loss,
which encourages exact answers at the cost of penalizing nearby or overlapping
answers that are sometimes equally accurate. We propose a mixed objective that
combines cross entropy loss with self-critical policy learning. The objective
uses rewards derived from word overlap to solve the misalignment between
evaluation metric and optimization objective. In addition to the mixed
objective, we improve dynamic coattention networks (DCN) with a deep residual
coattention encoder that is inspired by recent work in deep self-attention and
residual networks. Our proposals improve model performance across question
types and input lengths, especially for long questions that requires the
ability to capture long-term dependencies. On the Stanford Question Answering
Dataset, our model achieves state-of-the-art results with 75.1% exact match
accuracy and 83.1% F1, while the ensemble obtains 78.9% exact match accuracy
and 86.0% F1.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00107</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Separation of Water and Fat Magnetic Resonance Imaging Signals Using
  Deep Learning with Convolutional Neural Networks</dc:title>
 <dc:creator>Goldfarb, James W</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Purpose: A new method for magnetic resonance (MR) imaging water-fat
separation using a convolutional neural network (ConvNet) and deep learning
(DL) is presented. Feasibility of the method with complex and magnitude images
is demonstrated with a series of patient studies and accuracy of predicted
quantitative values is analyzed.
  Methods: Water-fat separation of 1200 gradient-echo acquisitions from 90
imaging sessions (normal, acute and chronic myocardial infarction) was
performed using a conventional model based method with modeling of R2* and
off-resonance and a multi-peak fat spectrum. A U-Net convolutional neural
network for calculation of water-only, fat-only, R2* and off-resonance images
was trained with 900 gradient-echo Multiple and single-echo complex and
magnitude input data algorithms were studied and compared to conventional
extended echo modeling.
  Results: The U-Net ConvNet was easily trained and provided water-fat
separation results visually comparable to conventional methods. Myocardial fat
deposition in chronic myocardial infarction and intramyocardial hemorrhage in
acute myocardial infarction were well visualized in the DL results. Predicted
values for R2*, off-resonance, water and fat signal intensities were well
correlated with conventional model based water fat separation (R2&gt;=0.97,
p&lt;0.001). DL images had a 14% higher signal-to-noise ratio (p&lt;0.001) when
compared to the conventional method.
  Conclusion: Deep learning utilizing ConvNets is a feasible method for MR
water-fat separationimaging with complex, magnitude and single echo image data.
A trained U-Net can be efficiently used for MR water-fat separation, providing
results comparable to conventional model based methods.
</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00107</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00108</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond Shared Hierarchies: Deep Multitask Learning through Soft Layer
  Ordering</dc:title>
 <dc:creator>Meyerson, Elliot</dc:creator>
 <dc:creator>Miikkulainen, Risto</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Existing deep multitask learning (MTL) approaches align layers shared between
tasks in a parallel ordering. Such an organization significantly constricts the
types of shared structure that can be learned. The necessity of parallel
ordering for deep MTL is first tested by comparing it with permuted ordering of
shared layers. The results indicate that a flexible ordering can enable more
effective sharing, thus motivating the development of a soft ordering approach,
which learns how shared layers are applied in different ways for different
tasks. Deep MTL with soft ordering outperforms parallel ordering methods across
a series of domains. These results suggest that the power of deep MTL comes
from learning highly general building blocks that can be assembled to meet the
demands of each task.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00108</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00110</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Algorithm for Reconstructing Singular Connection in Multi-Block
  CFD Applications</dc:title>
 <dc:creator>Yong-Xian, Wang</dc:creator>
 <dc:creator>Li-Lun, Zhang</dc:creator>
 <dc:creator>Yong-Gang, Che</dc:creator>
 <dc:creator>Chuan-Fu, Xu</dc:creator>
 <dc:creator>Wei, Liu</dc:creator>
 <dc:creator>Hua-Yong, Liu</dc:creator>
 <dc:creator>Zheng-Hua, Wang</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  An improved algorithm is proposed for the reconstruction of singular
connectivity from the available pairwise connections during preprocessing
phase. To evaluate the performance of the algorithm, an in-house computational
fluid dynamics (CFD) code is used in which high-order finite-difference method
for spatial discretization running on the Tianhe-1A supercomputer is employed.
Test cases with a varied amount of mesh points are chosen, and the test results
indicate that the improved singular connection reconstruction algorithm can
achieve a speedup factor of 1000X or more when compared with the naive search
method adopted in the former version of our code. Moreover, the parallel
efficiency can benefit from the strategy of local communication based on the
algorithm.
</dc:description>
 <dc:description>Comment: 10 pages, 3 figures, 2 tables. Pre-print version</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00110</dc:identifier>
 <dc:identifier>Transaction of Nanjing University of Aeronautics &amp; Astronautics.
  2013, 30(S):51-57</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00111</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Task Learning by Deep Collaboration and Application in Facial
  Landmark Detection</dc:title>
 <dc:creator>Trottier, Ludovic</dc:creator>
 <dc:creator>Gigu&#xe8;re, Philippe</dc:creator>
 <dc:creator>Chaib-draa, Brahim</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional neural networks (CNN) have become the most successful and
popular approach in many vision-related domains. While CNNs are particularly
well-suited for capturing a proper hierarchy of concepts from real-world
images, they are limited to domains where data is abundant. Recent attempts
have looked into mitigating this data scarcity problem by casting their
original single-task problem into a new multi-task learning (MTL) problem. The
main goal of this inductive transfer mechanism is to leverage domain-specific
information from related tasks, in order to improve generalization on the main
task. While recent results in the deep learning (DL) community have shown the
promising potential of training task-specific CNNs in a soft parameter sharing
framework, integrating the recent DL advances for improving knowledge sharing
is still an open problem. In this paper, we propose the Deep Collaboration
Network (DCNet), a novel approach for connecting task-specific CNNs in a MTL
framework. We define connectivity in terms of two distinct non-linear
transformations. One aggregates task-specific features into global features,
while the other merges back the global features with each task-specific
network. Based on the observation that task relevance depends on depth, our
transformations use skip connections as suggested by residual networks, to more
easily deactivate unrelated task-dependent features. To validate our approach,
we employ facial landmark detection (FLD) datasets as they are readily amenable
to MTL, given the number of tasks they include. Experimental results show that
we can achieve up to 24.31% relative improvement in failure rate over other
state-of-the-art MTL approaches. We finally perform an ablation study showing
that our approach effectively allows knowledge sharing, by leveraging
domain-specific features at particular depths from tasks that we know are
related.
</dc:description>
 <dc:description>Comment: Under review at the International Conference on Learning
  Representations (2018)</dc:description>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00111</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00112</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PupilNet v2.0: Convolutional Neural Networks for CPU based real time
  Robust Pupil Detection</dc:title>
 <dc:creator>Fuhl, Wolfgang</dc:creator>
 <dc:creator>Santini, Thiago</dc:creator>
 <dc:creator>Kasneci, Gjergji</dc:creator>
 <dc:creator>Rosenstiel, Wolfgang</dc:creator>
 <dc:creator>Kasneci, Enkelejda</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Real-time, accurate, and robust pupil detection is an essential prerequisite
for pervasive video-based eye-tracking. However, automated pupil detection in
realworld scenarios has proven to be an intricate challenge due to fast
illumination changes, pupil occlusion, non-centered and off-axis eye recording,
as well as physiological eye characteristics. In this paper, we approach this
challenge through: I) a convolutional neural network (CNN) running in real time
on a single core, II) a novel computational intensive two stage CNN for
accuracy improvement, and III) a fast propability distribution based refinement
method as a practical alternative to II. We evaluate the proposed approaches
against the state-of-the-art pupil detection algorithms, improving the
detection rate up to ~9% percent points on average over all data sets (~7% on
one CPU core 7ms). This evaluation was performed on over 135,000 images: 94,000
images from the literature, and 41,000 new hand-labeled and challenging images
contributed by this work (v1.0).
</dc:description>
 <dc:description>Comment: Pupil detection, pupil center estimation, image processing, CNN.
  arXiv admin note: substantial text overlap with arXiv:1601.04902</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00112</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00113</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proving Soundness of Extensional Normal-Form Bisimilarities</dc:title>
 <dc:creator>Biernacki, Dariusz</dc:creator>
 <dc:creator>Lenglet, Serguei</dc:creator>
 <dc:creator>Polesiuk, Piotr</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Normal-form bisimilarity is a simple, easy-to-use behavioral equivalence that
relates terms in lambda-calculi by decomposing their normal forms into
bisimilar subterms. Besides, they allow for powerful up-to techniques, such as
bisimulation up to context, which simplify bisimulation proofs even further.
However, proving soundness of these relations becomes complicated in the
presence of eta-expansion and usually relies on ad hoc proof methods which
depend on the language. In this paper we propose a more systematic proof method
to show that an extensional normal-form bisimilarity along with its
corresponding bisimulation up to context are sound. We illustrate our technique
with three calculi: the call-by-value lambda-calculus, the call-by-value
lambda-calculus with the delimited-control operators shift and reset, and the
call-by-value lambda-calculus with the abortive control operators call/cc and
abort. In the first two cases, there was previously no sound bisimulation up to
context validating the eta-law, whereas no theory of normal-form bisimulations
for the calculus of abortive control has been presented before. Our results
have been fully formalized in the Coq proof assistant.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00113</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00117</identifier>
 <datestamp>2018-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Countering Adversarial Images using Input Transformations</dc:title>
 <dc:creator>Guo, Chuan</dc:creator>
 <dc:creator>Rana, Mayank</dc:creator>
 <dc:creator>Cisse, Moustapha</dc:creator>
 <dc:creator>van der Maaten, Laurens</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper investigates strategies that defend against adversarial-example
attacks on image-classification systems by transforming the inputs before
feeding them to the system. Specifically, we study applying image
transformations such as bit-depth reduction, JPEG compression, total variance
minimization, and image quilting before feeding the image to a convolutional
network classifier. Our experiments on ImageNet show that total variance
minimization and image quilting are very effective defenses in practice, in
particular, when the network is trained on transformed images. The strength of
those defenses lies in their non-differentiable nature and their inherent
randomness, which makes it difficult for an adversary to circumvent the
defenses. Our best defense eliminates 60% of strong gray-box and 90% of strong
black-box attacks by a variety of major attack methods
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures, submitted to ICLR 2018</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00117</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00120</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical Modeling of FSO Fronthaul Channel for Drone-based Networks</dc:title>
 <dc:creator>Najafi, Marzieh</dc:creator>
 <dc:creator>Ajam, Hedieh</dc:creator>
 <dc:creator>Jamali, Vahid</dc:creator>
 <dc:creator>Diamantoulakis, Panagiotis D.</dc:creator>
 <dc:creator>Karagiannidis, George K.</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a drone-based communication network, where several drones hover
above an area and serve as mobile remote radio heads for a large number of
mobile users. We assume that the drones employ free space optical (FSO) links
for fronthauling of the users' data to a central unit. The main focus of this
paper is to quantify the geometric loss of the FSO channel arising from random
fluctuation of the position and orientation of the drones. In particular, we
derive upper and lower bounds, corresponding approximate expressions, and a
closed-form statistical model for the geometric loss. Simulation results
validate our derivations and quantify the FSO channel quality as a function of
the drone's instability, i.e., the variation of its position and orientation.
</dc:description>
 <dc:description>Comment: This paper has been submitted to ICC 2018</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00120</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00121</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamical SimRank Search on Time-Varying Networks</dc:title>
 <dc:creator>Yu, Weiren</dc:creator>
 <dc:creator>Lin, Xuemin</dc:creator>
 <dc:creator>Zhang, Wenjie</dc:creator>
 <dc:creator>McCann, Julie A.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  In this article, we study the efficient dynamical computation of all-pairs
SimRanks on time-varying graphs. Li {\em et al}.'s approach requires $O(r^4
n^2)$ time and $O(r^2 n^2)$ memory in a graph with $n$ nodes, where $r$ is the
target rank of the low-rank SVD. (1) We first consider edge update that does
not accompany new node insertions. We show that the SimRank update $\Delta S$
in response to every link update is expressible as a rank-one Sylvester matrix
equation. This provides an incremental method requiring $O(Kn^2)$ time and
$O(n^2)$ memory in the worst case to update all pairs of similarities for $K$
iterations. (2) To speed up the computation further, we propose a lossless
pruning strategy that captures the &quot;affected areas&quot; of $\Delta S$ to eliminate
unnecessary retrieval. This reduces the time of the incremental SimRank to
$O(K(m+|AFF|))$, where $m$ is the number of edges in the old graph, and $|AFF|
(\le n^2)$ is the size of &quot;affected areas&quot; in $\Delta S$, and in practice,
$|AFF| \ll n^2$. (3) We also consider edge updates that accompany node
insertions, and categorize them into three cases, according to which end of the
inserted edge is a new node. For each case, we devise an efficient incremental
algorithm that can support new node insertions. (4) We next design an efficient
batch incremental method that handles &quot;similar sink edges&quot; simultaneously and
eliminates redundant edge updates. (5) To achieve linear memory, we devise a
memory-efficient strategy that dynamically updates all pairs of SimRanks column
by column in just $O(Kn+m)$ memory, without the need to store all $(n^2)$ pairs
of old SimRank scores. Experimental studies on various datasets demonstrate
that our solution substantially outperforms the existing incremental SimRank
methods, and is faster and more memory-efficient than its competitors on
million-scale graphs.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00123</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Backpropagation through the Void: Optimizing control variates for
  black-box gradient estimation</dc:title>
 <dc:creator>Grathwohl, Will</dc:creator>
 <dc:creator>Choi, Dami</dc:creator>
 <dc:creator>Wu, Yuhuai</dc:creator>
 <dc:creator>Roeder, Geoff</dc:creator>
 <dc:creator>Duvenaud, David</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Gradient-based optimization is the foundation of deep learning and
reinforcement learning. Even when the mechanism being optimized is unknown or
not differentiable, optimization using high-variance or biased gradient
estimates is still often the best strategy. We introduce a general framework
for learning low-variance, unbiased gradient estimators for black-box functions
of random variables. Our method uses gradients of a neural network trained
jointly with model parameters or policies, and is applicable in both discrete
and continuous settings. We demonstrate this framework for training discrete
latent-variable models. We also give an unbiased, action-conditional extension
of the advantage actor-critic reinforcement learning algorithm.
</dc:description>
 <dc:description>Comment: Submitted to ICLR 2018</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00123</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00124</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>User Environment Detection with Acoustic Sensors Embedded on Mobile
  Devices for the Recognition of Activities of Daily Living</dc:title>
 <dc:creator>Pires, Ivan Miguel</dc:creator>
 <dc:creator>Garcia, Nuno M.</dc:creator>
 <dc:creator>Pombo, Nuno</dc:creator>
 <dc:creator>Fl&#xf3;rez-Revuelta, Francisco</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  The detection of the environment where user is located, is of extreme use for
the identification of Activities of Daily Living (ADL). ADL can be identified
by use of the sensors available in many off-the-shelf mobile devices, including
magnetic and motion, and the environment can be also identified using acoustic
sensors. The study presented in this paper is divided in two parts: firstly, we
discuss the recognition of the environment using acoustic sensors (i.e.,
microphone), and secondly, we fuse this information with motion and magnetic
sensors (i.e., motion and magnetic sensors) for the recognition of standing
activities of daily living. The recognition of the environments and the ADL are
performed using pattern recognition techniques, in order to develop a system
that includes data acquisition, data processing, data fusion, and artificial
intelligence methods. The artificial intelligence methods explored in this
study are composed by different types of Artificial Neural Networks (ANN),
comparing the different types of ANN and selecting the best methods to
implement in the different stages of the system developed. Conclusions point to
the use of Deep Neural Networks (DNN) with normalized data for the
identification of ADL with 85.89% of accuracy, the use of Feedforward neural
networks with non-normalized data for the identification of the environments
with 86.50% of accuracy, and the use of DNN with normalized data for the
identification of standing activities with 100% of accuracy.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00124</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00126</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerated Sparse Subspace Clustering</dc:title>
 <dc:creator>Hashemi, Abolfazl</dc:creator>
 <dc:creator>Vikalo, Haris</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  State-of-the-art algorithms for sparse subspace clustering perform spectral
clustering on a similarity matrix typically obtained by representing each data
point as a sparse combination of other points using either basis pursuit (BP)
or orthogonal matching pursuit (OMP). BP-based methods are often prohibitive in
practice while the performance of OMP-based schemes are unsatisfactory,
especially in settings where data points are highly similar. In this paper, we
propose a novel algorithm that exploits an accelerated variant of orthogonal
least-squares to efficiently find the underlying subspaces. We show that under
certain conditions the proposed algorithm returns a subspace-preserving
solution. Simulation results illustrate that the proposed method compares
favorably with BP-based method in terms of running time while being
significantly more accurate than OMP-based schemes.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00126</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00129</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automata Guided Hierarchical Reinforcement Learning for Zero-shot Skill
  Composition</dc:title>
 <dc:creator>Li, Xiao</dc:creator>
 <dc:creator>Ma, Yao</dc:creator>
 <dc:creator>Belta, Calin</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  An obstacle that prevents the wide adoption of (deep) reinforcement learning
(RL) in control systems is its need for a large amount of interactions with the
environ- ment in order to master a skill. The learned skill usually generalizes
poorly across domains and re-training is often necessary when presented with a
new task. We present a framework that combines methods in formal methods with
hierarchi- cal reinforcement learning (HRL). The set of techniques we provide
allows for convenient specification of tasks with complex logic, learn
hierarchical policies (meta-controller and low-level controllers) with
well-defined intrinsic rewards us- ing any RL methods and is able to construct
new skills from existing ones without additional learning. We evaluate the
proposed methods in a simple grid world simulation as well as simulation on a
Baxter robot.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00129</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00131</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diffusive Molecular Communications with Reactive Signaling</dc:title>
 <dc:creator>Jamali, Vahid</dc:creator>
 <dc:creator>Farsad, Nariman</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:creator>Goldsmith, Andrea</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  This paper focuses on molecular communication (MC) systems where the
signaling molecules may participate in a reversible bimolecular reaction in the
channel. The motivation for studying these MC systems is that they can realize
the concept of constructive and destructive signal superposition, which leads
to favorable properties such as inter-symbol interference (ISI) reduction and
avoiding environmental contamination due to continuous release of molecules
into the channel. This work first derives the maximum likelihood (ML) detector
for a binary MC system with reactive signaling molecules under the assumption
that the detector has perfect knowledge of the ISI. The performance of this
genie-aided ML detector yields an upper bound on the performance of any
practical detector. In addition, two suboptimal detectors of different
complexity are proposed. The proposed ML detector as well as one of the
suboptimal detectors require the channel response (CR) of the considered MC
system. Moreover, the CR is needed for the performance evaluation of all
proposed detectors. However, analyzing MC with reactive signaling is
challenging since the underlying partial differential equations that describe
the reaction-diffusion mechanism are coupled and non-linear. Therefore, an
algorithm is developed in this paper for efficient computation of the CR to any
arbitrary transmit symbol sequence. The accuracy of this algorithm is validated
via particle-based simulation. Simulation results using the developed CR
algorithm show that the performance of the proposed suboptimal detectors can
approach that of the genie- aided ML detector. Moreover, these results show
that MC systems with reactive signaling have superior performance relative to
those with non-reactive signaling due to the reduction of ISI enabled by the
chemical reactions.
</dc:description>
 <dc:description>Comment: This paper has been submitted to IEEE International Conference on
  Communications (ICC) 2018</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00131</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00137</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pomegranate: fast and flexible probabilistic modeling in python</dc:title>
 <dc:creator>Schreiber, Jacob</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present pomegranate, an open source machine learning package for
probabilistic modeling in Python. Probabilistic modeling encompasses a wide
range of methods that explicitly describe uncertainty using probability
distributions. Three widely used probabilistic models implemented in
pomegranate are general mixture models, hidden Markov models, and Bayesian
networks. A primary focus of pomegranate is to abstract away the complexities
of training models from their definition. This allows users to focus on
specifying the correct model for their application instead of being limited by
their understanding of the underlying algorithms. An aspect of this focus
involves the collection of additive sufficient statistics from data sets as a
strategy for training models. This approach trivially enables many useful
learning strategies, such as out-of-core learning, minibatch learning, and
semi-supervised learning, without requiring the user to consider how to
partition data or modify the algorithms to handle these tasks themselves.
pomegranate is written in Cython to speed up calculations and releases the
global interpreter lock to allow for built-in multithreaded parallelism, making
it competitive with---or outperform---other implementations of similar
algorithms. This paper presents an overview of the design choices in
pomegranate, and how they have enabled complex features to be supported by
simple code.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00137</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00138</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visualizing and Understanding Atari Agents</dc:title>
 <dc:creator>Greydanus, Sam</dc:creator>
 <dc:creator>Koul, Anurag</dc:creator>
 <dc:creator>Dodge, Jonathan</dc:creator>
 <dc:creator>Fern, Alan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Deep reinforcement learning (deep RL) agents have achieved remarkable success
in a broad range of game-playing and continuous control tasks. While these
agents are effective at maximizing rewards, it is often unclear what strategies
they use to do so. In this paper, we take a step toward explaining deep RL
agents through a case study in three Atari 2600 environments. In particular, we
focus on understanding agents in terms of their visual attentional patterns
during decision making. To this end, we introduce a method for generating rich
saliency maps and use it to explain 1) what strong agents attend to 2) whether
agents are making decisions for the right or wrong reasons, and 3) how agents
evolve during the learning phase. We also test our method on non-expert human
subjects and find that it improves their ability to reason about these agents.
Our techniques are general and, though we focus on Atari, our long-term
objective is to produce tools that explain any deep RL policy.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures. NIPS 2017 Interpretability workshop, accepted
  paper (oral+poster)</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00138</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00139</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Segmentation-by-Detection: A Cascade Network for Volumetric Medical
  Image Segmentation</dc:title>
 <dc:creator>Tang, Min</dc:creator>
 <dc:creator>Zhang, Zichen</dc:creator>
 <dc:creator>Cobzas, Dana</dc:creator>
 <dc:creator>Jagersand, Martin</dc:creator>
 <dc:creator>Jaremko, Jacob L.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose an attention mechanism for 3D medical image segmentation. The
method, named segmentation-by-detection, is a cascade of a detection module
followed by a segmentation module. The detection module enables a region of
interest to come to attention and produces a set of object region candidates
which are further used as an attention model. Rather than dealing with the
entire volume, the segmentation module distills the information from the
potential region. This scheme is an efficient solution for volumetric data as
it reduces the influence of the surrounding noise which is especially important
for medical data with low signal-to-noise ratio. Experimental results on 3D
ultrasound data of the femoral head shows superiority of the proposed method
when compared with a standard fully convolutional network like the U-Net.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00139</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00141</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training GANs with Optimism</dc:title>
 <dc:creator>Daskalakis, Constantinos</dc:creator>
 <dc:creator>Ilyas, Andrew</dc:creator>
 <dc:creator>Syrgkanis, Vasilis</dc:creator>
 <dc:creator>Zeng, Haoyang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We address the issue of limit cycling behavior in training Generative
Adversarial Networks and propose the use of Optimistic Mirror Decent (OMD) for
training Wasserstein GANs. Recent theoretical results have shown that
optimistic mirror decent (OMD) can enjoy faster regret rates in the context of
zero-sum games. WGANs is exactly a context of solving a zero-sum game with
simultaneous no-regret dynamics. Moreover, we show that optimistic mirror
decent addresses the limit cycling problem in training WGANs. We formally show
that in the case of bi-linear zero-sum games the last iterate of OMD dynamics
converges to an equilibrium, in contrast to GD dynamics which are bound to
cycle. We also portray the huge qualitative difference between GD and OMD
dynamics with toy examples, even when GD is modified with many adaptations
proposed in the recent literature, such as gradient penalty or momentum. We
apply OMD WGAN training to a bioinformatics problem of generating DNA
sequences. We observe that models trained with OMD achieve consistently smaller
KL divergence with respect to the true underlying distribution, than models
trained with GD variants. Finally, we introduce a new algorithm, Optimistic
Adam, which is an optimistic variant of Adam. We apply it to WGAN training on
CIFAR10 and observe improved performance in terms of inception score as
compared to Adam.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00141</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00142</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sampling and Reconstruction of Graph Signals via Weak Submodularity and
  Semidefinite Relaxation</dc:title>
 <dc:creator>Hashemi, Abolfazl</dc:creator>
 <dc:creator>Shafipour, Rasoul</dc:creator>
 <dc:creator>Vikalo, Haris</dc:creator>
 <dc:creator>Mateos, Gonzalo</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study the problem of sampling a bandlimited graph signal in the presence
of noise, where the objective is to select a node subset of prescribed
cardinality that minimizes the signal reconstruction mean squared error (MSE).
To that end, we formulate the task at hand as the minimization of MSE subject
to binary constraints, and approximate the resulting NP-hard problem via
semidefinite programming (SDP) relaxation. Moreover, we provide an alternative
formulation based on maximizing a monotone weak submodular function and propose
a randomized-greedy algorithm to find a sub-optimal subset. We then derive a
worst-case performance guarantee on the MSE returned by the randomized greedy
algorithm for general non-stationary graph signals. The efficacy of the
proposed methods is illustrated through numerical simulations on synthetic and
real-world graphs. Notably, the randomized greedy algorithm yields an
order-of-magnitude speedup over state-of-the-art greedy sampling schemes, while
incurring only a marginal MSE performance loss.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00142</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00146</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A multitask deep learning model for real-time deployment in embedded
  systems</dc:title>
 <dc:creator>Mart&#xed;, Miquel</dc:creator>
 <dc:creator>Maki, Atsuto</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose an approach to Multitask Learning (MTL) to make deep learning
models faster and lighter for applications in which multiple tasks need to be
solved simultaneously, which is particularly useful in embedded, real-time
systems. We develop a multitask model for both Object Detection and Semantic
Segmentation and analyze the challenges that appear during its training. Our
multitask network is 1.6x faster, lighter and uses less memory than deploying
the single-task models in parallel. We conclude that MTL has the potential to
give superior performance in exchange of a more complex training process that
introduces challenges not present in single-task models.
</dc:description>
 <dc:description>Comment: 2 pages, 5 figures. Poster presentation at Swedish Symposium on Deep
  Learning SSDL2017, Stockholm, Sweden. June 20-21, 2017</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00146</dc:identifier>
 <dc:identifier>Swedish Symposium on Deep Learning 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00150</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Erratum: Link prediction in drug-target interactions network using
  similarity indices</dc:title>
 <dc:creator>Lu, Yiding</dc:creator>
 <dc:creator>Guo, Yufan</dc:creator>
 <dc:creator>Korhonen, Anna</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Background: In silico drug-target interaction (DTI) prediction plays an
integral role in drug repositioning: the discovery of new uses for existing
drugs. One popular method of drug repositioning is network-based DTI
prediction, which uses complex network theory to predict DTIs from a
drug-target network. Currently, most network-based DTI prediction is based on
machine learning methods such as Restricted Boltzmann Machines (RBM) or Support
Vector Machines (SVM). These methods require additional information about the
characteristics of drugs, targets and DTIs, such as chemical structure, genome
sequence, binding types, causes of interactions, etc., and do not perform
satisfactorily when such information is unavailable. We propose a new,
alternative method for DTI prediction that makes use of only network topology
information attempting to solve this problem.
  Results: We compare our method for DTI prediction against the well-known RBM
approach. We show that when applied to the MATADOR database, our approach based
on node neighborhoods yield higher precision for high-ranking predictions than
RBM when no information regarding DTI types is available.
  Conclusion: This demonstrates that approaches purely based on network
topology provide a more suitable approach to DTI prediction in the many
real-life situations where little or no prior knowledge is available about the
characteristics of drugs, targets, or their interactions.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00150</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00155</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Wikipedian: Generating Textual Summaries from Knowledge Base
  Triples</dc:title>
 <dc:creator>Vougiouklis, Pavlos</dc:creator>
 <dc:creator>Elsahar, Hady</dc:creator>
 <dc:creator>Kaffee, Lucie-Aim&#xe9;e</dc:creator>
 <dc:creator>Gravier, Christoph</dc:creator>
 <dc:creator>Laforest, Frederique</dc:creator>
 <dc:creator>Hare, Jonathon</dc:creator>
 <dc:creator>Simperl, Elena</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Most people do not interact with Semantic Web data directly. Unless they have
the expertise to understand the underlying technology, they need textual or
visual interfaces to help them make sense of it. We explore the problem of
generating natural language summaries for Semantic Web data. This is
non-trivial, especially in an open-domain context. To address this problem, we
explore the use of neural networks. Our system encodes the information from a
set of triples into a vector of fixed dimensionality and generates a textual
summary by conditioning the output on the encoded vector. We train and evaluate
our models on two corpora of loosely aligned Wikipedia snippets and DBpedia and
Wikidata triples with promising results.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00155</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00159</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Signature Scheme Based on Punctured Reed--Muller Code With Random
  Insertion</dc:title>
 <dc:creator>Lee, Wijik</dc:creator>
 <dc:creator>Kim, Young-Sik</dc:creator>
 <dc:creator>No, Jong-Seon</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this paper, we propose a new signature scheme based on a punctured
Reed--Muller (RM) code with random insertion, which improves the Goppa
code-based signature scheme developed by Courtois, Finiasz, and Sendrier (CFS).
The CFS signature scheme has certain drawbacks in terms of scaling of the
parameters and a lack of existential unforgeability under adaptive chosen
message attacks (EUF-CMA) security proof. Further, the proposed modified RM
code-based signature scheme can use complete decoding, which can be implemented
using a recursive decoding method, and thus syndromes for errors larger than
the error correctability can be decoded for signing, which improves the
probability of successful signing and reduces the signing time. Using the
puncturing and insertion methods, the proposed RM code-based signature scheme
can avoid some known attacks for RM code-based cryptosystems. The parameters of
the proposed signature scheme such as error weight parameter $w$ and the
maximum signing trial $N$, can be adjusted in terms of signing time and
security level, and it is also proved that the proposed signature scheme
achieves EUF-CMA security.
</dc:description>
 <dc:description>Comment: 22 pages, 3 figures</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00164</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Object Localization with Fitness NMS and Bounded IoU Loss</dc:title>
 <dc:creator>Tychsen-Smith, Lachlan</dc:creator>
 <dc:creator>Petersson, Lars</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We demonstrate that many detection methods are designed to identify only a
sufficently accurate bounding box, rather than the best available one. To
address this issue we propose a simple and fast modification to the existing
methods called Fitness NMS. This method is tested with the DeNet model and
obtains a significantly improved MAP at greater localization accuracies without
a loss in evaluation rate. Next we derive a novel bounding box regression loss
based on a set of IoU upper bounds that better matches the goal of IoU
maximization while still providing good convergence properties. Following these
novelties we investigate RoI clustering schemes for improving evaluation rates
for the DeNet \textit{wide} model variants and provide an analysis of
localization performance at various input image dimensions. We obtain a
MAP[0.5:0.95] of 33.6\%@79Hz and 41.8\%@5Hz for MSCOCO and a Titan X (Maxwell).
</dc:description>
 <dc:description>Comment: CVPR2018 Submission</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00164</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00165</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Neural Networks as Gaussian Processes</dc:title>
 <dc:creator>Lee, Jaehoon</dc:creator>
 <dc:creator>Bahri, Yasaman</dc:creator>
 <dc:creator>Novak, Roman</dc:creator>
 <dc:creator>Schoenholz, Samuel S.</dc:creator>
 <dc:creator>Pennington, Jeffrey</dc:creator>
 <dc:creator>Sohl-Dickstein, Jascha</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A deep fully-connected neural network with an i.i.d. prior over its
parameters is equivalent to a Gaussian process (GP) in the limit of infinite
network width. This correspondence enables exact Bayesian inference for neural
networks on regression tasks by means of straightforward matrix computations.
For single hidden-layer networks, the covariance function of this GP has long
been known. Recently, kernel functions for multi-layer random neural networks
have been developed, but only outside of a Bayesian framework. As such,
previous work has not identified the correspondence between using these kernels
as the covariance function for a GP and performing fully Bayesian prediction
with a deep neural network. In this work, we derive this correspondence and
develop a computationally efficient pipeline to compute the covariance
functions. We then use the resulting GP to perform Bayesian inference for deep
neural networks on MNIST and CIFAR-10. We find that the GP-based predictions
are competitive and can outperform neural networks trained with stochastic
gradient descent. We observe that the trained neural network accuracy
approaches that of the corresponding GP-based computation with increasing layer
width, and that the GP uncertainty is strongly correlated with prediction
error. We connect our observations to the recent development of signal
propagation in random neural networks.
</dc:description>
 <dc:description>Comment: 10 pages + appendices</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00165</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00167</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Cost of Uncertainty in Curing Epidemics</dc:title>
 <dc:creator>Hoffmann, Jessica</dc:creator>
 <dc:creator>Caramanis, Constantine</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Motivated by the study of controlling (curing) epidemics, we consider the
spread of an SI process on a known graph, where we have a limited budget to use
to transition infected nodes back to the susceptible state (i.e., to cure
nodes). Recent work has demonstrated that under perfect information (which
nodes are/are not infected), the budget required for curing a graph precisely
depends on its CutWidth. We develop a model for observation uncertainty, and
show that even a minor degradation in the assumption of perfect knowledge of
the state of the infection drastically alters the landscape -- infections that
could previously be cured in sublinear time, now may require exponential time
to cure. Our main result characterizes the necessary curing budget required as
a function of the per-node observation uncertainty.
</dc:description>
 <dc:description>Comment: 37 pages, 3 figures</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00167</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00168</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Outdoor to Indoor Penetration Loss at 28 GHz for Fixed Wireless Access</dc:title>
 <dc:creator>Bas, C. Umit</dc:creator>
 <dc:creator>Wang, Rui</dc:creator>
 <dc:creator>Choi, Thomas</dc:creator>
 <dc:creator>Hur, Sooyoung</dc:creator>
 <dc:creator>Whang, Kuyeon</dc:creator>
 <dc:creator>Park, Jeongho</dc:creator>
 <dc:creator>Zhang, Jianzhong</dc:creator>
 <dc:creator>Molisch, Andreas F.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper present the results from a 28 GHz channel sounding campaign
performed to investigate the effects of outdoor to indoor penetration on the
wireless propagation channel characteristics for an urban microcell in a fixed
wireless access scenario. The measurements are performed with a real-time
channel sounder, which can measure path loss up to 169 dB, and equipped with
phased array antennas that allows electrical beam steering for directionally
resolved measurements in dynamic environments. Thanks to the short measurement
time and the excellent phase stability of the system, we obtain both
directional and omnidirectional channel power delay profiles without any delay
uncertainty. For outdoor and indoor receiver locations, we compare path loss,
delay spreads and angular spreads obtained for two different types of
buildings.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00169</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Double Directional Propagation Channel Measurements at 28 GHz</dc:title>
 <dc:creator>Bas, C. Umit</dc:creator>
 <dc:creator>Wang, Rui</dc:creator>
 <dc:creator>Sangodoyin, Seun</dc:creator>
 <dc:creator>Hur, Sooyoung</dc:creator>
 <dc:creator>Whang, Kuyeon</dc:creator>
 <dc:creator>Park, Jeongho</dc:creator>
 <dc:creator>Zhang, Jianzhong</dc:creator>
 <dc:creator>Molisch, Andreas F.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper presents results from the (to our knowledge) first dynamic
double-directionally resolved measurement campaign at mm-wave frequencies for
an outdoor microcellular scenario. The measurements are performed with USC's
real-time channel sounder equipped with phased array antennas that can steer
beams electrically in microseconds, allowing directional measurements in
dynamic environments. Exploiting the phase coherency of the setup, the
multi-path components can be tracked over time to investigate the temporal
dependencies of the channel characteristics. We present results for
time-varying path-loss, delay spread, mean angles and angular spreads observed
at the transmitter (TX) and receiver (RX) in the presence of moving vehicles
and pedestrians. Additionally, we investigate excess losses observed due to
blockage by vehicles and compare the cases when TX and RX are using fixed beams
or when they are capable of adjusting beam directions dynamically.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00170</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>28 GHz Microcell Measurement Campaign for Residential Environment</dc:title>
 <dc:creator>Bas, C. Umit</dc:creator>
 <dc:creator>Wang, Rui</dc:creator>
 <dc:creator>Sangodoyin, Seun</dc:creator>
 <dc:creator>Hur, Sooyoung</dc:creator>
 <dc:creator>Whang, Kuyeon</dc:creator>
 <dc:creator>Park, Jeongho</dc:creator>
 <dc:creator>Zhang, Jianzhong</dc:creator>
 <dc:creator>Molisch, Andreas F.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper presents results from the (to our knowledge) first
double-directionally resolved measurement campaign at mm-wave frequencies in a
suburban microcell. The measurements are performed with a real-time channel
sounder equipped with phased antenna arrays that allows electrical beam
steering in microseconds, and which can measure path-loss of up to 169 dB.
Exploiting the phase coherency of the measurements in the different beams, we
obtain both directional and omnidirectional channel power delay profiles
without any delay uncertainty. We present statistics of channel characteristics
such as path-loss, shadowing and delay spread results for line-of-sight and
non-line-of-sight cases, as well as sample results for power angular spectrum
and extracted multi-path components.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00170</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00179</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Keyword-based Query Comprehending via Multiple Optimized-Demand
  Augmentation</dc:title>
 <dc:creator>Pan, Boyuan</dc:creator>
 <dc:creator>Li, Hao</dc:creator>
 <dc:creator>Zhao, Zhou</dc:creator>
 <dc:creator>Cai, Deng</dc:creator>
 <dc:creator>He, Xiaofei</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we consider the problem of machine reading task when the
questions are in the form of keywords, rather than natural language. In recent
years, researchers have achieved significant success on machine reading
comprehension tasks, such as SQuAD and TriviaQA. These datasets provide a
natural language question sentence and a pre-selected passage, and the goal is
to answer the question according to the passage. However, in the situation of
interacting with machines by means of text, people are more likely to raise a
query in form of several keywords rather than a complete sentence. The
keyword-based query comprehension is a new challenge, because small variations
to a question may completely change its semantical information, thus yield
different answers. In this paper, we propose a novel neural network system that
consists a Demand Optimization Model based on a passage-attention neural
machine translation and a Reader Model that can find the answer given the
optimized question. The Demand Optimization Model optimizes the original query
and output multiple reconstructed questions, then the Reader Model takes the
new questions as input and locate the answers from the passage. To make
predictions robust, an evaluation mechanism will score the reconstructed
questions so the final answer strike a good balance between the quality of both
the Demand Optimization Model and the Reader Model. Experimental results on
several datasets show that our framework significantly improves multiple strong
baselines on this challenging task.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00181</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding all Maximal Area Parallelograms in a Convex Polygon</dc:title>
 <dc:creator>Jin, Kai</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:description>  We consider the problem of finding the maximum area parallelogram (MAP)
inside a given convex polygon. Our main result is an algorithm for computing
the MAP in an $n$-sided polygon in $O(n^2)$ time. Achieving this running time
requires proving several new structural properties of the MAP. Our algorithm
actually computes all the locally maximal area parallelograms (LMAPs). In
addition to the algorithm, we prove that the LMAPs interleave each other, thus
the number of LMAPs is bounded by $O(n)$.
  We discuss applications of our result to, among others, the problem of
computing the maximum area centrally-symmetric convex body (MAC) inside a
convex polygon, and the simplest case of the Heilbronn Triangle Problem.
</dc:description>
 <dc:description>Comment: The conference version of this paper was published in CCCG 2011</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00181</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00189</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A generalized concatenation construction for q-ary 1-perfect codes</dc:title>
 <dc:creator>Romanov, Alexander M.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We consider perfect 1-error correcting codes over a finite field with $q$
elements (briefly $q$-ary 1-perfect codes). In this paper, a generalized
concatenation construction for $q$-ary 1-perfect codes is presented that allows
us to construct $q$-ary 1-perfect codes of length $(q - 1)nm + n + m$ from the
given $q$-ary 1-perfect codes of length $n =(q^{s_1} - 1) / (q - 1)$ and $m =
(q^{s_2} - 1) / (q - 1)$, where $s_1, s_2$ are natural numbers not less than
two. This construction allows us to also construct $q$-ary codes with
parameters $(q^{s_1 + s_2}, q^{q^{s_1 + s_2} - (s_1 + s_2) - 1}, 3)_q$ and can
be regarded as a $q$-ary analogue of the well-known Phelps construction.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00189</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00199</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PoseCNN: A Convolutional Neural Network for 6D Object Pose Estimation in
  Cluttered Scenes</dc:title>
 <dc:creator>Xiang, Yu</dc:creator>
 <dc:creator>Schmidt, Tanner</dc:creator>
 <dc:creator>Narayanan, Venkatraman</dc:creator>
 <dc:creator>Fox, Dieter</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Estimating the 6D pose of known objects is important for robots to interact
with objects in the real world. The problem is challenging due to the variety
of objects as well as the complexity of the scene caused by clutter and
occlusion between objects. In this work, we introduce a new Convolutional
Neural Network (CNN) for 6D object pose estimation named PoseCNN. PoseCNN
estimates the 3D translation of an object by localizing its center in the image
and predicting its distance from the camera. The 3D rotation of the object is
estimated by regressing to a quaternion representation. PoseCNN is able to
handle symmetric objects and is also robust to occlusion between objects. In
addition, we contribute a large scale video dataset for 6D object pose
estimation named the YCB-Video dataset. Our dataset provides accurate 6D poses
of 21 objects from the YCB dataset observed in 92 videos with 133,827 frames.
We conduct experiments on our YCB-Video dataset and the OccludedLINEMOD dataset
to show that PoseCNN provides very good estimates using only color as input.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00199</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00201</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Credimus</dc:title>
 <dc:creator>Hemaspaandra, Edith</dc:creator>
 <dc:creator>Hemaspaandra, Lane A.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:description>  We believe that economic design and computational complexity---while already
important to each other---should become even more important to each other with
each passing year. But for that to happen, experts in on the one hand such
areas as social choice, economics, and political science and on the other hand
computational complexity will have to better understand each other's
worldviews.
  This article, written by two complexity theorists who also work in
computational social choice theory, focuses on one direction of that process by
presenting a brief overview of how most computational complexity theorists view
the world. Although our immediate motivation is to make the lens through which
complexity theorists see the world be better understood by those in the social
sciences, we also feel that even within computer science it is very important
for nontheoreticians to understand how theoreticians think, just as it is
equally important within computer science for theoreticians to understand how
nontheoreticians think.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00201</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00205</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Effective Low-bitwidth Convolutional Neural Networks</dc:title>
 <dc:creator>Zhuang, Bohan</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:creator>Tan, Mingkui</dc:creator>
 <dc:creator>Liu, Lingqiao</dc:creator>
 <dc:creator>Reid, Ian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper tackles the problem of training a deep convolutional neural
network with both low-precision weights and low-bitwidth activations.
Optimizing a low-precision network is very challenging since the training
process can easily get trapped in a poor local minima, which results in
substantial accuracy loss. To mitigate this problem, we propose three
simple-yet-effective approaches to improve the network training. First, we
propose to use a two-stage optimization strategy to progressively find good
local minima. Specifically, we propose to first optimize a net with quantized
weights and then quantized activations. This is in contrast to the traditional
methods which optimize them simultaneously. Second, following a similar spirit
of the first method, we propose another progressive optimization approach which
progressively decreases the bit-width from high-precision to low-precision
during the course of training. Third, we adopt a novel learning scheme to
jointly train a full-precision model alongside the low-precision one. By doing
so, the full-precision model provides hints to guide the low-precision model
training. Extensive experiments on various datasets ( i.e., CIFAR-100 and
ImageNet) show the effectiveness of the proposed methods. To highlight, using
our methods to train a 4-bit precision network leads to no performance decrease
in comparison with its full-precision counterpart with standard network
architectures ( i.e., AlexNet and ResNet-50).
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00207</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning deep features for source color laser printer identification
  based on cascaded learning</dc:title>
 <dc:creator>Kim, Do-Guk</dc:creator>
 <dc:creator>Hou, Jong-Uk</dc:creator>
 <dc:creator>Lee, Heung-Kyu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Color laser printers have fast printing speed and high resolution, and
forgeries using color laser printers can cause significant harm to society. A
source printer identification technique can be employed as a countermeasure to
those forgeries. This paper presents a color laser printer identification
method based on cascaded learning of deep neural networks. The refiner network
is trained by adversarial training to refine the synthetic dataset for halftone
color decomposition. The halftone color decomposing ConvNet is trained with the
refined dataset, and the trained knowledge is transferred to the printer
identifying ConvNet to enhance the accuracy. The robustness about rotation and
scaling is considered in training process, which is not considered in existing
methods. Experiments are performed on eight color laser printers, and the
performance is compared with several existing methods. The experimental results
clearly show that the proposed method outperforms existing source color laser
printer identification methods.
</dc:description>
 <dc:description>Comment: 11 pages, 16 figures, submitted to Signal Processing: Image
  Communication</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00207</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00208</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy Preserving and Collusion Resistant Energy Sharing</dc:title>
 <dc:creator>Hong, Yuan</dc:creator>
 <dc:creator>Wang, Han</dc:creator>
 <dc:creator>Xie, Shangyu</dc:creator>
 <dc:creator>Liu, Bingyu</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Energy has been increasingly generated or collected by different entities on
the power grid (e.g., universities, hospitals and householdes) via solar
panels, wind turbines or local generators in the past decade. With local
energy, such electricity consumers can be considered as &quot;microgrids&quot; which can
simulataneously generate and consume energy. Some microgrids may have excessive
energy that can be shared to other power consumers on the grid. To this end,
all the entities have to share their local private information (e.g., their
local demand, local supply and power quality data) to each other or a
third-party to find and implement the optimal energy sharing solution. However,
such process is constrained by privacy concerns raised by the microgrids. In
this paper, we propose a privacy preserving scheme for all the microgrids which
can securely implement their energy sharing against both semi-honest and
colluding adversaries. The proposed approach includes two secure communication
protocols that can ensure quantified privacy leakage and handle collusions.
</dc:description>
 <dc:description>Comment: ICASSP 2018</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00208</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00210</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the complete weight enumerators of some linear codes with a few
  weights</dc:title>
 <dc:creator>Qi, Minglong</dc:creator>
 <dc:creator>Xiong, Shengwu</dc:creator>
 <dc:creator>Yuan, Jingling</dc:creator>
 <dc:creator>Rao, Wenbi</dc:creator>
 <dc:creator>Zhong, Luo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Linear codes with a few weights have important applications in authentication
codes, secret sharing, consumer electronics, etc.. The determination of the
parameters such as Hamming weight distributions and complete weight enumerators
of linear codes are important research topics. In this paper, we consider some
classes of linear codes with a few weights and determine the complete weight
enumerators from which the corresponding Hamming weight distributions are
derived with help of some sums involving Legendre symbol.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00210</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00214</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Coalition Formation Approach to Coordinated Task Allocation in
  Heterogeneous UAV Networks</dc:title>
 <dc:creator>Afghah, Fatemeh</dc:creator>
 <dc:creator>Zaeri-Amirani, Mohammad</dc:creator>
 <dc:creator>Razi, Abolfazl</dc:creator>
 <dc:creator>Chakareski, Jacob</dc:creator>
 <dc:creator>Bentley, Elizabeth</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  The problem of adversary target detection and the subsequent task completion
using a heterogeneous network of resource-constrained UAVs is considered. No
prior knowledge about locations and required resources to identify these
targets is available to the UAVs. In the proposed leader-follower coalition
formation model, the UAV that first locates a target serves as the coalition
leader and selects a group of follower UAVs to complete the task associated
with the identified target. The goal of the coalition formation is to complete
the designated tasks with minimal resource utilization. Another role of
coalition members is to make the ground station aware of the detected adversary
target by forwarding its signal to the station via a distributed cooperative
relaying scheme. We also propose a reputation-based mechanism for coalition
formation to monitor the cooperative behavior of the UAVs over the course of
time and exclude potentially untrustworthy UAVs. Simulation results show the
efficiency of the proposed method in forming optimal coalitions compared to
alternative methods.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures, submitted to ACC 2018</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00214</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00215</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimum Energy Quantized Neural Networks</dc:title>
 <dc:creator>Moons, Bert</dc:creator>
 <dc:creator>Goetschalckx, Koen</dc:creator>
 <dc:creator>Van Berckelaer, Nick</dc:creator>
 <dc:creator>Verhelst, Marian</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This work targets the automated minimum-energy optimization of Quantized
Neural Networks (QNNs) - networks using low precision weights and activations.
These networks are trained from scratch at an arbitrary fixed point precision.
At iso-accuracy, QNNs using fewer bits require deeper and wider network
architectures than networks using higher precision operators, while they
require less complex arithmetic and less bits per weights. This fundamental
trade-off is analyzed and quantified to find the minimum energy QNN for any
benchmark and hence optimize energy-efficiency. To this end, the energy
consumption of inference is modeled for a generic hardware platform. This
allows drawing several conclusions across different benchmarks. First, energy
consumption varies orders of magnitude at iso-accuracy depending on the number
of bits used in the QNN. Second, in a typical system, BinaryNets or int4
implementations lead to the minimum energy solution, outperforming int8
networks up to 2-10x at iso-accuracy. All code used for QNN training is
available from https://github.com/BertMoons.
</dc:description>
 <dc:description>Comment: preprint for work presented at the 51st Asilomar Conference on
  Signals, Systems and Computers</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2017-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00218</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatio-Temporal Reference Frames as Geographic Objects</dc:title>
 <dc:creator>Simmons, Andrew</dc:creator>
 <dc:creator>Vasa, Rajesh</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  It is often desirable to analyse trajectory data in local coordinates
relative to a reference location. Similarly, temporal data also needs to be
transformed to be relative to an event. Together, temporal and spatial
contextualisation permits comparative analysis of similar trajectories taken
across multiple reference locations. To the GIS professional, the procedures to
establish a reference frame at a location and reproject the data into local
coordinates are well known, albeit tedious. However, GIS tools are now often
used by subject matter experts who may not have the deep knowledge of
coordinate frames and projections required to use these techniques effectively.
  We introduce a novel method for representing spatio-temporal reference frames
using ordinary geographic objects available in GIS tools. We argue that our
method both reduces the number of manual steps required to reproject data to a
local reference frame, in addition to reducing the number of concepts a novice
user would need to learn.
</dc:description>
 <dc:description>Comment: 4 pages. To be published in the proceedings of the ACM SIGSPATIAL
  conference 2017. Minor typo corrected</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00220</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Hardness of Synthesizing Elementary Net Systems from Highly
  Restricted Inputs</dc:title>
 <dc:creator>Rosenke, Christian</dc:creator>
 <dc:creator>Tredup, Ronny</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Elementary net systems (ENS) are the most fundamental class of Petri nets.
Their synthesis problem has important applications in the design of digital
hardware and commercial processes. Given a labeled transition system (TS) $A$,
feasibility is the NP-complete decision problem whether $A$ can be equivalently
synthesized into an ENS. It is well known that $A$ is feasible if and only if
it has the event state separation property (ESSP) and the state separation
property (SSP). Recently, these properties have also been studied individually
for their practical implications. A fast ESSP algorithm, for instance, would
allow applications to at least validate the language equivalence of $A$ and a
synthesized ENS. Being able to efficiently decide SSP, on the other hand, could
serve as a quick-fail preprocessing mechanism for synthesis. Although a few
tractable subclasses have been found, this paper destroys much of the hope that
many practically meaningful input restrictions make feasibility or at least one
of ESSP and SSP efficient. We show that all three problems remain NP-complete
even if the input is restricted to linear TSs where every event occurs at most
three times or if the input is restricted to TSs where each event occurs at
most twice and each state has at most two successor and two predecessor states.
</dc:description>
 <dc:description>Comment: Technical Report</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00220</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00221</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Variational Inference for Fully Bayesian Sparse Gaussian
  Process Regression Models</dc:title>
 <dc:creator>Yu, Haibin</dc:creator>
 <dc:creator>Hoang, Trong Nghia</dc:creator>
 <dc:creator>Low, Kian Hsiang</dc:creator>
 <dc:creator>Jaillet, Patrick</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper presents a novel variational inference framework for deriving a
family of Bayesian sparse Gaussian process regression (SGPR) models whose
approximations are variationally optimal with respect to the full-rank GPR
model enriched with various corresponding correlation structures of the
observation noises.
  Our variational Bayesian SGPR (VBSGPR) models jointly treat both the
distributions of the inducing variables and hyperparameters as variational
parameters, which enables the decomposability of the variational lower bound
that in turn can be exploited for stochastic optimization.
  Such a stochastic optimization involves iteratively following the stochastic
gradient of the variational lower bound to improve its estimates of the optimal
variational distributions of the inducing variables and hyperparameters (and
hence the predictive distribution) of our VBSGPR models and is guaranteed to
achieve asymptotic convergence to them.
  We show that the stochastic gradient is an unbiased estimator of the exact
gradient and can be computed in constant time per iteration, hence achieving
scalability to big data.
  We empirically evaluate the performance of our proposed framework on two
real-world, massive datasets.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00221</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00227</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vertex-Context Sampling for Weighted Network Embedding</dc:title>
 <dc:creator>Chen, Chih-Ming</dc:creator>
 <dc:creator>Yang, Yi-Hsuan</dc:creator>
 <dc:creator>Chen, Yian</dc:creator>
 <dc:creator>Tsai, Ming-Feng</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  In recent years, network embedding methods have garnered increasing attention
because of their effectiveness in various information retrieval tasks. The goal
is to learn low-dimensional representations of vertexes in an information
network and simultaneously capture and preserve the network structure. Critical
to the performance of a network embedding method is how the edges/vertexes of
the network is sampled for the learning process. Many existing methods adopt a
uniform sampling method to reduce learning complexity, but when the network is
non-uniform (i.e. a weighted network) such uniform sampling incurs information
loss. The goal of this paper is to present a generalized vertex sampling
framework that works seamlessly with most existing network embedding methods to
support weighted instead of uniform vertex/edge sampling. For efficiency, we
propose a delicate sequential vertex-to-context graph data structure, such that
sampling a training pair for learning takes only constant time. For scalability
and memory efficiency, we design the graph data structure in a way that keeps
space consumption low without requiring additional space. In addition to
implementing existing network embedding methods, the proposed framework can be
used to implement extensions that feature high-order proximity modeling and
weighted relation modeling. Experiments conducted on three datasets, including
a commercial large-scale one, verify the effectiveness and efficiency of the
proposed weighted network embedding methods on a variety of tasks, including
word similarity search, multi-label classification, and item recommendation.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00227</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00229</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reducing Model Complexity for DNN Based Large-Scale Audio Classification</dc:title>
 <dc:creator>Wu, Yuzhong</dc:creator>
 <dc:creator>Lee, Tan</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Audio classification is the task of identifying the sound categories that are
associated with a given audio signal. This paper presents an investigation on
large-scale audio classification based on the recently released AudioSet
database. AudioSet comprises 2 millions of audio samples from YouTube, which
are human-annotated with 527 sound category labels. Audio classification
experiments with the balanced training set and the evaluation set of AudioSet
are carried out by applying different types of neural network models. The
classification performance and the model complexity of these models are
compared and analyzed. While the CNN models show better performance than MLP
and RNN, its model complexity is relatively high and undesirable for practical
use. We propose two different strategies that aim at constructing
low-dimensional embedding feature extractors and hence reducing the number of
model parameters. It is shown that the simplified CNN model has only 1/22 model
parameters of the original model, with only a slight degradation of
performance.
</dc:description>
 <dc:description>Comment: Submitted to ICASSP 2018</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00229</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00231</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Load Balancing Strategies for Graph Applications on GPUs</dc:title>
 <dc:creator>Raval, Ananya</dc:creator>
 <dc:creator>Nasre, Rupesh</dc:creator>
 <dc:creator>Kumar, Vivek</dc:creator>
 <dc:creator>R, Vasudevan</dc:creator>
 <dc:creator>Vadhiyar, Sathish</dc:creator>
 <dc:creator>Pingali, Keshav</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Acceleration of graph applications on GPUs has found large interest due to
the ubiquitous use of graph processing in various domains. The inherent
\textit{irregularity} in graph applications leads to several challenges for
parallelization. A key challenge, which we address in this paper, is that of
load-imbalance. If the work-assignment to threads uses node-based graph
partitioning, it can result in skewed task-distribution, leading to poor
load-balance. In contrast, if the work-assignment uses edge-based graph
partitioning, the load-balancing is better, but the memory requirement is
relatively higher. This makes it unsuitable for large graphs. In this work, we
propose three techniques for improved load-balancing of graph applications on
GPUs. Each technique brings in unique advantages, and a user may have to employ
a specific technique based on the requirement. Using Breadth First Search and
Single Source Shortest Paths as our processing kernels, we illustrate the
effectiveness of each of the proposed techniques in comparison to the existing
node-based and edge-based mechanisms.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00232</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Re-DPoctor: Real-time health data releasing with w-day differential
  privacy</dc:title>
 <dc:creator>Zhang, Jiajun</dc:creator>
 <dc:creator>Liang, Xiaohui</dc:creator>
 <dc:creator>Zhang, Zhikun</dc:creator>
 <dc:creator>He, Shibo</dc:creator>
 <dc:creator>Shi, Zhiguo</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Wearable devices enable users to collect health data and share them with
healthcare providers for improved health service. Since health data contain
privacy-sensitive information, unprotected data release system may result in
privacy leakage problem. Most of the existing work use differential privacy for
private data release. However, they have limitations in healthcare scenarios
because they do not consider the unique features of health data being collected
from wearables, such as continuous real-time collection and pattern
preservation. In this paper, we propose Re-DPoctor, a real-time health data
releasing scheme with $w$-day differential privacy where the privacy of health
data collected from any consecutive $w$ days is preserved. We improve utility
by using a specially-designed partition algorithm to protect the health data
patterns. Meanwhile, we improve privacy preservation by applying newly proposed
adaptive sampling technique and budget allocation method. We prove that
Re-DPoctor satisfies $w$-day differential privacy. Experiments on real health
data demonstrate that our method achieves better utility with strong privacy
guarantee than existing state-of-the-art methods.
</dc:description>
 <dc:description>Comment: Accepted for publication at 2017 IEEE Global Communications
  Conference (GLOBECOM)</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00238</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Single Multi-feature detector for Amodal 3D Object Detection in RGB-D
  Images</dc:title>
 <dc:creator>Luo, Qianhui</dc:creator>
 <dc:creator>Ma, Huifang</dc:creator>
 <dc:creator>Wang, Yue</dc:creator>
 <dc:creator>Tang, Li</dc:creator>
 <dc:creator>Xiong, Rong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper aims at fast and high-accuracy amodal 3D object detections in
RGB-D images, which requires a compact 3D bounding box around the whole object
even under partial observations. To avoid the time-consuming proposals
preextraction, we propose a single end-to-end framework based on the deep
neural networks which hierarchically incorporates appearance and geometric
features from 2.5D representation to 3D objects. The depth information has
helped on reducing the output space of 3D bounding boxes into a manageable set
of 3D anchor boxes with different sizes on multiple feature layers. At
prediction time, in a convolutional fashion, the network predicts scores for
categories and adjustments for locations, sizes and orientations of each 3D
anchor box, which has considered multi-scale 2D features. Experiments on the
challenging SUN RGB-D datasets show that our algorithm outperforms the
state-of-the-art by 10.2 in mAP and is 88x faster than the Deep Sliding Shape.
In addition, experiments suggest our algorithm even with a smaller input image
size performs comparably but is 454x faster than the state-of-art on NYUV2
datasets.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00238</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00239</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Classification With Augmented Features</dc:title>
 <dc:creator>Hou, Chenping</dc:creator>
 <dc:creator>Zeng, Ling-Li</dc:creator>
 <dc:creator>Hu, Dewen</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  With the evolution of data collection ways, it is possible to produce
abundant data described by multiple feature sets. Previous studies show that
including more features does not necessarily bring positive effect. How to
prevent the augmented features worsening classification performance is crucial
but rarely studied. In this paper, we study this challenging problem by
proposing a secure classification approach, whose accuracy is never degenerated
when exploiting augmented features. We propose two ways to achieve the security
of our method named as SEcure Classification (SEC). Firstly, to leverage
augmented features, we learn various types of classifiers and adapt them by
employing a specially designed robust loss. It provides various candidate
classifiers to meet the following assumption of security operation. Secondly,
we integrate all candidate classifiers by approximately maximizing the
performance improvement. Under a mild assumption, the integrated classifier has
theoretical security guarantee. Several new optimization methods have been
developed to accommodate the problems with proved convergence. Besides
evaluating SEC on 16 data sets, we also apply SEC in the application of
diagnostic classification of schizophrenia since it has vast application
potentiality. Experimental results demonstrate the effectiveness of SEC in both
tackling security problem and discriminating schizophrenic patients from
healthy controls.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00239</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00244</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Inferencing of Compressed Deep Neural Networks</dc:title>
 <dc:creator>Vooturi, Dharma Teja</dc:creator>
 <dc:creator>Goyal, Saurabh</dc:creator>
 <dc:creator>Choudhury, Anamitra R.</dc:creator>
 <dc:creator>Sabharwal, Yogish</dc:creator>
 <dc:creator>Verma, Ashish</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Large number of weights in deep neural networks makes the models difficult to
be deployed in low memory environments such as, mobile phones, IOT edge devices
as well as &quot;inferencing as a service&quot; environments on cloud. Prior work has
considered reduction in the size of the models, through compression techniques
like pruning, quantization, Huffman encoding etc. However, efficient
inferencing using the compressed models has received little attention,
specially with the Huffman encoding in place. In this paper, we propose
efficient parallel algorithms for inferencing of single image and batches,
under various memory constraints. Our experimental results show that our
approach of using variable batch size for inferencing achieves 15-25\%
performance improvement in the inference throughput for AlexNet, while
maintaining memory and latency constraints.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00244</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00247</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Text Language Identification for the South African Languages</dc:title>
 <dc:creator>Duvenhage, Bernardt</dc:creator>
 <dc:creator>Ntini, Mfundo</dc:creator>
 <dc:creator>Ramonyai, Phala</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Virtual assistants and text chatbots have recently been gaining popularity.
Given the short message nature of text-based chat interactions, the language
identification systems of these bots might only have 15 or 20 characters to
make a prediction. However, accurate text language identification is important,
especially in the early stages of many multilingual natural language processing
pipelines.
  This paper investigates the use of a naive Bayes classifier, to accurately
predict the language family that a piece of text belongs to, combined with a
lexicon based classifier to distinguish the specific South African language
that the text is written in. This approach leads to a 31% reduction in the
language detection error.
  In the spirit of reproducible research the training and testing datasets as
well as the code are published on github. Hopefully it will be useful to create
a text language identification shared task for South African languages.
</dc:description>
 <dc:description>Comment: Accepted to appear in the proceedings of The 28th Annual Symposium of
  the Pattern Recognition Association of South Africa, 2017</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00247</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00248</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Query-free Clothing Retrieval via Implicit Relevance Feedback</dc:title>
 <dc:creator>Chen, Zhuoxiang</dc:creator>
 <dc:creator>Xu, Zhe</dc:creator>
 <dc:creator>Zhang, Ya</dc:creator>
 <dc:creator>Gu, Xiao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Image-based clothing retrieval is receiving increasing interest with the
growth of online shopping. In practice, users may often have a desired piece of
clothing in mind (e.g., either having seen it before on the street or requiring
certain specific clothing attributes) but may be unable to supply an image as a
query. We model this problem as a new type of image retrieval task in which the
target image resides only in the user's mind (called &quot;mental image retrieval&quot;
hereafter). Because of the absence of an explicit query image, we propose to
solve this problem through relevance feedback. Specifically, a new Bayesian
formulation is proposed that simultaneously models the retrieval target and its
high-level representation in the mind of the user (called the &quot;user metric&quot;
hereafter) as posterior distributions of pre-fetched shop images and
heterogeneous features extracted from multiple clothing attributes,
respectively. Requiring only clicks as user feedback, the proposed algorithm is
able to account for the variability in human decision-making. Experiments with
real users demonstrate the effectiveness of the proposed algorithm.
</dc:description>
 <dc:description>Comment: 12 pages, under review at IEEE Transactions on Multimedia</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00248</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00253</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Learning of Structure-Aware Fully Convolutional Networks for
  Landmark Localization</dc:title>
 <dc:creator>Chen, Yu</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:creator>Wei, Xiu-Shen</dc:creator>
 <dc:creator>Liu, Lingqiao</dc:creator>
 <dc:creator>Yang, Jian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Landmark/pose estimation in single monocular images have received much effort
in computer vision due to its important applications. It remains a challenging
task when input images severe occlusions caused by, e.g., adverse camera views.
Under such circumstances, biologically implausible pose predictions may be
produced. In contrast, human vision is able to predict poses by exploiting
geometric constraints of landmark point inter-connectivity. To address the
problem, by incorporating priors about the structure of pose components, we
propose a novel structure-aware fully convolutional network to implicitly take
such priors into account during training of the deep network. Explicit learning
of such constraints is typically challenging. Instead, inspired by how human
identifies implausible poses, we design discriminators to distinguish the real
poses from the fake ones (such as biologically implausible ones). If the pose
generator G generates results that the discriminator fails to distinguish from
real ones, the network successfully learns the priors. Training of the network
follows the strategy of conditional Generative Adversarial Networks (GANs). The
effectiveness of the proposed network is evaluated on three pose-related tasks:
2D single human pose estimation, 2D facial landmark estimation and 3D single
human pose estimation. The proposed approach significantly outperforms the
state-of-the-art methods and almost always generates plausible pose
predictions, demonstrating the usefulness of implicit learning of structures
using GANs.
</dc:description>
 <dc:description>Comment: 14 pages. Extended version of arXiv:1705.00389</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00253</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00257</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bluetooth 5: a concrete step forward towards the IoT</dc:title>
 <dc:creator>Collotta, Mario</dc:creator>
 <dc:creator>Pau, Giovanni</dc:creator>
 <dc:creator>Talty, Timothy</dc:creator>
 <dc:creator>Tonguz, Ozan K.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Six years after the adoption of the standard 4.0, the Bluetooth Special
Interest Group (SIG), a non-profit association that deals with the study and
the development of technology standards including those of Bluetooth, has
officially released the main features of Bluetooth 5.0. It is one of the
significant developments in short-range wireless communication technology. As
stated by the SIG, the new standard will forever change the way people approach
the Internet of Things (IoT), turning it into something that takes place around
them in an almost natural and transparent way. In this article, the future IoT
scenarios and use cases that justify the push for Bluetooth 5 are introduced. A
set of new technical features that are included in Bluetooth 5 are presented,
and their advantages and drawbacks are described.
</dc:description>
 <dc:description>Comment: 17 pages, 3 figures, 3 tables, 15 references, IEEE Communications
  Magazine journal</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00257</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00258</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Smooth Neighbors on Teacher Graphs for Semi-supervised Learning</dc:title>
 <dc:creator>Luo, Yucen</dc:creator>
 <dc:creator>Zhu, Jun</dc:creator>
 <dc:creator>Li, Mengxi</dc:creator>
 <dc:creator>Ren, Yong</dc:creator>
 <dc:creator>Zhang, Bo</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The paper proposes an inductive semi-supervised learning method, called
Smooth Neighbors on Teacher Graphs (SNTG). At each iteration during training, a
graph is dynamically constructed based on predictions of the teacher model,
i.e., the implicit self-ensemble of models. Then the graph serves as a
similarity measure with respect to which the representations of &quot;similar&quot;
neighboring points are learned to be smooth on the low dimensional manifold. We
achieve state-of-the-art results on semi-supervised learning benchmarks. The
error rates are 9.89%, 3.99% for CIFAR-10 with 4000 labels, SVHN with 500
labels, respectively. In particular, the improvements are significant when the
labels are scarce. For non-augmented MNIST with only 20 labels, the error rate
is reduced from previous 4.81% to 1.36%. Our method is also effective under
noisy supervision and shows robustness to incorrect labels.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00258</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00260</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The geometry of optimally transported meshes on the sphere</dc:title>
 <dc:creator>Budd, Chris J.</dc:creator>
 <dc:creator>McRae, Andrew T. T.</dc:creator>
 <dc:creator>Cotter, Colin J.</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Mesh redistribution methods provide meshes with increased resolution in
particular regions of interest, while requiring that the connectivity of the
mesh remains fixed. Some state of the art methods attempt to explicitly
prescribe both the local cell size and their alignment to features of the
solution. However, the resulting problem is overdetermined, necessitating a
compromise between these conflicting requirements. An alternative approach,
extolled by the current authors, is to prescribe only the local cell size and
augment this with an optimal transport condition. It is well-known that the
resulting problem is well-posed and has a unique solution, not just in
Euclidean space but also on the sphere. Although the optimal transport approach
abandons explicit control over mesh anisotropy, previous work has shown that,
on the plane, the meshes produced are naturally aligned to various simple
features. In this paper, we show that the same is true on the sphere.
Furthermore, formal results on the regularity of solutions to optimal transport
problems imply the sphere is actually more benign than the plane for mesh
generation, due to its intrinsic curvature. We also see informal evidence of
this. We provide a wide range of examples to showcase the behaviour of
optimally transported meshes on the sphere, from axisymmetric cases that can be
solved analytically to more general examples that are tackled numerically.
Evaluation of the singular values and singular vectors of the mesh
transformation provides a quantitative measure of the mesh anisotropy, and this
is shown to match analytic predictions.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00260</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00267</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Acquiring Target Stacking Skills by Goal-Parameterized Deep
  Reinforcement Learning</dc:title>
 <dc:creator>Li, Wenbin</dc:creator>
 <dc:creator>Bohg, Jeannette</dc:creator>
 <dc:creator>Fritz, Mario</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Understanding physical phenomena is a key component of human intelligence and
enables physical interaction with previously unseen environments. In this
paper, we study how an artificial agent can autonomously acquire this intuition
through interaction with the environment. We created a synthetic block stacking
environment with physics simulation in which the agent can learn a policy
end-to-end through trial and error. Thereby, we bypass to explicitly model
physical knowledge within the policy. We are specifically interested in tasks
that require the agent to reach a given goal state that may be different for
every new trial. To this end, we propose a deep reinforcement learning
framework that learns policies which are parametrized by a goal. We validated
the model on a toy example navigating in a grid world with different target
positions and in a block stacking task with different target structures of the
final tower. In contrast to prior work, our policies show better generalization
across different goals.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00267</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00270</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Determination of Checkpointing Intervals for Malleable Applications</dc:title>
 <dc:creator>Raghavendra, K.</dc:creator>
 <dc:creator>Vadhiyar, Sathish S</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Selecting optimal intervals of checkpointing an application is important for
minimizing the run time of the application in the presence of system failures.
Most of the existing efforts on checkpointing interval selection were developed
for sequential applications while few efforts deal with parallel applications
where the applications are executed on the same number of processors for the
entire duration of execution. Some checkpointing systems support parallel
applications where the number of processors on which the applications execute
can be changed during the execution. We refer to these kinds of parallel
applications as {\em malleable} applications. In this paper, we develop a
performance model for malleable parallel applications that estimates the amount
of useful work performed in unit time (UWT) by a malleable application in the
presence of failures as a function of checkpointing interval. We use this
performance model function with different intervals and select the interval
that maximizes the UWT value. By conducting a large number of simulations with
the traces obtained on real supercomputing systems, we show that the
checkpointing intervals determined by our model can lead to high efficiency of
applications in the presence of failures.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00270</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00275</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Dynamic Arrays</dc:title>
 <dc:creator>Bille, Philip</dc:creator>
 <dc:creator>Christiansen, Anders Roy</dc:creator>
 <dc:creator>Ettienne, Mikko Berggren</dc:creator>
 <dc:creator>G&#xf8;rtz, Inge Li</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:description>  We present a highly optimized implementation of tiered vectors, a data
structure for maintaining a sequence of $n$ elements supporting access in time
$O(1)$ and insertion and deletion in time $O(n^\epsilon)$ for $\epsilon &gt; 0$
while using $o(n)$ extra space. We consider several different implementation
optimizations in C++ and compare their performance to that of vector and
multiset from the standard library on sequences with up to $10^8$ elements. Our
fastest implementation uses much less space than multiset while providing
speedups of $40\times$ for access operations compared to multiset and speedups
of $10.000\times$ compared to vector for insertion and deletion operations
while being competitive with both data structures for all other operations.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00275</dc:identifier>
 <dc:identifier>doi:10.4230/LIPIcs.ESA.2017.16</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00279</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Paraphrase Generation with Deep Reinforcement Learning</dc:title>
 <dc:creator>Li, Zichao</dc:creator>
 <dc:creator>Jiang, Xin</dc:creator>
 <dc:creator>Shang, Lifeng</dc:creator>
 <dc:creator>Li, Hang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Automatic generation of paraphrases from a given sentence is an important yet
challenging task in natural language processing (NLP), and plays a key role in
a number of applications such as question answering, search, and dialogue. In
this paper, we present a deep reinforcement learning approach to paraphrase
generation. Specifically, we propose a new framework for the task, which
consists of a \textit{generator} and an \textit{evaluator}, both of which are
learned from data. The generator, built as a sequence-to-sequence learning
model, can produce paraphrases given a sentence. The evaluator, constructed as
a deep matching model, can judge whether two sentences are paraphrases of each
other. The generator is first trained by deep learning and then further
fine-tuned by reinforcement learning in which the reward is given by the
evaluator. For the learning of the evaluator, we propose two methods based on
supervised learning and inverse reinforcement learning respectively, depending
on the type of available training data. Empirical study shows that the learned
evaluator can guide the generator to produce more accurate paraphrases.
Experimental results demonstrate the proposed models (the generators)
outperform the state-of-the-art methods in paraphrase generation in both
automatic evaluation and human evaluation.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00282</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inapproximability of the independent set polynomial in the complex plane</dc:title>
 <dc:creator>Bezakova, Ivona</dc:creator>
 <dc:creator>Galanis, Andreas</dc:creator>
 <dc:creator>Goldberg, Leslie Ann</dc:creator>
 <dc:creator>Stefankovic, Daniel</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We study the complexity of approximating the independent set polynomial
$Z_G(\lambda)$ of a graph $G$ with maximum degree $\Delta$ when the activity
$\lambda$ is a complex number.
  This problem is already well understood when $\lambda$ is real using
connections to the $\Delta$-regular tree $T$. The key concept in that case is
the &quot;occupation ratio&quot; of the tree $T$. This ratio is the contribution to
$Z_T(\lambda)$ from independent sets containing the root of the tree, divided
by $Z_T(\lambda)$ itself. If $\lambda$ is such that the occupation ratio
converges to a limit, as the height of $T$ grows, then there is an FPTAS for
approximating $Z_G(\lambda)$ on a graph $G$ with maximum degree $\Delta$.
Otherwise, the approximation problem is NP-hard.
  Unsurprisingly, the case where $\lambda$ is complex is more challenging.
Peters and Regts identified the values of $\lambda$ for which the occupation
ratio of the $\Delta$-regular tree converges. These values carve a
cardioid-shaped region $\Lambda_\Delta$ in the complex plane. Motivated by the
picture in the real case, they asked whether $\Lambda_\Delta$ marks the true
approximability threshold for general complex values $\lambda$.
  Our main result shows that for every $\lambda$ outside of $\Lambda_\Delta$,
the problem of approximating $Z_G(\lambda)$ on graphs $G$ with maximum degree
at most $\Delta$ is indeed NP-hard. In fact, when $\lambda$ is outside of
$\Lambda_\Delta$ and is not a positive real number, we give the stronger result
that approximating $Z_G(\lambda)$ is actually #P-hard. If $\lambda$ is a
negative real number outside of $\Lambda_\Delta$, we show that it is #P-hard to
even decide whether $Z_G(\lambda)&gt;0$, resolving in the affirmative a conjecture
of Harvey, Srivastava and Vondrak.
  Our proof techniques are based around tools from complex analysis -
specifically the study of iterative multivariate rational maps.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00282</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00284</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Approximation Schemes for the Restricted Shortest Path Problem</dc:title>
 <dc:creator>Holzm&#xfc;ller, David</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  The Restricted Shortest Path (RSP) problem, also known as the
Delay-Constrained Least-Cost (DCLC) problem, is an NP-hard bicriteria
optimization problem on graphs with $n$ vertices and $m$ edges. In a graph
where each edge is assigned a cost and a delay, the goal is to find a min-cost
path which does not exceed a delay bound. In this paper, we present improved
approximation schemes for RSP on several graph classes. For planar graphs,
undirected graphs with positive integer resource (= delay) values, and graphs
with $m \in \Omega(n \log n)$, we obtain $(1 + \varepsilon)$-approximations in
time $O(mn/\varepsilon)$. For general graphs and directed acyclic graphs, we
match the results by Xue et al. (2008, [10]) and Ergun et al. (2002, [1]),
respectively, but with arguably simpler algorithms.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00284</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00289</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep and Shallow convections in Atmosphere Models on Intel Xeon Phi
  Coprocessor Systems</dc:title>
 <dc:creator>Ramesh, Srinivasan</dc:creator>
 <dc:creator>Vadhiyar, Sathish</dc:creator>
 <dc:creator>Nanjundiah, Ravi</dc:creator>
 <dc:creator>Vinayachandran, PN</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Deep and shallow convection calculations occupy significant times in
atmosphere models. These calculations also present significant load imbalances
due to varying cloud covers over different regions of the grid. In this work,
we accelerate these calculations on Intel{\textregistered} Xeon
Phi{\texttrademark} Coprocessor Systems. By employing dynamic scheduling in
OpenMP, we demonstrate large reductions in load imbalance and about 10%
increase in speedups. By careful categorization of data as private,
firstprivate and shared, we minimize data copying overheads for the
coprocessors. We identify regions of false sharing among threads and eliminate
them by loop rearrangements. We also employ proportional partitioning of
independent column computations across both the CPU and coprocessor cores based
on the performance ratio of the computations on the heterogeneous resources.
These techniques along with various vectorization strategies resulted in about
30% improvement in convection calculations.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00289</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00294</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Automatic Generation of Entertaining Dialogues in Chinese
  Crosstalks</dc:title>
 <dc:creator>Du, Shikang</dc:creator>
 <dc:creator>Wan, Xiaojun</dc:creator>
 <dc:creator>Ye, Yajie</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Crosstalk, also known by its Chinese name xiangsheng, is a traditional
Chinese comedic performing art featuring jokes and funny dialogues, and one of
China's most popular cultural elements. It is typically in the form of a
dialogue between two performers for the purpose of bringing laughter to the
audience, with one person acting as the leading comedian and the other as the
supporting role. Though general dialogue generation has been widely explored in
previous studies, it is unknown whether such entertaining dialogues can be
automatically generated or not. In this paper, we for the first time
investigate the possibility of automatic generation of entertaining dialogues
in Chinese crosstalks. Given the utterance of the leading comedian in each
dialogue, our task aims to generate the replying utterance of the supporting
role. We propose a humor-enhanced translation model to address this task and
human evaluation results demonstrate the efficacy of our proposed model. The
feasibility of automatic entertaining dialogue generation is also verified.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00300</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Killing Two Birds with One Stone: Malicious Domain Detection with High
  Accuracy and Coverage</dc:title>
 <dc:creator>Khalil, Issa</dc:creator>
 <dc:creator>Guan, Bei</dc:creator>
 <dc:creator>Nabeel, Mohamed</dc:creator>
 <dc:creator>Yu, Ting</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Inference based techniques are one of the major approaches to analyze DNS
data and detecting malicious domains. The key idea of inference techniques is
to first define associations between domains based on features extracted from
DNS data. Then, an inference algorithm is deployed to infer potential malicious
domains based on their direct/indirect associations with known malicious ones.
The way associations are defined is key to the effectiveness of an inference
technique. It is desirable to be both accurate (i.e., avoid falsely associating
domains with no meaningful connections) and with good coverage (i.e., identify
all associations between domains with meaningful connections). Due to the
limited scope of information provided by DNS data, it becomes a challenge to
design an association scheme that achieves both high accuracy and good
coverage.
  In this paper, we propose a new association scheme to identify domains
controlled by the same entity. Our key idea is an in-depth analysis of active
DNS data to accurately separate public IPs from dedicated ones, which enables
us to build high-quality associations between domains. Our scheme identifies
many meaningful connections between domains that are discarded by existing
state-of-the-art approaches. Our experimental results show that the proposed
association scheme not only significantly improves the domain coverage compared
to existing approaches but also achieves better detection accuracy.
  Existing path-based inference algorithm is specifically designed for DNS data
analysis. It is effective but computationally expensive. As a solution, we
investigate the effectiveness of combining our association scheme with the
generic belief propagation algorithm. Through comprehensive experiments, we
show that this approach offers significant efficiency and scalability
improvement with only minor negative impact of detection accuracy.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00300</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00304</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Attention to Participation: Reviewing and Modelling Engagement with
  Computers</dc:title>
 <dc:creator>Miquel-Ribe, Marc</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Over the last decades, the Internet and mobile technology have consolidated
the digital as a public sphere of life. Designers are asked to create engaging
digital experiences. However, in some cases engagement is seen as a
psychological state, while in others it emphasizes a participative vein. In
this paper, I review and discuss both and propose a new definition to clarify
the concept engagement with computers. Thus, engagement is a quality of an
active connection between a user and a computing product, either a website or a
mobile phone app. Studying it requires understanding a set of aspects like the
user's affect, motivation and attention, as well as the product's design,
content and composition. Finally, I propose explaining these concepts aligned
with engagement and integrate them into a preliminary model to measure the
manifestations.
</dc:description>
 <dc:description>Comment: 28 pages, 5 figures</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00304</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00305</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-View Data Generation Without View Supervision</dc:title>
 <dc:creator>Chen, Micka&#xeb;l</dc:creator>
 <dc:creator>Denoyer, Ludovic</dc:creator>
 <dc:creator>Arti&#xe8;res, Thierry</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The development of high-dimensional generative models has recently gained a
great surge of interest with the introduction of variational auto-encoders and
generative adversarial neural networks. Different variants have been proposed
where the underlying latent space is structured, for example, based on
attributes describing the data to generate. We focus on a particular problem
where one aims at generating samples corresponding to a number of objects under
various views. We assume that the distribution of the data is driven by two
independent latent factors: the content, which represents the intrinsic
features of an object, and the view, which stands for the settings of a
particular observation of that object. Therefore, we propose a generative model
and a conditional variant built on such a disentangled latent space. This
approach allows us to generate realistic samples corresponding to various
objects in a high variety of views. Unlike many multi-view approaches, our
model doesn't need any supervision on the views but only on the content.
Compared to other conditional generation approaches that are mostly based on
binary or categorical attributes, we make no such assumption about the factors
of variations. Our model can be used on problems with a huge, potentially
infinite, number of categories. We experiment it on four image datasets on
which we demonstrate the effectiveness of the model and its ability to
generalize.
</dc:description>
 <dc:description>Comment: Submitted at ICLR 2018</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00309</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Neural Machine Translation through Phrase-based Forced
  Decoding</dc:title>
 <dc:creator>Zhang, Jingyi</dc:creator>
 <dc:creator>Utiyama, Masao</dc:creator>
 <dc:creator>Sumita, Eiichro</dc:creator>
 <dc:creator>Neubig, Graham</dc:creator>
 <dc:creator>Nakamura, Satoshi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Compared to traditional statistical machine translation (SMT), neural machine
translation (NMT) often sacrifices adequacy for the sake of fluency. We propose
a method to combine the advantages of traditional SMT and NMT by exploiting an
existing phrase-based SMT model to compute the phrase-based decoding cost for
an NMT output and then using this cost to rerank the n-best NMT outputs. The
main challenge in implementing this approach is that NMT outputs may not be in
the search space of the standard phrase-based decoding algorithm, because the
search space of phrase-based SMT is limited by the phrase-based translation
rule table. We propose a soft forced decoding algorithm, which can always
successfully find a decoding path for any NMT output. We show that using the
forced decoding cost to rerank the NMT outputs can successfully improve
translation quality on four different language pairs.
</dc:description>
 <dc:description>Comment: IJCNLP2017</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00309</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00310</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Search Powered Navigation</dc:title>
 <dc:creator>Dehghani, Mostafa</dc:creator>
 <dc:creator>Jagfeld, Glorianna</dc:creator>
 <dc:creator>Azarbonyad, Hosein</dc:creator>
 <dc:creator>Olieman, Alex</dc:creator>
 <dc:creator>Kamps, Jaap</dc:creator>
 <dc:creator>Marx, Maarten</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Query-based searching and browsing-based navigation are the two main
components of exploratory search. Search lets users dig in deep by controlling
their actions to focus on and find just the information they need, whereas
navigation helps them to get an overview to decide which content is most
important. In this paper, we introduce the concept of &quot;search powered
navigation&quot; and investigate the effect of empowering navigation with search
functionality on information seeking behavior of users and their experience by
conducting a user study on exploratory search tasks, differentiated by
different types of information needs. Our main findings are as follows: First,
we observe radically different search tactics. Using search, users are able to
control and augment their search focus, hence they explore the data in a
depth-first, bottom-up manner. Conversely, using pure navigation they tend to
check different options to be able to decide on their path into the data, which
corresponds to a breadth-first, top-down exploration. Second, we observe a
general natural tendency to combine aspects of search and navigation, however,
our experiments show that the search functionality is essential to solve
exploratory search tasks that require finding documents related to a narrow
domain. Third, we observe a natural need for search powered navigation: users
using a system without search functionality find creative ways to mimic
searching using navigation.
</dc:description>
 <dc:description>Comment: Accepted for publication in ACM SIGIR International Conference on the
  Theory of Information Retrieval</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00310</dc:identifier>
 <dc:identifier>doi:10.1145/3121050.3121105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00312</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Potential and Challenges of CAD with Equational Constraints for
  SC-Square</dc:title>
 <dc:creator>Davenport, James H.</dc:creator>
 <dc:creator>England, Matthew</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>68W30, 03C10</dc:subject>
 <dc:subject>I.1.2</dc:subject>
 <dc:description>  Cylindrical algebraic decomposition (CAD) is a core algorithm within Symbolic
Computation, particularly for quantifier elimination over the reals and
polynomial systems solving more generally. It is now finding increased
application as a decision procedure for Satisfiability Modulo Theories (SMT)
solvers when working with non-linear real arithmetic. We discuss the potentials
from increased focus on the logical structure of the input brought by the SMT
applications and SC-Square project, particularly the presence of equational
constraints. We also highlight the challenges for exploiting these: primitivity
restrictions, well-orientedness questions, and the prospect of incrementality.
</dc:description>
 <dc:description>Comment: Accepted into proceedings of MACIS 2017</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00312</dc:identifier>
 <dc:identifier>In: Blomer J., Kotsireas I., Kutsia T., Simos D. (eds)
  Mathematical Aspects of Computer and Information Sciences (Proc. MACIS '17),
  pp. 280-285. (Lecture Notes in Computer Science 10693). Springer
  International, 2017</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-72453-9_22</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00313</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Avoiding Your Teacher's Mistakes: Training Neural Networks with
  Controlled Weak Supervision</dc:title>
 <dc:creator>Dehghani, Mostafa</dc:creator>
 <dc:creator>Severyn, Aliaksei</dc:creator>
 <dc:creator>Rothe, Sascha</dc:creator>
 <dc:creator>Kamps, Jaap</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Training deep neural networks requires massive amounts of training data, but
for many tasks only limited labeled data is available. This makes weak
supervision attractive, using weak or noisy signals like the output of
heuristic methods or user click-through data for training. In a semi-supervised
setting, we can use a large set of data with weak labels to pretrain a neural
network and then fine-tune the parameters with a small amount of data with true
labels. This feels intuitively sub-optimal as these two independent stages
leave the model unaware about the varying label quality. What if we could
somehow inform the model about the label quality? In this paper, we propose a
semi-supervised learning method where we train two neural networks in a
multi-task fashion: a &quot;target network&quot; and a &quot;confidence network&quot;. The target
network is optimized to perform a given task and is trained using a large set
of unlabeled data that are weakly annotated. We propose to weight the gradient
updates to the target network using the scores provided by the second
confidence network, which is trained on a small amount of supervised data. Thus
we avoid that the weight updates computed from noisy labels harm the quality of
the target network model. We evaluate our learning strategy on two different
tasks: document ranking and sentiment classification. The results demonstrate
that our approach not only enhances the performance compared to the baselines
but also speeds up the learning process from weak labels.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2017-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00313</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00317</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear/Quadratic Programming-Based Optimal Power Flow using Linear Power
  Flow and Absolute Loss Approximations</dc:title>
 <dc:creator>Fortenbacher, Philipp</dc:creator>
 <dc:creator>Demiray, Turhan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents a novel method to approximate the nonlinear AC optimal
power flow (OPF) into tractable linear/ quadratic programming (LP/QP) based OPF
problems that can be used for power system planning and operation. We derive a
linear power flow approximation and include a convex reformulation of the power
losses in the form of absolute value functions. We show three ways how we can
incorporate this approximation into an LP/QP based OPF problem. The usefulness
of our OPF methods is analyzed for the IEEE test case grids. As a result, the
errors on voltage magnitudes and angles are reasonable, while obtaining
near-optimal results. We find that our methods reduce significantly the
computational complexity compared to the nonlinear AC-OPF making them a good
choice for planning purposes.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00317</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00322</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Saliency Detection via Fusing Foreground and Background Priors</dc:title>
 <dc:creator>Huang, Kan</dc:creator>
 <dc:creator>Zhu, Chunbiao</dc:creator>
 <dc:creator>Li, Ge</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automatic Salient object detection has received tremendous attention from
research community and has been an increasingly important tool in many computer
vision tasks. This paper proposes a novel bottom-up salient object detection
framework which considers both foreground and background cues. First, A series
of background and foreground seeds are selected from an image reliably, and
then used for calculation of saliency map separately. Next, a combination of
foreground and background saliency map is performed. Last, a refinement step
based on geodesic distance is utilized to enhance salient regions, thus
deriving the final saliency map. Particularly we provide a robust scheme for
seeds selection which contributes a lot to accuracy improvement in saliency
detection. Extensive experimental evaluations demonstrate the effectiveness of
our proposed method against other outstanding methods.
</dc:description>
 <dc:description>Comment: Project website: https://github.com/ChunbiaoZhu/FBP</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00322</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00326</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The quoter model: a paradigmatic model of the social flow of written
  information</dc:title>
 <dc:creator>Bagrow, James P.</dc:creator>
 <dc:creator>Mitchell, Lewis</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  We propose a model for the social flow of information in the form of text
data, which simulates the posting and sharing of short social media posts.
Nodes in a graph representing a social network take turns generating words,
leading to a symbolic time series associated with each node. Information
propagates over the graph via a quoting mechanism, where nodes randomly copy
short segments of text from each other. We characterize information flows from
these text via information-theoretic estimators, and we derive analytic
relationships between model parameters and the values of these estimators. We
explore and validate the model with simulations on small network motifs and
larger random graphs. Tractable models such as ours that generate symbolic data
while controlling the information flow allow us to test and compare measures of
information flow applicable to real social media data. In particular, by
choosing different network structures, we can develop test scenarios to
determine whether or not measures of information flow can distinguish between
true and spurious interactions, and how topological network properties relate
to information flow.
</dc:description>
 <dc:description>Comment: 23 pages, 9 figures</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00326</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00331</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Structure and Interpretability of Word Embeddings</dc:title>
 <dc:creator>Senel, Lutfi Kerem</dc:creator>
 <dc:creator>Utlu, Ihsan</dc:creator>
 <dc:creator>Yucesoy, Veysel</dc:creator>
 <dc:creator>Koc, Aykut</dc:creator>
 <dc:creator>Cukur, Tolga</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Dense word embeddings, which encode semantic meanings of words to low
dimensional vector spaces have become very popular in natural language
processing (NLP) research due to their state-of-the-art performances in many
NLP tasks. Word embeddings are substantially successful in capturing semantic
relations among words, so a meaningful semantic structure must be present in
the respective vector spaces. However, in many cases, this semantic structure
is broadly and heterogeneously distributed across the embedding dimensions,
which makes interpretation a big challenge. In this study, we propose a
statistical method to uncover the latent semantic structure in the dense word
embeddings. To perform our analysis we introduce a new dataset (SEMCAT) that
contains more than 6500 words semantically grouped under 110 categories. We
further propose a method to quantify the interpretability of the word
embeddings; the proposed method is a practical alternative to the classical
word intrusion test that requires human intervention.
</dc:description>
 <dc:description>Comment: 10 Pages, 7 Figures</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2017-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00331</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00333</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Experimental Analysis of the Power Consumption of Convolutional
  Neural Networks for Keyword Spotting</dc:title>
 <dc:creator>Tang, Raphael</dc:creator>
 <dc:creator>Wang, Weijie</dc:creator>
 <dc:creator>Tu, Zhucheng</dc:creator>
 <dc:creator>Lin, Jimmy</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  Nearly all previous work on small-footprint keyword spotting with neural
networks quantify model footprint in terms of the number of parameters and
multiply operations for an inference pass. These values are, however, proxy
measures since empirical performance in actual deployments is determined by
many factors. In this paper, we study the power consumption of a family of
convolutional neural networks for keyword spotting on a Raspberry Pi. We find
that both proxies are good predictors of energy usage, although the number of
multiplies is more predictive than the number of parameters. We also confirm
that models with the highest accuracies are, unsurprisingly, the most power
hungry.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00333</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00336</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Coupled Lattice Boltzmann Method and Discrete Element Method for
  Discrete Particle Simulations of Particulate Flows</dc:title>
 <dc:creator>Rettinger, Christoph</dc:creator>
 <dc:creator>R&#xfc;de, Ulrich</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  Discrete particle simulations are widely used to study large-scale
particulate flows in complex geometries where particle-particle and
particle-fluid interactions require an adequate representation but the
computational cost has to be kept low. In this work, we present a novel
coupling approach for such simulations. A lattice Boltzmann formulation of the
generalized Navier-Stokes equations is used to describe the fluid motion. This
promises efficient simulations suitable for high performance computing and,
since volume displacement effects by the solid phase are considered, our
approach is also applicable to non-dilute particulate systems. The discrete
element method is combined with an explicit evaluation of interparticle
lubrication forces to simulate the motion of individual submerged particles.
Drag, pressure and added mass forces determine the momentum transfer by
fluid-particle interactions. A stable coupling algorithm is presented and
discussed in detail. We demonstrate the validity of our approach for dilute as
well as dense systems by predicting the settling velocity of spheres over a
broad range of solid volume fractions in good agreement with semi-empirical
correlations. Additionally, the accuracy of particle-wall interactions in a
viscous fluid is thoroughly tested and established. Our approach can thus be
readily used for various particulate systems and can be extended
straightforward to e.g. non-spherical particles.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00336</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00339</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Spectral Analysis of the Internet Delay Space and Detecting Anomalous
  Routing Paths</dc:title>
 <dc:creator>G&#xfc;rsun, Gonca</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Latency is one of the most critical performance metrics for a wide range of
applications. Therefore, it is important to understand the underlying
mechanisms that give rise to the observed latency values and diagnose the ones
that are unexpectedly high. In this paper, we study the Internet delay space
via robust principal component analysis (RPCA). Using RPCA, we show that the
delay space, i.e. the matrix of measured round trip times between end hosts,
can be decomposed into two components - the expected latency between end hosts
with respect to the current state of the Internet and the inflation on the
paths between the end hosts. Using this decomposition, first we study the
well-known low-dimensionality phenomena of the delay space and ask what
properties of the end hosts define the dimensions. Second, using the
decomposition, we develop a filtering method to detect the paths which
experience unexpected latencies and identify routing anomalies. We show that
our filter successfully identifies an anomalous route even when its observed
latency is not obviously high in magnitude.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00342</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Orthogonal Machine Learning: Power and Limitations</dc:title>
 <dc:creator>Mackey, Lester</dc:creator>
 <dc:creator>Syrgkanis, Vasilis</dc:creator>
 <dc:creator>Zadik, Ilias</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Economics - Econometrics</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Double machine learning provides $\sqrt{n}$-consistent estimates of
parameters of interest even when high-dimensional or nonparametric nuisance
parameters are estimated at an $n^{-1/4}$ rate. The key is to employ
Neyman-orthogonal moment equations which are first-order insensitive to
perturbations in the nuisance parameters. We show that the $n^{-1/4}$
requirement can be improved to $n^{-1/(2k+2)}$ by employing a $k$-th order
notion of orthogonality that grants robustness to more complex or
higher-dimensional nuisance parameters. In the partially linear regression
setting popular in causal inference, we show that we can construct second-order
orthogonal moments if and only if the treatment residual is not normally
distributed. Our proof relies on Stein's lemma and may be of independent
interest. We conclude by demonstrating the robustness benefits of an explicit
doubly-orthogonal estimation procedure for treatment effect.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00342</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00349</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic calcium scoring in low-dose chest CT using deep neural
  networks with dilated convolutions</dc:title>
 <dc:creator>Lessmann, Nikolas</dc:creator>
 <dc:creator>van Ginneken, Bram</dc:creator>
 <dc:creator>Zreik, Majd</dc:creator>
 <dc:creator>de Jong, Pim A.</dc:creator>
 <dc:creator>de Vos, Bob D.</dc:creator>
 <dc:creator>Viergever, Max A.</dc:creator>
 <dc:creator>I&#x161;gum, Ivana</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Heavy smokers undergoing screening with low-dose chest CT are affected by
cardiovascular disease as much as by lung cancer. Low-dose chest CT scans
acquired in screening enable quantification of atherosclerotic calcifications
and thus enable identification of subjects at increased cardiovascular risk.
This paper presents a method for automatic detection of coronary artery,
thoracic aorta and cardiac valve calcifications in low-dose chest CT using two
consecutive convolutional neural networks. The first network identifies and
labels potential calcifications according to their anatomical location and the
second network identifies true calcifications among the detected candidates.
This method was trained and evaluated on a set of 1744 CT scans from the
National Lung Screening Trial. To determine whether any reconstruction or only
images reconstructed with soft tissue filters can be used for calcification
detection, we evaluated the method on soft and medium/sharp filter
reconstructions separately. On soft filter reconstructions, the method achieved
F1 scores of 0.89, 0.89, 0.67, and 0.55 for coronary artery, thoracic aorta,
aortic valve and mitral valve calcifications, respectively. On sharp filter
reconstructions, the F1 scores were 0.84, 0.81, 0.64, and 0.66, respectively.
Linearly weighted kappa coefficients for risk category assignment based on per
subject coronary artery calcium were 0.91 and 0.90 for soft and sharp filter
reconstructions, respectively. These results demonstrate that the presented
method enables reliable automatic cardiovascular risk assessment in all
low-dose chest CT scans acquired for lung cancer screening.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE Transactions on Medical Imaging</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00349</dc:identifier>
 <dc:identifier>doi:10.1109/TMI.2017.2769839</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00350</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Still not systematic after all these years: On the compositional skills
  of sequence-to-sequence recurrent networks</dc:title>
 <dc:creator>Lake, Brenden M.</dc:creator>
 <dc:creator>Baroni, Marco</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Humans can understand and produce new utterances effortlessly, thanks to
their systematic compositional skills. Once a person learns the meaning of a
new verb &quot;dax,&quot; he or she can immediately understand the meaning of &quot;dax twice&quot;
or &quot;sing and dax.&quot; In this paper, we introduce the SCAN domain, consisting of a
set of simple compositional navigation commands paired with the corresponding
action sequences. We then test the zero-shot generalization capabilities of a
variety of recurrent neural networks (RNNs) trained on SCAN with
sequence-to-sequence methods. We find that RNNs can generalize well when the
differences between training and test commands are small, so that they can
apply &quot;mix-and-match&quot; strategies to solve the task. However, when
generalization requires systematic compositional skills (as in the &quot;dax&quot;
example above), RNNs fail spectacularly. We conclude with a proof-of-concept
experiment in neural machine translation, supporting the conjecture that lack
of systematicity is an important factor explaining why neural networks need
very large training sets.
</dc:description>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00351</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shift-Invariant Kernel Additive Modelling for Audio Source Separation</dc:title>
 <dc:creator>Yela, Delia Fano</dc:creator>
 <dc:creator>Ewert, Sebastian</dc:creator>
 <dc:creator>O'Hanlon, Ken</dc:creator>
 <dc:creator>Sandler, Mark B.</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>H.5.5</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:description>  A major goal in blind source separation to identify and separate sources is
to model their inherent characteristics. While most state-of-the-art approaches
are supervised methods trained on large datasets, interest in non-data-driven
approaches such as Kernel Additive Modelling (KAM) remains high due to their
interpretability and adaptability. KAM performs the separation of a given
source applying robust statistics on the time-frequency bins selected by a
source-specific kernel function, commonly the K-NN function. This choice
assumes that the source of interest repeats in both time and frequency. In
practice, this assumption does not always hold. Therefore, we introduce a
shift-invariant kernel function capable of identifying similar spectral content
even under frequency shifts. This way, we can considerably increase the amount
of suitable sound material available to the robust statistics. While this leads
to an increase in separation performance, a basic formulation, however, is
computationally expensive. Therefore, we additionally present acceleration
techniques that lower the overall computational complexity.
</dc:description>
 <dc:description>Comment: Feedback is welcome</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00351</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00354</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>JSUT corpus: free large-scale Japanese speech corpus for end-to-end
  speech synthesis</dc:title>
 <dc:creator>Sonobe, Ryosuke</dc:creator>
 <dc:creator>Takamichi, Shinnosuke</dc:creator>
 <dc:creator>Saruwatari, Hiroshi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Thanks to improvements in machine learning techniques including deep
learning, a free large-scale speech corpus that can be shared between academic
institutions and commercial companies has an important role. However, such a
corpus for Japanese speech synthesis does not exist. In this paper, we designed
a novel Japanese speech corpus, named the &quot;JSUT corpus,&quot; that is aimed at
achieving end-to-end speech synthesis. The corpus consists of 10 hours of
reading-style speech data and its transcription and covers all of the main
pronunciations of daily-use Japanese characters. In this paper, we describe how
we designed and analyzed the corpus. The corpus is freely available online.
</dc:description>
 <dc:description>Comment: Submitted to ICASSP2018</dc:description>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00354</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00355</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection for 5G-NOMA: An Online Adaptive Machine Learning Approach</dc:title>
 <dc:creator>Awan, Daniyal Amir</dc:creator>
 <dc:creator>Cavalcante, Renato L. G.</dc:creator>
 <dc:creator>Yukawa, Masahiro</dc:creator>
 <dc:creator>Stanczak, Slawomir</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Non-orthogonal multiple access (NOMA) has emerged as a promising radio access
technique for enabling the performance enhancements promised by the
fifth-generation (5G) networks in terms of connectivity, low latency, and high
spectrum efficiency. In the NOMA uplink, successive interference cancellation
(SIC) based detection with device clustering has been suggested. In the case of
multiple receive antennas, SIC can be combined with the minimum mean-squared
error (MMSE) beamforming. However, there exists a tradeoff between the NOMA
cluster size and the incurred SIC error. Larger clusters lead to larger errors
but they are desirable from the spectrum efficiency and connectivity point of
view. We propose a novel online learning based detection for the NOMA uplink.
In particular, we design an online adaptive filter in the sum space of linear
and Gaussian reproducing kernel Hilbert spaces (RKHSs). Such a sum space design
is robust against variations of a dynamic wireless network that can deteriorate
the performance of a purely nonlinear adaptive filter. We demonstrate by
simulations that the proposed method outperforms the MMSE-SIC based detection
for large cluster sizes.
</dc:description>
 <dc:description>Comment: Accepted at ICC 2018</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2018-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00355</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00362</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complex-valued image denosing based on group-wise complex-domain
  sparsity</dc:title>
 <dc:creator>Katkovnik, Vladimir</dc:creator>
 <dc:creator>Ponomarenko, Mykola</dc:creator>
 <dc:creator>Egiazarian, Karen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Phase imaging and wavefront reconstruction from noisy observations of complex
exponent is a topic of this paper. It is a highly non-linear problem because
the exponent is a 2{\pi}-periodic function of phase. The reconstruction of
phase and amplitude is difficult. Even with an additive Gaussian noise in
observations distributions of noisy components in phase and amplitude are
signal dependent and non-Gaussian. Additional difficulties follow from a prior
unknown correlation of phase and amplitude in real life scenarios. In this
paper, we propose a new class of non-iterative and iterative complex domain
filters based on group-wise sparsity in complex domain. This sparsity is based
on the techniques implemented in Block-Matching 3D filtering (BM3D) and 3D/4D
High-Order Singular Decomposition (HOSVD) exploited for spectrum design,
analysis and filtering. The introduced algorithms are a generalization of the
ideas used in the CD-BM3D algorithms presented in our previous publications.
The algorithms are implemented as a MATLAB Toolbox. The efficiency of the
algorithms is demonstrated by simulation tests.
</dc:description>
 <dc:description>Comment: Submitted to Signal Processing</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00362</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00363</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Servant of Many Masters: Shifting priorities in Pareto-optimal
  sequential decision-making</dc:title>
 <dc:creator>Critch, Andrew</dc:creator>
 <dc:creator>Russell, Stuart</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  It is often argued that an agent making decisions on behalf of two or more
principals who have different utility functions should adopt a {\em
Pareto-optimal} policy, i.e., a policy that cannot be improved upon for one
agent without making sacrifices for another. A famous theorem of Harsanyi shows
that, when the principals have a common prior on the outcome distributions of
all policies, a Pareto-optimal policy for the agent is one that maximizes a
fixed, weighted linear combination of the principals' utilities.
  In this paper, we show that Harsanyi's theorem does not hold for principals
with different priors, and derive a more precise generalization which does
hold, which constitutes our main result. In this more general case, the
relative weight given to each principal's utility should evolve over time
according to how well the agent's observations conform with that principal's
prior. The result has implications for the design of contracts, treaties, joint
ventures, and robots.
</dc:description>
 <dc:description>Comment: 10 pages. arXiv admin note: substantial text overlap with
  arXiv:1701.01302</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00363</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00366</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Full-info Training for Deep Speaker Feature Learning</dc:title>
 <dc:creator>Li, Lantian</dc:creator>
 <dc:creator>Tang, Zhiyuan</dc:creator>
 <dc:creator>Wang, Dong</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  In recent studies, it has shown that speaker patterns can be learned from
very short speech segments (e.g., 0.3 seconds) by a carefully designed
convolutional &amp; time-delay deep neural network (CT-DNN) model. By enforcing the
model to discriminate the speakers in the training data, frame-level speaker
features can be derived from the last hidden layer. In spite of its good
performance, a potential problem of the present model is that it involves a
parametric classifier, i.e., the last affine layer, which may consume some
discriminative knowledge, thus leading to `information leak' for the feature
learning. This paper presents a full-info training approach that discards the
parametric classifier and enforces all the discriminative knowledge learned by
the feature net. Our experiments on the Fisher database demonstrate that this
new training scheme can produce more coherent features, leading to consistent
and notable performance improvement on the speaker verification task.
</dc:description>
 <dc:description>Comment: Submitted to ICASSP 2018</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00375</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CMS Analysis and Data Reduction with Apache Spark</dc:title>
 <dc:creator>Gutsche, Oliver</dc:creator>
 <dc:creator>Canali, Luca</dc:creator>
 <dc:creator>Cremer, Illia</dc:creator>
 <dc:creator>Cremonesi, Matteo</dc:creator>
 <dc:creator>Elmer, Peter</dc:creator>
 <dc:creator>Fisk, Ian</dc:creator>
 <dc:creator>Girone, Maria</dc:creator>
 <dc:creator>Jayatilaka, Bo</dc:creator>
 <dc:creator>Kowalkowski, Jim</dc:creator>
 <dc:creator>Khristenko, Viktor</dc:creator>
 <dc:creator>Motesnitsalis, Evangelos</dc:creator>
 <dc:creator>Pivarski, Jim</dc:creator>
 <dc:creator>Sehrish, Saba</dc:creator>
 <dc:creator>Surdy, Kacper</dc:creator>
 <dc:creator>Svyatkovskiy, Alexey</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Experimental Particle Physics has been at the forefront of analyzing the
world's largest datasets for decades. The HEP community was among the first to
develop suitable software and computing tools for this task. In recent times,
new toolkits and systems for distributed data processing, collectively called
&quot;Big Data&quot; technologies have emerged from industry and open source projects to
support the analysis of Petabyte and Exabyte datasets in industry. While the
principles of data analysis in HEP have not changed (filtering and transforming
experiment-specific data formats), these new technologies use different
approaches and tools, promising a fresh look at analysis of very large datasets
that could potentially reduce the time-to-physics with increased interactivity.
Moreover these new tools are typically actively developed by large communities,
often profiting of industry resources, and under open source licensing. These
factors result in a boost for adoption and maturity of the tools and for the
communities supporting them, at the same time helping in reducing the cost of
ownership for the end-users. In this talk, we are presenting studies of using
Apache Spark for end user data analysis. We are studying the HEP analysis
workflow separated into two thrusts: the reduction of centrally produced
experiment datasets and the end-analysis up to the publication plot. Studying
the first thrust, CMS is working together with CERN openlab and Intel on the
CMS Big Data Reduction Facility. The goal is to reduce 1 PB of official CMS
data to 1 TB of ntuple output for analysis. We are presenting the progress of
this 2-year project with first results of scaling up Spark-based HEP analysis.
Studying the second thrust, we are presenting studies on using Apache Spark for
a CMS Dark Matter physics search, comparing Spark's feasibility, usability and
performance to the ROOT-based analysis.
</dc:description>
 <dc:description>Comment: Proceedings for 18th International Workshop on Advanced Computing and
  Analysis Techniques in Physics Research (ACAT 2017). arXiv admin note: text
  overlap with arXiv:1703.04171</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00375</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00379</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Linear Digital Self-Interference Cancellation for In-Band
  Full-Duplex Radios Using Neural Networks</dc:title>
 <dc:creator>Balatsoukas-Stimming, Alexios</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Full-duplex systems require very strong self-interference cancellation in
order to operate correctly and a significant portion of the self-interference
signal is due to non-linear effects created by various transceiver impairments.
As such, linear cancellation alone is usually not sufficient and sophisticated
non-linear cancellation algorithms have been proposed in the literature. In
this work, we investigate the use of a neural network as an alternative to the
traditional non-linear cancellation method that is based on polynomial basis
functions. Measurement results from a full-duplex testbed demonstrate that a
small and simple feedforward neural network canceller works exceptionally well,
as it can match the performance of the polynomial non-linear canceller with
potentially significantly lower computational complexity.
</dc:description>
 <dc:description>Comment: Submitted to the IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP) 2018</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00385</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pseudorandom States, Non-Cloning Theorems and Quantum Money</dc:title>
 <dc:creator>Ji, Zhengfeng</dc:creator>
 <dc:creator>Liu, Yi-Kai</dc:creator>
 <dc:creator>Song, Fang</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We propose the concept of pseudorandom states and study their constructions,
properties, and applications. Under the assumption that quantum-secure one-way
functions exist, we present concrete and efficient constructions of
pseudorandom states. The non-cloning theorem plays a central role in our
study---it motivates the proper definition and characterizes one of the
important properties of pseudorandom quantum states. Namely, there is no
efficient quantum algorithm that can create more copies of the state from a
given number of pseudorandom states. As the main application, we prove that any
family of pseudorandom states naturally gives rise to a private-key quantum
money scheme.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00385</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00386</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analyzing the Approximation Error of the Fast Graph Fourier Transform</dc:title>
 <dc:creator>LeMagoarou, Luc</dc:creator>
 <dc:creator>Tremblay, Nicolas</dc:creator>
 <dc:creator>Gribonval, R&#xe9;mi</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  The graph Fourier transform (GFT) is in general dense and requires O(n^2)
time to compute and O(n^2) memory space to store. In this paper, we pursue our
previous work on the approximate fast graph Fourier transform (FGFT). The FGFT
is computed via a truncated Jacobi algorithm, and is defined as the product of
J Givens rotations (very sparse orthogonal matrices). The truncation parameter,
J, represents a trade-off between precision of the transform and time of
computation (and storage space). We explore further this trade-off and study,
on different types of graphs, how is the approximation error distributed along
the spectrum.
</dc:description>
 <dc:description>Comment: ASILOMAR conference</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00388</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Tolerant Testing</dc:title>
 <dc:creator>Blum, Avrim</dc:creator>
 <dc:creator>Hu, Lunjia</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this work, we give the first algorithms for tolerant testing of nontrivial
classes in the active model: estimating the distance of a target function to a
hypothesis class C with respect to some arbitrary distribution D, using only a
small number of label queries to a polynomial-sized pool of unlabeled examples
drawn from D. Specifically, we show that for the class D of unions of d
intervals on the line, we can estimate the error rate of the best hypothesis in
the class to an additive error epsilon from only $O(\frac{1}{\epsilon^6}\log
\frac{1}{\epsilon})$ label queries to an unlabeled pool of size
$O(\frac{d}{\epsilon^2}\log \frac{1}{\epsilon})$. The key point here is the
number of labels needed is independent of the VC-dimension of the class. This
extends the work of Balcan et al. [2012] who solved the non-tolerant testing
problem for this class (distinguishing the zero-error case from the case that
the best hypothesis in the class has error greater than epsilon).
  We also consider the related problem of estimating the performance of a given
learning algorithm A in this setting. That is, given a large pool of unlabeled
examples drawn from distribution D, can we, from only a few label queries,
estimate how well A would perform if the entire dataset were labeled? We focus
on k-Nearest Neighbor style algorithms, and also show how our results can be
applied to the problem of hyperparameter tuning (selecting the best value of k
for the given learning problem).
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00388</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00398</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time-Triggered Co-Scheduling of Computation and Communication with
  Jitter Requirements</dc:title>
 <dc:creator>Minaeva, Anna</dc:creator>
 <dc:creator>Akesson, Benny</dc:creator>
 <dc:creator>Hanzalek, Zdenek</dc:creator>
 <dc:creator>Dasari, Dakshina</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The complexity of embedded application design is increasing with growing user
demands. In particular, automotive embedded systems are highly complex in
nature, and their functionality is realized by a set of periodic tasks. These
tasks may have hard real-time requirements and communicate over an
interconnect. The problem is to efficiently co-schedule task execution on cores
and message transmission on the interconnect so that timing constraints are
satisfied. Contemporary works typically deal with zero-jitter scheduling, which
results in lower resource utilization, but has lower memory requirements. This
article focuses on jitter-constrained scheduling that puts constraints on the
tasks jitter, increasing schedulability over zero- jitter scheduling. The
contributions of this article are: 1) Integer Linear Programming and
Satisfiability Modulo Theory model exploiting problem-specific information to
reduce the formulations complexity to schedule small applications. 2) A
heuristic approach, employing three levels of scheduling scaling to real-world
use-cases with 10000 tasks and messages. 3) An experimental evaluation of the
proposed approaches on a case-study and on synthetic data sets showing the
efficiency of both zero-jitter and jitter- constrained scheduling. It shows
that up to 28% higher resource utilization can be achieved by having up to 10
times longer computation time with relaxed jitter requirements.
</dc:description>
 <dc:description>Comment: IEEE Transactions on Computers (2017)</dc:description>
 <dc:date>2017-10-02</dc:date>
 <dc:date>2017-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00398</dc:identifier>
 <dc:identifier>doi:10.1109/TC.2017.2722443</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00399</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Counterfactual Explanations without Opening the Black Box: Automated
  Decisions and the GDPR</dc:title>
 <dc:creator>Wachter, Sandra</dc:creator>
 <dc:creator>Mittelstadt, Brent</dc:creator>
 <dc:creator>Russell, Chris</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  There has been much discussion of the right to explanation in the EU General
Data Protection Regulation, and its existence, merits, and disadvantages.
Implementing a right to explanation that opens the black box of algorithmic
decision-making faces major legal and technical barriers. Explaining the
functionality of complex algorithmic decision-making systems and their
rationale in specific cases is a technically challenging problem. Some
explanations may offer little meaningful information to data subjects, raising
questions around their value. Explanations of automated decisions need not
hinge on the general public understanding how algorithmic systems function.
Even though such interpretability is of great importance and should be pursued,
explanations can, in principle, be offered without opening the black box.
Looking at explanations as a means to help a data subject act rather than
merely understand, one could gauge the scope and content of explanations
according to the specific goal or action they are intended to support. From the
perspective of individuals affected by automated decision-making, we propose
three aims for explanations: (1) to inform and help the individual understand
why a particular decision was reached, (2) to provide grounds to contest the
decision if the outcome is undesired, and (3) to understand what would need to
change in order to receive a desired result in the future, based on the current
decision-making model. We assess how each of these goals finds support in the
GDPR. We suggest data controllers should offer a particular type of
explanation, unconditional counterfactual explanations, to support these three
aims. These counterfactual explanations describe the smallest change to the
world that can be made to obtain a desirable outcome, or to arrive at the
closest possible world, without needing to explain the internal logic of the
system.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2017-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00399</dc:identifier>
 <dc:identifier>Harvard Journal of Law &amp; Technology, 2018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00400</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimal Exploration in Structured Stochastic Bandits</dc:title>
 <dc:creator>Combes, Richard</dc:creator>
 <dc:creator>Magureanu, Stefan</dc:creator>
 <dc:creator>Proutiere, Alexandre</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper introduces and addresses a wide class of stochastic bandit
problems where the function mapping the arm to the corresponding reward
exhibits some known structural properties. Most existing structures (e.g.
linear, Lipschitz, unimodal, combinatorial, dueling, ...) are covered by our
framework. We derive an asymptotic instance-specific regret lower bound for
these problems, and develop OSSB, an algorithm whose regret matches this
fundamental limit. OSSB is not based on the classical principle of &quot;optimism in
the face of uncertainty&quot; or on Thompson sampling, and rather aims at matching
the minimal exploration rates of sub-optimal arms as characterized in the
derivation of the regret lower bound. We illustrate the efficiency of OSSB
using numerical experiments in the case of the linear bandit problem and show
that OSSB outperforms existing algorithms, including Thompson sampling.
</dc:description>
 <dc:description>Comment: 13 pages, NIPS 2017</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00402</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Successive Cancellation Soft Output Detector For Uplink MU-MIMO Systems
  With One-bit ADCs</dc:title>
 <dc:creator>Cho, Yun-Seong</dc:creator>
 <dc:creator>Kim, Seonho</dc:creator>
 <dc:creator>Hong, Song-Nam</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>H.1.1</dc:subject>
 <dc:description>  In this paper, we present a successive-cancellation-soft-output (SCSO)
detector for an uplink multiuser multiple-input-multiple-output (MU-MIMO)
system with one-bit analog-to-digital converters (ADCs). The proposed detector
produces soft outputs (e.g., log-likelihood ratios (LLRs)) from one-bit
quantized observations in a successive way: each user k's message is
sequentially decoded from a channel decoder $k$ for $k=1,...,K$ in that order,
and the previously decoded messages are exploited to improve the reliabilities
of LLRs. Furthermore, we develop an efficient greedy algorithm to optimize a
decoding order. Via simulation results, we demonstrate that the proposed
ordered SCSO detector outperforms the other detectors for the coded MU-MIMO
systems with one-bit ADCs.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures, submitted to ICC 2018</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00402</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00404</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building Data-driven Models with Microstructural Images: Generalization
  and Interpretability</dc:title>
 <dc:creator>Ling, Julia</dc:creator>
 <dc:creator>Hutchinson, Maxwell</dc:creator>
 <dc:creator>Antono, Erin</dc:creator>
 <dc:creator>DeCost, Brian</dc:creator>
 <dc:creator>Holm, Elizabeth A.</dc:creator>
 <dc:creator>Meredig, Bryce</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:description>  As data-driven methods rise in popularity in materials science applications,
a key question is how these machine learning models can be used to understand
microstructure. Given the importance of process-structure-property relations
throughout materials science, it seems logical that models that can leverage
microstructural data would be more capable of predicting property information.
While there have been some recent attempts to use convolutional neural networks
to understand microstructural images, these early studies have focused only on
which featurizations yield the highest machine learning model accuracy for a
single data set. This paper explores the use of convolutional neural networks
for classifying microstructure with a more holistic set of objectives in mind:
generalization between data sets, number of features required, and
interpretability.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00404</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00405</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Price of Information in Combinatorial Optimization</dc:title>
 <dc:creator>Singla, Sahil</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Consider a network design application where we wish to lay down a
minimum-cost spanning tree in a given graph; however, we only have stochastic
information about the edge costs. To learn the precise cost of any edge, we
have to conduct a study that incurs a price. Our goal is to find a spanning
tree while minimizing the disutility, which is the sum of the tree cost and the
total price that we spend on the studies. In a different application, each edge
gives a stochastic reward value. Our goal is to find a spanning tree while
maximizing the utility, which is the tree reward minus the prices that we pay.
  Situations such as the above two often arise in practice where we wish to
find a good solution to an optimization problem, but we start with only some
partial knowledge about the parameters of the problem. The missing information
can be found only after paying a probing price, which we call the price of
information. What strategy should we adopt to optimize our expected
utility/disutility?
  A classical example of the above setting is Weitzman's &quot;Pandora's box&quot;
problem where we are given probability distributions on values of $n$
independent random variables. The goal is to choose a single variable with a
large value, but we can find the actual outcomes only after paying a price. Our
work is a generalization of this model to other combinatorial optimization
problems such as matching, set cover, facility location, and prize-collecting
Steiner tree. We give a technique that reduces such problems to their non-price
counterparts, and use it to design exact/approximation algorithms to optimize
our utility/disutility. Our techniques extend to situations where there are
additional constraints on what parameters can be probed or when we can
simultaneously probe a subset of the parameters.
</dc:description>
 <dc:description>Comment: SODA 2018</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00405</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00414</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intelligent Parameter Tuning in Optimization-based Iterative CT
  Reconstruction via Deep Reinforcement Learning</dc:title>
 <dc:creator>Shen, Chenyang</dc:creator>
 <dc:creator>Gonzalez, Yesenia</dc:creator>
 <dc:creator>Chen, Liyuan</dc:creator>
 <dc:creator>Jiang, Steve B.</dc:creator>
 <dc:creator>Jia, Xun</dc:creator>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A number of image-processing problems can be formulated as optimization
problems. The objective function typically contains several terms specifically
designed for different purposes. Parameters in front of these terms are used to
control the relative weights among them. It is of critical importance to tune
these parameters, as quality of the solution depends on their values. Tuning
parameter is a relatively straightforward task for a human, as one can
intelligently determine the direction of parameter adjustment based on the
solution quality. Yet manual parameter tuning is not only tedious in many
cases, but becomes impractical when a number of parameters exist in a problem.
Aiming at solving this problem, this paper proposes an approach that employs
deep reinforcement learning to train a system that can automatically adjust
parameters in a human-like manner. We demonstrate our idea in an example
problem of optimization-based iterative CT reconstruction with a pixel-wise
total-variation regularization term. We set up a parameter tuning policy
network (PTPN), which maps an CT image patch to an output that specifies the
direction and amplitude by which the parameter at the patch center is adjusted.
We train the PTPN via an end-to-end reinforcement learning procedure. We
demonstrate that under the guidance of the trained PTPN for parameter tuning at
each pixel, reconstructed CT images attain quality similar or better than in
those reconstructed with manually tuned parameters.
</dc:description>
 <dc:description>Comment: 8 pages, 8 figures, 2 tables</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00414</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00415</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Analysis for Massive MIMO Downlink with Low Complexity
  Approximate Zero-Forcing Precoding</dc:title>
 <dc:creator>Zhang, Cheng</dc:creator>
 <dc:creator>Jing, Yindi</dc:creator>
 <dc:creator>Huang, Yongming</dc:creator>
 <dc:creator>Yang, Luxi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Zero-forcing (ZF) precoding plays an important role for massive MIMO downlink
due to its near optimal performance. However, the high computation cost of the
involved matrix inversion hinders its application. In this paper, we adopt the
first order Neumann series (NS) for a low-complexity approximation. By
introducing a relaxation parameter jointly with one selected user's
interference to others into the precondition matrix, we propose the
identity-plus-column NS (ICNS) method. By further exploiting the multi-user
diversity gain via choosing the user with the largest interference to others,
the ordered ICNS method is also proposed. Moreover, the sum-rate approximations
of the proposed ICNS method and the competitive existing identity matrix based
NS (INS) method are derived in closed-form, based on which the performance loss
of ICNS due to inversion approximation compared with ideal ZF and its
performance gain over INS are explicitly analyzed for three typical massive
MIMO scenarios. Finally, simulations verify our analytical results and also
show that the proposed two designs achieve better performance-complexity
tradeoff than ideal ZF and existing low-complexity ZF precodings for practical
large antenna number, correlated channels and not-so-small loading factor.
</dc:description>
 <dc:description>Comment: 30 Pages, 9 figures, submitted to IEEE Transactions on Communications</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00415</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00425</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non Uniform On Chip Power Delivery Network Synthesis Methodology</dc:title>
 <dc:creator>Benediktsson, Patrick</dc:creator>
 <dc:creator>Flandrin, Jon A.</dc:creator>
 <dc:creator>Zheng, Chen</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  In this paper, we proposed a non-uniform power delivery network (PDN)
synthesis methodology. It first constructs initial PDN using uniform approach.
Then preliminary power integrity analysis is performed to derive IR-safe
candidate window. Congestion map is obtained based global route congestion
estimation. A self-adaptive non-uniform PDN synthesis is then performed to
globally and locally optimize PDN over selected regions. The PDN synthesis is
congestion-driven and IR- guarded. Experimental results show significant timing
important in trade-off small PDN length reduction with no EM/IR impact. We
further explored potential power savings using our non-uniform PDN synthesis
methodology.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures, 3 tables</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00436</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Representations for Efficient Architecture Search</dc:title>
 <dc:creator>Liu, Hanxiao</dc:creator>
 <dc:creator>Simonyan, Karen</dc:creator>
 <dc:creator>Vinyals, Oriol</dc:creator>
 <dc:creator>Fernando, Chrisantha</dc:creator>
 <dc:creator>Kavukcuoglu, Koray</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We explore efficient neural architecture search methods and present a simple
yet powerful evolutionary algorithm that can discover new architectures
achieving state of the art results. Our approach combines a novel hierarchical
genetic representation scheme that imitates the modularized design pattern
commonly adopted by human experts, and an expressive search space that supports
complex topologies. Our algorithm efficiently discovers architectures that
outperform a large number of manually designed models for image classification,
obtaining top-1 error of 3.6% on CIFAR-10 and 20.3% when transferred to
ImageNet, which is competitive with the best existing neural architecture
search approaches and represents the new state of the art for evolutionary
strategies on this task. We also present results using random search, achieving
0.3% less top-1 accuracy on CIFAR-10 and 0.1% less on ImageNet whilst reducing
the architecture search time from 36 hours down to 1 hour.
</dc:description>
 <dc:description>Comment: Under review as a conference paper at ICLR 2018</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00439</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sampling and multilevel coarsening algorithms for fast matrix
  approximations</dc:title>
 <dc:creator>Ubaru, Shashanka</dc:creator>
 <dc:creator>Saad, Yousef</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>15A69, 15A18</dc:subject>
 <dc:description>  This paper addresses matrix approximation problems for matrices that are
large, sparse and/or that are representations of large graphs. To tackle these
problems, we consider algorithms that are based primarily on coarsening
techniques, possibly combined with random sampling. A multilevel coarsening
technique is proposed which utilizes a hypergraph associated with the data
matrix and a graph coarsening strategy based on column matching. Theoretical
results are established that characterize the quality of the dimension
reduction achieved by a coarsening step, when a proper column matching strategy
is employed. We consider a number of standard applications of this technique as
well as a few new ones. Among the standard applications we first consider the
problem of computing the partial SVD for which a combination of sampling and
coarsening yields significantly improved SVD results relative to sampling
alone. We also consider the Column subset selection problem, a popular low rank
approximation method used in data related applications, and show how multilevel
coarsening can be adapted for this problem. Similarly, we consider the problem
of graph sparsification and show how coarsening techniques can be employed to
solve it. Numerical experiments illustrate the performances of the methods in
various applications.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00439</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00441</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data, Depth, and Design: Learning Reliable Models for Melanoma Screening</dc:title>
 <dc:creator>Valle, Eduardo</dc:creator>
 <dc:creator>Fornaciali, Michel</dc:creator>
 <dc:creator>Menegola, Afonso</dc:creator>
 <dc:creator>Tavares, Julia</dc:creator>
 <dc:creator>Bittencourt, Fl&#xe1;via Vasques</dc:creator>
 <dc:creator>Li, Lin Tzy</dc:creator>
 <dc:creator>Avila, Sandra</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  State of the art on melanoma screening evolved rapidly in the last two years,
with the adoption of deep learning. Those models, however, pose challenges of
their own, as they are expensive to train and difficult to parameterize.
Objective: We investigate the methodological issues for designing and
evaluating deep learning models for melanoma screening, by exploring nine
choices often faced to design deep networks: model architecture, training
dataset, image resolution, type of data augmentation, input normalization, use
of segmentation, duration of training, additional use of SVM, and test data
augmentation. Methods: We perform a two-level full factorial experiment, for
five different test datasets, resulting in 2560 exhaustive trials, which we
analyze using a multi-way ANOVA. Results: The main finding is that the size of
training data has a disproportionate influence, explaining almost half the
variation in performance. Of the other factors, test data augmentation and
input resolution are the most helpful. Deeper models, when combined, with extra
data, also help. We show that the costly full factorial design, or the
unreliable sequential optimization, are not the only options: ensembles of
models provide reliable results with limited resources. Conclusions and
Significance: To move research forward on automated melanoma screening, we need
to curate larger shared datasets. Optimizing hyperparameters and measuring
performance on the same dataset is common, but leads to overoptimistic results.
Ensembles of models are a cost-effective alternative to the expensive
full-factorial and to the unstable sequential designs.
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures, 2 tables. Article submitted to IEEE Journal of
  Biomedical Health Informatics Special Issue on Skin Lesion Image Analysis for
  Melanoma Detection</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00441</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00449</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attacking Binarized Neural Networks</dc:title>
 <dc:creator>Galloway, Angus</dc:creator>
 <dc:creator>Taylor, Graham W.</dc:creator>
 <dc:creator>Moussa, Medhat</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Neural networks with low-precision weights and activations offer compelling
efficiency advantages over their full-precision equivalents. The two most
frequently discussed benefits of quantization are reduced memory consumption,
and a faster forward pass when implemented with efficient bitwise operations.
We propose a third benefit of very low-precision neural networks: improved
robustness against some adversarial attacks, and in the worst case, performance
that is on par with full-precision models. We focus on the very low-precision
case where weights and activations are both quantized to $\pm$1, and note that
stochastically quantizing weights in just one layer can sharply reduce the
impact of iterative attacks. We observe that non-scaled binary neural networks
exhibit a similar effect to the original defensive distillation procedure that
led to gradient masking, and a false notion of security. We address this by
conducting both black-box and white-box experiments with binary models that do
not artificially mask gradients.
</dc:description>
 <dc:description>Comment: Under review as a conference paper at ICLR 2018</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00449</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00455</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Piecewise Linear Neural Network verification: A comparative study</dc:title>
 <dc:creator>Bunel, Rudy</dc:creator>
 <dc:creator>Turkaslan, Ilker</dc:creator>
 <dc:creator>Torr, Philip H. S.</dc:creator>
 <dc:creator>Kohli, Pushmeet</dc:creator>
 <dc:creator>Kumar, M. Pawan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The success of Deep Learning and its potential use in many important safety-
critical applications has motivated research on formal verification of Neural
Network (NN) models. Despite the reputation of learned NN models to behave as
black boxes and the theoretical hardness of proving their properties,
researchers have been successful in verifying some classes of models by
exploiting their piecewise linear structure. Unfortunately, most of these
approaches test their algorithms without comparison with other approaches. As a
result, the pros and cons of the different algorithms are not well understood.
Motivated by the need to accelerate progress in this very important area, we
investigate the trade-offs of a number of different approaches based on Mixed
Integer Programming, Satisfiability Modulo Theory, as well as a novel method
based on the Branch-and-Bound framework. We also propose a new data set of
benchmarks, in addition to a collection of pre- viously released testcases that
can be used to compare existing methods. Our analysis not only allows a
comparison to be made between different strategies, the comparison of results
from different solvers also revealed implementation bugs in published methods.
We expect that the availability of our benchmark and the analysis of the
different approaches will allow researchers to develop and evaluate promising
approaches for making progress on this important topic.
</dc:description>
 <dc:description>Comment: Submitted to ICLR 2018, code available at
  https://github.com/oval-group/PLNN-verification</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00455</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00457</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Almost instant brain atlas segmentation for large-scale studies</dc:title>
 <dc:creator>Fedorov, Alex</dc:creator>
 <dc:creator>Damaraju, Eswar</dc:creator>
 <dc:creator>Calhoun, Vince</dc:creator>
 <dc:creator>Plis, Sergey</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Large scale studies of group differences in healthy controls and patients and
screenings for early stage disease prevention programs require processing and
analysis of extensive multisubject datasets. Complexity of the task increases
even further when segmenting structural MRI of the brain into an atlas with
more than 50 regions. Current automatic approaches are time-consuming and
hardly scalable; they often involve many error prone intermediate steps and
don't utilize other available modalities. To alleviate these problems, we
propose a feedforward fully convolutional neural network trained on the output
produced by the state of the art models. Incredible speed due to available
powerful GPUs neural network makes this analysis much easier and faster (from
$&gt;10$ hours to a minute). The proposed model is more than two orders of
magnitudes faster than the state of the art and yet as accurate. We have
evaluated the network's performance by comparing it with the state of the art
in the task of differentiating region volumes of healthy controls and patients
with schizophrenia on a dataset with 311 subjects. This comparison provides a
strong evidence that speed did not harm the accuracy. The overall quality may
also be increased by utilizing multi-modal datasets (not an easy task for other
models) by simple adding more modalities as an input. Our model will be useful
in large-scale studies as well as in clinical care solutions, where it can
significantly reduce delay between the patient screening and the result.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00457</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00462</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Early prediction of the duration of protests using probabilistic Latent
  Dirichlet Allocation and Decision Trees</dc:title>
 <dc:creator>Paul, Satyakama</dc:creator>
 <dc:creator>Hasija, Madhur</dc:creator>
 <dc:creator>Marwala, Tshilidzi</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Protests and agitations are an integral part of every democratic civil
society. In recent years, South Africa has seen a large increase in its
protests. The objective of this paper is to provide an early prediction of the
duration of protests from its free flowing English text description. Free
flowing descriptions of the protests help us in capturing its various nuances
such as multiple causes, courses of actions etc. Next we use a combination of
unsupervised learning (topic modeling) and supervised learning (decision trees)
to predict the duration of the protests. Our results show a high degree (close
to 90%) of accuracy in early prediction of the duration of protests.We expect
the work to help police and other security services in planning and managing
their resources in better handling protests in future.
</dc:description>
 <dc:description>Comment: This paper is to appear in the 4th IEEE Latin American Conference on
  Computational Intelligence LA-CCI. This paper was written by Satyakama and
  Madhur and supervised by Tshilidzi</dc:description>
 <dc:date>2017-09-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00462</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00464</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Information-Theoretic Analysis of Deep Latent-Variable Models</dc:title>
 <dc:creator>Alemi, Alexander A.</dc:creator>
 <dc:creator>Poole, Ben</dc:creator>
 <dc:creator>Fischer, Ian</dc:creator>
 <dc:creator>Dillon, Joshua V.</dc:creator>
 <dc:creator>Saurous, Rif A.</dc:creator>
 <dc:creator>Murphy, Kevin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present an information-theoretic framework for understanding trade-offs in
unsupervised learning of deep latent-variables models using variational
inference. This framework emphasizes the need to consider latent-variable
models along two dimensions: the ability to reconstruct inputs (distortion) and
the communication cost (rate). We derive the optimal frontier of generative
models in the two-dimensional rate-distortion plane, and show how the standard
evidence lower bound objective is insufficient to select between points along
this frontier. However, by performing targeted optimization to learn generative
models with different rates, we are able to learn many models that can achieve
similar generative performance but make vastly different trade-offs in terms of
the usage of the latent variable. Through experiments on MNIST and Omniglot
with a variety of architectures, we show how our framework sheds light on many
recent proposed extensions to the variational autoencoder family.
</dc:description>
 <dc:description>Comment: 22 pages, 6 figures</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2018-01-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00464</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00465</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing quantum optimization algorithms via faster quantum gradient
  computation</dc:title>
 <dc:creator>Gily&#xe9;n, Andr&#xe1;s</dc:creator>
 <dc:creator>Arunachalam, Srinivasan</dc:creator>
 <dc:creator>Wiebe, Nathan</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We consider a generic framework of optimization algorithms based on gradient
descent. We develop a quantum algorithm that computes the gradient of a
multi-variate real-valued function $f:\mathbb{R}^d\rightarrow \mathbb{R}$ by
evaluating it at only a logarithmic number of points in superposition. Our
algorithm is an improved version of Jordan's gradient calculation algorithm,
providing an approximation of the gradient $\nabla f$ with quadratically better
dependence on the evaluation accuracy of $f$, for an important class of smooth
functions. Furthermore, we show that most objective functions arising from
quantum optimization procedures satisfy the necessary smoothness conditions,
hence our algorithm provides a quadratic improvement in the complexity of
computing their gradient. We also show that in a continuous phase-query model,
our gradient computation algorithm has optimal query complexity up to
poly-logarithmic factors, for a particular class of smooth functions. Moreover,
we show that for low-degree multivariate polynomials our algorithm can provide
exponential speedups compared to Jordan's algorithm in terms of the dimension
$d$.
  One of the technical challenges in applying our gradient computation
procedure for quantum optimization problems is the need to convert between a
probability oracle (which is common in quantum optimization procedures) and a
phase oracle (which is common in quantum algorithms) of the objective function
$f$. We provide efficient subroutines to perform this delicate interconversion
between the two types of oracles incurring only a logarithmic overhead, which
might be of independent interest. Finally, using these tools we improve the
runtime of prior approaches for training quantum auto-encoders, variational
quantum eigensolvers, and quantum approximate optimization algorithms (QAOA).
</dc:description>
 <dc:description>Comment: 57 pages, 5 figures</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00465</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00482</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning with Latent Language</dc:title>
 <dc:creator>Andreas, Jacob</dc:creator>
 <dc:creator>Klein, Dan</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The named concepts and compositional operators present in natural language
provide a rich source of information about the kinds of abstractions humans use
to navigate the world. Can this linguistic background knowledge improve the
generality and efficiency of learned classifiers and control policies? This
paper aims to show that using the space of natural language strings as a
parameter space is an effective way to capture natural task structure. In a
pretraining phase, we learn a language interpretation model that transforms
inputs (e.g. images) into outputs (e.g. labels) given natural language
descriptions. To learn a new concept (e.g. a classifier), we search directly in
the space of descriptions to minimize the interpreter's loss on training
examples. Crucially, our models do not require language data to learn these
concepts: language is used only in pretraining to impose structure on
subsequent learning. Results on image classification, text editing, and
reinforcement learning show that, in all settings, models with a linguistic
parameterization outperform those without.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00482</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00489</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Don't Decay the Learning Rate, Increase the Batch Size</dc:title>
 <dc:creator>Smith, Samuel L.</dc:creator>
 <dc:creator>Kindermans, Pieter-Jan</dc:creator>
 <dc:creator>Le, Quoc V.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  It is common practice to decay the learning rate. Here we show one can
usually obtain the same learning curve on both training and test sets by
instead increasing the batch size during training. This procedure is successful
for stochastic gradient descent (SGD), SGD with momentum, Nesterov momentum,
and Adam. It reaches equivalent test accuracies after the same number of
training epochs, but with fewer parameter updates, leading to greater
parallelism and shorter training times. We can further reduce the number of
parameter updates by increasing the learning rate $\epsilon$ and scaling the
batch size $B \propto \epsilon$. Finally, one can increase the momentum
coefficient $m$ and scale $B \propto 1/(1-m)$, although this tends to slightly
reduce the test accuracy. Crucially, our techniques allow us to repurpose
existing training schedules for large batch training with no hyper-parameter
tuning. We train Inception-ResNet-V2 on ImageNet to $77\%$ validation accuracy
in under 2500 parameter updates, efficiently utilizing training batches of
65536 images.
</dc:description>
 <dc:description>Comment: 11 pages, 7 figures</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00489</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00493</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TERSE-KF: Event-Trigger Diffusion Kalman Filter with Application to
  Localization and Time Synchronization</dc:title>
 <dc:creator>Alanwar, Amr</dc:creator>
 <dc:creator>Chang, Tsang-Kai</dc:creator>
 <dc:creator>Srivastava, Mani</dc:creator>
 <dc:creator>Mehta, Ankur</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  The performance of a distributed network state estimation problem depends
strongly on collaborative signal processing, which often involves excessive
communication and computation overheads on a resource-constrained sensor node.
In this work, we approach the distributed estimation problem from the viewpoint
of sensor networks to design a more efficient algorithm with reduced overheads,
while still achieving the required performance bounds on the results. We
propose an event-trigger diffusion Kalman filter, specifying when to
communicate relative measurements between nodes based on a local signal
indicative of the network error performance. This holistic approach leads to an
energy-aware state estimation algorithm, which we then apply to the distributed
simultaneous localization and time synchronization problem. We analytically
prove that this algorithm leads to bounded error performance. Our algorithm is
then evaluated on a physical testbed of a mobile quadrotor node moving through
a network of stationary custom ultra-wideband wireless devices. We observe the
trade-off between communication cost and error performance. For instance, we
are able to save 86% of the communication overhead, while introducing 16%
degradation in the performance.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00493</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00499</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Widening siamese architectures for stereo matching</dc:title>
 <dc:creator>Brandao, Patrick</dc:creator>
 <dc:creator>Mazomenos, Evangelos</dc:creator>
 <dc:creator>Stoyanov, Danail</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Computational stereo is one of the classical problems in computer vision.
Numerous algorithms and solutions have been reported in recent years focusing
on developing methods for computing similarity, aggregating it to obtain
spatial support and finally optimizing an energy function to find the final
disparity. In this paper, we focus on the feature extraction component of
stereo matching architecture and we show standard CNNs operation can be used to
improve the quality of the features used to find point correspondences.
Furthermore, we propose a simple space aggregation that hugely simplifies the
correlation learning problem. Our results on benchmark data are compelling and
show promising potential even without refining the solution.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00499</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00501</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning One-hidden-layer Neural Networks with Landscape Design</dc:title>
 <dc:creator>Ge, Rong</dc:creator>
 <dc:creator>Lee, Jason D.</dc:creator>
 <dc:creator>Ma, Tengyu</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of learning a one-hidden-layer neural network: we
assume the input $x\in \mathbb{R}^d$ is from Gaussian distribution and the
label $y = a^\top \sigma(Bx) + \xi$, where $a$ is a nonnegative vector in
$\mathbb{R}^m$ with $m\le d$, $B\in \mathbb{R}^{m\times d}$ is a full-rank
weight matrix, and $\xi$ is a noise vector. We first give an analytic formula
for the population risk of the standard squared loss and demonstrate that it
implicitly attempts to decompose a sequence of low-rank tensors simultaneously.
  Inspired by the formula, we design a non-convex objective function $G(\cdot)$
whose landscape is guaranteed to have the following properties: 1. All local
minima of $G$ are also global minima.
  2. All global minima of $G$ correspond to the ground truth parameters.
  3. The value and gradient of $G$ can be estimated using samples.
  With these properties, stochastic gradient descent on $G$ provably converges
to the global minimum and learn the ground-truth parameters. We also prove
finite sample complexity result and validate the results by simulations.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00502</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>User Scheduling for Millimeter Wave MIMO Communications with
  Low-Resolution ADCs</dc:title>
 <dc:creator>Choi, Jinseok</dc:creator>
 <dc:creator>Evans, Brian L.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In millimeter wave (mmWave) systems, we investigate uplink user scheduling
when a basestation employs low-resolution analog-to-digital converters (ADCs)
with a large number of antennas. To reduce power consumption in the receiver,
low-resolution ADCs can be a potential solution for mmWave systems in which
many antennas are likely to be deployed to compensate for the large path loss.
Due to quantization error, we show that the channel structure in the beamspace,
in addition to the channel magnitude and beamspace orthogonality, plays a key
role in maximizing the achievable rates of scheduled users. Consequently, we
derive the optimal criteria with respect to the channel structure in the
beamspace that maximizes the uplink sum rate for multi-user multiple input
multiple output (MIMO) systems with a zero-forcing receiver. Leveraging the
derived criteria, we propose an efficient scheduling algorithm for mmWave
systems with low-resolution ADCs. Numerical results validate that the proposed
algorithm outperforms conventional user scheduling methods in terms of the sum
rate.
</dc:description>
 <dc:description>Comment: Submitted to International Conference on Communications 2018</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00502</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00504</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Partial Orthology, Paralogy and Xenology Relations - Satisfiability in
  terms of Di-Cographs</dc:title>
 <dc:creator>N&#xf8;jgaard, Nikolai</dc:creator>
 <dc:creator>El-Mabrouk, Nadia</dc:creator>
 <dc:creator>Merkle, Daniel</dc:creator>
 <dc:creator>Wieseke, Nikolas</dc:creator>
 <dc:creator>Hellmuth, Marc</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  A variety of methods based on sequence similarity, reconciliation, synteny or
functional characteristics, can be used to infer homology relations, that is,
orthology, paralogy and xenology relations between genes of a given gene family
$\mathbb{G}$. The (inferred) homology relations might not cover each pair of
genes and thus, provide only partial knowledge on the full set of homology
relations. Moreover, for particular pairs of genes it might be known with a
high degree of certainty that they are not orthologs (resp.\ paralogs,
xenologs) which yields forbidden pairs of genes. The question arises as whether
such sets of (partial) homology relations with or without forbidden gene pairs
are satisfiable, i.e., can they simultaneously co-exist in an evolutionary
history for $\mathbb{G}$.
  In this contribution, we characterize satisfiable homology relations. To this
end, we employ the graph structure provided by these relations. In particular,
the latter allows us to characterize full satisfiable homology relations as
so-called di-cographs. Let $m$ denote the total number of known and forbidden
gene pairs. We provide a simple $\mathcal{O}(|\mathbb{G}|^2 +
m|\mathbb{G}|)$-time algorithm to determine whether such homology relations are
satisfiable and, in the positive case, to construct event-labeled gene trees
containing speciation, duplication and horizontal gene transfer (HGT) events
that can explain the relations. The provided algorithm is evaluated on
large-scaled simulated data sets. As we shall see, a comparably small amount of
information about the original homologous relationships between the gene pairs
is necessary to reconstruct most of the original relations. The algorithm and
datasets are freely-available.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00504</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00509</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Philosophy of Bitcoin/Blockchain Technology: Is it a Chaotic,
  Complex System?</dc:title>
 <dc:creator>Santos, Renato P. dos</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>cs.CR, cs.IT, q-fin.GN</dc:subject>
 <dc:description>  The philosophy of blockchain technology is concerned, among other things,
with blockchain ontology, how it might be characterised, how it is being
created, implemented, and adopted, how it operates in the world, and how it
evolves over time. This paper concentrates on whether Bitcoin/blockchain can be
considered a complex system and, if so, whether it is a chaotic one. Beyond
mere academic curiosity, a positive response would raise concerns about the
likelihood of Bitcoin/blockchain entering a 2010-Flash-Crash-type of chaotic
regime, with catastrophic consequences for financial systems based on it. The
paper starts by highlighting the relevant details of the Bitcoin/blockchain
ecosystem formed by the blockchain itself, bitcoin end users (payers and
payees), capital gains seekers, miners, full nodes maintainers, and developers,
and their interactions. Then the Information Theory of Complex Systems is
briefly discussed for later use. Finally, the blockchain is investigated with
the help of Crutchfield's Statistical Complexity measure. The low non-null
statistical complexity value obtained suggests that the blockchain may be
considered algorithmically complicated but hardly a complex system and unlikely
to enter a chaotic regime.
</dc:description>
 <dc:description>Comment: 14 pages, 1 figure</dc:description>
 <dc:date>2017-10-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00509</dc:identifier>
 <dc:identifier>Metaphilosophy, 48(2017) 620-633</dc:identifier>
 <dc:identifier>doi:10.1111/meta.12266</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00513</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating Discourse Phenomena in Neural Machine Translation</dc:title>
 <dc:creator>Bawden, Rachel</dc:creator>
 <dc:creator>Sennrich, Rico</dc:creator>
 <dc:creator>Birch, Alexandra</dc:creator>
 <dc:creator>Haddow, Barry</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  For machine translation to tackle discourse phenomena, models must have
access to extra-sentential linguistic context. There has been recent interest
in modelling context in neural machine translation (NMT), but models have been
principally evaluated with standard automatic metrics, poorly adapted to
evaluating discourse phenomena. In this article, we present hand-crafted,
discourse test sets, designed to test the models' ability to exploit previous
source and target sentences. We investigate the performance of recently
proposed multi-encoder NMT models trained on subtitles for English to French.
We also explore a novel way of exploiting context from the previous sentence.
Despite gains using BLEU, multi-encoder models give limited improvement in the
handling of discourse phenomena: 50% accuracy on our coreference test set and
53.5% for coherence/cohesion (compared to a non-contextual baseline of 50%). A
simple strategy of decoding the concatenation of the previous and current
sentence leads to good performance, and our novel strategy of multi-encoding
and decoding of two sentences leads to the best performance (72.5% for
coreference and 57% for coherence/cohesion), highlighting the importance of
target-side context.
</dc:description>
 <dc:description>Comment: Added reference, corrected typos in test set, resulting in minor,
  insignificant improvements to results</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00513</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00520</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uncovering Latent Style Factors for Expressive Speech Synthesis</dc:title>
 <dc:creator>Wang, Yuxuan</dc:creator>
 <dc:creator>Skerry-Ryan, RJ</dc:creator>
 <dc:creator>Xiao, Ying</dc:creator>
 <dc:creator>Stanton, Daisy</dc:creator>
 <dc:creator>Shor, Joel</dc:creator>
 <dc:creator>Battenberg, Eric</dc:creator>
 <dc:creator>Clark, Rob</dc:creator>
 <dc:creator>Saurous, Rif A.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Prosodic modeling is a core problem in speech synthesis. The key challenge is
producing desirable prosody from textual input containing only phonetic
information. In this preliminary study, we introduce the concept of &quot;style
tokens&quot; in Tacotron, a recently proposed end-to-end neural speech synthesis
model. Using style tokens, we aim to extract independent prosodic styles from
training data. We show that without annotation data or an explicit supervision
signal, our approach can automatically learn a variety of prosodic variations
in a purely data-driven way. Importantly, each style token corresponds to a
fixed style factor regardless of the given text sequence. As a result, we can
control the prosodic style of synthetic speech in a somewhat predictable and
globally consistent way.
</dc:description>
 <dc:description>Comment: Submitted to NIPS ML4Audio workshop and ICASSP</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00524</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving SIEM capabilities through an enhanced probe for encrypted
  Skype traffic detection</dc:title>
 <dc:creator>Di Mauro, Mario</dc:creator>
 <dc:creator>Di Sarno, Cesario</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Nowadays, the Security Information and Event Management (SIEM) systems take
on great relevance in handling security issues for critical infrastructures as
Internet Service Providers. Basically, a SIEM has two main functions: i) the
collection and the aggregation of log data and security information from
disparate network devices (routers, firewalls, intrusion detection systems, ad
hoc probes and others) and ii) the analysis of the gathered data by
implementing a set of correlation rules aimed at detecting potential suspicious
events as the presence of encrypted real-time traffic. In the present work, the
authors propose an enhanced implementation of a SIEM where a particular focus
is given to the detection of encrypted Skype traffic by using an ad-hoc
developed enhanced probe (ESkyPRO) conveniently governed by the SIEM itself.
Such enhanced probe, able to interact with an agent counterpart deployed into
the SIEM platform, is designed by exploiting some machine learning concepts.
The main purpose of the proposed ad-hoc SIEM is to correlate the information
received by ESkyPRO and other types of data obtained by an Intrusion Detection
System (IDS) probe in order to make the encrypted Skype traffic detection as
accurate as possible.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00524</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00525</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Internet of Cloud: Security and Privacy issues</dc:title>
 <dc:creator>Cook, Allan</dc:creator>
 <dc:creator>Robinson, Michael</dc:creator>
 <dc:creator>Ferrag, Mohamed Amine</dc:creator>
 <dc:creator>Maglaras, Leandros A.</dc:creator>
 <dc:creator>He, Ying</dc:creator>
 <dc:creator>Jones, Kevin</dc:creator>
 <dc:creator>Janicke, Helge</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The synergy between the cloud and the IoT has emerged largely due to the
cloud having attributes which directly benefit the IoT and enable its continued
growth. IoT adopting Cloud services has brought new security challenges. In
this book chapter, we pursue two main goals: 1) to analyse the different
components of Cloud computing and the IoT and 2) to present security and
privacy problems that these systems face. We thoroughly investigate current
security and privacy preservation solutions that exist in this area, with an
eye on the Industrial Internet of Things, discuss open issues and propose
future directions
</dc:description>
 <dc:description>Comment: 27 pages, 4 figures</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00525</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00529</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Text Annotation Graphs: Annotating Complex Natural Language Phenomena</dc:title>
 <dc:creator>Forbes, Angus G.</dc:creator>
 <dc:creator>Lee, Kristine</dc:creator>
 <dc:creator>Hahn-Powell, Gus</dc:creator>
 <dc:creator>Valenzuela-Esc&#xe1;rcega, Marco A.</dc:creator>
 <dc:creator>Surdeanu, Mihai</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper introduces a new web-based software tool for annotating text, Text
Annotation Graphs, or TAG. It provides functionality for representing complex
relationships between words and word phrases that are not available in other
software tools, including the ability to define and visualize relationships
between the relationships themselves (semantic hypergraphs). Additionally, we
include an approach to representing text annotations in which annotation
subgraphs, or semantic summaries, are used to show relationships outside of the
sequential context of the text itself. Users can use these subgraphs to quickly
find similar structures within the current document or external annotated
documents. Initially, TAG was developed to support information extraction tasks
on a large database of biomedical articles. However, our software is flexible
enough to support a wide range of annotation tasks for any domain. Examples are
provided that showcase TAG's capabilities on morphological parsing and event
extraction tasks.
</dc:description>
 <dc:description>Comment: In submission to LREC'18</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00529</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00530</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>School bus routing by maximizing trip compatibility</dc:title>
 <dc:creator>Shafahi, Ali</dc:creator>
 <dc:creator>Wang, Zhongxiang</dc:creator>
 <dc:creator>Haghani, Ali</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  School bus planning is usually divided into routing and scheduling due to the
complexity of solving them concurrently. However, the separation between these
two steps may lead to worse solutions with higher overall costs than that from
solving them together. When finding the minimal number of trips in the routing
problem, neglecting the importance of trip compatibility may increase the
number of buses actually needed in the scheduling problem. This paper proposes
a new formulation for the multi-school homogeneous fleet routing problem that
maximizes trip compatibility while minimizing total travel time. This
incorporates the trip compatibility for the scheduling problem in the routing
problem. Since the problem is inherently just a routing problem, finding a good
solution is not cumbersome. To compare the performance of the model with
traditional routing problems, we generate eight mid-size data sets. Through
importing the generated trips of the routing problems into the bus scheduling
(blocking) problem, it is shown that the proposed model uses up to 13% fewer
buses than the common traditional routing models.
</dc:description>
 <dc:description>Comment: The final version of this paper will be published in Transportation
  Research Record: Journal of the Transportation Research Board, No. 2667. The
  publication index can be found at
  https://pubsindex.trb.org/view/2017/C/1437820</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00530</dc:identifier>
 <dc:identifier>doi:10.3141/2667-03</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00532</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An iterative school decomposition algorithm for solving the multi-school
  bus routing and scheduling problem</dc:title>
 <dc:creator>Wang, Zhongxiang</dc:creator>
 <dc:creator>Shafahi, Ali</dc:creator>
 <dc:creator>Haghani, Ali</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Servicing the school transportation demand safely with a minimum number of
buses is one of the highest financial goals for school transportation
directors. To achieve that objective, a good and efficient way to solve the
routing and scheduling problem is required. Due to the growth of the computing
power, the spotlight has been shed on solving the combined problem of the
school bus routing and scheduling. A recent attempt tried to model the routing
problem by maximizing the trip compatibilities with the hope of requiring fewer
buses in the scheduling problem. However, an over-counting problem associated
with trip compatibility could diminish the performance of this approach. An
extended model is proposed in this paper to resolve this issue along with an
iterative solution algorithm. This extended model is an integrated model for
multi-school bus routing and scheduling problem. The result shows better
solutions for 8 test problems can be found with a fewer number of buses (up to
25%) and shorter travel time (up to 7% per trip).
</dc:description>
 <dc:description>Comment: This paper was submitted to TRB Annual Meeting 2018</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00532</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00536</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beautiful and damned. Combined effect of content quality and social ties
  on user engagement</dc:title>
 <dc:creator>Aiello, Luca M.</dc:creator>
 <dc:creator>Schifanella, Rossano</dc:creator>
 <dc:creator>Redi, Miriam</dc:creator>
 <dc:creator>Svetlichnaya, Stacey</dc:creator>
 <dc:creator>Liu, Frank</dc:creator>
 <dc:creator>Osindero, Simon</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  User participation in online communities is driven by the intertwinement of
the social network structure with the crowd-generated content that flows along
its links. These aspects are rarely explored jointly and at scale. By looking
at how users generate and access pictures of varying beauty on Flickr, we
investigate how the production of quality impacts the dynamics of online social
systems. We develop a deep learning computer vision model to score images
according to their aesthetic value and we validate its output through
crowdsourcing. By applying it to over 15B Flickr photos, we study for the first
time how image beauty is distributed over a large-scale social system.
Beautiful images are evenly distributed in the network, although only a small
core of people get social recognition for them. To study the impact of exposure
to quality on user engagement, we set up matching experiments aimed at
detecting causality from observational data. Exposure to beauty is
double-edged: following people who produce high-quality content increases one's
probability of uploading better photos; however, an excessive imbalance between
the quality generated by a user and the user's neighbors leads to a decline in
engagement. Our analysis has practical implications for improving link
recommender systems.
</dc:description>
 <dc:description>Comment: 13 pages, 12 figures, final version published in IEEE Transactions on
  Knowledge and Data Engineering (Volume: PP, Issue: 99)</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00536</dc:identifier>
 <dc:identifier>doi:10.1109/TKDE.2017.2747552</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00537</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Materials that make robots smart</dc:title>
 <dc:creator>Correll, Nikolaus</dc:creator>
 <dc:creator>Heckman, Christoffer</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We posit that embodied artificial intelligence is not only a computational,
but also a materials problem. While the importance of material and structural
properties in the control loop are well understood, materials can take an
active role during control by tight integration of sensors, actuators,
computation and communication. We envision such materials to abstract
functionality, therefore making the construction of intelligent robots more
straightforward and robust. For example, robots could be made of bones that
measure load, muscles that move, skin that provides the robot with information
about the kind and location of tactile sensations ranging from pressure, to
texture and damage, eyes that extract high-level information, and brain
material that provides computation in a scalable manner. Such materials will
not resemble any existing engineered materials, but rather the heterogeneous
components out of which their natural counterparts are made. We describe the
state-of-the-art in so-called &quot;robotic materials&quot;, their opportunities for
revolutionizing applications ranging from manipulation to autonomous driving,
and open challenges the robotics community needs to address in collaboration
with allies, such as wireless sensor network researchers and polymer
scientists.
</dc:description>
 <dc:description>Comment: International Symposium on Robotics Research (ISRR), December, 2017</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00537</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00540</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of the Communication Traffic for Blockchain Synchronization of
  IoT Devices</dc:title>
 <dc:creator>Danzi, Pietro</dc:creator>
 <dc:creator>Kal&#xf8;r, Anders Ellersgaard</dc:creator>
 <dc:creator>Stefanovi&#x107;, &#x10c;edomir</dc:creator>
 <dc:creator>Popovski, Petar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Blockchain is a technology uniquely suited to support massive number of
transactions and smart contracts within the Internet of Things (IoT) ecosystem,
thanks to the decentralized accounting mechanism. In a blockchain network, the
states of the accounts are stored and updated by the validator nodes,
interconnected in a peer-to-peer fashion. IoT devices are characterized by
relatively low computing capabilities and low power consumption, as well as
sporadic and low-bandwidth wireless connectivity. An IoT device connects to one
or more validator nodes to observe or modify the state of the accounts. In
order to interact with the most recent state of accounts, a device needs to be
synchronized with the blockchain copy stored by the validator nodes. In this
work, we describe general architectures and synchronization protocols that
enable synchronization of the IoT endpoints to the blockchain, with different
communication costs and security levels. We model and analytically characterize
the traffic generated by the synchronization protocols, and also investigate
the power consumption and synchronization trade-off via numerical simulations.
To the best of our knowledge, this is the first study that rigorously models
the role of wireless connectivity in blockchain-powered IoT systems.
</dc:description>
 <dc:description>Comment: Paper submitted to IEEE International Conference on Communications
  (ICC) 2018</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00540</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00541</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TasNet: time-domain audio separation network for real-time,
  single-channel speech separation</dc:title>
 <dc:creator>Luo, Yi</dc:creator>
 <dc:creator>Mesgarani, Nima</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Robust speech processing in multi-talker environments requires effective
speech separation. Recent deep learning systems have made significant progress
toward solving this problem, yet it remains challenging particularly in
real-time, short latency applications. Most methods attempt to construct a mask
for each source in time-frequency representation of the mixture signal which is
not necessarily an optimal representation for speech separation. In addition,
time-frequency decomposition results in inherent problems such as
phase/magnitude decoupling and long time window which is required to achieve
sufficient frequency resolution. We propose Time-domain Audio Separation
Network (TasNet) to overcome these limitations. We directly model the signal in
the time-domain using encoder-decoder framework and perform the source
separation on nonnegative encoder outputs. This method removes the frequency
decomposition step and reduces the separation problem to estimation of source
masks on encoder outputs which is then synthesized by the decoder. Our system
outperforms the current state-of-the-art causal speech separation algorithms,
reduces the computational cost of speech separation, and significantly reduces
the minimum required latency of the output. This makes TasNet suitable for
applications where low-power, real-time implementation is desirable such as in
hearable and telecommunication devices.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00541</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00546</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Review of Privacy and Consent Management in Healthcare: A Focus on
  Emerging Data Sources</dc:title>
 <dc:creator>Asghar, Muhammad Rizwan</dc:creator>
 <dc:creator>Lee, TzeHowe</dc:creator>
 <dc:creator>Baig, Mirza Mansoor</dc:creator>
 <dc:creator>Ullah, Ehsan</dc:creator>
 <dc:creator>Russello, Giovanni</dc:creator>
 <dc:creator>Dobbie, Gillian</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The emergence of New Data Sources (NDS) in healthcare is revolutionising
traditional electronic health records in terms of data availability, storage,
and access. Increasingly, clinicians are using NDS to build a virtual holistic
image of a patient's health condition. This research is focused on a review and
analysis of the current legislation and privacy rules available for healthcare
professionals. NDS in this project refers to and includes patient-generated
health data, consumer device data, wearable health and fitness data, and data
from social media.
  This project reviewed legal and regulatory requirements for New Zealand,
Australia, the European Union, and the United States to establish the ground
reality of existing mechanisms in place concerning the use of NDS. The outcome
of our research is to recommend changes and enhancements required to better
prepare for the 'tsunami' of NDS and applications in the currently evolving
data-driven healthcare area and precision or personalised health initiatives
such as Precision Driven Health (PDH) in New Zealand.
</dc:description>
 <dc:description>Comment: 5 pages, The 13th IEEE International Conference on eScience - Safe
  Data Workshop</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00546</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00548</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Autonomous Electric Race Car Design</dc:title>
 <dc:creator>Funk, Niklas</dc:creator>
 <dc:creator>Alatur, Nikhilesh</dc:creator>
 <dc:creator>Deuber, Robin</dc:creator>
 <dc:creator>Gonon, Frederick</dc:creator>
 <dc:creator>Messikommer, Nico</dc:creator>
 <dc:creator>Nubert, Julian</dc:creator>
 <dc:creator>Patriarca, Moritz</dc:creator>
 <dc:creator>Schaefer, Simon</dc:creator>
 <dc:creator>Scotoni, Dominic</dc:creator>
 <dc:creator>B&#xfc;nger, Nicholas</dc:creator>
 <dc:creator>Dube, Renaud</dc:creator>
 <dc:creator>Khanna, Raghav</dc:creator>
 <dc:creator>Pfeiffer, Mark</dc:creator>
 <dc:creator>Wilhelm, Erik</dc:creator>
 <dc:creator>Siegwart, Roland</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Autonomous driving and electric vehicles are nowadays very active research
and development areas. In this paper we present the conversion of a standard
Kyburz eRod into an autonomous vehicle that can be operated in challenging
environments such as Swiss mountain passes. The overall hardware and software
architectures are described in detail with a special emphasis on the sensor
requirements for autonomous vehicles operating in partially structured
environments. Furthermore, the design process itself and the finalized system
architecture are presented. The work shows state of the art results in
localization and controls for self-driving high-performance electric vehicles.
Test results of the overall system are presented, which show the importance of
generalizable state estimation algorithms to handle a plethora of conditions.
</dc:description>
 <dc:description>Comment: Paper submitted and accepted to the EVS30 Symposium, from October
  9-11, 2017 in Stuttgart, Germany</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00548</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00549</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Just ASK: Building an Architecture for Extensible Self-Service Spoken
  Language Understanding</dc:title>
 <dc:creator>Kumar, Anjishnu</dc:creator>
 <dc:creator>Gupta, Arpit</dc:creator>
 <dc:creator>Chan, Julian</dc:creator>
 <dc:creator>Tucker, Sam</dc:creator>
 <dc:creator>Hoffmeister, Bjorn</dc:creator>
 <dc:creator>Dreyer, Markus</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>68T50</dc:subject>
 <dc:description>  This paper presents the design of the machine learning architecture that
underlies the Alexa Skills Kit (ASK), which was the first Spoken Language
Understanding (SLU) Software Development Kit (SDK) for a virtual digital
assistant, as far as we are aware. At Amazon, the infrastructure powers more
than 25,000 skills built through the ASK, as well as AWS's Amazon Lex SLU
Service. The ASK emphasizes flexibility, predictability and a rapid iteration
cycle for third party developers. It imposes inductive biases that allow it to
learn robust SLU models from extremely small and sparse datasets and, in doing
so, removes significant barriers to entry for software developers and dialog
systems researchers.
</dc:description>
 <dc:description>Comment: Accepted for publication at the 1st Workshop on Conversational AI at
  NIPS 2017</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2017-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00549</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00558</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recognizing Textures with Mobile Cameras for Pedestrian Safety
  Applications</dc:title>
 <dc:creator>Jain, Shubham</dc:creator>
 <dc:creator>Gruteser, Marco</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  As smartphone rooted distractions become commonplace, the lack of compelling
safety measures has led to a rise in the number of injuries to distracted
walkers. Various solutions address this problem by sensing a pedestrian's
walking environment. Existing camera-based approaches have been largely limited
to obstacle detection and other forms of object detection. Instead, we present
TerraFirma, an approach that performs material recognition on the pedestrian's
walking surface. We explore, first, how well commercial off-the-shelf
smartphone cameras can learn texture to distinguish among paving materials in
uncontrolled outdoor urban settings. Second, we aim at identifying when a
distracted user is about to enter the street, which can be used to support
safety functions such as warning the user to be cautious. To this end, we
gather a unique dataset of street/sidewalk imagery from a pedestrian's
perspective, that spans major cities like New York, Paris, and London. We
demonstrate that modern phone cameras can be enabled to distinguish materials
of walking surfaces in urban areas with more than 90% accuracy, and accurately
identify when pedestrians transition from sidewalk to street.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00561</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>This robot stinks! Differences between perceived mistreatment of robot
  and computer partners</dc:title>
 <dc:creator>Carlson, Zachary</dc:creator>
 <dc:creator>Lemmon, Louise</dc:creator>
 <dc:creator>Higgins, MacCallister</dc:creator>
 <dc:creator>Frank, David</dc:creator>
 <dc:creator>Feil-Seifer, David</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Robots (and computers) are increasingly being used in scenarios where they
interact socially with people. How people react to these agents is telling
about the perceived animacy of such agents. Mistreatment of robots (or
computers) by co-workers might provoke such telling reactions. The purpose of
this study was to discover if people perceived mistreatment directed towards a
robot any differently than toward a computer. This will provide some
understanding of how people perceive robots in collaborative social settings.
  We conducted a between-subjects study with 80 participants. Participants
worked cooperatively with either a robot or a computer which acted as the
&quot;recorder&quot; for the group. A confederate either acted aggressively or neutrally
towards the &quot;recorder.&quot; We hypothesized that people would not socially accept
mistreatment towards an agent that they felt was intelligent and similar to
themselves; that participants would perceive the robot as more similar in
appearance and emotional capability to themselves than a computer; and would
observe more mistreatment. The final results supported our hypothesis; the
participants observed mistreatment in the robot, but not the computer.
Participants felt significantly more sympathetic towards the robot and also
believed that it was much more emotionally capable.
</dc:description>
 <dc:description>Comment: Submitted to International Journal of Social Robotics</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00561</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00565</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Typically-Correct Derandomization for Small Time and Space</dc:title>
 <dc:creator>Hoza, William M.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Suppose a language $L$ can be decided by a bounded-error randomized algorithm
that runs in space $S$ and time $n \cdot \text{poly}(S)$. We give a randomized
algorithm for $L$ that still runs in space $O(S)$ and time $n \cdot
\text{poly}(S)$ that uses only $O(S)$ random bits; our algorithm has a low
failure probability on all but a negligible fraction of inputs of each length.
An immediate corollary is a deterministic algorithm for $L$ that runs in space
$O(S)$ and succeeds on all but a negligible fraction of inputs of each length.
  Next, suppose a language $L$ can be decided by a nondeterministic algorithm
that runs in space $S$ and time $n \cdot \text{poly}(S)$. We give an
unambiguous algorithm for $L$ that runs in space $O(S \sqrt{\log S})$ and time
$2^{O(S)}$ that succeeds on all but a negligible fraction of inputs of each
length.
  Finally, we prove that $\mathbf{BPL} \subseteq \mathbf{L}/(n + O(\log^2 n))$
and $\mathbf{NL} \subseteq \mathbf{UL}/(n + O(\log^2 n))$, improving results by
Fortnow and Klivans (STACS '06) and Reinhardt and Allender (SICOMP '00),
respectively. If the original randomized/nondeterministic algorithm runs in
quasilinear time, we show that fewer than $n$ bits of advice suffice (for
disambiguation, this involves increasing the space complexity to $O(\log n
\sqrt{\log \log n})$).
</dc:description>
 <dc:description>Comment: 47 pages, 11 figures</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00565</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00571</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient $\widetilde{O}(n/\epsilon)$ Spectral Sketches for the
  Laplacian and its Pseudoinverse</dc:title>
 <dc:creator>Jambulapati, Arun</dc:creator>
 <dc:creator>Sidford, Aaron</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper we consider the problem of efficiently computing
$\epsilon$-sketches for the Laplacian and its pseudoinverse. Given a Laplacian
and an error tolerance $\epsilon$, we seek to construct a function $f$ such
that for any vector $x$ (chosen obliviously from $f$), with high probability
$(1-\epsilon) x^\top A x \leq f(x) \leq (1 + \epsilon) x^\top A x$ where $A$ is
either the Laplacian or its pseudoinverse. Our goal is to construct such a
sketch $f$ efficiently and to store it in the least space possible.
  We provide nearly-linear time algorithms that, when given a Laplacian matrix
$\mathcal{L} \in \mathbb{R}^{n \times n}$ and an error tolerance $\epsilon$,
produce $\tilde{O}(n/\epsilon)$-size sketches of both $\mathcal{L}$ and its
pseudoinverse. Our algorithms improve upon the previous best sketch size of
$\widetilde{O}(n / \epsilon^{1.6})$ for sketching the Laplacian form by Andoni
et al (2015) and $O(n / \epsilon^2)$ for sketching the Laplacian pseudoinverse
by Batson, Spielman, and Srivastava (2008).
  Furthermore we show how to compute all-pairs effective resistances from
$\widetilde{O}(n/\epsilon)$ size sketch in $\widetilde{O}(n^2/\epsilon)$ time.
This improves upon the previous best running time of
$\widetilde{O}(n^2/\epsilon^2)$ by Spielman and Srivastava (2008).
</dc:description>
 <dc:description>Comment: Accepted to SODA 2018; v2 fixes a small bug in the proof of lemma 3.
  This does not affect correctness of any of our results</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:date>2018-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00571</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00574</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Clothing Material Perception using Tactile Sensing and Deep
  Learning</dc:title>
 <dc:creator>Yuan, Wenzhen</dc:creator>
 <dc:creator>Mo, Yuchen</dc:creator>
 <dc:creator>Wang, Shaoxiong</dc:creator>
 <dc:creator>Adelson, Edward</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Humans represent the objects in the same category using their properties, in
order to well discriminate and understand them, and an intelligent robot should
be able to do the same. In this work, we propose a robot system that can
automatically perceive the object properties through touch. We work on the
common object category of clothing. The robot moves under the guidance of an
external Kinect sensor, and squeezes the clothes with a GelSight tactile
sensor, then it recognizes the 11 properties of the clothing according to the
tactile data. The target properties are the physical properties, like
thickness, fuzziness, softness and endurance, and semantic properties like
wearing season and preferred washing methods. We collect a dataset of 153
varied pieces of clothes, and make 6616 exploring iterations on them. To learn
the useful information from the high-dimensional sensory output, we applied
Convolutional Neural Networks (CNN) on the tactile data for recognizing the
clothing properties, and on the Kinect depth images for selecting exploration
locations. Experiments show that using the trained neural networks, the robot
can automatically explore the unknown clothes and learn their properties. This
work proposes a new architecture for active tactile perception system with
vision-touch system, and has potential to enable robots to help humans with
varied clothing related housework.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00574</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00575</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random Subspace Two-dimensional LDA for Face Recognition</dc:title>
 <dc:creator>Bingham, Garrett</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, a novel technique named random subspace two-dimensional LDA
(RS-2DLDA) is developed for face recognition. This approach offers a number of
improvements over the random subspace two-dimensional PCA (RS2DPCA) framework
introduced by Nguyen et al. [5]. Firstly, the eigenvectors from 2DLDA have more
discriminative power than those from 2DPCA, resulting in higher accuracy for
the RS-2DLDA method over RS-2DPCA. Various distance metrics are evaluated, and
a weighting scheme is developed to further boost accuracy. A series of
experiments on the MORPH-II and ORL datasets are conducted to demonstrate the
effectiveness of this approach.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00575</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00581</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Grant-free Radio Access IoT Networks: Scalability Analysis in
  Coexistence Scenarios</dc:title>
 <dc:creator>Masoudi, Meysam</dc:creator>
 <dc:creator>Azari, Amin</dc:creator>
 <dc:creator>Yavuz, Emre Altug</dc:creator>
 <dc:creator>Cavdar, Cicek</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  IoT networks with grant-free radio access, like SigFox and LoRa, offer
low-cost durable communications over unlicensed band. These networks are
becoming more and more popular due to the ever-increasing need for ultra
durable, in terms of battery lifetime, IoT networks. Most studies evaluate the
system performance assuming single radio access technology deployment. In this
paper, we study the impact of coexisting competing radio access technologies on
the system performance. Considering $\mathpzc K$ technologies, defined by time
and frequency activity factors, bandwidth, and power, which share a set of
radio resources, we derive closed-form expressions for the successful
transmission probability, expected battery lifetime, and experienced delay as a
function of distance to the serving access point. Our analytical model, which
is validated by simulation results, provides a tool to evaluate the coexistence
scenarios and analyze how introduction of a new coexisting technology may
degrade the system performance in terms of success probability and battery
lifetime. We further investigate solutions in which this destructive effect
could be compensated, e.g., by densifying the network to a certain extent and
utilizing joint reception.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00581</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00583</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning from Noisy Image Labels with Quality Embedding</dc:title>
 <dc:creator>Yao, Jiangchao</dc:creator>
 <dc:creator>Wang, Jiajie</dc:creator>
 <dc:creator>Tsang, Ivor</dc:creator>
 <dc:creator>Zhang, Ya</dc:creator>
 <dc:creator>Sun, Jun</dc:creator>
 <dc:creator>Zhang, Chengqi</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  There is an emerging trend to leverage noisy image datasets in many visual
recognition tasks. However, the label noise among the datasets severely
degenerates the \mbox{performance of deep} learning approaches. Recently, one
mainstream is to introduce the latent label to handle label noise, which has
shown promising improvement in the network designs. Nevertheless, the mismatch
between latent labels and noisy labels still affects the predictions in such
methods. To address this issue, we propose a quality embedding model, which
explicitly introduces a quality variable to represent the trustworthiness of
noisy labels. Our key idea is to identify the mismatch between the latent and
noisy labels by embedding the quality variables into different subspaces, which
effectively minimizes the noise effect. At the same time, the high-quality
labels is still able to be applied for training. To instantiate the model, we
further propose a Contrastive-Additive Noise network (CAN), which consists of
two important layers: (1) the contrastive layer estimates the quality variable
in the embedding space to reduce noise effect; and (2) the additive layer
aggregates the prior predictions and noisy labels as the posterior to train the
classifier. Moreover, to tackle the optimization difficulty, we deduce an SGD
algorithm with the reparameterization tricks, which makes our method scalable
to big data. We conduct the experimental evaluation of the proposed method over
a range of noisy image datasets. Comprehensive results have demonstrated CAN
outperforms the state-of-the-art deep learning approaches.
</dc:description>
 <dc:description>Comment: Under review for Transactions on Image Processing</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00591</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bio-Inspired Multi-Exposure Fusion Framework for Low-light Image
  Enhancement</dc:title>
 <dc:creator>Ying, Zhenqiang</dc:creator>
 <dc:creator>Li, Ge</dc:creator>
 <dc:creator>Gao, Wen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Low-light images are not conducive to human observation and computer vision
algorithms due to their low visibility. Although many image enhancement
techniques have been proposed to solve this problem, existing methods
inevitably introduce contrast under- and over-enhancement. Inspired by human
visual system, we design a multi-exposure fusion framework for low-light image
enhancement. Based on the framework, we propose a dual-exposure fusion
algorithm to provide an accurate contrast and lightness enhancement.
Specifically, we first design the weight matrix for image fusion using
illumination estimation techniques. Then we introduce our camera response model
to synthesize multi-exposure images. Next, we find the best exposure ratio so
that the synthetic image is well-exposed in the regions where the original
image is under-exposed. Finally, the enhanced result is obtained by fusing the
input image and the synthetic image according to the weight matrix. Experiments
show that our method can obtain results with less contrast and lightness
distortion compared to that of several state-of-the-art methods.
</dc:description>
 <dc:description>Comment: Project website: https://baidut.github.io/BIMEF/</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00591</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00599</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Parametric Search for Path and Tree Partitioning</dc:title>
 <dc:creator>Frederickson, Greg N.</dc:creator>
 <dc:creator>Zhou, Samson</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present linear-time algorithms for partitioning a path or a tree with
weights on the vertices by removing $k$ edges to maximize the minimum-weight
component. We also use the same framework to partition a path with weight on
the vertices, removing $k$ edges to minimize the maximum-weight component. The
algorithms use the parametric search paradigm, testing candidate values until
an optimum is found while simultaneously reducing the running time needed for
each test. For path-partitioning, the algorithm employs a synthetic weighting
scheme that results in a constant fraction reduction in running time after each
test. For tree-partitioning, our dual-pronged strategy makes progress no matter
what the specific structure of our tree is.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00599</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00603</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Constrained Tensor Factorization by Alternating Optimization
  with Primal-Dual Splitting</dc:title>
 <dc:creator>Ono, Shunsuke</dc:creator>
 <dc:creator>Kasai, Takuma</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Tensor factorization with hard and/or soft constraints has played an
important role in signal processing and data analysis. However, existing
algorithms for constrained tensor factorization have two drawbacks: (i) they
require matrix-inversion; and (ii) they cannot (or at least is very difficult
to) handle structured regularizations. We propose a new tensor factorization
algorithm that circumvents these drawbacks. The proposed method is built upon
alternating optimization, and each subproblem is solved by a primal-dual
splitting algorithm, yielding an efficient and flexible algorithmic framework
to constrained tensor factorization. The advantages of the proposed method over
a state-of-the-art constrained tensor factorization algorithm, called AO-ADMM,
are demonstrated on regularized nonnegative tensor factorization.
</dc:description>
 <dc:description>Comment: 5 pages, submitted to ICASSP2018</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00603</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00609</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Security Against Impersonation Attacks in Distributed Systems</dc:title>
 <dc:creator>Brown, Philip N.</dc:creator>
 <dc:creator>Borowski, Holly</dc:creator>
 <dc:creator>Marden, Jason R.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In a multi-agent system, transitioning from a centralized to a distributed
decision-making strategy can introduce vulnerability to adversarial
manipulation. We study the potential for adversarial manipulation in a class of
graphical coordination games where the adversary can pose as a friendly agent
in the game, thereby influencing the decision-making rules of a subset of
agents. The adversary's influence can cascade throughout the system, indirectly
influencing other agents' behavior and significantly impacting the emergent
collective behavior. The main results in this paper focus on characterizing
conditions under which the adversary's local influence can dramatically impact
the emergent global behavior, e.g., destabilize efficient Nash equilibria.
</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00609</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00614</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Multimodal Anomaly Detector for Robot-Assisted Feeding Using an
  LSTM-based Variational Autoencoder</dc:title>
 <dc:creator>Park, Daehyung</dc:creator>
 <dc:creator>Hoshi, Yuuna</dc:creator>
 <dc:creator>Kemp, Charles C.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The detection of anomalous executions is valuable for reducing potential
hazards in assistive manipulation. Multimodal sensory signals can be helpful
for detecting a wide range of anomalies. However, the fusion of
high-dimensional and heterogeneous modalities is a challenging problem. We
introduce a long short-term memory based variational autoencoder (LSTM-VAE)
that fuses signals and reconstructs their expected distribution. We also
introduce an LSTM-VAE-based detector using a reconstruction-based anomaly score
and a state-based threshold. For evaluations with 1,555 robot-assisted feeding
executions including 12 representative types of anomalies, our detector had a
higher area under the receiver operating characteristic curve (AUC) of 0.8710
than 5 other baseline detectors from the literature. We also show the
multimodal fusion through the LSTM-VAE is effective by comparing our detector
with 17 raw sensory signals versus 4 hand-engineered features.
</dc:description>
 <dc:description>Comment: 8 pages, under review</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00614</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00617</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Polarized Have We Become? A Multimodal Classification of Trump
  Followers and Clinton Followers</dc:title>
 <dc:creator>Wang, Yu</dc:creator>
 <dc:creator>Feng, Yang</dc:creator>
 <dc:creator>Hong, Zhe</dc:creator>
 <dc:creator>Berger, Ryan</dc:creator>
 <dc:creator>Luo, Jiebo</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Polarization in American politics has been extensively documented and
analyzed for decades, and the phenomenon became all the more apparent during
the 2016 presidential election, where Trump and Clinton depicted two radically
different pictures of America. Inspired by this gaping polarization and the
extensive utilization of Twitter during the 2016 presidential campaign, in this
paper we take the first step in measuring polarization in social media and we
attempt to predict individuals' Twitter following behavior through analyzing
ones' everyday tweets, profile images and posted pictures. As such, we treat
polarization as a classification problem and study to what extent Trump
followers and Clinton followers on Twitter can be distinguished, which in turn
serves as a metric of polarization in general. We apply LSTM to processing
tweet features and we extract visual features using the VGG neural network.
Integrating these two sets of features boosts the overall performance. We are
able to achieve an accuracy of 69%, suggesting that the high degree of
polarization recorded in the literature has started to manifest itself in
social media as well.
</dc:description>
 <dc:description>Comment: 16 pages, SocInfo 2017, 9th International Conference on Social
  Informatics</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00617</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-67217-5_27</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00618</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ThrottleBot - Performance without Insight</dc:title>
 <dc:creator>Chang, Michael Alan</dc:creator>
 <dc:creator>Panda, Aurojit</dc:creator>
 <dc:creator>Tsai, Yuan-Cheng</dc:creator>
 <dc:creator>Wang, Hantao</dc:creator>
 <dc:creator>Shenker, Scott</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Large scale applications are increasingly built by composing sets of
microservices. In this model the functionality for a single application might
be split across 100s or 1000s of microservices. Resource provisioning for these
applications is complex, requiring administrators to understand both the
functioning of each microservice, and dependencies between microservices in an
application. In this paper we present ThrottleBot, a system that automates the
process of determining what resource when allocated to which microservice is
likely to have the greatest impact on application performance. We demonstrate
the efficacy of our approach by applying ThrottleBot to both synthetic and real
world applications. We believe that ThrottleBot when combined with existing
microservice orchestrators, e.g., Kubernetes, enables push-button deployment of
web scale applications.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00618</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00625</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decentralized Deep Scheduling for Interference Channels</dc:title>
 <dc:creator>de Kerret, Paul</dc:creator>
 <dc:creator>Gesbert, David</dc:creator>
 <dc:creator>Filippone, Maurizio</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study the problem of decentralized scheduling in
Interference Channels (IC). In this setting, each Transmitter (TX) receives an
arbitrary amount of feedback regarding the global multi-user channel state
based on which it decides whether to transmit or to stay silent without any
form of communication with the other TXs. While many methods have been proposed
to tackle the problem of link scheduling in the presence of reliable Channel
State Information (CSI), finding the optimally robust transmission strategy in
the presence of arbitrary channel uncertainties at each TX has remained elusive
for the past years. In this work, we recast the link scheduling problem as a
decentralized classification problem and we propose the use of Collaborative
Deep Neural Networks (C-DNNs) to solve this problem. After adequate training,
the scheduling obtained using the C-DNNs flexibly adapts to the decentralized
CSI configuration to outperform other scheduling algorithms.
</dc:description>
 <dc:description>Comment: Submitted to the 2018 IEEE International Conference on Communications
  (ICC)</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00625</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00629</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sleep Stage Classification Based on Multi-level Feature Learning and
  Recurrent Neural Networks via Wearable Device</dc:title>
 <dc:creator>Zhang, Xin</dc:creator>
 <dc:creator>Kou, Weixuan</dc:creator>
 <dc:creator>Chang, Eric I-Chao</dc:creator>
 <dc:creator>Gao, He</dc:creator>
 <dc:creator>Fan, Yubo</dc:creator>
 <dc:creator>Xu, Yan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  This paper proposes a practical approach for automatic sleep stage
classification based on a multi-level feature learning framework and Recurrent
Neural Network (RNN) classifier using heart rate and wrist actigraphy derived
from a wearable device. The feature learning framework is designed to extract
low- and mid-level features. Low-level features capture temporal and frequency
domain properties and mid-level features learn compositions and structural
information of signals. Since sleep staging is a sequential problem with
long-term dependencies, we take advantage of RNNs with Bidirectional Long
Short-Term Memory (BLSTM) architectures for sequence data learning. To simulate
the actual situation of daily sleep, experiments are conducted with a resting
group in which sleep is recorded in resting state, and a comprehensive group in
which both resting sleep and non-resting sleep are included.We evaluate the
algorithm based on an eight-fold cross validation to classify five sleep stages
(W, N1, N2, N3, and REM). The proposed algorithm achieves weighted precision,
recall and F1 score of 58.0%, 60.3%, and 58.2% in the resting group and 58.5%,
61.1%, and 58.5% in the comprehensive group, respectively. Various comparison
experiments demonstrate the effectiveness of feature learning and BLSTM. We
further explore the influence of depth and width of RNNs on performance. Our
method is specially proposed for wearable devices and is expected to be
applicable for long-term sleep monitoring at home. Without using too much prior
domain knowledge, our method has the potential to generalize sleep disorder
detection.
</dc:description>
 <dc:description>Comment: 11 pages, 10 figures</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00629</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00639</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A topology for Team Policies and Existence of Optimal Team Policies in
  Stochastic Team Theory</dc:title>
 <dc:creator>Sald&#x131;, Naci</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper, we establish the existence of team-optimal policies for static
teams and a class of sequential dynamic teams. We first consider the static
team problems and show the existence of optimal policies under certain
regularity conditions on the observation channels by introducing a topology on
the set of policies. Then we consider sequential dynamic teams and establish
the existence of an optimal policy via the static reduction method of
Witsenhausen. We apply our findings to the well-known counterexample of
Witsenhausen and the Gaussian relay channel problem.
</dc:description>
 <dc:description>Comment: 9 pages, double column</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00639</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00648</identifier>
 <datestamp>2017-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Augmentation in Emotion Classification Using Generative Adversarial
  Networks</dc:title>
 <dc:creator>Zhu, Xinyue</dc:creator>
 <dc:creator>Liu, Yifan</dc:creator>
 <dc:creator>Qin, Zengchang</dc:creator>
 <dc:creator>Li, Jiahong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  It is a difficult task to classify images with multiple class labels using
only a small number of labeled examples, especially when the label (class)
distribution is imbalanced. Emotion classification is such an example of
imbalanced label distribution, because some classes of emotions like
\emph{disgusted} are relatively rare comparing to other labels like {\it happy
or sad}. In this paper, we propose a data augmentation method using generative
adversarial networks (GAN). It can complement and complete the data manifold
and find better margins between neighboring classes. Specifically, we design a
framework with a CNN model as the classifier and a cycle-consistent adversarial
networks (CycleGAN) as the generator. In order to avoid gradient vanishing
problem, we employ the least-squared loss as adversarial loss. We also propose
several evaluation methods on three benchmark datasets to validate GAN's
performance. Empirical results show that we can obtain 5%~10% increase in the
classification accuracy after employing the GAN-based data augmentation
techniques.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:date>2017-12-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00648</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00651</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A bound for the shortest reset words for semisimple synchronizing
  automata via the packing number</dc:title>
 <dc:creator>Rodaro, Emanuele</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Representation Theory</dc:subject>
 <dc:description>  We show that if a semisimple synchronizing automaton with $n$ states has a
minimal reachable non-unary subset of cardinality $r\ge 2$, then there is a
reset word of length at most $(n-1)D(2,r,n)$, where $D(2,r,n)$ is the
$2$-packing number for families of $r$-subsets of $[1,n]$.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00651</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00657</identifier>
 <datestamp>2017-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-Robust Communications over a Broadcast Channel</dc:title>
 <dc:creator>Keresztfalvi, Tibor</dc:creator>
 <dc:creator>Lapidoth, Amos</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We establish the deterministic-code capacity region of a network with one
transmitter and two receivers: an &quot;ordinary receiver&quot; and a &quot;robust receiver.&quot;
The channel to the ordinary receiver is a given (known) discrete memoryless
channel (DMC), whereas the channel to the robust receiver is an arbitrarily
varying channel (AVC). Both receivers are required to decode the &quot;common
message,&quot; whereas only the ordinary receiver is required to decode the &quot;private
message.&quot;
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:date>2017-12-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00657</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00658</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Candidates v.s. Noises Estimation for Large Multi-Class Classification
  Problem</dc:title>
 <dc:creator>Han, Lei</dc:creator>
 <dc:creator>Zhang, Tong</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper proposes a method for multi-class classification problems, where
the number of classes $K$ is large. The method, referred to as {\em Candidates
v.s. Noises Estimation} (CANE), selects a small subset of candidate classes and
samples the remaining classes. We show that CANE is always consistent and
computationally efficient. Moreover, the resulting estimator has low
statistical variance approaching that of the maximum likelihood estimator, when
the observed label belongs to the selected candidates with high probability. In
practice, we use a tree structure with leaves as classes to promote fast beam
search for candidate selection. We also apply the CANE method to estimate word
probabilities in neural language models. Experiments show that CANE achieves
better prediction accuracy over the Noise-Contrastive Estimation (NCE), its
variants and a number of the state-of-the-art tree classifiers, while it gains
significant speedup compared to the standard $\mathcal{O}(K)$ methods.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00658</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00659</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Concave losses for robust dictionary learning</dc:title>
 <dc:creator>de Araujo, Rafael Will M</dc:creator>
 <dc:creator>Hirata, Roberto</dc:creator>
 <dc:creator>Rakotomamonjy, Alain</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Traditional dictionary learning methods are based on quadratic convex loss
function and thus are sensitive to outliers. In this paper, we propose a
generic framework for robust dictionary learning based on concave losses. We
provide results on composition of concave functions, notably regarding
super-gradient computations, that are key for developing generic dictionary
learning algorithms applicable to smooth and non-smooth losses. In order to
improve identification of outliers, we introduce an initialization heuristic
based on undercomplete dictionary learning. Experimental results using
synthetic and real data demonstrate that our method is able to better detect
outliers, is capable of generating better dictionaries, outperforming
state-of-the-art methods such as K-SVD and LC-KSVD.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00659</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00667</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Erd\H{o}s-P\'osa property of chordless cycles and its applications</dc:title>
 <dc:creator>Kim, Eun Jung</dc:creator>
 <dc:creator>Kwon, O-joung</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A chordless cycle in a graph $G$ is an induced subgraph of $G$ which is a
cycle of length at least four. We prove that the Erd\H{o}s-P\'osa property
holds for chordless cycles, which resolves the major open question concerning
the Erd\H{o}s-P\'osa property. Our proof for chordless cycles is constructive:
in polynomial time, one can find either $k+1$ vertex-disjoint chordless cycles,
or $ck^2 \log k$ vertices hitting every chordless cycle for some constant $c$.
It immediately implies an approximation algorithm of factor
$\mathcal{O}(\sf{opt}\log {\sf opt})$ for Chordal Vertex Deletion. We
complement our main result by showing that chordless cycles of length at least
$\ell$ for any fixed $\ell\ge 5$ do not have the Erd\H{o}s-P\'osa property.
  As a corollary, for a non-negative integral function $w$ defined on the
vertex set of a graph $G$, the minimum value $\sum_{x\in S}w(x)$ over all
vertex sets $S$ hitting all cycles of $G$ is at most $\mathcal{O}(k^2 \log k)$
where $k$ is the maximum number of cycles (not necessarily vertex-disjoint) in
$G$ such that each vertex $v$ is used at most $w(v)$ times.
</dc:description>
 <dc:description>Comment: 34 pages, 10 figures, to appear in SODA 2018</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00667</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00669</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formal Analysis of Hybrid Systems Using Feature Indented Assertions</dc:title>
 <dc:creator>da Costa, Antonio Anastasio Bruto</dc:creator>
 <dc:creator>Dasgupta, Pallab</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Model based design is a recommended step in the design of embedded control
systems. A formal analysis of models helps in arriving at provably correct
designs that meet the necessary functional requirements. Often such analysis
needs to look beyond functional correctness to evaluate the margins of
behavioral attributes. Our notion of features addresses this requirement. The
syntactic fabric of our feature definitions enjoys similarity with assertion
languages; however, unlike assertions, the consequent of features are real
valued expressions representing the feature value. In this article, we give
insights into the extensive work we have done in the formal analysis of
features for hybrid models. We describe a methodology for abstract
interpretation of features over hybrid automata models, leveraging reachability
solvers for extracting feature ranges formally and further demonstrate how
Satisfiability Modulo Theory (SMT) solvers can be used for extracting
behavioural traces corresponding to corner cases of a feature.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00669</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00671</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Development and validation of a novel dementia of Alzheimer's type (DAT)
  score based on metabolism FDG-PET imaging</dc:title>
 <dc:creator>Popuri, Karteek</dc:creator>
 <dc:creator>Balachandar, Rakesh</dc:creator>
 <dc:creator>Alpert, Kathryn</dc:creator>
 <dc:creator>Lu, Donghuan</dc:creator>
 <dc:creator>Bhalla, Mahadev</dc:creator>
 <dc:creator>Mackenzie, Ian</dc:creator>
 <dc:creator>Hsiung, Robin Ging-Yuek</dc:creator>
 <dc:creator>Wang, Lei</dc:creator>
 <dc:creator>Beg, Mirza Faisal</dc:creator>
 <dc:creator>Initiative, the Alzhemier's Disease Neuroimaging</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Fluorodeoxyglucose positron emission tomography (FDG-PET) imaging based 3D
topographic brain glucose metabolism patterns from normal controls (NC) and
individuals with dementia of Alzheimer's type (DAT) are used to train a novel
multi-scale ensemble classification model. This ensemble model outputs a
FDG-PET DAT score (FPDS) between 0 and 1 denoting the probability of a subject
to be clinically diagnosed with DAT based on their metabolism profile. A novel
7 group image stratification scheme is devised that groups images not only
based on their associated clinical diagnosis but also on past and future
trajectories of the clinical diagnoses, yielding a more continuous
representation of the different stages of DAT spectrum that mimics a real-world
clinical setting. The potential for using FPDS as a DAT biomarker was validated
on a large number of FDG-PET images (N=2984) obtained from the Alzheimer's
Disease Neuroimaging Initiative (ADNI) database taken across the proposed
stratification, and a good classification AUC (area under the curve) of 0.78
was achieved in distinguishing between images belonging to subjects on a DAT
trajectory and those images taken from subjects not progressing to a DAT
diagnosis. Further, the FPDS biomarker achieved state-of-the-art performance on
the mild cognitive impairment (MCI) to DAT conversion prediction task with an
AUC of 0.81, 0.80, 0.77 for the 2, 3, 5 years to conversion windows
respectively.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00671</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00674</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TCPSnitch: Dissecting the Usage of the Socket API</dc:title>
 <dc:creator>Schueren, Gregory Vander</dc:creator>
 <dc:creator>De Coninck, Quentin</dc:creator>
 <dc:creator>Bonaventure, Olivier</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Networked applications interact with the TCP/IP stack through the socket API.
Over the years, various extensions have been added to this popular API. In this
paper, we propose and implement the TCPSnitch software that tracks the
interactions between Linux and Android applications and the TCP/IP stack. We
collect a dataset containing the interactions produced by more than 120
different applications. Our analysis reveals that applications use a variety of
API calls. On Android, many applications use various socket options even if the
Java API does not expose them directly. TCPSnitch and the associated dataset
are publicly available.
</dc:description>
 <dc:description>Comment: See https://www.tcpsnitch.org</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00674</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00677</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding and Predicting The Attractiveness of Human Action Shot</dc:title>
 <dc:creator>Dai, Bin</dc:creator>
 <dc:creator>Wang, Baoyuan</dc:creator>
 <dc:creator>Hua, Gang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Selecting attractive photos from a human action shot sequence is quite
challenging, because of the subjective nature of the &quot;attractiveness&quot;, which is
mainly a combined factor of human pose in action and the background. Prior
works have actively studied high-level image attributes including
interestingness, memorability, popularity, and aesthetics. However, none of
them has ever studied the &quot;attractiveness&quot; of human action shot. In this paper,
we present the first study of the &quot;attractiveness&quot; of human action shots by
taking a systematic data-driven approach. Specifically, we create a new
action-shot dataset composed of about 8000 high quality action-shot photos. We
further conduct rich crowd-sourced human judge studies on Amazon Mechanical
Turk(AMT) in terms of global attractiveness of a single photo, and relative
attractiveness of a pair of photos. A deep Siamese network with a novel hybrid
distribution matching loss was further proposed to fully exploit both types of
ratings. Extensive experiments reveal that (1) the property of action shot
attractiveness is subjective but predicable (2) our proposed method is both
efficient and effective for predicting the attractive human action shots.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00677</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00681</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extracting an English-Persian Parallel Corpus from Comparable Corpora</dc:title>
 <dc:creator>Karimi, Akbar</dc:creator>
 <dc:creator>Ansari, Ebrahim</dc:creator>
 <dc:creator>Bigham, Bahram Sadeghi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Parallel data are an important part of a reliable Statistical Machine
Translation (SMT) system. The more of these data are available, the better the
quality of the SMT system. However, for some language pairs such as
Persian-English, parallel sources of this kind are scarce. In this paper, a
bidirectional method is proposed to extract parallel sentences from English and
Persian document aligned Wikipedia. Two machine translation systems are
employed to translate from Persian to English and the reverse after which an IR
system is used to measure the similarity of the translated sentences. Adding
the extracted sentences to the training data of the existing SMT systems is
shown to improve the quality of the translation. Furthermore, the proposed
method slightly outperforms the one-directional approach. The extracted corpus
consists of about 200,000 sentences which have been sorted by their degree of
similarity calculated by the IR system and is freely available for public
access on the Web.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, 3 tables and extended abstract version is
  submitted to LREC2018</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00681</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00686</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Complexity of Random Quantum Computations and the Jones
  Polynomial</dc:title>
 <dc:creator>Mann, Ryan L.</dc:creator>
 <dc:creator>Bremner, Michael J.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  There is a natural relationship between Jones polynomials and quantum
computation. We use this relationship to show that the complexity of evaluating
relative-error approximations of Jones polynomials can be used to bound the
classical complexity of approximately simulating random quantum computations.
We prove that random quantum computations cannot be classically simulated up to
a constant total variation distance, under the assumption that (1) the
Polynomial Hierarchy does not collapse and (2) the average-case complexity of
relative-error approximations of the Jones polynomial matches the worst-case
complexity over a constant fraction of random links. Our results provide a
straightforward relationship between the approximation of Jones polynomials and
the complexity of random quantum computations.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00686</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00693</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical evaluation of visual quality metrics for image denoising</dc:title>
 <dc:creator>Egiazarian, Karen</dc:creator>
 <dc:creator>Ponomarenko, Mykola</dc:creator>
 <dc:creator>Lukin, Vladimir</dc:creator>
 <dc:creator>Ieremeiem, Oleg</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper studies the problem of full reference visual quality assessment of
denoised images with a special emphasis on images with low contrast and
noise-like texture. Denoising of such images together with noise removal often
results in image details loss or smoothing. A new test image database, FLT,
containing 75 noise-free &quot;reference&quot; images and 300 filtered (&quot;distorted&quot;)
images is developed. Each reference image, corrupted by an additive white
Gaussian noise, is denoised by the BM3D filter with four different values of
threshold parameter (four levels of noise suppression). After carrying out a
perceptual quality assessment of distorted images, the mean opinion scores
(MOS) are obtained and compared with the values of known full reference quality
metrics. As a result, the Spearman Rank Order Correlation Coefficient (SROCC)
between PSNR values and MOS has a value close to zero, and SROCC between values
of known full-reference image visual quality metrics and MOS does not exceed
0.82 (which is reached by a new visual quality metric proposed in this paper).
The FLT dataset is more complex than earlier datasets used for assessment of
visual quality for image denoising. Thus, it can be effectively used to design
new image visual quality metrics for image denoising.
</dc:description>
 <dc:description>Comment: Submitted to ICASSP 2018</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00693</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00694</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpretable and Pedagogical Examples</dc:title>
 <dc:creator>Milli, Smitha</dc:creator>
 <dc:creator>Abbeel, Pieter</dc:creator>
 <dc:creator>Mordatch, Igor</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Teachers intentionally pick the most informative examples to show their
students. However, if the teacher and student are neural networks, the examples
that the teacher network learns to give, although effective at teaching the
student, are typically uninterpretable. We show that training the student and
teacher iteratively, rather than jointly, can produce interpretable teaching
strategies. We evaluate interpretability by (1) measuring the similarity of the
teacher's emergent strategies to intuitive strategies in each domain and (2)
conducting human experiments to evaluate how effective the teacher's strategies
are at teaching humans. We show that the teacher network learns to select or
generate interpretable, pedagogical examples to teach rule-based,
probabilistic, boolean, and hierarchical concepts.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00694</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00695</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Universal Marginalizer for Amortized Inference in Generative Models</dc:title>
 <dc:creator>Douglas, Laura</dc:creator>
 <dc:creator>Zarov, Iliyan</dc:creator>
 <dc:creator>Gourgoulias, Konstantinos</dc:creator>
 <dc:creator>Lucas, Chris</dc:creator>
 <dc:creator>Hart, Chris</dc:creator>
 <dc:creator>Baker, Adam</dc:creator>
 <dc:creator>Sahani, Maneesh</dc:creator>
 <dc:creator>Perov, Yura</dc:creator>
 <dc:creator>Johri, Saurabh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of inference in a causal generative model where the
set of available observations differs between data instances. We show how
combining samples drawn from the graphical model with an appropriate masking
function makes it possible to train a single neural network to approximate all
the corresponding conditional marginal distributions and thus amortize the cost
of inference. We further demonstrate that the efficiency of importance sampling
may be improved by basing proposals on the output of the neural network. We
also outline how the same network can be used to generate samples from an
approximate joint posterior via a chain decomposition of the graph.
</dc:description>
 <dc:description>Comment: Submitted to the NIPS 2017 Workshop on Advances in Approximate
  Bayesian Inference</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00695</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00698</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive coordination of working-memory and reinforcement learning in
  non-human primates performing a trial-and-error problem solving task</dc:title>
 <dc:creator>Viejo, Guillaume</dc:creator>
 <dc:creator>Girard, Beno&#xee;t</dc:creator>
 <dc:creator>Procyk, Emmanuel</dc:creator>
 <dc:creator>Khamassi, Mehdi</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Accumulating evidence suggest that human behavior in trial-and-error learning
tasks based on decisions between discrete actions may involve a combination of
reinforcement learning (RL) and working-memory (WM). While the understanding of
brain activity at stake in this type of tasks often involve the comparison with
non-human primate neurophysiological results, it is not clear whether monkeys
use similar combined RL and WM processes to solve these tasks. Here we analyzed
the behavior of five monkeys with computational models combining RL and WM. Our
model-based analysis approach enables to not only fit trial-by-trial choices
but also transient slowdowns in reaction times, indicative of WM use. We found
that the behavior of the five monkeys was better explained in terms of a
combination of RL and WM despite inter-individual differences. The same
coordination dynamics we used in a previous study in humans best explained the
behavior of some monkeys while the behavior of others showed the opposite
pattern, revealing a possible different dynamics of WM process. We further
analyzed different variants of the tested models to open a discussion on how
the long pretraining in these tasks may have favored particular coordination
dynamics between RL and WM. This points towards either inter-species
differences or protocol differences which could be further tested in humans.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00698</dc:identifier>
 <dc:identifier>Behavioural Brain Research, Elsevier, 2017,
  \&amp;\#x3008;10.1016/j.bbr.2017.09.030\&amp;\#x3009</dc:identifier>
 <dc:identifier>doi:10.1016/j.bbr.2017.09.030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00705</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Training of Convolutional Neural Nets on Large Distributed
  Systems</dc:title>
 <dc:creator>Kumar, Sameer</dc:creator>
 <dc:creator>Sreedhar, Dheeraj</dc:creator>
 <dc:creator>Saxena, Vaibhav</dc:creator>
 <dc:creator>Sabharwal, Yogish</dc:creator>
 <dc:creator>Verma, Ashish</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Deep Neural Networks (DNNs) have achieved im- pressive accuracy in many
application domains including im- age classification. Training of DNNs is an
extremely compute- intensive process and is solved using variants of the
stochastic gradient descent (SGD) algorithm. A lot of recent research has
focussed on improving the performance of DNN training. In this paper, we
present optimization techniques to improve the performance of the data parallel
synchronous SGD algorithm using the Torch framework: (i) we maintain data
in-memory to avoid file I/O overheads, (ii) we present a multi-color based MPI
Allreduce algorithm to minimize communication overheads, and (iii) we propose
optimizations to the Torch data parallel table framework that handles
multi-threading. We evaluate the performance of our optimizations on a Power 8
Minsky cluster with 32 nodes and 128 NVidia Pascal P100 GPUs. With our
optimizations, we are able to train 90 epochs of the ResNet-50 model on the
Imagenet-1k dataset using 256 GPUs in just 48 minutes. This significantly
improves on the previously best known performance of training 90 epochs of the
ResNet-50 model on the same dataset using 256 GPUs in 65 minutes. To the best
of our knowledge, this is the best known training performance demonstrated for
the Imagenet- 1k dataset.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00705</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00714</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Doris: A tool for interactive exploration of historic corpora (Extended
  Version)</dc:title>
 <dc:creator>Guha, Sreya</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Insights into social phenomenon can be gleaned from trends and patterns in
corpora of documents associated with that phenomenon. Recent years have
witnessed the use of computational techniques, mostly based on keywords, to
analyze large corpora for these purposes. In this paper, we extend these
techniques to incorporate semantic features. We introduce Doris, an interactive
exploration tool that combines semantic features with information retrieval
techniques to enable exploration of document corpora corresponding to the
social phenomenon. We discuss the semantic techniques and describe an
implementation on a corpus of United States (US) presidential speeches. We
illustrate, with examples, how the ability to combine syntactic and semantic
features in a visualization helps researchers more easily gain insights into
the underlying phenomenon.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00714</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00715</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Related Fact Checks: a tool for combating fake news</dc:title>
 <dc:creator>Guha, Sreya</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The emergence of &quot;Fake News&quot; and misinformation via online news and social
media has spurred an interest in computational tools to combat this phenomenon.
In this paper we present a new &quot;Related Fact Checks&quot; service, which can help a
reader critically evaluate an article and make a judgment on its veracity by
bringing up fact checks that are relevant to the article. We describe the core
technical problems that need to be solved in building a &quot;Related Fact Checks&quot;
service, and present results from an evaluation of an implementation.
</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00715</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00716</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flight Trajectory Planning for Fixed-Wing Aircraft in Loss of Thrust
  Emergencies</dc:title>
 <dc:creator>Paul, Saswata</dc:creator>
 <dc:creator>Hole, Frederick</dc:creator>
 <dc:creator>Zytek, Alexandra</dc:creator>
 <dc:creator>Varela, Carlos A.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Loss of thrust emergencies-e.g., induced by bird/drone strikes or fuel
exhaustion-create the need for dynamic data-driven flight trajectory planning
to advise pilots or control UAVs. While total loss of thrust trajectories to
nearby airports can be pre-computed for all initial points in a 3D flight plan,
dynamic aspects such as partial power and airplane surface damage must be
considered for accuracy. In this paper, we propose a new Dynamic Data-Driven
Avionics Software (DDDAS) approach which during flight updates a damaged
aircraft performance model, used in turn to generate plausible flight
trajectories to a safe landing site. Our damaged aircraft model is
parameterized on a baseline glide ratio for a clean aircraft configuration
assuming best gliding airspeed on straight flight. The model predicts purely
geometric criteria for flight trajectory generation, namely, glide ratio and
turn radius for different bank angles and drag configurations. Given actual
aircraft performance data, we dynamically infer the baseline glide ratio to
update the damaged aircraft model. Our new flight trajectory generation
algorithm thus can significantly improve upon prior Dubins based trajectory
generation work by considering these data-driven geometric criteria. We further
introduce a trajectory utility function to rank trajectories for safety. As a
use case, we consider the Hudson River ditching of US Airways 1549 in January
2009 using a flight simulator to evaluate our trajectories and to get sensor
data. In this case, a baseline glide ratio of 17.25:1 enabled us to generate
trajectories up to 28 seconds after the birds strike, whereas, a 19:1 baseline
glide ratio enabled us to generate trajectories up to 36 seconds after the
birds strike. DDDAS can significantly improve the accuracy of generated flight
trajectories thereby enabling better decision support systems for pilots in
emergency conditions.
</dc:description>
 <dc:description>Comment: This work was accepted as a full paper and presented in the Second
  International Conference on InfoSymbiotics / DDDAS (Dynamic Data Driven
  Applications Systems) held at MIT, Cambridge, Massachusetts in August, 2017</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00716</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00721</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating Historical Hourly Traffic Volumes via Machine Learning and
  Vehicle Probe Data: A Maryland Case Study</dc:title>
 <dc:creator>Seku&#x142;a, Przemys&#x142;aw</dc:creator>
 <dc:creator>Markovi&#x107;, Nikola</dc:creator>
 <dc:creator>Laan, Zachary Vander</dc:creator>
 <dc:creator>Sadabadi, Kaveh Farokhi</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  This paper focuses on the problem of estimating historical traffic volumes
between sparsely-located traffic sensors, which transportation agencies need to
accurately compute statewide performance measures. To this end, the paper
examines applications of vehicle probe data, automatic traffic recorder counts,
and neural network models to estimate hourly volumes in the Maryland highway
network, and proposes a novel approach that combines neural networks with an
existing profiling method. On average, the proposed approach yields 26% more
accurate estimates than volume profiles, which are currently used by
transportation agencies across the US to compute statewide performance
measures. The paper also quantifies the value of using vehicle probe data in
estimating hourly traffic volumes, which provides important managerial insights
to transportation agencies interested in acquiring this type of data. For
example, results show that volumes can be estimated with a mean absolute
percent error of about 20% at locations where average number of observed probes
is between 30 and 47 vehicles/hr, which provides a useful guideline for
assessing the value of probe vehicle data from different vendors.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00721</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00726</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comprehensive Low and High-level Feature Analysis for Early Rumor
  Detection on Twitter</dc:title>
 <dc:creator>Nguyen, Tu</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recent work have done a good job in modeling rumors and detecting them over
microblog streams. However, the performance of their automatic approaches are
not relatively high when looking early in the diffusion. A first intuition is
that, at early stage, most of the aggregated rumor features (e.g., propagation
features) are not mature and distinctive enough. The objective of rumor
debunking in microblogs, however, are to detect these misinformation as early
as possible. In this work, we leverage neural models in learning the hidden
representations of individual rumor-related tweets at the very beginning of a
rumor. Our extensive experiments show that the resulting signal improves our
classification performance over time, significantly within the first 10 hours.
To deepen the understanding of these low and high-level features in
contributing to the model performance over time, we conduct an extensive study
on a wide range of high impact rumor features for the 48 hours range. The end
model that engages these features are shown to be competitive, reaches over 90%
accuracy and out-performs strong baselines in our carefully cured dataset.
</dc:description>
 <dc:description>Comment: CIKM 2017 Workshop on Interpretable Data Mining - Bridging the Gap
  between Shallow and Deep Models (IDM 2017). arXiv admin note: substantial
  text overlap with arXiv:1709.04402</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00726</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00727</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Evaluation of Channel Decoding With Deep Neural Networks</dc:title>
 <dc:creator>Lyu, Wei</dc:creator>
 <dc:creator>Zhang, Zhaoyang</dc:creator>
 <dc:creator>Jiao, Chunxu</dc:creator>
 <dc:creator>Qin, Kangjian</dc:creator>
 <dc:creator>Zhang, Huazi</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  With the demand of high data rate and low latency in fifth generation (5G),
deep neural network decoder (NND) has become a promising candidate due to its
capability of one-shot decoding and parallel computing. In this paper, three
types of NND, i.e., multi-layer perceptron (MLP), convolution neural network
(CNN) and recurrent neural network (RNN), are proposed with the same parameter
magnitude. The performance of these deep neural networks are evaluated through
extensive simulation. Numerical results show that RNN has the best decoding
performance, yet at the price of the highest computational overhead. Moreover,
we find there exists a saturation length for each type of neural network, which
is caused by their restricted learning abilities.
</dc:description>
 <dc:description>Comment: 6 pages, 11 figures. arXiv admin note: text overlap with
  arXiv:1707.05697 by other authors</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00727</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00728</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Crossing Behaviour of Social Groups: Insights from Observations at
  Non-signalized Intersection</dc:title>
 <dc:creator>Gorrini, Andrea</dc:creator>
 <dc:creator>Crociani, Luca</dc:creator>
 <dc:creator>Vizzari, Giuseppe</dc:creator>
 <dc:creator>Bandini, Stefania</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Environmental, demographical and psychological factors have a demonstrated
impact on risky crossing behaviour. In this work we focus on the potential
influence of social factors on the considered phenomenon (i.e. group crossing
decision). We present the results of a video-recorded observation about the
crossing behaviour of singles and dyads at non-signalized intersections.
Results showed that crossing behaviour is characterized by three distinct
phases: (i) approaching, (ii) appraising (decision making) and (iii) crossing.
Dyads walk slower than single pedestrians in all phases. The crossing behaviour
of dyads is characterized by the emergence of a leader who takes the decision
to cross first, followed by the companion. However, there is no difference
between the accepted safety gap of singles and dyads. Understanding factors
influencing the crossing decision of social groups represents an important
result supporting the development of agent-based simulations of
pedestrian-vehicle interactions.
</dc:description>
 <dc:description>Comment: Pre-print of a paper presented at the 12th International Conference
  on Traffic and Granular Flow - TGF 2017, 19-22 July 2017, Washington DC, USA
  (2017)</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00728</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00739</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotic Signal Detection Rates with 1-bit Array Measurements</dc:title>
 <dc:creator>Stein, Manuel S.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This work considers detecting the presence of a band-limited random radio
source using an antenna array featuring a low-complexity digitization process
with single-bit output resolution. In contrast to high-resolution
analog-to-digital conversion, such a direct transformation of the analog radio
measurements to a binary representation can be implemented hardware and
energy-efficient. For a wireless spectrum monitoring problem, formulated as a
binary hypothesis test, we analyze the achievable detection performance when
using such 1-bit radio measurements from an array of sensors. To simplify the
derivations, we consider asymptotic statistical tests with exponential family
models, which results in analytic detection rate expressions without access to
the intractable 1-bit array likelihood. As an application, we explore the
detection capability of a GPS spectrum monitoring system with different numbers
of antennas and different observation intervals. Results show that binary
arrays with a moderate amount of sensors are capable of performing fast and
reliable spectrum monitoring.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00739</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00740</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Represent Programs with Graphs</dc:title>
 <dc:creator>Allamanis, Miltiadis</dc:creator>
 <dc:creator>Brockschmidt, Marc</dc:creator>
 <dc:creator>Khademi, Mahmoud</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Learning tasks on source code (i.e., formal languages) have been considered
recently, but most work has tried to transfer natural language methods and does
not capitalize on the unique opportunities offered by code's known syntax. For
example, long-range dependencies induced by using the same variable or function
in distant locations are often not considered. We propose to use graphs to
represent both the syntactic and semantic structure of code and use graph-based
deep learning methods to learn to reason over program structures.
  In this work, we present how to construct graphs from source code and how to
scale Gated Graph Neural Networks training to such large graphs. We evaluate
our method on two tasks: VarNaming, in which a network attempts to predict the
name of a variable given its usage, and VarMisuse, in which the network learns
to reason about selecting the correct variable that should be used at a given
program location. Our comparison to methods that use less structured program
representations shows the advantages of modeling known structure, and suggests
that our models learn to infer meaningful names and to solve the VarMisuse task
in many cases. Additionally, our testing showed that VarMisuse identifies a
number of bugs in mature open-source projects.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1705.07867</dc:description>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00740</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00745</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Routing and Scheduling Policies for Energy Harvesting
  Communication Networks</dc:title>
 <dc:creator>Calvo-Fullana, Miguel</dc:creator>
 <dc:creator>Ant&#xf3;n-Haro, Carles</dc:creator>
 <dc:creator>Matamoros, Javier</dc:creator>
 <dc:creator>Ribeiro, Alejandro</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper, we study the joint routing-scheduling problem in energy
harvesting communication networks. Our policies, which are based on stochastic
subgradient methods on the dual domain, act as an energy harvesting variant of
the stochastic family of backpresure algorithms. Specifically, we propose two
policies: (i) the Stochastic Backpressure with Energy Harvesting (SBP-EH), in
which a node's routing-scheduling decisions are determined by the difference
between the Lagrange multipliers associated to their queue stability
constraints and their neighbors'; and (ii) the Stochastic Soft Backpressure
with Energy Harvesting (SSBP-EH), an improved algorithm where the
routing-scheduling decision is of a probabilistic nature. For both policies, we
show that given sustainable data and energy arrival rates, the stability of the
data queues over all network nodes is guaranteed. Numerical results corroborate
the stability guarantees and illustrate the minimal gap in performance that our
policies offer with respect to classical ones which work with an unlimited
energy supply.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00745</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00748</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometric k-nearest neighbor estimation of entropy and mutual
  information</dc:title>
 <dc:creator>Lord, Warren M.</dc:creator>
 <dc:creator>Sun, Jie</dc:creator>
 <dc:creator>Bollt, Erik M.</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  Nonparametric estimation of mutual information is used in a wide range of
scientific problems to determine the dependence between variables. The
k-nearest neighbor (knn) methods are consistent, and therefore expected to work
well for large sample size. These methods use geometrically regular local
volume elements. This practice allows maximum localization of the volume
elements, but can also induce a bias due to a poor description of the local
geometry of the underlying probability measure. We introduce a new class of knn
estimators that we call geometric knn estimators (g-knn), which use more
complex local volume elements to better model the local geometry of the
probability measures. As an example of this class of estimators, we develop a
g-knn estimator of entropy and mutual information based on elliptical volume
elements, capturing the local stretching and compression common to a wide range
of dynamical systems attractors. In a series of numerical examples, this g-knn
estimator of mutual information outperforms the Kraskov-St\&quot;ogbauer-Grassberger
(KSG) estimator both when the joint distribution is thinly supported, and when
sample sizes are small. In particular, the examples suggest that the g-knn
estimators can be of particular relevance to applications in which the system
is large but data size is limited.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:date>2018-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00748</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00753</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network-size independent covering number bounds for deep networks</dc:title>
 <dc:creator>Kabra, Mayank</dc:creator>
 <dc:creator>Branson, Kristin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We give a covering number bound for deep learning networks that is
independent of the size of the network. The key for the simple analysis is that
for linear classifiers, rotating the data doesn't affect the covering number.
Thus, we can ignore the rotation part of each layer's linear transformation,
and get the covering number bound by concentrating on the scaling part.
</dc:description>
 <dc:description>Comment: We found a possible error in our analysis. We are re-evaluating, and
  may resubmit</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00753</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00757</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>REAP: An Efficient Incentive Mechanism for Reconciling Aggregation
  Accuracy and Individual Privacy in Crowdsensing</dc:title>
 <dc:creator>Zhang, Zhikun</dc:creator>
 <dc:creator>He, Shibo</dc:creator>
 <dc:creator>Chen, Jiming</dc:creator>
 <dc:creator>Zhang, Junshan</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Incentive mechanism plays a critical role in privacy-aware crowdsensing. Most
previous studies on co-design of incentive mechanism and privacy preservation
assume a trustworthy fusion center (FC). Very recent work has taken steps to
relax the assumption on trustworthy FC and allows participatory users (PUs) to
add well calibrated noise to their raw sensing data before reporting them,
whereas the focus is on the equilibrium behavior of data subjects with binary
data. Making a paradigm shift, this paper aim to quantify the privacy
compensation for continuous data sensing while allowing FC to directly control
PUs. There are two conflicting objectives in such scenario: FC desires better
quality data in order to achieve higher aggregation accuracy whereas PUs prefer
adding larger noise for higher privacy-preserving levels (PPLs). To achieve a
good balance therein, we design an efficient incentive mechanism to REconcile
FC's Aggregation accuracy and individual PU's data Privacy (REAP).
Specifically, we adopt the celebrated notion of differential privacy to measure
PUs' PPLs and quantify their impacts on FC's aggregation accuracy. Then,
appealing to Contract Theory, we design an incentive mechanism to maximize FC's
aggregation accuracy under a given budget. The proposed incentive mechanism
offers different contracts to PUs with different privacy preferences, by which
FC can directly control PUs. It can further overcome the information asymmetry,
i.e., the FC typically does not know each PU's precise privacy preference. We
derive closed-form solutions for the optimal contracts in both complete
information and incomplete information scenarios. Further, the results are
generalized to the continuous case where PUs' privacy preferences take values
in a continuous domain. Extensive simulations are provided to validate the
feasibility and advantages of our proposed incentive mechanism.
</dc:description>
 <dc:description>Comment: 11 pages, 6 figures</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00757</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00760</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Do Software Startups Pivot? Empirical Results from a Multiple Case
  Study</dc:title>
 <dc:creator>Bajwa, Sohaib Shahid</dc:creator>
 <dc:creator>Wang, Xiaofeng</dc:creator>
 <dc:creator>Duc, Anh Nguven</dc:creator>
 <dc:creator>Abrahamsson, Pekka</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In order to handle intense time pressure and survive in dynamic market,
software startups have to make crucial decisions constantly on whether to
change directions or stay on chosen courses, or in the terms of Lean Startup,
to pivot or to persevere. The existing research and knowledge on software
startup pivots are very limited. In this study, we focused on understanding the
pivoting processes of software startups, and identified the triggering factors
and pivot types. To achieve this, we employed a multiple case study approach,
and analyzed the data obtained from four software startups. The initial
findings show that different software startups make different types of pivots
related to business and technology during their product development life cycle.
The pivots are triggered by various factors including negative customer
feedback.
</dc:description>
 <dc:description>Comment: Conference publication, International Conference on Software Business
  (ICSOB'16), Slovenia</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00760</dc:identifier>
 <dc:identifier>In: Maglyas A., Lamprecht AL. (eds) Software Business. Lecture
  Notes in Business Information Processing, vol 240. Springer, Cham (2016)</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-40515-5_14</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00762</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Lower Bounds for the Fourier Entropy/Influence Conjecture via
  Lexicographic Functions</dc:title>
 <dc:creator>Hod, Rani</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Every Boolean function can be uniquely represented as a multilinear
polynomial. The entropy and the total influence are two ways to measure the
concentration of its Fourier coefficients, namely the monomial coefficients in
this representation: the entropy roughly measures their spread, while the total
influence measures their average level. The Fourier Entropy/Influence
conjecture of Friedgut and Kalai from 1996 states that the entropy to influence
ratio is bounded by a universal constant $C$.
  Using lexicographic Boolean functions, we present three explicit asymptotic
constructions that improve upon the previously best known lower bound
$C&gt;6.278944$ by O'Donnell and Tan, obtained via recursive composition. The
first uses their construction with the lexicographic function $\ell\left\langle
2/3\right\rangle $ of measure $2/3$ to demonstrate that
$C\ge4+3\log_{4}3&gt;6.377444$. The second generalizes their construction to
biased functions and obtains $C&gt;6.413846$ using $\ell\left\langle
\Phi\right\rangle $, where $\Phi$ is the inverse golden ratio. The third,
independent, construction gives $C&gt;6.454784$, even for monotone functions.
  Beyond modest improvements to the value of $C$, our constructions shed some
new light on the properties sought in potential counterexamples to the
conjecture.
  Additionally, we prove a Lipschitz-type condition on the total influence and
spectral entropy, which may be of independent interest.
</dc:description>
 <dc:description>Comment: 20+7 pages</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00762</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00765</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximation of Functions over Manifolds: A Moving Least-Squares
  Approach</dc:title>
 <dc:creator>Sober, Barak</dc:creator>
 <dc:creator>Aizenbud, Yariv</dc:creator>
 <dc:creator>Levin, David</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present an algorithm for approximating a function defined over a
$d$-dimensional manifold utilizing only noisy function values at locations
sampled from the manifold with noise. To produce the approximation we do not
require any knowledge regarding the manifold other than its dimension $d$. The
approximation scheme is based upon the Manifold Moving Least-Squares (MMLS).
The proposed algorithm is resistant to noise in both the domain and function
values. Furthermore, the approximant is shown to be smooth and of approximation
order of $\mathcal{O}(h^{m+1})$ for non-noisy data, where $h$ is the mesh size
with respect to the manifold domain, and $m$ is the degree of a local
polynomial approximation utilized in our algorithm. In addition, the proposed
algorithm is linear in time with respect to the ambient-space's dimension.
Thus, in case of extremely large ambient space dimension, we are able to avoid
the curse of dimensionality without having to perform non-linear dimension
reduction, which introduces distortions to the manifold data. Using numerical
experiments, we compare the presented method to state-of-the-art algorithms for
regression over manifolds and show its potential.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1606.07104</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00765</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00768</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SRL4ORL: Improving Opinion Role Labelling using Multi-task Learning with
  Semantic Role Labeling</dc:title>
 <dc:creator>Marasovi&#x107;, Ana</dc:creator>
 <dc:creator>Frank, Anette</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  For over 12 years, machine learning is used to extract opinion-holder-target
structures from text to answer the question: Who expressed what kind of
sentiment towards what?. However, recent neural approaches do not outperform
the state-of-the-art feature-based model for Opinion Role Labelling (ORL). We
suspect this is due to the scarcity of labelled training data and address this
issue using different multi-task learning techniques with a related task which
has substantially more data, i.e. Semantic Role Labelling (SRL). Despite
difficulties of the benchmark MPQA corpus, we show that indeed the ORL model
benefits from SRL knowledge.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00768</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00770</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scientific co-authorship networks</dc:title>
 <dc:creator>Cugmas, Marjan</dc:creator>
 <dc:creator>Ferligoj, Anu&#x161;ka</dc:creator>
 <dc:creator>Kronegger, Luka</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The paper addresses the stability of the co-authorship networks in time. The
analysis is done on the networks of Slovenian researchers in two time periods
(1991-2000 and 2001-2010). Two researchers are linked if they published at
least one scientific bibliographic unit in a given time period. As proposed by
Kronegger et al. (2011), the global network structures are examined by
generalized blockmodeling with the assumed
multi-core--semi-periphery--periphery blockmodel type. The term core denotes a
group of researchers who published together in a systematic way with each
other.
  The obtained blockmodels are comprehensively analyzed by visualizations and
through considering several statistics regarding the global network structure.
To measure the stability of the obtained blockmodels, different adjusted
modified Rand and Wallace indices are applied. Those enable to distinguish
between the splitting and merging of cores when operationalizing the stability
of cores. Also, the adjusted modified indices can be used when new researchers
occur in the second time period (newcomers) and when some researchers are no
longer present in the second time period (departures). The research disciplines
are described and clustered according to the values of these indices.
Considering the obtained clusters, the sources of instability of the research
disciplines are studied (e.g., merging or splitting of cores, newcomers or
departures). Furthermore, the differences in the stability of the obtained
cores on the level of scientific disciplines are studied by linear regression
analysis where some personal characteristics of the researchers (e.g., age,
gender), are also considered.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00770</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00774</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum programming made easy</dc:title>
 <dc:creator>Paolini, Luca</dc:creator>
 <dc:creator>Roversi, Luca</dc:creator>
 <dc:creator>Zorzi, Margherita</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We introduce the functional language IQu (&quot;Haiku&quot;) which, under the paradigm
&quot;quantum data &amp; classical control&quot; and in accordance with the model QRAM,
allows to define and manipulate quantum circuits also by means of intermediate
and partial measurement. Idealized Algol is the reference for the design of
IQu. We extend the type system of Idealized Algol for typing both
quantum-registers, i.e. the stores of quantum states, and quantum-circuits. The
types for quantum-registers do not make any reference to linear logic formulas
and are parametric on the dimension of the quantum-registers they are type of.
IQu operates on quantum circuits as they were classical data so no restriction
exists on their duplication. Concerning programming, we show the potential
effectiveness of IQu by encoding well known quantum algorithms in it.
</dc:description>
 <dc:description>Comment: Submitted</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00774</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00783</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knee Motion Generation Method for Transfemoral Prosthesis based on
  Kinematic Synergy and Inertial Motion</dc:title>
 <dc:creator>Sano, Hiroshi</dc:creator>
 <dc:creator>Wada, Takahiro</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Previous research has shown that the effective use of inertial motion (i.e.,
less or no torque input at the knee joint) plays an important role in achieving
a smooth gait of transfemoral prostheses in the swing phase. In our previous
research, a method for generating a timed knee trajectory close to able-bodied
individuals, which leads to sufficient clearance between the foot and the floor
and the knee extension, was proposed using the inertial motion. Limb motions
are known to correlate with each other during walking. This phenomenon is
called kinematic synergy. In the present study, we measure gaits in level
walking of able-bodied individuals with a wide range of walking velocities. We
show that this kinematic synergy also exists between the motions of the intact
limbs and those of the knee as determined by the inertial motion technique. We
then propose a new method for generating the motion of the knee joint using its
inertial motion close to the able-bodied individuals in mid-swing based on its
kinematic synergy, such that the method can adapt to the changes in the motion
velocity. The numerical simulation results show that the proposed method
achieves prosthetic walking similar to that of able-bodied individuals with a
wide range of constant walking velocities and termination of walking from
steady-state walking. Further investigations have found that a kinematic
synergy also exists at the start of walking. Overall, our method successfully
achieves knee motion generation from the initiation of walking through
steady-state walking with different velocities until termination of walking.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00783</dc:identifier>
 <dc:identifier>IEEE Transactions on Neural Systems and Rehabilitation Engineering
  ( Volume: PP, Issue: 99 ) pg 1</dc:identifier>
 <dc:identifier>doi:10.1109/TNSRE.2017.2759818</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00784</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Approximation Algorithm for Network Immunization</dc:title>
 <dc:creator>Tariq, Juvaria</dc:creator>
 <dc:creator>Ahmad, Muhammad</dc:creator>
 <dc:creator>Khan, Imdadullah</dc:creator>
 <dc:creator>Shabbir, Mudassir</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The problem of identifying important players in a given network is of pivotal
importance for viral marketing, public health management, network security and
various other fields of social network analysis. In this work we find the most
important vertices in a graph G = (V,E) to immunize so as the chances of an
epidemic outbreak is minimized. This problem is directly relevant to minimizing
the impact of a contagion spread (e.g. flu virus, computer virus and rumor) in
a graph (e.g. social network, computer network) with a limited budget (e.g. the
number of available vaccines, antivirus software, filters). It is well known
that this problem is computationally intractable (it is NP-hard). In this work
we reformulate the problem as a budgeted combinational optimization problem and
use techniques from spectral graph theory to design an efficient greedy
algorithm to find a subset of vertices to be immunized. We show that our
algorithm takes less time compared to the state of the art algorithm. Thus our
algorithm is scalable to networks of much larger sizes than best known
solutions proposed earlier. We also give analytical bounds on the quality of
our algorithm. Furthermore, we evaluate the efficacy of our algorithm on a
number of real world networks and demonstrate that the empirical performance of
algorithm supplements the theoretical bounds we present, both in terms of
approximation guarantees and computational efficiency.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00784</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00788</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the complexity of optimal homotopies</dc:title>
 <dc:creator>Chambers, Erin Wolf</dc:creator>
 <dc:creator>de Mesmay, Arnaud</dc:creator>
 <dc:creator>Ophelders, Tim</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this article, we provide new structural results and algorithms for the
Homotopy Height problem. In broad terms, this problem quantifies how much a
curve on a surface needs to be stretched to sweep continuously between two
positions. More precisely, given two homotopic curves $\gamma_1$ and $\gamma_2$
on a combinatorial (say, triangulated) surface, we investigate the problem of
computing a homotopy between $\gamma_1$ and $\gamma_2$ where the length of the
longest intermediate curve is minimized. Such optimal homotopies are relevant
for a wide range of purposes, from very theoretical questions in quantitative
homotopy theory to more practical applications such as similarity measures on
meshes and graph searching problems.
  We prove that Homotopy Height is in the complexity class NP, and the
corresponding exponential algorithm is the best one known for this problem.
This result builds on a structural theorem on monotonicity of optimal
homotopies, which is proved in a companion paper. Then we show that this
problem encompasses the Homotopic Fr\'echet distance problem which we therefore
also establish to be in NP, answering a question which has previously been
considered in several different settings. We also provide an O(log
n)-approximation algorithm for Homotopy Height on surfaces by adapting an
earlier algorithm of Har-Peled, Nayyeri, Salvatipour and Sidiropoulos in the
planar setting.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00788</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00791</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectral Methods for Immunization of Large Networks</dc:title>
 <dc:creator>Ahmad, Muhammad</dc:creator>
 <dc:creator>Tariq, Juvaria</dc:creator>
 <dc:creator>Shabbir, Mudassir</dc:creator>
 <dc:creator>Khan, Imdadullah</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Given a network of nodes, minimizing the spread of a contagion using a
limited budget is a well-studied problem with applications in network security,
viral marketing, social networks, and public health. In real graphs, virus may
infect a node which in turn infects its neighbor nodes and this may trigger an
epidemic in the whole graph. The goal thus is to select the best k nodes
(budget constraint) that are immunized (vaccinated, screened, filtered) so as
the remaining graph is less prone to the epidemic. It is known that the problem
is, in all practical models, computationally intractable even for moderate
sized graphs. In this paper we employ ideas from spectral graph theory to
define relevance and importance of nodes. Using novel graph theoretic
techniques, we then design an efficient approximation algorithm to immunize the
graph. Theoretical guarantees on the running time of our algorithm show that it
is more efficient than any other known solution in the literature. We test the
performance of our algorithm on several real world graphs. Experiments show
that our algorithm scales well for large graphs and outperforms state of the
art algorithms both in quality (containment of epidemic) and efficiency
(runtime and space complexity).
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00791</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00793</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D Mobile Localization Using Distance-only Measurements</dc:title>
 <dc:creator>Jiang, Bomin</dc:creator>
 <dc:creator>Anderson, Brian D. O.</dc:creator>
 <dc:creator>Hman, Hatem</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  For a group of cooperating UAVs, localizing each other is often a key task.
This paper studies the localization problem for a group of UAVs flying in 3D
space with very limited information, i.e., when noisy distance measurements are
the only type of inter-agent sensing that is available, and when only one UAV
knows a global coordinate basis, the others being GPS-denied. Initially for a
two-agent problem, but easily generalized to some multi-agent problems,
constraints are established on the minimum number of required distance
measurements required to achieve the localization. The paper also proposes an
algorithm based on semidefinite programming (SDP), followed by maximum
likelihood estimation using a gradient descent initialized from the SDP
calculation. The efficacy of the algorithm is verified with experimental noisy
flight data.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Aerospace and Electronic Systems</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00793</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00795</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Talos: Neutralizing Vulnerabilities with Security Workarounds for Rapid
  Response</dc:title>
 <dc:creator>Huang, Zhen</dc:creator>
 <dc:creator>D'Angelo, Mariana</dc:creator>
 <dc:creator>Miyani, Dhaval</dc:creator>
 <dc:creator>Lie, David</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:subject>D.1.2</dc:subject>
 <dc:description>  Considerable delays often exist between the discovery of a vulnerability and
the issue of a patch. One way to mitigate this window of vulnerability is to
use a configuration workaround, which prevents the vulnerable code from being
executed at the cost of some lost functionality -- but only if one is
available. Since program configurations are not specifically designed to
mitigate software vulnerabilities, we find that they only cover 25.2% of
vulnerabilities.
  To minimize patch delay vulnerabilities and address the limitations of
configuration workarounds, we propose Security Workarounds for Rapid Response
(SWRRs), which are designed to neutralize security vulnerabilities in a timely,
secure, and unobtrusive manner. Similar to configuration workarounds, SWRRs
neutralize vulnerabilities by preventing vulnerable code from being executed at
the cost of some lost functionality. However, the key difference is that SWRRs
use existing error-handling code within programs, which enables them to be
mechanically inserted with minimal knowledge of the program and minimal
developer effort. This allows SWRRs to achieve high coverage while still being
fast and easy to deploy.
  We have designed and implemented Talos, a system that mechanically
instruments SWRRs into a given program, and evaluate it on five popular Linux
server programs. We run exploits against 11 real-world software vulnerabilities
and show that SWRRs neutralize the vulnerabilities in all cases. Quantitative
measurements on 320 SWRRs indicate that SWRRs instrumented by Talos can
neutralize 75.1% of all potential vulnerabilities and incur a loss of
functionality similar to configuration workarounds in 71.3% of those cases. Our
overall conclusion is that automatically generated SWRRs can safely mitigate
2.1x more vulnerabilities, while only incurring a loss of functionality
comparable to that of traditional configuration workarounds.
</dc:description>
 <dc:description>Comment: Published in Proceedings of the 37th IEEE Symposium on Security and
  Privacy (Oakland 2016)</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00795</dc:identifier>
 <dc:identifier>2016 IEEE Symposium on Security and Privacy, 2016, Pages 618-635</dc:identifier>
 <dc:identifier>doi:10.1109/SP.2016.43</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00804</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Framework for evaluation of sound event detection in web videos</dc:title>
 <dc:creator>Badlani, Rohan</dc:creator>
 <dc:creator>Shah, Ankit</dc:creator>
 <dc:creator>Elizalde, Benjamin</dc:creator>
 <dc:creator>Kumar, Anurag</dc:creator>
 <dc:creator>Raj, Bhiksha</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  The largest source of sound events is web videos. Most videos lack sound
event labels at segment level, however, a significant number of them do respond
to text queries, from a match found to their metadata by the search engine. In
this paper we explore the extent to which a search query could be used as the
true label for the presence of sound events in the videos. For this, we
developed a framework for large-scale sound event recognition on web videos.
The framework crawls videos using search queries corresponding to 78 sound
event labels drawn from three datasets. The datasets are used to train three
classifiers, which were then run on 3.7 million video segments. We evaluated
performance using the search query as the true label and compare it (on a
subset) with human labeling. Both types exhibited close performance, to within
10%, and similar performance trends as the number of evaluated segments
increased. Hence, our experiments show potential for using search query as a
preliminary true label for sound events in web videos.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00804</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00808</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Optimal Choice Dictionary</dc:title>
 <dc:creator>Hagerup, Torben</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A choice dictionary is a data structure that can be initialized with a
parameter $n\in\{1,2,\ldots\}$ and subsequently maintains an initially empty
subset $S$ of $\{1,\ldots,n\}$ under insertion, deletion, membership queries
and an operation 'choice' that returns an arbitrary element of $S$. The choice
dictionary is fundamental in space-efficient computing and has numerous
applications. The best previous choice dictionary can be initialized with $n$
and a second parameter $t\in\{1,2,\ldots\}$ in constant time and subsequently
executes all operations in $O(t)$ time and occupies $n+O(n({t/w})^t+\log n)$
bits on a word RAM with a word length of $w=\Omega(\log n)$ bits. We describe a
new choice dictionary that, following a constant-time initialization, executes
all operations in constant time and, in addition to the space needed to store
$n$, occupies only $n+1$ bits, which is shown to be optimal if $w=o(n)$.
Allowed $\lceil\log_2(n+1)\rceil$ bits of additional space, the new data
structure also supports iteration over the set $S$ in constant time per
element.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00808</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00811</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Expressive power of recurrent neural networks</dc:title>
 <dc:creator>Khrulkov, Valentin</dc:creator>
 <dc:creator>Novikov, Alexander</dc:creator>
 <dc:creator>Oseledets, Ivan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep neural networks are surprisingly efficient at solving practical tasks,
but the theory behind this phenomenon is only starting to catch up with the
practice. Numerous works show that depth is the key to this efficiency. A
certain class of deep convolutional networks -- namely those that correspond to
the Hierarchical Tucker (HT) tensor decomposition -- has been proven to have
exponentially higher expressive power than shallow networks. I.e. a shallow
network of exponential width is required to realize the same score function as
computed by the deep architecture. In this paper, we prove the expressive power
theorem (an exponential lower bound on the width of the equivalent shallow
network) for a class of recurrent neural networks -- ones that correspond to
the Tensor Train (TT) decomposition. This means that even processing an image
patch by patch with an RNN can be exponentially more efficient than a (shallow)
convolutional network with one hidden layer. Using theoretical results on the
relation between the tensor decompositions we compare expressive powers of the
HT- and TT-Networks. We also implement the recurrent TT-Networks and provide
numerical evidence of their expressivity.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00811</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00812</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Channel masking for multivariate time series shapelets</dc:title>
 <dc:creator>Raychaudhuri, Dripta S.</dc:creator>
 <dc:creator>Grabocka, Josif</dc:creator>
 <dc:creator>Schmidt-Thieme, Lars</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Time series shapelets are discriminative sub-sequences and their similarity
to time series can be used for time series classification. Initial shapelet
extraction algorithms searched shapelets by complete enumeration of all
possible data sub-sequences. Research on shapelets for univariate time series
proposed a mechanism called shapelet learning which parameterizes the shapelets
and learns them jointly with a prediction model in an optimization procedure.
Trivial extension of this method to multivariate time series does not yield
very good results due to the presence of noisy channels which lead to
overfitting. In this paper we propose a shapelet learning scheme for
multivariate time series in which we introduce channel masks to discount noisy
channels and serve as an implicit regularization.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00812</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00814</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring Quantum Entropy</dc:title>
 <dc:creator>Acharya, Jayadev</dc:creator>
 <dc:creator>Issa, Ibrahim</dc:creator>
 <dc:creator>Shende, Nirmal V.</dc:creator>
 <dc:creator>Wagner, Aaron B.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The entropy of a quantum system is a measure of its randomness, and has
applications in measuring quantum entanglement. We study the problem of
measuring the von Neumann entropy, $S(\rho)$, and R\'enyi entropy,
$S_\alpha(\rho)$ of an unknown mixed quantum state $\rho$ in $d$ dimensions,
given access to independent copies of $\rho$.
  We provide an algorithm with copy complexity $O(d^{2/\alpha})$ for estimating
$S_\alpha(\rho)$ for $\alpha&lt;1$, and copy complexity $O(d^{2})$ for estimating
$S(\rho)$, and $S_\alpha(\rho)$ for non-integral $\alpha&gt;1$. These bounds are
at least quadratic in $d$, which is the order dependence on the number of
copies required for learning the entire state $\rho$. For integral $\alpha&gt;1$,
on the other hand, we provide an algorithm for estimating $S_\alpha(\rho)$ with
a sub-quadratic copy complexity of $O(d^{2-2/\alpha})$. We characterize the
copy complexity for integral $\alpha&gt;1$ up to constant factors by providing
matching lower bounds. For other values of $\alpha$, and the von Neumann
entropy, we show lower bounds on the algorithm that achieves the upper bound.
This shows that we either need new algorithms for better upper bounds, or
better lower bounds to tighten the results.
  For non-integral $\alpha$, and the von Neumann entropy, we consider the well
known Empirical Young Diagram (EYD) algorithm, which is the analogue of
empirical plug-in estimator in classical distribution estimation. As a
corollary, we strengthen a lower bound on the copy complexity of the EYD
algorithm for learning the maximally mixed state by showing that the lower
bound holds with exponential probability (which was previously known to hold
with a constant probability). For integral $\alpha&gt;1$, we provide new
concentration results of certain polynomials that arise in Kerov algebra of
Young diagrams.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00814</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00817</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Medoids in almost linear time via multi-armed bandits</dc:title>
 <dc:creator>Bagaria, Vivek</dc:creator>
 <dc:creator>Kamath, Govinda M.</dc:creator>
 <dc:creator>Ntranos, Vasilis</dc:creator>
 <dc:creator>Zhang, Martin J.</dc:creator>
 <dc:creator>Tse, David</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Computing the medoid of a large number of points in high-dimensional space is
an increasingly common operation in many data science problems. We present an
algorithm Med-dit which uses O(n log n) distance evaluations to compute the
medoid with high probability. Med-dit is based on a connection with the
multi-armed bandit problem. We evaluate the performance of Med-dit empirically
on the Netflix-prize and the single-cell RNA-Seq datasets, containing hundreds
of thousands of points living in tens of thousands of dimensions, and observe a
5-10x improvement in performance over the current state of the art. Med-dit is
available at https://github.com/bagavi/Meddit
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00817</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00821</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minor-free graphs have light spanners</dc:title>
 <dc:creator>Borradaile, Glencora</dc:creator>
 <dc:creator>Le, Hung</dc:creator>
 <dc:creator>Wulff-Nilsen, Christian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>68W25, 68W40</dc:subject>
 <dc:description>  We show that every $H$-minor-free graph has a light $(1+\epsilon)$-spanner,
resolving an open problem of Grigni and Sissokho and proving a conjecture of
Grigni and Hung. Our lightness bound is
\[O\left(\frac{\sigma_H}{\epsilon^3}\log \frac{1}{\epsilon}\right)\] where
$\sigma_H = |V(H)|\sqrt{\log |V(H)|}$ is the sparsity coefficient of
$H$-minor-free graphs. That is, it has a practical dependency on the size of
the minor $H$. Our result also implies that the polynomial time approximation
scheme (PTAS) for the Travelling Salesperson Problem (TSP) in $H$-minor-free
graphs by Demaine, Hajiaghayi and Kawarabayashi is an efficient PTAS whose
running time is $2^{O_H\left(\frac{1}{\epsilon^4}\log
\frac{1}{\epsilon}\right)}n^{O(1)}$ where $O_H$ ignores dependencies on the
size of $H$. Our techniques significantly deviate from existing lines of
research on spanners for $H$-minor-free graphs, but build upon the work of
Chechik and Wulff-Nilsen for spanners of general graphs.
</dc:description>
 <dc:description>Comment: 22 pages, 4 figures. Accepted to FOCS 2017</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00821</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00830</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BinPro: A Tool for Binary Source Code Provenance</dc:title>
 <dc:creator>Miyani, Dhaval</dc:creator>
 <dc:creator>Huang, Zhen</dc:creator>
 <dc:creator>Lie, David</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:description>  Enforcing open source licenses such as the GNU General Public License (GPL),
analyzing a binary for possible vulnerabilities, and code maintenance are all
situations where it is useful to be able to determine the source code
provenance of a binary. While previous work has either focused on computing
binary-to-binary similarity or source-to-source similarity, BinPro is the first
work we are aware of to tackle the problem of source-to-binary similarity.
BinPro can match binaries with their source code even without knowing which
compiler was used to produce the binary, or what optimization level was used
with the compiler. To do this, BinPro utilizes machine learning to compute
optimal code features for determining binary-to-source similarity and a static
analysis pipeline to extract and compute similarity based on those features.
Our experiments show that on average BinPro computes a similarity of 81% for
matching binaries and source code of the same applications, and an average
similarity of 25% for binaries and source code of similar but different
applications. This shows that BinPro's similarity score is useful for
determining if a binary was derived from a particular source code.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00830</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00831</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Network Flow with $k$-Arc Destruction</dc:title>
 <dc:creator>Ridremont, Thomas</dc:creator>
 <dc:creator>Watel, Dimitri</dc:creator>
 <dc:creator>Poirion, Pierre-Louis</dc:creator>
 <dc:creator>Picouleau, Christophe</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  When a flow is not allowed to be reoriented the Maximum Residual Flow Problem
with $k$-Arc Destruction is known to be $NP$-hard for $k=2$. We show that when
a flow is allowed to be adaptive the problem becomes polynomial for every fixed
$k$.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00831</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00832</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning</dc:title>
 <dc:creator>Lanctot, Marc</dc:creator>
 <dc:creator>Zambaldi, Vinicius</dc:creator>
 <dc:creator>Gruslys, Audrunas</dc:creator>
 <dc:creator>Lazaridou, Angeliki</dc:creator>
 <dc:creator>Tuyls, Karl</dc:creator>
 <dc:creator>Perolat, Julien</dc:creator>
 <dc:creator>Silver, David</dc:creator>
 <dc:creator>Graepel, Thore</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  To achieve general intelligence, agents must learn how to interact with
others in a shared environment: this is the challenge of multiagent
reinforcement learning (MARL). The simplest form is independent reinforcement
learning (InRL), where each agent treats its experience as part of its
(non-stationary) environment. In this paper, we first observe that policies
learned using InRL can overfit to the other agents' policies during training,
failing to sufficiently generalize during execution. We introduce a new metric,
joint-policy correlation, to quantify this effect. We describe an algorithm for
general MARL, based on approximate best responses to mixtures of policies
generated using deep reinforcement learning, and empirical game-theoretic
analysis to compute meta-strategies for policy selection. The algorithm
generalizes previous ones such as InRL, iterated best response, double oracle,
and fictitious play. Then, we present a scalable implementation which reduces
the memory requirement using decoupled meta-solvers. Finally, we demonstrate
the generality of the resulting policies in two partially observable settings:
gridworld coordination games and poker.
</dc:description>
 <dc:description>Comment: Camera-ready copy of NIPS 2017 paper, including appendix</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00832</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00837</identifier>
 <datestamp>2017-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Oversampling for Imbalanced Learning Based on K-Means and SMOTE</dc:title>
 <dc:creator>Last, Felix</dc:creator>
 <dc:creator>Douzas, Georgios</dc:creator>
 <dc:creator>Bacao, Fernando</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Learning from class-imbalanced data continues to be a common and challenging
problem in supervised learning as standard classification algorithms are
designed to handle balanced class distributions. While different strategies
exist to tackle this problem, methods which generate artificial data to achieve
a balanced class distribution are more versatile than modifications to the
classification algorithm. Such techniques, called oversamplers, modify the
training data, allowing any classifier to be used with class-imbalanced
datasets. Many algorithms have been proposed for this task, but most are
complex and tend to generate unnecessary noise. This work presents a simple and
effective oversampling method based on k-means clustering and SMOTE
oversampling, which avoids the generation of noise and effectively overcomes
imbalances between and within classes. Empirical results of extensive
experiments with 71 datasets show that training data oversampled with the
proposed method improves classification results. Moreover, k-means SMOTE
consistently outperforms other popular oversampling methods. An implementation
is made available in the python programming language.
</dc:description>
 <dc:description>Comment: 19 pages, 8 figures</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:date>2017-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00837</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00838</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Systems Approach for Eliciting Mission-Centric Security Requirements</dc:title>
 <dc:creator>Carter, Bryan</dc:creator>
 <dc:creator>Bakirtzis, Georgios</dc:creator>
 <dc:creator>Elks, Carl</dc:creator>
 <dc:creator>Fleming, Cody</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The security of cyber-physical systems is first and foremost a safety
problem, yet it is typically handled as a traditional security problem, which
means that solutions are based on defending against threats and are often
implemented too late. This approach neglects to take into consideration the
context in which the system is intended to operate, thus system safety may be
compromised. This paper presents a systems-theoretic analysis approach that
combines stakeholder perspectives with a modified version of Systems-Theoretic
Accident Model and Process (STAMP) that allows decision-makers to strategically
enhance the safety, resilience, and security of a cyber-physical system against
potential threats. This methodology allows the capture of vital
mission-specific information in a model, which then allows analysts to identify
and mitigate vulnerabilities in the locations most critical to mission success.
We present an overview of the general approach followed by a real example using
an unmanned aerial vehicle conducting a reconnaissance mission.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00838</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00843</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Probabilistic Bisection for Stochastic Root-Finding</dc:title>
 <dc:creator>Rodriguez, Sergio</dc:creator>
 <dc:creator>Ludkovski, Michael</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider numerical schemes for root finding of noisy responses through
generalizing the Probabilistic Bisection Algorithm (PBA) to the more practical
context where the sampling distribution is unknown and location-dependent. As
in standard PBA, we rely on a knowledge state for the approximate posterior of
the root location. To implement the corresponding Bayesian updating, we also
carry out inference of oracle accuracy, namely learning the probability of
correct response. To this end we utilize batched querying in combination with a
variety of frequentist and Bayesian estimators based on majority vote, as well
as the underlying functional responses, if available. For guiding sampling
selection we investigate both Information Directed sampling, as well as
Quantile sampling. Our numerical experiments show that these strategies perform
quite differently; in particular we demonstrate the efficiency of randomized
quantile sampling which is reminiscent of Thompson sampling. Our work is
motivated by the root-finding sub-routine in pricing of Bermudan financial
derivatives, illustrated in the last section of the paper.
</dc:description>
 <dc:description>Comment: 27 pages</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00843</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00848</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variational Inference of Disentangled Latent Concepts from Unlabeled
  Observations</dc:title>
 <dc:creator>Kumar, Abhishek</dc:creator>
 <dc:creator>Sattigeri, Prasanna</dc:creator>
 <dc:creator>Balakrishnan, Avinash</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Disentangled representations, where the higher level data generative factors
are reflected in disjoint latent dimensions, offer several benefits such as
ease of deriving invariant representations, transferability to other tasks,
interpretability, etc. We consider the problem of unsupervised learning of
disentangled representations from large pool of unlabeled observations, and
propose a variational inference based approach to infer disentangled latent
factors. We introduce a regularizer on the expectation of the approximate
posterior over observed data that encourages the disentanglement. We evaluate
the proposed approach using several quantitative metrics and empirically
observe significant gains over existing methods in terms of both
disentanglement and data likelihood (reconstruction quality).
</dc:description>
 <dc:description>Comment: added more related work</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00848</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00851</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Provable defenses against adversarial examples via the convex outer
  adversarial polytope</dc:title>
 <dc:creator>Kolter, J. Zico</dc:creator>
 <dc:creator>Wong, Eric</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We propose a method to learn deep ReLU-based classifiers that are provably
robust against norm-bounded adversarial perturbations (on the training data;
for previously unseen examples, the approach will be guaranteed to detect all
adversarial examples, though it may flag some non-adversarial examples as
well). The basic idea of the approach is to consider a convex outer
approximation of the set of activations reachable through a norm-bounded
perturbation, and we develop a robust optimization procedure that minimizes the
worst case loss over this outer region (via a linear program). Crucially, we
show that the dual problem to this linear program can be represented itself as
a deep network similar to the backpropagation network, leading to very
efficient optimization approaches that produce guaranteed bounds on the robust
loss. The end result is that by executing a few more forward and backward
passes through a slightly modified version of the original network (though
possibly with much larger batch sizes), we can learn a classifier that is
provably robust to any norm-bounded adversarial attack. We illustrate the
approach on a toy 2D robust classification task, and on a simple convolutional
architecture applied to MNIST, where we produce a classifier that provably has
less than 8.4% test error for any adversarial attack with bounded $\ell_\infty$
norm less than $\epsilon = 0.1$. This represents the largest verified network
that we are aware of, and we discuss future challenges in scaling the approach
to much larger domains.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00851</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00853</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Bernstein-Vazirani Algorithm to Attack Block Ciphers</dc:title>
 <dc:creator>Xie, Huiqin</dc:creator>
 <dc:creator>Yang, Li</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this paper, we study applications of Bernstein-Vazirani algorithm and
present several new methods to attack block ciphers. Specifically, we first
present a quantum algorithm for finding the linear structures of a function.
Based on it, we propose new quantum distinguishers for the 3-round Feistel
scheme and a new quantum algorithm to recover partial key of the Even-Mansour
construction. Afterwards, by observing that the linear structures of a
encryption function are actually high probability differentials of it, we apply
our algorithm to differential analysis and impossible differential
cryptanalysis respectively. We also propose a new kind of differential
cryptanalysis, called quantum small probability differential cryptanalysis,
based on the fact that the linear structures found by our algorithm are also
the linear structure of each component function. To our knowledge, no similar
method was proposed before. The efficiency and success probability of all
attacks are analyzed rigorously. Since our algorithm treats the encryption
function as a whole, it avoid the disadvantage of traditional differential
cryptanalysis that it is difficult to extending the differential path.
</dc:description>
 <dc:description>Comment: 28 pages, 1 figures</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00853</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00867</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The (Un)reliability of saliency methods</dc:title>
 <dc:creator>Kindermans, Pieter-Jan</dc:creator>
 <dc:creator>Hooker, Sara</dc:creator>
 <dc:creator>Adebayo, Julius</dc:creator>
 <dc:creator>Alber, Maximilian</dc:creator>
 <dc:creator>Sch&#xfc;tt, Kristof T.</dc:creator>
 <dc:creator>D&#xe4;hne, Sven</dc:creator>
 <dc:creator>Erhan, Dumitru</dc:creator>
 <dc:creator>Kim, Been</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Saliency methods aim to explain the predictions of deep neural networks.
These methods lack reliability when the explanation is sensitive to factors
that do not contribute to the model prediction. We use a simple and common
pre-processing step ---adding a constant shift to the input data--- to show
that a transformation with no effect on the model can cause numerous methods to
incorrectly attribute. In order to guarantee reliability, we posit that methods
should fulfill input invariance, the requirement that a saliency method mirror
the sensitivity of the model with respect to transformations of the input. We
show, through several examples, that saliency methods that do not satisfy input
invariance result in misleading attribution.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00867</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00878</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Polymorphic Sessions and Functions: A Tale of Two (Fully Abstract)
  Encodings</dc:title>
 <dc:creator>Toninho, Bernardo</dc:creator>
 <dc:creator>Yoshida, Nobuko</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  This work exploits the logical foundation of session types to determine what
kind of type discipline for the pi-calculus can exactly capture, and is
captured by, lambda-calculus behaviours. Leveraging the proof theoretic content
of the soundness and completeness of sequent calculus and natural deduction
presentations of linear logic, we develop the first mutually inverse and fully
abstract processes-as-functions and functions-as-processes encodings between a
polymorphic session pi-calculus and a linear formulation of System F. We are
then able to derive results of the session calculus from the theory of the
lambda-calculus: (1) we obtain a characterisation of inductive and coinductive
session types via their algebraic representations in System F; and (2) we
extend our results to account for value and process passing, entailing strong
normalisation.
</dc:description>
 <dc:description>Comment: Extended version of ESOP'18 paper (includes appendix with proofs and
  additional definitions)</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00878</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00881</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Steady State of Continuous Time Stochastic Opinion Dynamics</dc:title>
 <dc:creator>Woo, Jae Oh</dc:creator>
 <dc:creator>Baccelli, Fran&#xe7;ois</dc:creator>
 <dc:creator>Vishwanath, Sriram</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The present paper proposes a computational framework for continuous time
opinion dynamics with additive noise. We derive a non-local partial
differential equation for the distribution of opinions differences. We use
Mellin transforms to solve the stationary solution of this equation in closed
form. This approach can be applied both to linear dynamics on an interaction
graph and to bounded confidence dynamics in the Euclidean space. It leads to
several new qualitative results proper to continuous time bounded confidence
dynamics. To the best of our knowledge, the closed form expression on the
stationary distribution of the bounded confidence model is the first
quantitative result on the equilibria of this class of models. The solutions
are presented here in the simplest possible cases.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00881</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00885</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Deep Learning to Examine the Association between the Built
  Environment and Neighborhood Adult Obesity Prevalence</dc:title>
 <dc:creator>Maharana, Adyasha</dc:creator>
 <dc:creator>Nsoesie, Elaine O.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  More than one-third of the adult population in the United States is obese.
Obesity has been linked to factors such as, genetics, diet, physical activity
and the environment. However, evidence indicating associations between the
built environment and obesity has varied across studies and geographical
contexts. Here, we used deep learning and approximately 150,000 high resolution
satellite images to extract features of the built environment. We then
developed linear regression models to consistently quantify the association
between the extracted features and obesity prevalence at the census tract level
for six cities in the United States. The extracted features of the built
environment explained 72% to 90% of the variation in obesity prevalence across
cities. Outof-sample predictions were considerably high with correlations
greater than 80% between predicted and true obesity prevalence across all
census tracts. This study supports a strong association between the built
environment and obesity prevalence. Additionally, it also illustrates that
features of the built environment extracted from satellite images can be useful
for studying health indicators, such as obesity. Understanding the association
between specific features of the built environment and obesity prevalence can
lead to structural changes that could encourage physical activity and decreases
in obesity prevalence.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00885</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00888</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Set-to-Set Hashing with Applications in Visual Recognition</dc:title>
 <dc:creator>Jhuo, I-Hong</dc:creator>
 <dc:creator>Wang, Jun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Visual data, such as an image or a sequence of video frames, is often
naturally represented as a point set. In this paper, we consider the
fundamental problem of finding a nearest set from a collection of sets, to a
query set. This problem has obvious applications in large-scale visual
retrieval and recognition, and also in applied fields beyond computer vision.
One challenge stands out in solving the problem---set representation and
measure of similarity. Particularly, the query set and the sets in dataset
collection can have varying cardinalities. The training collection is large
enough such that linear scan is impractical. We propose a simple representation
scheme that encodes both statistical and structural information of the sets.
The derived representations are integrated in a kernel framework for flexible
similarity measurement. For the query set process, we adopt a learning-to-hash
pipeline that turns the kernel representations into hash bits based on simple
learners, using multiple kernel learning. Experiments on two visual retrieval
datasets show unambiguously that our set-to-set hashing framework outperforms
prior methods that do not take the set-to-set search setting.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00888</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00889</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structured Generative Adversarial Networks</dc:title>
 <dc:creator>Deng, Zhijie</dc:creator>
 <dc:creator>Zhang, Hao</dc:creator>
 <dc:creator>Liang, Xiaodan</dc:creator>
 <dc:creator>Yang, Luona</dc:creator>
 <dc:creator>Xu, Shizhen</dc:creator>
 <dc:creator>Zhu, Jun</dc:creator>
 <dc:creator>Xing, Eric P.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We study the problem of conditional generative modeling based on designated
semantics or structures. Existing models that build conditional generators
either require massive labeled instances as supervision or are unable to
accurately control the semantics of generated samples. We propose structured
generative adversarial networks (SGANs) for semi-supervised conditional
generative modeling. SGAN assumes the data x is generated conditioned on two
independent latent variables: y that encodes the designated semantics, and z
that contains other factors of variation. To ensure disentangled semantics in y
and z, SGAN builds two collaborative games in the hidden space to minimize the
reconstruction error of y and z, respectively. Training SGAN also involves
solving two adversarial games that have their equilibrium concentrating at the
true joint data distributions p(x, z) and p(x, y), avoiding distributing the
probability mass diffusely over data space that MLE-based methods may suffer.
We assess SGAN by evaluating its trained networks, and its performance on
downstream tasks. We show that SGAN delivers a highly controllable generator,
and disentangled representations; it also establishes start-of-the-art results
across multiple datasets when applied for semi-supervised image classification
(1.27%, 5.73%, 17.26% error rates on MNIST, SVHN and CIFAR-10 using 50, 1000
and 4000 labels, respectively). Benefiting from the separate modeling of y and
z, SGAN can generate images with high visual quality and strictly following the
designated semantic, and can be extended to a wide spectrum of applications,
such as style transfer.
</dc:description>
 <dc:description>Comment: To appear in NIPS 2017</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00889</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00894</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Mention Learning for Reading Comprehension with Neural Cascades</dc:title>
 <dc:creator>Swayamdipta, Swabha</dc:creator>
 <dc:creator>Parikh, Ankur P.</dc:creator>
 <dc:creator>Kwiatkowski, Tom</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Reading comprehension is a challenging task, especially when executed across
longer or across multiple evidence documents, where the answer is likely to
reoccur. Existing neural architectures typically do not scale to the entire
evidence, and hence, resort to selecting a single passage in the document
(either via truncation or other means), and carefully searching for the answer
within that passage. However, in some cases, this strategy can be suboptimal,
since by focusing on a specific passage, it becomes difficult to leverage
multiple mentions of the same answer throughout the document. In this work, we
take a different approach by constructing lightweight models that are combined
in a cascade to find the answer. Each submodel consists only of feed-forward
networks equipped with an attention mechanism, making it trivially
parallelizable. We show that our approach can scale to approximately an order
of magnitude larger evidence documents and can aggregate information from
multiple mentions of each answer candidate across the document. Empirically,
our approach achieves state-of-the-art performance on both the Wikipedia and
web domains of the TriviaQA dataset, outperforming more complex, recurrent
architectures.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00894</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00903</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Acceleration of tensor-product operations for high-order finite element
  methods</dc:title>
 <dc:creator>&#x15a;wirydowicz, Kasia</dc:creator>
 <dc:creator>Chalmers, Noel</dc:creator>
 <dc:creator>Karakus, Ali</dc:creator>
 <dc:creator>Warburton, Timothy</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  This paper is devoted to GPU kernel optimization and performance analysis of
three tensor-product operators arising in finite element methods. We provide a
mathematical background to these operations and implementation details.
Achieving close-to-the-peak performance for these operators requires extensive
optimization because of the operators' properties: low arithmetic intensity,
tiered structure, and the need to store intermediate results inside the kernel.
We give a guided overview of optimization strategies and we present a
performance model that allows us to compare the efficacy of these optimizations
against an empirically calibrated roofline.
</dc:description>
 <dc:description>Comment: 31 pages, 11 figures</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00903</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00905</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse-View X-Ray CT Reconstruction Using $\ell_1$ Prior with Learned
  Transform</dc:title>
 <dc:creator>Zheng, Xuehang</dc:creator>
 <dc:creator>Chun, Il Yong</dc:creator>
 <dc:creator>Li, Zhipeng</dc:creator>
 <dc:creator>Long, Yong</dc:creator>
 <dc:creator>Fessler, Jeffrey A.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:description>  A major challenge in X-ray computed tomography (CT) is reducing radiation
dose while maintaining high quality of reconstructed images. To reduce the
radiation dose, one can reduce the number of projection views (sparse-view CT);
however, it becomes difficult to achieve high quality image reconstruction as
the number of projection views decreases. Researchers have applied the concept
of learning sparse representations from (high-quality) CT image dataset to the
sparse-view CT reconstruction. We propose a new statistical CT reconstruction
model that combines penalized weighted-least squares (PWLS) and $\ell_1$
regularization with learned sparsifying transform (PWLS-ST-$\ell_1$), and an
algorithm for PWLS-ST-$\ell_1$. Numerical experiments for sparse-view 2D
fan-beam CT and 3D axial cone-beam CT show that the $\ell_1$ regularizer
significantly improves the sharpness of edges of reconstructed images compared
to the CT reconstruction methods using edge-preserving regularizer and $\ell_2$
regularization with learned ST.
</dc:description>
 <dc:description>Comment: The first two authors contributed equally to this work; 8 pages, 5
  figures</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00905</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00909</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weight-Based Variable Ordering in the Context of High-Level
  Consistencies</dc:title>
 <dc:creator>Woodward, Robert J.</dc:creator>
 <dc:creator>Choueiry, Berthe Y.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Dom/wdeg is one of the best performing heuristics for dynamic variable
ordering in backtrack search [Boussemart et al., 2004]. As originally defined,
this heuristic increments the weight of the constraint that causes a domain
wipeout (i.e., a dead-end) when enforcing arc consistency during search. &quot;The
process of weighting constraints with dom/wdeg is not defined when more than
one constraint lead to a domain wipeout [Vion et al., 2011].&quot; In this paper, we
investigate how weights should be updated in the context of two high-level
consistencies, namely, singleton (POAC) and relational consistencies (RNIC). We
propose, analyze, and empirically evaluate several strategies for updating the
weights. We statistically compare the proposed strategies and conclude with our
recommendations.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00909</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00913</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Does Phase Matter For Monaural Source Separation?</dc:title>
 <dc:creator>Dubey, Mohit</dc:creator>
 <dc:creator>Kenyon, Garrett</dc:creator>
 <dc:creator>Carlson, Nils</dc:creator>
 <dc:creator>Thresher, Austin</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  The &quot;cocktail party&quot; problem of fully separating multiple sources from a
single channel audio waveform remains unsolved. Current biological
understanding of neural encoding suggests that phase information is preserved
and utilized at every stage of the auditory pathway. However, current
computational approaches primarily discard phase information in order to mask
amplitude spectrograms of sound. In this paper, we seek to address whether
preserving phase information in spectral representations of sound provides
better results in monaural separation of vocals from a musical track by using a
neurally plausible sparse generative model. Our results demonstrate that
preserving phase information reduces artifacts in the separated tracks, as
quantified by the signal to artifact ratio (GSAR). Furthermore, our proposed
method achieves state-of-the-art performance for source separation, as
quantified by a mean signal to interference ratio (GSIR) of 19.46.
</dc:description>
 <dc:description>Comment: 4 pages, 2 figures, NIPS format</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00913</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00927</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Audio Set classification with attention model: A probabilistic
  perspective</dc:title>
 <dc:creator>Kong, Qiuqiang</dc:creator>
 <dc:creator>Xu, Yong</dc:creator>
 <dc:creator>Wang, Wenwu</dc:creator>
 <dc:creator>Plumbley, Mark D.</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  This paper investigate the classification of the Audio Set dataset. Audio Set
is a large scale multi instance learning (MIL) dataset of sound clips. In MIL,
a bag consists of several instances, and a bag is labelled positive if one or
more instances in the audio clip is positive. Audio Set is a MIL dataset
because an audio clip is labelled positive for a class if at least one frame
contains the corresponding class. We tackle this MIL problem using an attention
model and explain this attention model from a novel probabilistic perspective.
We define a probability space on each bag. Each instance in a bag has a
trainable probability measure for a class. Then the classification of a bag is
the expectation of the classification of the instances in the bag with respect
to the learned probability measure. Experimental results show that our proposed
attention model modeled by fully connected deep neural network obtains mAP of
0.327 on Audio Set dataset, outperforming the Google's baseline of 0.314 and
recurrent neural network of 0.325.
</dc:description>
 <dc:description>Comment: Submitted to ICASSP 2018</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00927</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00931</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Denotational Semantics for SPARC TSO</dc:title>
 <dc:creator>Kavanagh, Ryan</dc:creator>
 <dc:creator>Brookes, Stephen</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  The SPARC TSO weak memory model is defined axiomatically, with a
non-compositional formulation that makes modular reasoning about programs
difficult. Our denotational approach uses pomsets to provide a compositional
semantics capturing exactly the behaviours permitted by SPARC TSO. It uses
buffered states and an inductive definition of execution to assign an
input-output meaning to pomsets. We show that our denotational account is sound
and complete relative to the axiomatic account, that is, that it captures
exactly the behaviours permitted by the axiomatic account. Our compositional
approach facilitates the study of SPARC TSO and supports modular analysis of
program behaviour.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00931</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00937</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Discrete Representation Learning</dc:title>
 <dc:creator>Oord, Aaron van den</dc:creator>
 <dc:creator>Vinyals, Oriol</dc:creator>
 <dc:creator>Kavukcuoglu, Koray</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Learning useful representations without supervision remains a key challenge
in machine learning. In this paper, we propose a simple yet powerful generative
model that learns such discrete representations. Our model, the Vector
Quantised-Variational AutoEncoder (VQ-VAE), differs from VAEs in two key ways:
the encoder network outputs discrete, rather than continuous, codes; and the
prior is learnt rather than static. In order to learn a discrete latent
representation, we incorporate ideas from vector quantisation (VQ). Using the
VQ method allows the model to circumvent issues of &quot;posterior collapse&quot; --
where the latents are ignored when they are paired with a powerful
autoregressive decoder -- typically observed in the VAE framework. Pairing
these representations with an autoregressive prior, the model can generate high
quality images, videos, and speech as well as doing high quality speaker
conversion and unsupervised learning of phonemes, providing further evidence of
the utility of the learnt representations.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00937</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00938</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comparison of Feature-Based and Neural Scansion of Poetry</dc:title>
 <dc:creator>Agirrezabal, Manex</dc:creator>
 <dc:creator>Alegria, I&#xf1;aki</dc:creator>
 <dc:creator>Hulden, Mans</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Automatic analysis of poetic rhythm is a challenging task that involves
linguistics, literature, and computer science. When the language to be analyzed
is known, rule-based systems or data-driven methods can be used. In this paper,
we analyze poetic rhythm in English and Spanish. We show that the
representations of data learned from character-based neural models are more
informative than the ones from hand-crafted features, and that a
Bi-LSTM+CRF-model produces state-of-the art accuracy on scansion of poetry in
two languages. Results also show that the information about whole word
structure, and not just independent syllables, is highly informative for
performing scansion.
</dc:description>
 <dc:description>Comment: RANLP 2017</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00938</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00939</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Air Learning: Interpolation, Prediction, and Feature Analysis of
  Fine-grained Air Quality</dc:title>
 <dc:creator>Qi, Zhongang</dc:creator>
 <dc:creator>Wang, Tianchun</dc:creator>
 <dc:creator>Song, Guojie</dc:creator>
 <dc:creator>Hu, Weisong</dc:creator>
 <dc:creator>Li, Xi</dc:creator>
 <dc:creator>Zhongfei</dc:creator>
 <dc:creator>Zhang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The interpolation, prediction, and feature analysis of fine-gained air
quality are three important topics in the area of urban air computing. The
solutions to these topics can provide extremely useful information to support
air pollution control, and consequently generate great societal and technical
impacts. Most of the existing work solves the three problems separately by
different models. In this paper, we propose a general and effective approach to
solve the three problems in one model called the Deep Air Learning (DAL). The
main idea of DAL lies in embedding feature selection and semi-supervised
learning in different layers of the deep learning network. The proposed
approach utilizes the information pertaining to the unlabeled spatio-temporal
data to improve the performance of the interpolation and the prediction, and
performs feature selection and association analysis to reveal the main relevant
features to the variation of the air quality. We evaluate our approach with
extensive experiments based on real data sources obtained in Beijing, China.
Experiments show that DAL is superior to the peer models from the recent
literature when solving the topics of interpolation, prediction and feature
analysis of fine-gained air quality.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Knowledge and Data Engineering
  (TKDE), Major Revision</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00939</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00940</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monotone bargaining is Nash-solvable</dc:title>
 <dc:creator>Gurvich, Vladimir</dc:creator>
 <dc:creator>Koshevoy, Gleb</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Given two finite ordered sets $A = \{a_1, \ldots, a_m\}$ and $B = \{b_1,
\ldots, b_n\}$, introduce the set of $m n$ outcomes of the game $O = \{(a, b)
\mid a \in A, b \in B\} = \{(a_i, b_j) \mid i \in I = \{1, \ldots, m\}, j \in J
= \{1, \ldots, n\}$. Two players, Alice and Bob, have the sets of strategies
$X$ and $Y$ that consist of all monotone non-decreasing mappings $x: A
\rightarrow B$ and $y: B \rightarrow A$, respectively. It is easily seen that
each pair $(x,y) \in X \times Y$ produces at least one {\em deal}, that is, an
outcome $(a,b) \in O$ such that $x(a) = b$ and $y(b) = a$. Denote by $G(x,y)
\subseteq O$ the set of all such deals related to $(x,y)$. The obtained mapping
$G = G_{m,n}: X \times Y \rightarrow 2^O$ is a game correspondence. Choose an
arbitrary deal $g(x,y) \in G(x,y)$ to obtained a mapping $g : X \times Y
\rightarrow O$, which is a game form. We will show that each such game form is
tight and, hence, Nash-solvable, that is, for any pair $u = (u_A, u_B)$ of
utility functions $u_A : O \rightarrow \mathbb R$ of Alice and $u_B: O
\rightarrow \mathbb R$ of Bob, the obtained monotone bargaining game $(g, u)$
has at least one Nash equilibrium in pure strategies. Moreover, the same
equilibrium can be chosen for all selections $g(x,y) \in G(x,y)$. We also
obtain an efficient algorithm that determines such an equilibrium in time
linear in $m n$, although the numbers of strategies $|X| = \binom{m+n-1}{m}$
and $|Y| = \binom{m+n-1}{n}$ are exponential in $m n$. Our results show that,
somewhat surprising, the players have no need to hide or randomize their
bargaining strategies, even in the zero-sum case.
</dc:description>
 <dc:description>Comment: In this version we extend significantly Section 4. We add more
  classes of dual hypergraphs and show that for some of these classes the proof
  of the main theorem becomes much simpler than in general</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:date>2017-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00940</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00941</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Active Learning over the Long Tail</dc:title>
 <dc:creator>Geifman, Yonatan</dc:creator>
 <dc:creator>El-Yaniv, Ran</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper is concerned with pool-based active learning for deep neural
networks. Motivated by coreset dataset compression ideas, we present a novel
active learning algorithm that queries consecutive points from the pool using
farthest-first traversals in the space of neural activation over a
representation layer. We show consistent and overwhelming improvement in sample
complexity over passive learning (random sampling) for three datasets: MNIST,
CIFAR-10, and CIFAR-100. In addition, our algorithm outperforms the traditional
uncertainty sampling technique (obtained using softmax activations), and we
identify cases where uncertainty sampling is only slightly better than random
sampling.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00941</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00946</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Linear Dynamical Systems via Spectral Filtering</dc:title>
 <dc:creator>Hazan, Elad</dc:creator>
 <dc:creator>Singh, Karan</dc:creator>
 <dc:creator>Zhang, Cyril</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present an efficient and practical algorithm for the online prediction of
discrete-time linear dynamical systems with a symmetric transition matrix. We
circumvent the non-convex optimization problem using improper learning:
carefully overparameterize the class of LDSs by a polylogarithmic factor, in
exchange for convexity of the loss functions. From this arises a
polynomial-time algorithm with a near-optimal regret guarantee, with an
analogous sample complexity bound for agnostic learning. Our algorithm is based
on a novel filtering technique, which may be of independent interest: we
convolve the time series with the eigenvectors of a certain Hankel matrix.
</dc:description>
 <dc:description>Comment: Published as a conference paper at NIPS 2017</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00946</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00950</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond normality: Learning sparse probabilistic graphical models in the
  non-Gaussian setting</dc:title>
 <dc:creator>Morrison, Rebecca E.</dc:creator>
 <dc:creator>Baptista, Ricardo</dc:creator>
 <dc:creator>Marzouk, Youssef</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present an algorithm to identify sparse dependence structure in continuous
and non-Gaussian probability distributions, given a corresponding set of data.
The conditional independence structure of an arbitrary distribution can be
represented as an undirected graph (or Markov random field), but most
algorithms for learning this structure are restricted to the discrete or
Gaussian cases. Our new approach allows for more realistic and accurate
descriptions of the distribution in question, and in turn better estimates of
its sparse Markov structure. Sparsity in the graph is of interest as it can
accelerate inference, improve sampling methods, and reveal important
dependencies between variables. The algorithm relies on exploiting the
connection between the sparsity of the graph and the sparsity of transport
maps, which deterministically couple one probability measure to another.
</dc:description>
 <dc:description>Comment: Accepted in NIPS 2017</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00950</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00953</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Query Image Disambiguation for Content-Based Image Retrieval</dc:title>
 <dc:creator>Barz, Bj&#xf6;rn</dc:creator>
 <dc:creator>Denzler, Joachim</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Query images presented to content-based image retrieval systems often have
various different interpretations, making it difficult to identify the search
objective pursued by the user. We propose a technique for overcoming this
ambiguity, while keeping the amount of required user interaction at a minimum.
To achieve this, the neighborhood of the query image is divided into coherent
clusters from which the user may choose the relevant ones. A novel feedback
integration technique is then employed to re-rank the entire database with
regard to both the user feedback and the original query. We evaluate our
approach on the publicly available MIRFLICKR-25K dataset, where it leads to a
relative improvement of average precision by 23% over the baseline retrieval,
which does not distinguish between different image senses.
</dc:description>
 <dc:description>Comment: VISAPP 2018 paper, 8 pages, 5 figures. Source code:
  https://github.com/cvjena/aid</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00953</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00956</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Running Time Analysis of the (1+1)-EA for OneMax and LeadingOnes under
  Bit-wise Noise</dc:title>
 <dc:creator>Qian, Chao</dc:creator>
 <dc:creator>Bian, Chao</dc:creator>
 <dc:creator>Jiang, Wu</dc:creator>
 <dc:creator>Tang, Ke</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In many real-world optimization problems, the objective function evaluation
is subject to noise, and we cannot obtain the exact objective value.
Evolutionary algorithms (EAs), a type of general-purpose randomized
optimization algorithm, have shown able to solve noisy optimization problems
well. However, previous theoretical analyses of EAs mainly focused on
noise-free optimization, which makes the theoretical understanding largely
insufficient. Meanwhile, the few existing theoretical studies under noise often
considered the one-bit noise model, which flips a randomly chosen bit of a
solution before evaluation; while in many realistic applications, several bits
of a solution can be changed simultaneously. In this paper, we study a natural
extension of one-bit noise, the bit-wise noise model, which independently flips
each bit of a solution with some probability. We analyze the running time of
the (1+1)-EA solving OneMax and LeadingOnes under bit-wise noise for the first
time, and derive the ranges of the noise level for polynomial and
super-polynomial running time bounds. The analysis on LeadingOnes under
bit-wise noise can be easily transferred to one-bit noise, and improves the
previously known results. Since our analysis discloses that the (1+1)-EA can be
efficient only under low noise levels, we also study whether the sampling
strategy can bring robustness to noise. We prove that using sampling can
significantly increase the largest noise level allowing a polynomial running
time, that is, sampling is robust to noise.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00956</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00959</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transition from Plan Driven to SAFe : Periodic Team Self-Assessment</dc:title>
 <dc:creator>Razzak, Mohammad Abdur</dc:creator>
 <dc:creator>Noll, John</dc:creator>
 <dc:creator>Richardson, Ita</dc:creator>
 <dc:creator>Canna, Clodagh Nic</dc:creator>
 <dc:creator>Beecham, Sarah</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Context: How to adopt, scale and tailor agile methods depends on several
factors such as the size of the organization, business goals, operative model,
and needs. The Scaled Agile Framework (SAFe) was developed to support
organizations to scale agile practices across the enterprise. Problem: Early
adopters of SAFe tend to be large multi-national enterprises who report that
the adoption of SAFe has led to significant productivity and quality gains.
However, little is known about whether these benefits translate to small to
medium sized enterprises (SMEs). Method: As part of a longitudinal study of an
SME transitioning to SAFe we ask, to what extent are SAFe practices adopted at
the team level? We targeted all team members and administrated a mixed method
survey in February, 2017 and in July, 2017 to identify and evaluate the
adoption rate of SAFe practices. Results: Initially in Quarter 1, teams were
struggling with PI/Release health and Technical health throughout the
organization as most of the teams were transitioning from plan-driven to SAFe .
But, during the transition period in Quarter 3, we observed discernible
improvements in different areas of SAFe practice adoption. Conclusion: The
observed improvement might be due to teams merely becoming more familiar with
the practices over-time. However, management had also made some structural
changes to the teams that may account for the change.
</dc:description>
 <dc:description>Comment: 10, QuASD, Profes 2017</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00959</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00962</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-Delay Efficient Power Control in Wireless Networks</dc:title>
 <dc:creator>Zappone, Alessio</dc:creator>
 <dc:creator>Sanguinetti, Luca</dc:creator>
 <dc:creator>Debbah, Merouane</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This work aims at developing a power control framework to jointly optimize
energy efficiency (measured in bit/Joule) and delay in wireless networks. A
multi-objective approach is taken to deal with both performance metrics, while
ensuring a minimum quality-of-service to each user in the network. Each user in
the network is modeled as a rational agent that engages in a generalized
non-cooperative game. Feasibility conditions are derived for the existence of
each player's best response, and used to show that if these conditions are met,
the game best response dynamics will converge to a unique Nash equilibrium.
Based on these results, a convergent power control algorithm is derived, which
can be implemented in a fully decentralized fashion. Next, a centralized power
control algorithm is proposed, which also serves as a benchmark for the
proposed decentralized solution. Due to the non-convexity of the centralized
problem, the tool of maximum block improvement is used, to trade-off complexity
with optimality.
</dc:description>
 <dc:description>Comment: 13 pages, 6 figures, to appear on IEEE Transactions on Communications</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00962</dc:identifier>
 <dc:identifier>doi:10.1109/TCOMM.2017.2755644</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00963</identifier>
 <datestamp>2017-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Computational Complexity of Finding Separators in Temporal Graphs</dc:title>
 <dc:creator>Zschoche, Philipp</dc:creator>
 <dc:creator>Fluschnik, Till</dc:creator>
 <dc:creator>Molter, Hendrik</dc:creator>
 <dc:creator>Niedermeier, Rolf</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Vertex separators, that is, vertex sets whose deletion disconnects two
distinguished vertices in a graph, play a pivotal role in algorithmic graph
theory. For instance, the concept of tree decompositions of graphs is tightly
connected to the separator concept. For many realistic models of the real
world, however, it is necessary to consider graphs whose edge set changes with
time. More specifically, the edges are labeled with time stamps. In the
literature, these graphs are referred to as temporal graphs, temporal networks,
time-varying networks, edge-scheduled networks, etc. While there is an
extensive literature on separators in &quot;static&quot; graphs, much less is known for
the temporal setting. Building on previous work (e.g., Kempe et al. [STOC
'00]), for the first time we systematically investigate the (parameterized)
complexity of finding separators in temporal graphs. Doing so, we discover a
rich landscape of computationally (fixed-parameter) tractable and intractable
cases. In particular, we shed light on the so far seemingly overlooked fact
that two frequently used models of temporal separation may lead to quite
significant differences in terms of computational complexity. More
specifically, considering paths in temporal graphs one may distinguish between
strict paths (the time stamps along a path are strictly increasing) and
non-strict paths (the time stamps along a path are monotonically
non-decreasing). We observe that the corresponding strict case of temporal
separators leads to several computationally much easier to handle cases than
the non-strict case does.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:date>2017-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00963</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00967</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Influence Networks for Rule-based Models</dc:title>
 <dc:creator>Forbes, Angus G.</dc:creator>
 <dc:creator>Burks, Andrew</dc:creator>
 <dc:creator>Lee, Kristine</dc:creator>
 <dc:creator>Li, Xing</dc:creator>
 <dc:creator>Boutillier, Pierre</dc:creator>
 <dc:creator>Krivine, Jean</dc:creator>
 <dc:creator>Fontana, Walter</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Quantitative Biology - Molecular Networks</dc:subject>
 <dc:description>  We introduce the Dynamic Influence Network (DIN), a novel visual analytics
technique for representing and analyzing rule-based models of protein-protein
interaction networks. Rule-based modeling has proved instrumental in developing
biological models that are concise, comprehensible, easily extensible, and that
mitigate the combinatorial complexity of multi-state and multi-component
biological molecules. Our technique visualizes the dynamics of these rules as
they evolve over time. Using the data produced by KaSim, an open source
stochastic simulator of rule-based models written in the Kappa language, DINs
provide a node-link diagram that represents the influence that each rule has on
the other rules. That is, rather than representing individual biological
components or types, we instead represent the rules about them (as nodes) and
the current influence of these rules (as links). Using our interactive DIN-Viz
software tool, researchers are able to query this dynamic network to find
meaningful patterns about biological processes, and to identify salient aspects
of complex rule-based models. To evaluate the effectiveness of our approach, we
investigate a simulation of a circadian clock model that illustrates the
oscillatory behavior of the KaiC protein phosphorylation cycle.
</dc:description>
 <dc:description>Comment: Accepted to TVCG, in press</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00967</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00968</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Reinforcement Learning for Resource Allocation in V2V
  Communications</dc:title>
 <dc:creator>Ye, Hao</dc:creator>
 <dc:creator>Li, Geoffrey Ye</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this article, we develop a decentralized resource allocation mechanism for
vehicle-to-vehicle (V2V) communication systems based on deep reinforcement
learning. Each V2V link is considered as an agent, making its own decisions to
find optimal sub-band and power level for transmission. Since the proposed
method is decentralized, the global information is not required for each agent
to make its decisions, hence the transmission overhead is small. From the
simulation results, each agent can learn how to satisfy the V2V constraints
while minimizing the interference to vehicle-to-infrastructure (V2I)
communications.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00968</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00970</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Classification-Based Perspective on GAN Distributions</dc:title>
 <dc:creator>Santurkar, Shibani</dc:creator>
 <dc:creator>Schmidt, Ludwig</dc:creator>
 <dc:creator>M&#x105;dry, Aleksander</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A fundamental, and still largely unanswered, question in the context of
Generative Adversarial Networks (GANs) is whether GANs are actually able to
capture the key characteristics of the datasets they are trained on. The
current approaches to examining this issue require significant human
supervision, such as visual inspection of sampled images, and often offer only
fairly limited scalability. In this paper, we propose new techniques that
employ a classification-based perspective to evaluate synthetic GAN
distributions and their capability to accurately reflect the essential
properties of the training data. These techniques require only minimal human
supervision and can easily be scaled and adapted to evaluate a variety of
state-of-the-art GANs on large, popular datasets. Our analysis indicates that
GANs have significant problems in reproducing the more distributional
properties of the training dataset. In particular, when seen through the lens
of classification, the diversity of GAN data is orders of magnitude less than
that of the original data.
</dc:description>
 <dc:description>Comment: Under review as a conference paper at ICLR 2018</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:date>2017-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00970</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00972</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Achievement of Higher Flexibility in Multiple Choice-based Tests
  Using Image Classification Techniques</dc:title>
 <dc:creator>Afifi, Mahmoud</dc:creator>
 <dc:creator>Hussain, Khaled F.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In spite of the high accuracy of the existing optical mark reading (OMR)
systems and devices, a few restrictions remain existent. In this work, we aim
to reduce the restrictions of multiple choice questions (MCQ) within tests. We
use an image registration technique to extract the answer boxes from the answer
sheets. Unlike other systems that rely on simple image processing steps to
recognize the extracted answer boxes, we address the problem from another
perspective by training a classifier to recognize the class of each answer box
(i.e. confirmed, crossed out, and blank answer). This gives us the ability to
deal with a variety of shading and mark patterns, and distinguish between
chosen and canceled answers. All existing machine learning techniques require a
large number of examples in order to train the classifier, therefore we present
a dataset that consists of five real MCQ tests and a quiz that have different
answer sheet templates. We evaluate two strategies of classification: a
straight-forward approach and a two-stage classifier approach. We test two
handcrafted feature methods and a convolutional neural network. At the end, we
present an easy-to-use graphical user interface of the proposed system.
Compared with existing OMR systems, the proposed system is considered of a
higher accuracy and the least constraints. We believe that the presented work
will further direct the development of OMR systems towards template-free MCQ
tests without restrictions.
</dc:description>
 <dc:description>Comment: 13 pages, 7 figures, 5 tables</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:date>2017-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00972</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00973</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-Aware Virtual Machine Management in Inter-datacenter Networks
  over Elastic Optical Infrastructure</dc:title>
 <dc:creator>Zhang, Liang</dc:creator>
 <dc:creator>Han, Tao</dc:creator>
 <dc:creator>Ansari, Nirwan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Datacenters (DCs), deployed in a large scale to support the ever increasing
demand for data processing applications, consume tremendous energy. Powering
DCs with renewable energy can effectively reduce the brown energy consumption.
Owing to geographically distributed deployment of DCs, the renewable energy
generation and the data processing demands usually vary in different DCs.
Migrating virtual machines (VMs) among DCs according to the availability of
renewable energy helps match the energy demands and the renewable energy
generation in DCs, and thus maximizes the utilization of renewable energy. We
first elicit the renewable energy-aware inter-datacenter (inter-DC) VM
migration problem in an inter-DC network over the elastic optical
infrastructure, present it as a many-manycast communications problem, and then
formulate it as an integer linear programming problem. The objective is to
minimize the total cost of the brown energy consumption of DCs in such inter-DC
network via VM migration. We use CVX and Gurobi to solve this problem for small
network configurations, and we propose a few heuristic algorithms that
approximate the optimal solution for large network configurations. Through
extensive simulations, we show that the proposed algorithms, by migrating VM
among DCs, can reduce up to 19.7% cost of the brown energy consumption.
</dc:description>
 <dc:description>Comment: Comments: to appear in IEEE Transactions on Green Communications and
  Networking</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00973</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00982</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From which world is your graph?</dc:title>
 <dc:creator>Li, Cheng</dc:creator>
 <dc:creator>Wong, Felix</dc:creator>
 <dc:creator>Liu, Zhenming</dc:creator>
 <dc:creator>Kanade, Varun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Discovering statistical structure from links is a fundamental problem in the
analysis of social networks. Choosing a misspecified model, or equivalently, an
incorrect inference algorithm will result in an invalid analysis or even
falsely uncover patterns that are in fact artifacts of the model. This work
focuses on unifying two of the most widely used link-formation models: the
stochastic blockmodel (SBM) and the small world (or latent space) model (SWM).
Integrating techniques from kernel learning, spectral graph theory, and
nonlinear dimensionality reduction, we develop the first statistically sound
polynomial-time algorithm to discover latent patterns in sparse graphs for both
models. When the network comes from an SBM, the algorithm outputs a block
structure. When it is from an SWM, the algorithm outputs estimates of each
node's latent position.
</dc:description>
 <dc:description>Comment: To appear in NIPS 2017</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00982</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00991</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Partial correlation graphs and the neighborhood lattice</dc:title>
 <dc:creator>Amini, Arash A.</dc:creator>
 <dc:creator>Aragam, Bryon</dc:creator>
 <dc:creator>Zhou, Qing</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We define and study partial correlation graphs (PCGs) with variables in a
general Hilbert space and their connections to generalized neighborhood
regression, without making any distributional assumptions. Using
operator-theoretic arguments, and especially the properties of projection
operators on Hilbert spaces, we show that these neighborhood regressions have
the algebraic structure of a lattice, which we call a neighborhood lattice.
This lattice property significantly reduces the number of conditions one has to
check when testing all partial correlation relations among a collection of
variables. In addition, we generalize the notion of perfectness in graphical
models for a general PCG to this Hilbert space setting, and establish that
almost all Gram matrices are perfect. Under this perfectness assumption, we
show how these neighborhood lattices may be &quot;graphically&quot; computed using
separation properties of PCGs. We also discuss extensions of these ideas to
directed models, which present unique challenges compared to their undirected
counterparts. Our results have implications for multivariate statistical
learning in general, including structural equation models, subspace clustering,
and dimension reduction. For example, we discuss how to compute neighborhood
lattices efficiently and furthermore how they can be used to reduce the sample
complexity of learning directed acyclic graphs. Our work demonstrates that this
abstract viewpoint via projection operators significantly simplifies existing
ideas and arguments from the graphical modeling literature, and furthermore can
be used to extend these ideas to more general nonparametric settings.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.00991</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01004</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AxonDeepSeg: automatic axon and myelin segmentation from microscopy data
  using convolutional neural networks</dc:title>
 <dc:creator>Zaimi, Aldo</dc:creator>
 <dc:creator>Wabartha, Maxime</dc:creator>
 <dc:creator>Herman, Victor</dc:creator>
 <dc:creator>Antonsanti, Pierre-Louis</dc:creator>
 <dc:creator>Perone, Christian Samuel</dc:creator>
 <dc:creator>Cohen-Adad, Julien</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Segmentation of axon and myelin from microscopy images of the nervous system
provides useful quantitative information about the tissue microstructure, such
as axon density and myelin thickness. This could be used for instance to
document cell morphometry across species, or to validate novel non-invasive
quantitative magnetic resonance imaging techniques. Most currently-available
segmentation algorithms are based on standard image processing and usually
require multiple processing steps and/or parameter tuning by the user to adapt
to different modalities. Moreover, only few methods are publicly available. We
introduce AxonDeepSeg, an open-source software that performs axon and myelin
segmentation of microscopic images using deep learning. AxonDeepSeg features:
(i) a convolutional neural network architecture; (ii) an easy training
procedure to generate new models based on manually-labelled data and (iii) two
ready-to-use models trained from scanning electron microscopy (SEM) and
transmission electron microscopy (TEM). Results show high pixel-wise accuracy
across various species: 85% on rat SEM, 81% on human SEM, 95% on mice TEM and
84% on macaque TEM. Segmentation of a full rat spinal cord slice is computed
and morphological metrics are extracted and compared against the literature.
AxonDeepSeg is freely available at https://github.com/neuropoly/axondeepseg
</dc:description>
 <dc:description>Comment: 14 pages, 7 figures</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:date>2017-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01005</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>In-Bed Pose Estimation: Deep Learning with Shallow Dataset</dc:title>
 <dc:creator>Liu, Shuangjun</dc:creator>
 <dc:creator>Yin, Yu</dc:creator>
 <dc:creator>Ostadabbas, Sarah</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Although human pose estimation for various computer vision (CV) applications
has been studied extensively in the last few decades, yet in-bed pose
estimation using camera-based vision methods has been ignored by the CV
community because it is assumed to be identical to the general purpose pose
estimation methods. However, in-bed pose estimation has its own specialized
aspects and comes with specific challenges including the notable differences in
lighting conditions throughout a day and also having different pose
distribution from the common human surveillance viewpoint. In this paper, we
demonstrate that these challenges significantly lessen the effectiveness of
existing general purpose pose estimation models. In order to address the
lighting variation challenge, infrared selective (IRS) image acquisition
technique is proposed to provide uniform quality data under various lighting
conditions. Deep learning framework proves to be the most effective model in
human pose estimation, however the lack of large public dataset for in-bed
poses prevents us from using a large network from scratch. In this work, we
explored the idea of employing a pre-trained convolutional neural network (CNN)
model trained on large public datasets of general human poses and fine-tuning
the model using our own shallow (limited in size and different in perspective
and color) in-bed IRS dataset. We developed an IRS imaging system and collected
IRS image data from several realistic life-size mannequins in a simulated
hospital room environment. A pre-trained CNN called convolutional pose machine
(CPM) was repurposed for in-bed pose estimation by fine-tuning its specific
intermediate layers. Using the HOG rectification method, the pose estimation
performance of CPM significantly improved by 26.4% in PCK0.1 criteria compared
to the model without such rectification.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01006</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Neural Machine Translation with Partially Aligned Corpora</dc:title>
 <dc:creator>Wang, Yining</dc:creator>
 <dc:creator>Zhao, Yang</dc:creator>
 <dc:creator>Zhang, Jiajun</dc:creator>
 <dc:creator>Zong, Chengqing</dc:creator>
 <dc:creator>Xue, Zhengshan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  While neural machine translation (NMT) has become the new paradigm, the
parameter optimization requires large-scale parallel data which is scarce in
many domains and language pairs. In this paper, we address a new translation
scenario in which there only exists monolingual corpora and phrase pairs. We
propose a new method towards translation with partially aligned sentence pairs
which are derived from the phrase pairs and monolingual corpora. To make full
use of the partially aligned corpora, we adapt the conventional NMT training
method in two aspects. On one hand, different generation strategies are
designed for aligned and unaligned target words. On the other hand, a different
objective function is designed to model the partially aligned parts. The
experiments demonstrate that our method can achieve a relatively good result in
such a translation scenario, and tiny bitexts can boost translation quality to
a large extent.
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures, Accepted as a long paper by IJCNLP-2017</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01007</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wireless Network Simplification: The Performance of Routing</dc:title>
 <dc:creator>Ezzeldin, Yahya H.</dc:creator>
 <dc:creator>Sengupta, Ayan</dc:creator>
 <dc:creator>Fragouli, Christina</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Consider a wireless Gaussian network where a source wishes to communicate
with a destination with the help of N full-duplex relay nodes. Most practical
systems today route information from the source to the destination using the
best path that connects them. In this paper, we show that routing can in the
worst case result in an unbounded gap from the network capacity - or reversely,
physical layer cooperation can offer unbounded gains over routing. More
specifically, we show that for $N$-relay Gaussian networks with an arbitrary
topology, routing can in the worst case guarantee an approximate fraction
$\frac{1}{\left\lfloor N/2 \right\rfloor + 1}$ of the capacity of the full
network, independently of the SNR regime. We prove that this guarantee is
fundamental, i.e., it is the highest worst-case guarantee that we can provide
for routing in relay networks. Next, we consider how these guarantees are
refined for Gaussian layered relay networks with $L$ layers and $N_L$ relays
per layer. We prove that for arbitrary $L$ and $N_L$, there always exists a
route in the network that approximately achieves at least $\frac{2}{(L-1)N_L +
4}$ $\left(\mbox{resp.}\frac{2}{LN_L+2}\right)$ of the network capacity for odd
$L$ (resp. even $L$), and there exist networks where the best routes exactly
achieve these fractions. These results are formulated within the network
simplification framework, that asks what fraction of the capacity we can
achieve by using a subnetwork (in our case, a single path). A fundamental step
in our proof is a simplification result for MIMO antenna selection that may
also be of independent interest. To the best of our knowledge, this is the
first result that characterizes, for general wireless network topologies, what
is the performance of routing with respect to physical layer cooperation
techniques that approximately achieve the network capacity.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01008</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cost-Efficient and Robust On-Demand Video Transcoding Using
  Heterogeneous Cloud Services</dc:title>
 <dc:creator>Li, Xiangbo</dc:creator>
 <dc:creator>Salehi, Mohsen Amini</dc:creator>
 <dc:creator>Bayoumi, Magdy</dc:creator>
 <dc:creator>Tzeng, Nian-Feng</dc:creator>
 <dc:creator>Buyya, Rajkumar</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Video streams usually have to be transcoded to match the characteristics of
viewers' devices. Streaming providers have to store numerous transcoded
versions of a given video to serve various display devices. Given the fact that
viewers' access pattern to video streams follows a long tail distribution, for
the video streams with low access rate, we propose to transcode them in an
on-demand manner using cloud computing services. The challenge in utilizing
cloud services for on-demand video transcoding is to maintain a robust QoS for
viewers and cost-efficiency for streaming service providers. To address this
challenge, we present the Cloud-based Video Streaming Services (CVS2)
architecture. It includes a QoS-aware scheduling that maps transcoding tasks to
the VMs by considering the affinity of the transcoding tasks with the allocated
heterogeneous VMs. To maintain robustness in the presence of varying streaming
requests, the architecture includes a cost-efficient VM Provisioner. This
component provides a self- configurable cluster of heterogeneous VMs. The
cluster is reconfigured dynamically to maintain the maximum affinity with the
arriving workload. Results obtained under diverse workload conditions
demonstrate that CVS2 architecture can maintain a robust QoS for viewers while
reducing the incurred cost of the streaming service provider up to 85%
</dc:description>
 <dc:description>Comment: IEEE Transactions on Parallel and Distributed Systems</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01008</dc:identifier>
 <dc:identifier>doi:10.1109/TPDS.2017.2766069</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01010</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic FPGA Detection and Protection of Hardware Trojan: A Comparative
  Analysis</dc:title>
 <dc:creator>Alanwar, Amr</dc:creator>
 <dc:creator>Aboelnaga, Mona A.</dc:creator>
 <dc:creator>Alkabani, Yousra</dc:creator>
 <dc:creator>El-Kharashi, M. Watheq</dc:creator>
 <dc:creator>Bedour, Hassan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Hardware Trojan detection and protection is becoming more crucial as more
untrusted third parties manufacture many parts of critical systems nowadays.
The most common way to detect hardware Trojans is comparing the untrusted
design with a golden (trusted) one. However, third-party intellectual
properties (IPs) are black boxes with no golden IPs to trust. So, previous
attempts to detect hardware Trojans will not work with third-party IPs. In this
work, we present novel methods for Trojan protection and detection on field
programmable gate arrays (FPGAs) without the need for golden chips. Presented
methods work at runtime instead of test time. We provide a wide spectrum of
Trojan detection and protection methods. While the simplest methods have low
overhead and provide limited protection mechanisms, more sophisticated and
costly techniques are introduced that can detect hardware Trojans and even
clean up the system from infected IPs. Moreover, we study the cost of using the
FPGA partial reconfiguration feature to get rid of infected IPs. In addition,
we discuss the possibility to construct IP core certificate authority that
maintains a centralized database of unsafe vendors and IPs. We show the
practicality of the introduced schemes by implementing the different
methodologies on FPGAs. Results show that simple methods present negligible
overheads and as we try to increase security the delay and power overheads
increase.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01012</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Genetic Policy Optimization</dc:title>
 <dc:creator>Gangwani, Tanmay</dc:creator>
 <dc:creator>Peng, Jian</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Genetic algorithms have been widely used in many practical optimization
problems. Inspired by natural selection, operators, including mutation,
crossover and selection, provide effective heuristics for search and black-box
optimization. However, they have not been shown useful for deep reinforcement
learning, possibly due to the catastrophic consequence of parameter crossovers
of neural networks. Here, we present Genetic Policy Optimization (GPO), a new
genetic algorithm for sample-efficient deep policy optimization. GPO uses
imitation learning for policy crossover in the state space and applies policy
gradient methods for mutation. Our experiments on Mujoco tasks show that GPO as
a genetic algorithm is able to provide superior performance over the
state-of-the-art policy gradient methods and achieves comparable or higher
sample efficiency.
</dc:description>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01022</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>People as Sensors: Imputing Maps from Human Actions</dc:title>
 <dc:creator>Afolabi, Oladapo</dc:creator>
 <dc:creator>Driggs-Campbell, Katherine</dc:creator>
 <dc:creator>Dong, Roy</dc:creator>
 <dc:creator>Kochenderfer, Mykel J.</dc:creator>
 <dc:creator>Sastry, S. Shankar</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Despite growing attention in autonomy, there are still many open problems,
including how autonomous vehicles will interact and communicate with other
agents, such as human drivers and pedestrians. Unlike most approaches that
focus on pedestrian detection and planning for collision avoidance, this paper
considers modeling the interaction between human drivers and pedestrians and
how it might influence map estimation, as a proxy for detection. We take a
mapping inspired approach and incorporate people as sensors into mapping
frameworks. By taking advantage of other agents' actions, we demonstrate how we
can impute portions of the map that would otherwise be occluded. We evaluate
our framework in human driving experiments and on real-world data, using
occupancy grids and landmark-based mapping approaches. Our approach
significantly improves overall environment awareness and out-performs standard
mapping techniques.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01024</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SPARK: Static Program Analysis Reasoning and Retrieving Knowledge</dc:title>
 <dc:creator>Sodsong, Wasuwee</dc:creator>
 <dc:creator>Scholz, Bernhard</dc:creator>
 <dc:creator>Chawla, Sanjay</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Program analysis is a technique to reason about programs without executing
them, and it has various applications in compilers, integrated development
environments, and security. In this work, we present a machine learning
pipeline that induces a security analyzer for programs by example. The security
analyzer determines whether a program is either secure or insecure based on
symbolic rules that were deduced by our machine learning pipeline. The machine
pipeline is two-staged consisting of a Recurrent Neural Networks (RNN) and an
Extractor that converts an RNN to symbolic rules.
  To evaluate the quality of the learned symbolic rules, we propose a
sampling-based similarity measurement between two infinite regular languages.
We conduct a case study using real-world data. In this work, we discuss the
limitations of existing techniques and possible improvements in the future. The
results show that with sufficient training data and a fair distribution of
program paths it is feasible to deducing symbolic security rules for the
OpenJDK library with millions lines of code.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01030</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Searchable Symmetric Encryption Scheme using BlockChain</dc:title>
 <dc:creator>Li, Huige</dc:creator>
 <dc:creator>Zhang, Fangguo</dc:creator>
 <dc:creator>He, Jiejie</dc:creator>
 <dc:creator>Tian, Haibo</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  At present, the cloud storage used in searchable symmetric encryption schemes
(SSE) is provided in a private way, which cannot be seen as a true cloud.
Moreover, the cloud server is thought to be credible, because it always returns
the search result to the user, even they are not correct. In order to really
resist this malicious adversary and accelerate the usage of the data, it is
necessary to store the data on a public chain, which can be seen as a
decentralized system. As the increasing amount of the data, the search problem
becomes more and more intractable, because there does not exist any effective
solution at present.
  In this paper, we begin by pointing out the importance of storing the data in
a public chain. We then innovatively construct a model of SSE using
blockchain(SSE-using-BC) and give its security definition to ensure the privacy
of the data and improve the search efficiency. According to the size of data,
we consider two different cases and propose two corresponding schemes. Lastly,
the security and performance analyses show that our scheme is feasible and
secure.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:date>2017-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01032</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simply Exponential Upper Bound on the Maximum Number of Stable
  Matchings</dc:title>
 <dc:creator>Karlin, Anna R.</dc:creator>
 <dc:creator>Gharan, Shayan Oveis</dc:creator>
 <dc:creator>Weber, Robbie</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Stable matching is a classical combinatorial problem that has been the
subject of intense theoretical and empirical study since its introduction in
1962 in a seminal paper by Gale and Shapley. In this paper, we provide a new
upper bound on $f(n)$, the maximum number of stable matchings that a stable
matching instance with $n$ men and $n$ women can have. It has been a
long-standing open problem to understand the asymptotic behavior of $f(n)$ as
$n\to\infty$, first posed by Donald Knuth in the 1970s. Until now the best
lower bound was approximately $2.28^n$, and the best upper bound was $2^{n\log
n- O(n)}$. In this paper, we show that for all $n$, $f(n) \leq c^n$ for some
universal constant $c$. This matches the lower bound up to the base of the
exponent. Our proof is based on a reduction to counting the number of downsets
of a family of posets that we call &quot;mixing&quot;. The latter might be of independent
interest.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01032</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01034</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PS-DBSCAN: An Efficient Parallel DBSCAN Algorithm Based on Platform Of
  AI (PAI)</dc:title>
 <dc:creator>Hu, Xu</dc:creator>
 <dc:creator>Huang, Jun</dc:creator>
 <dc:creator>Qiu, Minghui</dc:creator>
 <dc:creator>Chen, Cen</dc:creator>
 <dc:creator>Chu, Wei</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We present PS-DBSCAN, a communication efficient parallel DBSCAN algorithm
that combines the disjoint-set data structure and Parameter Server framework in
Platform of AI (PAI). Since data points within the same cluster may be
distributed over different workers which result in several disjoint-sets,
merging them incurs large communication costs. In our algorithm, we employ a
fast global union approach to union the disjoint-sets to alleviate the
communication burden. Experiments over the datasets of different scales
demonstrate that PS-DBSCAN outperforms the PDSDBSCAN with 2-10 times speedup on
communication efficiency.
  We have released our PS-DBSCAN in an algorithm platform called Platform of AI
(PAI - https://pai.base.shuju.aliyun.com/) in Alibaba Cloud. We have also
demonstrated how to use the method in PAI.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01037</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparsity, variance and curvature in multi-armed bandits</dc:title>
 <dc:creator>Bubeck, S&#xe9;bastien</dc:creator>
 <dc:creator>Cohen, Michael B.</dc:creator>
 <dc:creator>Li, Yuanzhi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In (online) learning theory the concepts of sparsity, variance and curvature
are well-understood and are routinely used to obtain refined regret and
generalization bounds. In this paper we further our understanding of these
concepts in the more challenging limited feedback scenario. We consider the
adversarial multi-armed bandit and linear bandit settings and solve several
open problems pertaining to the existence of algorithms with favorable regret
bounds under the following assumptions: (i) sparsity of the individual losses,
(ii) small variation of the loss sequence, and (iii) curvature of the action
set. Specifically we show that (i) for $s$-sparse losses one can obtain
$\tilde{O}(\sqrt{s T})$-regret (solving an open problem by Kwon and Perchet),
(ii) for loss sequences with variation bounded by $Q$ one can obtain
$\tilde{O}(\sqrt{Q})$-regret (solving an open problem by Kale and Hazan), and
(iii) for linear bandit on an $\ell_p^n$ ball one can obtain $\tilde{O}(\sqrt{n
T})$-regret for $p \in [1,2]$ and one has $\tilde{\Omega}(n \sqrt{T})$-regret
for $p&gt;2$ (solving an open problem by Bubeck, Cesa-Bianchi and Kakade). A key
new insight to obtain these results is to use regularizers satisfying more
refined conditions than general self-concordance
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01039</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identification of Repetitive Processes at Steady- and Unsteady-state:
  Transfer Function</dc:title>
 <dc:creator>Antunes, Ricardo</dc:creator>
 <dc:creator>Gonz&#xe1;lez, Vicente A.</dc:creator>
 <dc:creator>Walsh, Kenneth</dc:creator>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Projects are finite terminating endeavors with distinctive outcomes, usually,
occurring under transient conditions. Nevertheless, most estimation, planning,
and scheduling approaches overlook the dynamics of project-based systems in
construction. These approaches underestimate the influence of process
repetitiveness, the variation of learning curves and the conservation of
processes' properties. So far, estimation and modeling approaches have enabled
a comprehensive understanding of repetitive processes in projects at
steady-state. However, there has been little research to understand and develop
an integrated and explicit representation of the dynamics of these processes in
either transient, steady or unsteady conditions. This study evaluates the
transfer function in its capability of simultaneously identifying and
representing the production behavior of repetitive processes in different state
conditions. The sample data for this research comes from the construction of an
offshore oil well and describes the performance of a particular process by
considering the inputs necessary to produce the outputs. The result is a
concise mathematical model that satisfactorily reproduces the process'
behavior. Identifying suitable modeling methods, which accurately represent the
dynamic conditions of production in repetitive processes, may provide more
robust means to plan and control construction projects based on a
mathematically driven production theory.
</dc:description>
 <dc:description>Comment: Proc. 23rd Ann. Conf. of the Int'l. Group for Lean Construction,
  28-31 July, Perth, Australia, pp. 793-802</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01039</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01041</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Hardware Implementation of Double-Layer Perceptron Based on
  Metal-Oxide Memristive Nanostructures</dc:title>
 <dc:creator>Mikhaylov, A. N.</dc:creator>
 <dc:creator>Morozov, O. A.</dc:creator>
 <dc:creator>Ovchinnikov, P. E.</dc:creator>
 <dc:creator>Antonov, I. N.</dc:creator>
 <dc:creator>Belov, A. I.</dc:creator>
 <dc:creator>Korolev, D. S.</dc:creator>
 <dc:creator>Koryazhkina, M. N.</dc:creator>
 <dc:creator>Sharapov, A. N.</dc:creator>
 <dc:creator>Gryaznov, E. G.</dc:creator>
 <dc:creator>Gorshkov, O. N.</dc:creator>
 <dc:creator>Kazantsev, V. B.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Physics - Applied Physics</dc:subject>
 <dc:description>  Construction and training principles have been proposed and tested for an
artificial neural network based on metal-oxide thin-film nanostructures
possessing bipolar resistive switching (memristive) effect. Experimental
electronic circuit of neural network is implemented as a double-layer
perceptron with a weight matrix composed of 32 memristive devices. The network
training algorithm takes into account technological variations of the
parameters of memristive nanostructures. Despite the limited size of weight
matrix the developed neural network model is well scalable and capable of
solving nonlinear classification problems.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01043</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Taught-Obesrve-Ask (TOA) Method for Object Detection with Critical
  Supervision</dc:title>
 <dc:creator>Wu, Chi-Hao</dc:creator>
 <dc:creator>Huang, Qin</dc:creator>
 <dc:creator>Li, Siyang</dc:creator>
 <dc:creator>Kuo, C. -C. Jay</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Being inspired by child's learning experience - taught first and followed by
observation and questioning, we investigate a critically supervised learning
methodology for object detection in this work. Specifically, we propose a
taught-observe-ask (TOA) method that consists of several novel components such
as negative object proposal, critical example mining, and machine-guided
question-answer (QA) labeling. To consider labeling time and performance
jointly, new evaluation methods are developed to compare the performance of the
TOA method, with the fully and weakly supervised learning methods. Extensive
experiments are conducted on the PASCAL VOC and the Caltech benchmark datasets.
The TOA method provides significantly improved performance of weakly
supervision yet demands only about 3-6% of labeling time of full supervision.
The effectiveness of each novel component is also analyzed.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01046</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Elasticutor: Rapid Elasticity for Realtime Stateful Stream Processing</dc:title>
 <dc:creator>Wang, Li</dc:creator>
 <dc:creator>Fu, Tom Z. J.</dc:creator>
 <dc:creator>Ma, Richard T. B.</dc:creator>
 <dc:creator>Winslett, Marianne</dc:creator>
 <dc:creator>Zhang, Zhenjie</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Elasticity is highly desirable for stream processing systems to guarantee low
latency against workload dynamics, such as surges in data arrival rate and
fluctuations in data distribution. Existing systems achieve elasticity
following a resource-centric approach that uses dynamic key partitioning across
the parallel instances, i.e. executors, to balance the workload and scale
operators. However, such operator-level key repartitioning needs global
synchronization and prohibits rapid elasticity. To address this problem, we
propose an executor-centric approach, whose core idea is to avoid
operator-level key repartitioning while implementing each executor as the
building block of elasticity. Following this new approach, we design the
Elasticutor framework with two level of optimizations: i) a novel
implementation of executors, i.e., elastic executors, that perform elastic
multi-core execution via efficient intra-executor load balancing and executor
scaling and ii) a global model-based scheduler that dynamically allocates CPU
cores to executors based on the instantaneous workloads. We implemented a
prototype of Elasticutor and conducted extensive experiments. Our results show
that Elasticutor doubles the throughput and achieves an average processing
latency up to 2 orders of magnitude lower than previous methods, for a dynamic
workload of real-world applications.
</dc:description>
 <dc:description>Comment: 14 pages, 16 figures</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01048</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dual Language Models for Code Mixed Speech Recognition</dc:title>
 <dc:creator>Garg, Saurabh</dc:creator>
 <dc:creator>Parekh, Tanmay</dc:creator>
 <dc:creator>Jyothi, Preethi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this work, we present a new approach to language modeling for bilingual
code-switched text. This technique, called dual language models, involves
building two complementary monolingual language models and combining them using
a probabilistic model for switching between the two. The objective of this
technique is to improve generalization when the amount of code-switched
training data is limited. We evaluate the efficacy of our approach using a
conversational Mandarin-English speech corpus. Using our model, we obtain
significant improvements in both perplexity measures and automatic speech
recognition error rates compared to a standard bilingual language model.
</dc:description>
 <dc:description>Comment: Submitted to ICASSP 2018</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01048</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01049</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Pricing-Based Edge Computing Resource Management in Mobile
  Blockchain</dc:title>
 <dc:creator>Xiong, Zehui</dc:creator>
 <dc:creator>Feng, Shaohan</dc:creator>
 <dc:creator>Niyato, Dusit</dc:creator>
 <dc:creator>Wang, Ping</dc:creator>
 <dc:creator>Han, Zhu</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  As the core issue of blockchain, the mining requires solving a proof-of-work
puzzle, which is resource expensive to implement in mobile devices due to high
computing power needed. Thus, the development of blockchain in mobile
applications is restricted. In this paper, we consider the edge computing as
the network enabler for mobile blockchain. In particular, we study optimal
pricing-based edge computing resource management to support mobile blockchain
applications where the mining process can be offloaded to an Edge computing
Service Provider (ESP). We adopt a two-stage Stackelberg game to jointly
maximize the profit of the ESP and the individual utilities of different
miners. In Stage I, the ESP sets the price of edge computing services. In Stage
II, the miners decide on the service demand to purchase based on the observed
prices. We apply the backward induction to analyze the sub-game perfect
equilibrium in each stage for uniform and discriminatory pricing schemes.
Further, the existence and uniqueness of Stackelberg game are validated for
both pricing schemes. At last, the performance evaluation shows that the ESP
intends to set the maximum possible value as the optimal price for profit
maximization under uniform pricing. In addition, the discriminatory pricing
helps the ESP encourage higher total service demand from miners and achieve
greater profit correspondingly.
</dc:description>
 <dc:description>Comment: 7 pages, submitted to one conference</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01050</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Socially-Aware Incentive Mechanism for Mobile Crowdsensing Service
  Market</dc:title>
 <dc:creator>Nie, Jiangtian</dc:creator>
 <dc:creator>Xiong, Zehui</dc:creator>
 <dc:creator>Niyato, Dusit</dc:creator>
 <dc:creator>Wang, Ping</dc:creator>
 <dc:creator>Luo, Jun</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Mobile Crowdsensing has shown a great potential to address large-scale
problems by allocating sensing tasks to pervasive Mobile Users (MUs). The MUs
will participate in a Crowdsensing platform if they can receive satisfactory
reward. In this paper, in order to effectively and efficiently recruit
sufficient MUs, i.e., participants, we investigate an optimal reward mechanism
of the monopoly Crowdsensing Service Provider (CSP). We model the rewarding and
participating as a two-stage game, and analyze the MUs' participation level and
the CSP's optimal reward mechanism using backward induction. At the same time,
the reward is designed taking the underlying social network effects amid the
mobile social network into account, for motivating the participants. Namely,
one MU will obtain additional benefits from information contributed or shared
by local neighbours in social networks. We derive the analytical expressions
for the discriminatory reward as well as uniform reward with complete
information, and approximations of reward incentive with incomplete
information. Performance evaluation reveals that the network effects
tremendously stimulate higher mobile participation level and greater revenue of
the CSP. In addition, the discriminatory reward enables the CSP to extract
greater surplus from this Crowdsensing service market.
</dc:description>
 <dc:description>Comment: 6 pages, submitted to one conference</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01050</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01053</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shadow Tomography of Quantum States</dc:title>
 <dc:creator>Aaronson, Scott</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We introduce the problem of *shadow tomography*: given an unknown
$D$-dimensional quantum mixed state $\rho$, as well as known two-outcome
measurements $E_{1},\ldots,E_{M}$, estimate the probability that $E_{i}$
accepts $\rho$, to within additive error $\varepsilon$, for each of the $M$
measurements. How many copies of $\rho$ are needed to achieve this, with high
probability? Surprisingly, we give a procedure that solves the problem by
measuring only $\widetilde{O}\left( \varepsilon^{-5}\cdot\log^{4} M\cdot\log
D\right)$ copies. This means, for example, that we can learn the behavior of an
arbitrary $n$-qubit state, on all accepting/rejecting circuits of some fixed
polynomial size, by measuring only $n^{O\left( 1\right)}$ copies of the state.
This resolves an open problem of the author, which arose from his work on
private-key quantum money schemes, but which also has applications to quantum
copy-protected software, quantum advice, and quantum one-way communication.
Recently, building on this work, Brand\~ao et al. have given a different
approach to shadow tomography using semidefinite programming, which achieves a
savings in computation time.
</dc:description>
 <dc:description>Comment: 25 pages</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01054</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Competition and Cooperation Analysis for Data Sponsored Market: A
  Network Effects Model</dc:title>
 <dc:creator>Xiong, Zehui</dc:creator>
 <dc:creator>Feng, Shaohan</dc:creator>
 <dc:creator>Niyato, Dusit</dc:creator>
 <dc:creator>Wang, Ping</dc:creator>
 <dc:creator>Zhang, Yang</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The data sponsored scheme allows the content provider to cover parts of the
cellular data costs for mobile users. Thus the content service becomes
appealing to more users and potentially generates more profit gain to the
content provider. In this paper, we consider a sponsored data market with a
monopoly network service provider, a single content provider, and multiple
users. In particular, we model the interactions of three entities as a
two-stage Stackelberg game, where the service provider and content provider act
as the leaders determining the pricing and sponsoring strategies, respectively,
in the first stage, and the users act as the followers deciding on their data
demand in the second stage. We investigate the mutual interaction of the
service provider and content provider in two cases: (i) competitive case, where
the content provider and service provider optimize their strategies separately
and competitively, each aiming at maximizing the profit and revenue,
respectively; and (ii) cooperative case, where the two providers jointly
optimize their strategies, with the purpose of maximizing their aggregate
profits. We analyze the sub-game perfect equilibrium in both cases. Via
extensive simulations, we demonstrate that the network effects significantly
improve the payoff of three entities in this market, i.e., utilities of users,
the profit of content provider and the revenue of service provider. In
addition, it is revealed that the cooperation between the two providers is the
best choice for all three entities.
</dc:description>
 <dc:description>Comment: 7 pages, submitted to one conference</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01054</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01061</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Automata Recognizing Birecurrent Sets</dc:title>
 <dc:creator>Ryzhikov, Andrew</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In this note we study automata recognizing birecurrent sets. A set of words
is birecurrent if the minimal partial DFA recognizing this set and the minimal
partial DFA recognizing the reversal of this set are both strongly connected.
This notion was introduced by Perrin, and Dolce et al. provided a
characterization of such sets. We prove that deciding whether a partial DFA
recognizes a birecurrent set is a PSPACE-complete problem. We show that this
problem is PSPACE-complete even in the case of binary partial DFAs with all
states accepting and in the case of binary complete DFAs. We also consider a
related problem of computing the rank of a partial DFA.
</dc:description>
 <dc:description>Comment: A slightly updated version</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01061</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01062</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Glimpse LSTM with Color-Depth Feature Fusion for Human Detection</dc:title>
 <dc:creator>Li, Hengduo</dc:creator>
 <dc:creator>Liu, Jun</dc:creator>
 <dc:creator>Zhang, Guyue</dc:creator>
 <dc:creator>Gao, Yuan</dc:creator>
 <dc:creator>Wu, Yirui</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  With the development of depth cameras such as Kinect and Intel Realsense,
RGB-D based human detection receives continuous research attention due to its
usage in a variety of applications. In this paper, we propose a new
Multi-Glimpse LSTM (MG-LSTM) network, in which multi-scale contextual
information is sequentially integrated to promote the human detection
performance. Furthermore, we propose a feature fusion strategy based on our
MG-LSTM network to better incorporate the RGB and depth information. To the
best of our knowledge, this is the first attempt to utilize LSTM structure for
RGB-D based human detection. Our method achieves superior performance on two
publicly available datasets.
</dc:description>
 <dc:description>Comment: ICIP 2017 Oral</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01068</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compressing Word Embeddings via Deep Compositional Code Learning</dc:title>
 <dc:creator>Shu, Raphael</dc:creator>
 <dc:creator>Nakayama, Hideki</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Natural language processing (NLP) models often require a massive number of
parameters for word embeddings, resulting in a large storage or memory
footprint. Deploying neural NLP models to mobile devices requires compressing
the word embeddings without any significant sacrifices in performance. For this
purpose, we propose to construct the embeddings with few basis vectors. For
each word, the composition of basis vectors is determined by a hash code. To
maximize the compression rate, we adopt the multi-codebook quantization
approach instead of binary coding scheme. Each code is composed of multiple
discrete numbers, such as (3, 2, 1, 8), where the value of each component is
limited to a fixed range. We propose to directly learn the discrete codes in an
end-to-end neural network by applying the Gumbel-softmax trick. Experiments
show the compression rate achieves 98% in a sentiment analysis task and 94% ~
99% in machine translation tasks without performance loss. In both tasks, the
proposed method can improve the model performance by slightly lowering the
compression rate. Compared to other approaches such as character-level
segmentation, the proposed method is language-independent and does not require
modifications to the network architecture.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:date>2017-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01068</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01074</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Minimum Distance of Some Narrow-Sense Primitive BCH Codes</dc:title>
 <dc:creator>Li, Shuxing</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Due to wide applications of BCH codes, the determination of their minimum
distance is of great interest. However, this is a very challenging problem for
which few theoretical results have been reported in the last four decades. Even
for the narrow-sense primitive BCH codes, which form the most well-studied
subclass of BCH codes, there are very few theoretical results on the minimum
distance. In this paper, we present new results on the minimum distance of
narrow-sense primitive BCH codes with special Bose distance. We prove that for
a prime power $q$, the $q$-ary narrow-sense primitive BCH code with length
$q^m-1$ and Bose distance $q^m-q^{m-1}-q^i-1$, where $\frac{m-2}{2} \le i \le
m-\lfloor \frac{m}{3} \rfloor-1$, has minimum distance $q^m-q^{m-1}-q^i-1$.
This is achieved by employing the beautiful theory of sets of quadratic forms,
symmetric bilinear forms and alternating bilinear forms over finite fields,
which can be best described using the framework of association schemes.
</dc:description>
 <dc:description>Comment: 40 pages</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01074</dc:identifier>
 <dc:identifier>SIAM Journal on Discrete Mathematics, 31(4):2530-2569, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01079</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transmission Network Reduction Method using Nonlinear Optimization</dc:title>
 <dc:creator>Fortenbacher, Philipp</dc:creator>
 <dc:creator>Demiray, Turhan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents a new method to determine the susceptances of a reduced
transmission network representation by using nonlinear optimization. We use
Power Transfer Distribution Factors (PTDFs) to convert the original grid into a
reduced version, from which we determine the susceptances. From our case
studies we find that considering a reduced injection-independent evaluated PTDF
matrix is the best approximation and is by far better than an
injection-dependent evaluated PTDF matrix over a given set of
arbitrarily-chosen power injection scenarios. We also compare our nonlinear
approach with existing methods from literature in terms of the approximation
error and computation time. On average, we find that our approach reduces the
mean error of the power flow deviations between the original power system and
its reduced version.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01079</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01082</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Capacity of SWIPT Systems with a Nonlinear Energy Harvesting
  Circuit</dc:title>
 <dc:creator>Morsi, Rania</dc:creator>
 <dc:creator>Jamali, Vahid</dc:creator>
 <dc:creator>Ng, Derrick Wing Kwan</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study information-theoretic limits for simultaneous
wireless information and power transfer (SWIPT) systems employing a practical
nonlinear radio frequency (RF) energy harvesting (EH) receiver. In particular,
we consider a three-node system with one transmitter that broadcasts a common
signal to separated information decoding (ID) and EH receivers. Owing to the
nonlinearity of the EH receiver circuit, the efficiency of wireless power
transfer depends significantly on the waveform of the transmitted signal. In
this paper, we aim to answer the following fundamental question: What is the
optimal input distribution of the transmit waveform that maximizes the rate of
the ID receiver for a given required harvested power at the EH receiver? In
particular, we study the capacity of a SWIPT system impaired by additive white
Gaussian noise (AWGN) under average-power (AP) and peak-power (PP) constraints
at the transmitter and an EH constraint at the EH receiver. Using Hermite
polynomial bases, we prove that the optimal capacity-achieving input
distribution that maximizes the rate-energy region is unique and discrete with
a finite number of mass points. Furthermore, we show that the optimal input
distribution for the same problem without PP constraint is discrete whenever
the EH constraint is active and continuous zero-mean Gaussian, otherwise. Our
numerical results show that the rate-energy region is enlarged for a larger PP
constraint and that the rate loss of the considered SWIPT system compared to
the AWGN channel without EH receiver is reduced by increasing the AP budget.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures, submitted for possible conference publication</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01082</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01085</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>k-server via multiscale entropic regularization</dc:title>
 <dc:creator>Bubeck, Sebastien</dc:creator>
 <dc:creator>Cohen, Michael B.</dc:creator>
 <dc:creator>Lee, James R.</dc:creator>
 <dc:creator>Lee, Yin Tat</dc:creator>
 <dc:creator>Madry, Aleksander</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:description>  We present an $O((\log k)^2)$-competitive randomized algorithm for the
$k$-server problem on hierarchically separated trees (HSTs). This is the first
$o(k)$-competitive randomized algorithm for which the competitive ratio is
independent of the size of the underlying HST. Our algorithm is designed in the
framework of online mirror descent where the mirror map is a multiscale
entropy. When combined with Bartal's static HST embedding reduction, this leads
to an $O((\log k)^2 \log n)$-competitive algorithm on any $n$-point metric
space. We give a new dynamic HST embedding that yields an $O((\log k)^3 \log
\Delta)$-competitive algorithm on any metric space where the ratio of the
largest to smallest non-zero distance is at most $\Delta$.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01085</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01094</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Omega-Net: Fully Automatic, Multi-View Cardiac MR Detection,
  Orientation, and Segmentation with Deep Neural Networks</dc:title>
 <dc:creator>Vigneault, Davis M.</dc:creator>
 <dc:creator>Xie, Weidi</dc:creator>
 <dc:creator>Ho, Carolyn Y.</dc:creator>
 <dc:creator>Bluemke, David A.</dc:creator>
 <dc:creator>Noble, J. Alison</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Pixelwise segmentation of the left ventricular (LV) myocardium and the four
cardiac chambers in 2-D steady state free precession (SSFP) cine sequences is
an essential preprocessing step for a wide range of analyses. Variability in
contrast, appearance, orientation, and placement of the heart between patients,
clinical views, scanners, and protocols makes fully automatic semantic
segmentation a notoriously difficult problem. Here, we present ${\Omega}$-Net
(Omega-Net): a novel convolutional neural network (CNN) architecture for
simultaneous detection, transformation into a canonical orientation, and
semantic segmentation. First, a coarse-grained segmentation is performed on the
input image, second, the features learned during this coarse-grained
segmentation are used to predict the parameters needed to transform the input
image into a canonical orientation, and third, a fine-grained segmentation is
performed on the transformed image. In this work, ${\Omega}$-Nets of varying
depths were trained to detect five foreground classes in any of three clinical
views (short axis, SA, four-chamber, 4C, two-chamber, 2C), without prior
knowledge of the view being segmented. This constitutes a substantially more
challenging problem compared with prior work. The architecture was trained on a
cohort of patients with hypertrophic cardiomyopathy (HCM, N = 42) and healthy
control subjects (N = 21). Network performance as measured by weighted
foreground intersection-over-union (IoU) was substantially improved in the
best-performing ${\Omega}$- Net compared with U-Net segmentation without
detection or orientation (0.858 vs 0.834). We believe this architecture
represents a substantive advancement over prior approaches, with implications
for biomedical image segmentation more generally.
</dc:description>
 <dc:description>Comment: First two authors contributed equally to this work</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:date>2017-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01094</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01097</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Empirical Study on Leanness and Flexibility in Distributed Software
  Development</dc:title>
 <dc:creator>Razzak, Mohammad Abdur</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Nowadays, many individuals and teams involved on projects are already using
agile development techniques as part of their daily work. However, we have much
less experience in how to scale and manage agile practices in distributed
software development. Distributed and global development- that requiring
attention to many technical, organizational, and cultural issues as the teams
interact to cooperatively delivery the solution. Alongside, very large team
sizes, teams of teams, and more complex management structures forcing
additional attention to coordination and management. At this level, there is an
increasing need to standardize best practices to avoid reinvention and
miscommunication across artifacts and processes. Complexity issues in
enterprise software delivery can have significant impact on the adoption of
agile approaches. As a consequence, agile strategies will typically need to be
evaluated, tailored, and perhaps combined with traditional approaches to suit
the particular context. The characteristics of software products and software
development processes open up new possibilities that are different from those
offered in other domains to achieve leanness and flexibility. Whilst Lean
principles are universal, a further understanding of the techniques required to
apply such principles from a software development angle. Thus, the aim of this
research is to identify, how leanness facilitate flexibility in distributed
software development to speed-up development process.
</dc:description>
 <dc:description>Comment: 4</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01097</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01100</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One Model to Rule them all: Multitask and Multilingual Modelling for
  Lexical Analysis</dc:title>
 <dc:creator>Bjerva, Johannes</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  When learning a new skill, you take advantage of your preexisting skills and
knowledge. For instance, if you are a skilled violinist, you will likely have
an easier time learning to play cello. Similarly, when learning a new language
you take advantage of the languages you already speak. For instance, if your
native language is Norwegian and you decide to learn Dutch, the lexical overlap
between these two languages will likely benefit your rate of language
acquisition. This thesis deals with the intersection of learning multiple tasks
and learning multiple languages in the context of Natural Language Processing
(NLP), which can be defined as the study of computational processing of human
language. Although these two types of learning may seem different on the
surface, we will see that they share many similarities.
  The traditional approach in NLP is to consider a single task for a single
language at a time. However, recent advances allow for broadening this
approach, by considering data for multiple tasks and languages simultaneously.
This is an important approach to explore further as the key to improving the
reliability of NLP, especially for low-resource languages, is to take advantage
of all relevant data whenever possible. In doing so, the hope is that in the
long term, low-resource languages can benefit from the advances made in NLP
which are currently to a large extent reserved for high-resource languages.
This, in turn, may then have positive consequences for, e.g., language
preservation, as speakers of minority languages will have a lower degree of
pressure to using high-resource languages. In the short term, answering the
specific research questions posed should be of use to NLP researchers working
towards the same goal.
</dc:description>
 <dc:description>Comment: PhD thesis, University of Groningen</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01110</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Rudimentary Model for Low-Latency Anonymous Communication Systems</dc:title>
 <dc:creator>Zheng, Yufan</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we present a rudimentary model for low-latency anonymous
communication systems. Specifically, we study distributed OR algorithm as an
abstract of the system. Based on our model, we give several satisfactory lower
bounds of anonymity leakage of a deterministic OR algorithm. Some of them
reveal a trade-off between anonymity and communication complexity. For the
randomized OR algorithm, we only give a relatively trivial but possibly tight
lower bound when leaving out communication complexity. And we find the
relationship between our model and some open case in the study of secret
sharing scheme, if considering communication complexity.
</dc:description>
 <dc:description>Comment: 19 pages</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01110</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01115</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Control and Quality-of-Service in Multihop Wireless Networks</dc:title>
 <dc:creator>S., Ashok Krishnan K.</dc:creator>
 <dc:creator>Sharma, Vinod</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Control of wireless multihop networks, while simultaneously meeting
end-to-end mean delay requirements of different flows is a challenging problem.
Additionally, distributed computation of control parameters adds to the
complexity. Using the notion of discrete review used in fluid control of
networks, a distributed algorithm is proposed for control of multihop wireless
networks with interference constraints. The algorithm meets end-to-end mean
delay requirements by solving an optimization problem at review instants. The
optimization incorporates delay requirements as weights in the function being
maximized. The weights are dynamic and vary depending on queue length
information. The optimization is done in a distributed manner using an
incremental gradient ascent algorithm. The stability of the network under the
proposed policy is analytically studied and the policy is shown to be
throughput optimal.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01115</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01117</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Motion Artifact Detection in Confocal Laser Endomicroscopy Images</dc:title>
 <dc:creator>Stoeve, Maike P.</dc:creator>
 <dc:creator>Aubreville, Marc</dc:creator>
 <dc:creator>Oetter, Nicolai</dc:creator>
 <dc:creator>Knipfer, Christian</dc:creator>
 <dc:creator>Neumann, Helmut</dc:creator>
 <dc:creator>Stelzle, Florian</dc:creator>
 <dc:creator>Maier, Andreas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Confocal Laser Endomicroscopy (CLE), an optical imaging technique allowing
non-invasive examination of the mucosa on a (sub)cellular level, has proven to
be a valuable diagnostic tool in gastroenterology and shows promising results
in various anatomical regions including the oral cavity. Recently, the
feasibility of automatic carcinoma detection for CLE images of sufficient
quality was shown. However, in real world data sets a high amount of CLE images
is corrupted by artifacts. Amongst the most prevalent artifact types are
motion-induced image deteriorations. In the scope of this work, algorithmic
approaches for the automatic detection of motion artifact-tainted image regions
were developed. Hence, this work provides an important step towards clinical
applicability of automatic carcinoma detection. Both, conventional machine
learning and novel, deep learning-based approaches were assessed. The deep
learning-based approach outperforms the conventional approaches, attaining an
AUC of 0.90.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01117</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01124</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-end Flow Correlation Tracking with Spatial-temporal Attention</dc:title>
 <dc:creator>Zhu, Zheng</dc:creator>
 <dc:creator>Wu, Wei</dc:creator>
 <dc:creator>Zou, Wei</dc:creator>
 <dc:creator>Yan, Junjie</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Discriminative correlation filters (DCF) with deep convolutional features
have achieved favorable performance in recent tracking benchmarks. However,
most of existing DCF trackers only consider appearance features of current
frame, and hardly benefit from motion and inter-frame information. The lack of
temporal information degrades the tracking performance during challenges such
as partial occlusion and deformation. In this work, we focus on making use of
the rich flow information in consecutive frames to improve the feature
representation and the tracking accuracy. Firstly, individual components,
including optical flow estimation, feature extraction, aggregation and
correlation filter tracking are formulated as special layers in network. To the
best of our knowledge, this is the first work to jointly train flow and
tracking task in a deep learning framework. Then the historical feature maps at
predefined intervals are warped and aggregated with current ones by the guiding
of flow. For adaptive aggregation, we propose a novel spatial-temporal
attention mechanism. Extensive experiments are performed on four challenging
tracking datasets: OTB2013, OTB2015, VOT2015 and VOT2016, and the proposed
method achieves superior results on these benchmarks.
</dc:description>
 <dc:description>Comment: 11 pages, 7 figures</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01124</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01125</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spintronics based Stochastic Computing for Efficient Bayesian Inference
  System</dc:title>
 <dc:creator>Jia, Xiaotao</dc:creator>
 <dc:creator>Yang, Jianlei</dc:creator>
 <dc:creator>Wang, Zhaohao</dc:creator>
 <dc:creator>Chen, Yiran</dc:creator>
 <dc:creator>Hai</dc:creator>
 <dc:creator>Li</dc:creator>
 <dc:creator>Zhao, Weisheng</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Bayesian inference is an effective approach for solving statistical learning
problems especially with uncertainty and incompleteness. However, inference
efficiencies are physically limited by the bottlenecks of conventional
computing platforms. In this paper, an emerging Bayesian inference system is
proposed by exploiting spintronics based stochastic computing. A stochastic
bitstream generator is realized as the kernel components by leveraging the
inherent randomness of spintronics devices. The proposed system is evaluated by
typical applications of data fusion and Bayesian belief networks. Simulation
results indicate that the proposed approach could achieve significant
improvement on inference efficiencies in terms of power consumption and
inference speed.
</dc:description>
 <dc:description>Comment: accepted by ASPDAC 2018 conference</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01131</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structured Variational Inference for Coupled Gaussian Processes</dc:title>
 <dc:creator>Adam, Vincent</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Sparse variational approximations allow for principled and scalable inference
in Gaussian Process (GP) models. In settings where several GPs are part of the
generative model, theses GPs are a posteriori coupled. For many applications
such as regression where predictive accuracy is the quantity of interest, this
coupling is not crucial. Howewer if one is interested in posterior uncertainty,
it cannot be ignored. A key element of variational inference schemes is the
choice of the approximate posterior parameterization. When the number of latent
variables is large, mean field (MF) methods provide fast and accurate posterior
means while more structured posterior lead to inference algorithm of greater
computational complexity. Here, we extend previous sparse GP approximations and
propose a novel parameterization of variational posteriors in the multi-GP
setting allowing for fast and scalable inference capturing posterior
dependencies.
</dc:description>
 <dc:description>Comment: * Updated references. * Corrected typos</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:date>2017-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01131</dc:identifier>
 <dc:identifier>Advances in Approximate Bayesian Inference, NIPS 2017 Workshop</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01134</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accountability of AI Under the Law: The Role of Explanation</dc:title>
 <dc:creator>Doshi-Velez, Finale</dc:creator>
 <dc:creator>Kortz, Mason</dc:creator>
 <dc:creator>Budish, Ryan</dc:creator>
 <dc:creator>Bavitz, Chris</dc:creator>
 <dc:creator>Gershman, Sam</dc:creator>
 <dc:creator>O'Brien, David</dc:creator>
 <dc:creator>Schieber, Stuart</dc:creator>
 <dc:creator>Waldo, James</dc:creator>
 <dc:creator>Weinberger, David</dc:creator>
 <dc:creator>Wood, Alexandra</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The ubiquity of systems using artificial intelligence or &quot;AI&quot; has brought
increasing attention to how those systems should be regulated. The choice of
how to regulate AI systems will require care. AI systems have the potential to
synthesize large amounts of data, allowing for greater levels of
personalization and precision than ever before---applications range from
clinical decision support to autonomous driving and predictive policing. That
said, there exist legitimate concerns about the intentional and unintentional
negative consequences of AI systems. There are many ways to hold AI systems
accountable. In this work, we focus on one: explanation. Questions about a
legal right to explanation from AI systems was recently debated in the EU
General Data Protection Regulation, and thus thinking carefully about when and
how explanation from AI systems might improve accountability is timely. In this
work, we review contexts in which explanation is currently required under the
law, and then list the technical considerations that must be considered if we
desired AI systems that could provide kinds of explanations that are currently
required of humans.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:date>2017-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01134</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01149</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fuzzy clustering using linguistic-valued exponent</dc:title>
 <dc:creator>Le, Hung Thai</dc:creator>
 <dc:creator>Tran, Khang Ding</dc:creator>
 <dc:creator>Van Le, Hung</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The purpose of this paper is to study the algorithm FCM and some of its
famous innovations, analyse and discover the method of applying hedge algebra
theory that uses algebra to represent linguistic-valued variables, to FCM.
Then, this paper will propose a new FCM-based algorithm which uses hedge
algebra to model FCM's exponent parameter. Finally, the design, analysis and
implementation of the new algorithm as well some experimental results will be
presented to prove our algorithm's capacity of solving clustering problems in
practice.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01149</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01161</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Filterbanks from Raw Speech for Phone Recognition</dc:title>
 <dc:creator>Zeghidour, Neil</dc:creator>
 <dc:creator>Usunier, Nicolas</dc:creator>
 <dc:creator>Kokkinos, Iasonas</dc:creator>
 <dc:creator>Schatz, Thomas</dc:creator>
 <dc:creator>Synnaeve, Gabriel</dc:creator>
 <dc:creator>Dupoux, Emmanuel</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We train a bank of complex filters that operates on the raw waveform and
feeds into a convolutional neural network for end-to-end phone recognition.
These time-domain filterbanks (TD-filterbanks) are initialized as an
approximation of mel-filterbanks (MFSC, for mel-frequency spectral
coefficients), and then fine-tuned jointly with the remaining convolutional
architecture. We perform phone recognition experiments on TIMIT and show that
for several architectures, models trained on TD-filterbanks consistently
outperform their counterparts trained on comparable MFSC. We get our best
performance by learning all front-end steps, from pre-emphasis up to averaging.
Finally, we observe that the filters at convergence have an asymmetric impulse
response, and that some of them remain almost analytic.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01171</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Bane of Low-Dimensionality Clustering</dc:title>
 <dc:creator>Cohen-Addad, Vincent</dc:creator>
 <dc:creator>de Mesmay, Arnaud</dc:creator>
 <dc:creator>Rotenberg, Eva</dc:creator>
 <dc:creator>Roytman, Alan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  In this paper, we give a conditional lower bound of $n^{\Omega(k)}$ on
running time for the classic k-median and k-means clustering objectives (where
n is the size of the input), even in low-dimensional Euclidean space of
dimension four, assuming the Exponential Time Hypothesis (ETH). We also
consider k-median (and k-means) with penalties where each point need not be
assigned to a center, in which case it must pay a penalty, and extend our lower
bound to at least three-dimensional Euclidean space.
  This stands in stark contrast to many other geometric problems such as the
traveling salesman problem, or computing an independent set of unit spheres.
While these problems benefit from the so-called (limited) blessing of
dimensionality, as they can be solved in time $n^{O(k^{1-1/d})}$ or
$2^{n^{1-1/d}}$ in d dimensions, our work shows that widely-used clustering
objectives have a lower bound of $n^{\Omega(k)}$, even in dimension four.
  We complete the picture by considering the two-dimensional case: we show that
there is no algorithm that solves the penalized version in time less than
$n^{o(\sqrt{k})}$, and provide a matching upper bound of $n^{O(\sqrt{k})}$.
  The main tool we use to establish these lower bounds is the placement of
points on the moment curve, which takes its inspiration from constructions of
point sets yielding Delaunay complexes of high complexity.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01171</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01198</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design and Analysis of a Secure Three Factor User Authentication Scheme
  Using Biometric and Smart Card</dc:title>
 <dc:creator>Mustafa, Hossen Asiful</dc:creator>
 <dc:creator>Kafi, Hasan Muhammad</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Password security can no longer provide enough security in the area of remote
user authentication. Considering this security drawback, researchers are trying
to find solution with multifactor remote user authentication system. Recently,
three factor remote user authentication using biometric and smart card has
drawn a considerable attention of the researchers. However, most of the current
proposed schemes have security flaws. They are vulnerable to attacks like user
impersonation attack, server masquerading attack, password guessing attack,
insider attack, denial of service attack, forgery attack, etc. Also, most of
them are unable to provide mutual authentication, session key agreement and
password, or smart card recovery system. Considering these drawbacks, we
propose a secure three factor user authentication scheme using biometric and
smart card. Through security analysis, we show that our proposed scheme can
overcome drawbacks of existing systems and ensure high security in remote user
authentication.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures, 2 tables</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01198</dc:identifier>
 <dc:identifier>International Journal of Computer Science and Information Security
  (IJCSIS), Vol. 15, No. 6, June 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01201</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional Drift Networks for Video Classification</dc:title>
 <dc:creator>Graham, Dillon</dc:creator>
 <dc:creator>Langroudi, Seyed Hamed Fatemi</dc:creator>
 <dc:creator>Kanan, Christopher</dc:creator>
 <dc:creator>Kudithipudi, Dhireesha</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  Analyzing spatio-temporal data like video is a challenging task that requires
processing visual and temporal information effectively. Convolutional Neural
Networks have shown promise as baseline fixed feature extractors through
transfer learning, a technique that helps minimize the training cost on visual
information. Temporal information is often handled using hand-crafted features
or Recurrent Neural Networks, but this can be overly specific or prohibitively
complex. Building a fully trainable system that can efficiently analyze
spatio-temporal data without hand-crafted features or complex training is an
open challenge. We present a new neural network architecture to address this
challenge, the Convolutional Drift Network (CDN). Our CDN architecture combines
the visual feature extraction power of deep Convolutional Neural Networks with
the intrinsically efficient temporal processing provided by Reservoir
Computing. In this introductory paper on the CDN, we provide a very simple
baseline implementation tested on two egocentric (first-person) video activity
datasets.We achieve video-level activity classification results on-par with
state-of-the art methods. Notably, performance on this complex spatio-temporal
task was produced by only training a single feed-forward layer in the CDN.
</dc:description>
 <dc:description>Comment: Published in IEEE Rebooting Computing</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01201</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01204</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Metrics for Deep Generative Models</dc:title>
 <dc:creator>Chen, Nutan</dc:creator>
 <dc:creator>Klushyn, Alexej</dc:creator>
 <dc:creator>Kurle, Richard</dc:creator>
 <dc:creator>Jiang, Xueyan</dc:creator>
 <dc:creator>Bayer, Justin</dc:creator>
 <dc:creator>van der Smagt, Patrick</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Neural samplers such as variational autoencoders (VAEs) or generative
adversarial networks (GANs) approximate distributions by transforming samples
from a simple random source---the latent space---to samples from a more complex
distribution represented by a dataset. While the manifold hypothesis implies
that the density induced by a dataset contains large regions of low density,
the training criterions of VAEs and GANs will make the latent space densely
covered. Consequently points that are separated by low-density regions in
observation space will be pushed together in latent space, making stationary
distances poor proxies for similarity. We transfer ideas from Riemannian
geometry to this setting, letting the distance between two points be the
shortest path on a Riemannian manifold induced by the transformation. The
method yields a principled distance measure, provides a tool for visual
inspection of deep generative models, and an alternative to linear
interpolation in latent space. In addition, it can be applied for robot
movement generalization using previously learned skills. The method is
evaluated on a synthetic dataset with known ground truth; on a simulated robot
arm dataset; on human motion capture data; and on a generative model of
handwritten digits.
</dc:description>
 <dc:description>Comment: Submitted to the 21st International Conference on Artificial
  Intelligence and Statistics (AISTATS) 2018 on 13 October 2017</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01214</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Refounding legitimacy towards Aethogenesis</dc:title>
 <dc:creator>Auber, Olivier</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The fusion of humans and technology takes us into an unknown world described
by some authors as populated by quasi living species that would relegate us -
ordinary humans - to the rank of alienated agents emptied of our identity and
consciousness. I argue instead that our world is woven of simple though
invisible perspectives which - if we become aware of them - may renew our
ability for making judgments and enhance our autonomy. I became aware of these
invisible perspectives by observing and practicing a real time collective net
art experiment called the Poietic Generator. As the perspectives unveiled by
this experiment are invisible I have called them anoptical perspectives i.e.
non-optical by analogy with the optical perspective of the Renaissance. Later I
have come to realize that these perspectives obtain their cognitive structure
from the political origins of our language. Accordingly it is possible to
define certain cognitive criteria for assessing the legitimacy of the anoptical
perspectives just like some artists and architects of the Renaissance defined
the geometrical criteria that established the legitimacy of the optical one.
</dc:description>
 <dc:description>Comment: Proceedings of 18th International Research Conference in The
  Planetary Collegium's Series 'Art &amp; consciousness in the post-biological era'
  Shanghai 2015. 9 pages. 4 figures</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01214</dc:identifier>
 <dc:identifier>Technoetic Arts Volume 14 Number 3 December 2016 pp. 235-249(15)</dc:identifier>
 <dc:identifier>doi:10.1386/tear.14.3.235_1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01218</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Background Subtraction via Fast Robust Matrix Completion</dc:title>
 <dc:creator>Rezaei, Behnaz</dc:creator>
 <dc:creator>Ostadabbas, Sarah</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  Background subtraction is the primary task of the majority of video
inspection systems. The most important part of the background subtraction which
is common among different algorithms is background modeling. In this regard,
our paper addresses the problem of background modeling in a computationally
efficient way, which is important for current eruption of &quot;big data&quot; processing
coming from high resolution multi-channel videos. Our model is based on the
assumption that background in natural images lies on a low-dimensional
subspace. We formulated and solved this problem in a low-rank matrix completion
framework. In modeling the background, we benefited from the in-face extended
Frank-Wolfe algorithm for solving a defined convex optimization problem. We
evaluated our fast robust matrix completion (fRMC) method on both background
models challenge (BMC) and Stuttgart artificial background subtraction (SABS)
datasets. The results were compared with the robust principle component
analysis (RPCA) and low-rank robust matrix completion (RMC) methods, both
solved by inexact augmented Lagrangian multiplier (IALM). The results showed
faster computation, at least twice as when IALM solver is used, while having a
comparable accuracy even better in some challenges, in subtracting the
backgrounds in order to detect moving objects in the scene.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01224</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Design of a Mobile App for Promotion of Physical Activity and
  Self-Management in Prostate Cancer Survivors: Personas, Feature Ideation and
  Low-Fidelity Prototyping</dc:title>
 <dc:creator>Monteiro-Guerra, Francisco</dc:creator>
 <dc:creator>Rivera-Romero, Octavio</dc:creator>
 <dc:creator>Mylonopoulou, Vasiliki</dc:creator>
 <dc:creator>Signorelli, Gabriel R.</dc:creator>
 <dc:creator>Zambrana, Francisco</dc:creator>
 <dc:creator>Fernandez-Luque, Luis</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Most prostate cancer survivors are confronted with disease-related and
treatment-related side effects that impact their quality of life. A tool that
combines specific physical activity coaching with the promotion of a healthy
lifestyle and self-management guidance might be a successful method to enhance
a lifestyle change in these patients. As a prerequisite for useful health
technology, it is important to consider a design process centred in the
patients. The aim of this study was to investigate the context of the problem
and the user needs to support the ideation of a low-fidelity prototype of a
tool to promote a healthy lifestyle among early-stage prostate cancer
survivors. A user-centred design approach was followed involving a
multidisciplinary team. The prototype was developed in 3 phases. In phase 1,
the context was studied with 2 systematic reviews of the state of practice and
consulting with 3 specialists in Oncology, resulting in a global use case and
main requirements. In phase 2, the needs and barriers of the users were studied
based on literature research and validated with 3 specialists, resulting in the
creation of 3 personas. In phase 3, 2 sessions were held to ideate and
prioritize possible app features, based on brainstorming and selection
techniques. Using the Ninja Mock and Proto.io software a low-fidelity prototype
was developed, resulting in 25 interactive screens. Understanding the user
needs and context seems to be essential to highlight key goals, hence
facilitating the bridge between ideation of the tool and the intended users
tasks and experiences. The conclusion of this first stage of the design process
brings valuable details (such as barriers of the users to technology and to
physical activity) for future iterations of design of the mobile app.
</dc:description>
 <dc:description>Comment: To be published in conference proceedings of the 30th IEEE
  International Symposium on Computer-Based Medical Systems - IEEE CBMS 2017</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01228</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Fast Successive Over-Relaxation Algorithm for Force-Directed Network
  Graph Drawing</dc:title>
 <dc:creator>Wang, Yong-Xian</dc:creator>
 <dc:creator>Wang, Zhang-Hua</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Force-directed approach is one of the most widely used methods in graph
drawing research. There are two main problems with the traditional
force-directed algorithms. First, there is no mature theory to ensure the
convergence of iteration sequence used in the algorithm and further, it is hard
to estimate the rate of convergence even if the convergence is satisfied.
Second, the running time cost is increased intolerablely in drawing large-
scale graphs, and therefore the advantages of the force-directed approach are
limited in practice. This paper is focused on these problems and presents a
sufficient condition for ensuring the convergence of iterations. We then
develop a practical heuristic algorithm for speeding up the iteration in
force-directed approach using a successive over-relaxation (SOR) strategy. The
results of computational tests on the several benchmark graph datasets used
widely in graph drawing research show that our algorithm can dramatically
improve the performance of force-directed approach by decreasing both the
number of iterations and running time, and is 1.5 times faster than the latter
on average.
</dc:description>
 <dc:description>Comment: 17 pages, 4 figures, 1 table</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01228</dc:identifier>
 <dc:identifier>Sci. China Inf. Sci. (2012) 55: 677</dc:identifier>
 <dc:identifier>doi:10.1007/s11432-011-4208-9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01229</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward real-time data query systems in HEP</dc:title>
 <dc:creator>Pivarski, Jim</dc:creator>
 <dc:creator>Lange, David</dc:creator>
 <dc:creator>Jatuphattharachat, Thanat</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Exploratory data analysis tools must respond quickly to a user's questions,
so that the answer to one question (e.g. a visualized histogram or fit) can
influence the next. In some SQL-based query systems used in industry, even very
large (petabyte) datasets can be summarized on a human timescale (seconds),
employing techniques such as columnar data representation, caching, indexing,
and code generation/JIT-compilation. This article describes progress toward
realizing such a system for High Energy Physics (HEP), focusing on the
intermediate problems of optimizing data access and calculations for &quot;query
sized&quot; payloads, such as a single histogram or group of histograms, rather than
large reconstruction or data-skimming jobs. These techniques include direct
extraction of ROOT TBranches into Numpy arrays and compilation of Python
analysis functions (rather than SQL) to be executed very quickly. We will also
discuss the problem of caching and actively delivering jobs to worker nodes
that have the necessary input data preloaded in cache. All of these pieces of
the larger solution are available as standalone GitHub repositories, and could
be used in current analyses.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures, proceedings for ACAT 2017</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01229</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01231</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Tight Approximation for Fully Dynamic Bin Packing without Bundling</dc:title>
 <dc:creator>Feldkord, Bj&#xf6;rn</dc:creator>
 <dc:creator>Feldotto, Matthias</dc:creator>
 <dc:creator>Riechers, S&#xf6;ren</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider a variant of the classical Bin Packing Problem, called Fully
Dynamic Bin Packing. In this variant, items of a size in $(0,1]$ must be packed
in bins of unit size. In each time step, an item either arrives or departs from
the packing. An algorithm for this problem must maintain a feasible packing
while only repacking a bounded number of items in each time step.
  We develop an algorithm which repacks only a constant number of items per
time step and, unlike previous work, does not rely on bundling of small items
which allowed those solutions to move an unbounded number of small items as
one. Our algorithm has an asymptotic approximation ratio of roughly $1.3871$
which is complemented by a lower bound of Balogh et al., resulting in a tight
approximation ratio for this problem. As a direct corollary, we also close the
gap to the lower bound of the Relaxed Online Bin Packing Problem in which only
insertions of items occur.
</dc:description>
 <dc:description>Comment: 25 pages, 2 figures</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01239</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Routing Networks: Adaptive Selection of Non-linear Functions for
  Multi-Task Learning</dc:title>
 <dc:creator>Rosenbaum, Clemens</dc:creator>
 <dc:creator>Klinger, Tim</dc:creator>
 <dc:creator>Riemer, Matthew</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Multi-task learning (MTL) with neural networks leverages commonalities in
tasks to improve performance, but often suffers from task interference which
reduces the benefits of transfer. To address this issue we introduce the
routing network paradigm, a novel neural network and training algorithm. A
routing network is a kind of self-organizing neural network consisting of two
components: a router and a set of one or more function blocks. A function block
may be any neural network - for example a fully-connected or a convolutional
layer. Given an input the router makes a routing decision, choosing a function
block to apply and passing the output back to the router recursively,
terminating when a fixed recursion depth is reached. In this way the routing
network dynamically composes different function blocks for each input. We
employ a collaborative multi-agent reinforcement learning (MARL) approach to
jointly train the router and function blocks. We evaluate our model against
cross-stitch networks and shared-layer baselines on multi-task settings of the
MNIST, mini-imagenet, and CIFAR-100 datasets. Our experiments demonstrate a
significant improvement in accuracy, with sharper convergence. In addition,
routing networks have nearly constant per-task training cost while cross-stitch
networks scale linearly with the number of tasks. On CIFAR-100 (20 tasks) we
obtain cross-stitch performance levels with an 85% reduction in training time.
</dc:description>
 <dc:description>Comment: Under Review at ICLR 2018</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:date>2017-12-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01239</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01243</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ResBinNet: Residual Binary Neural Network</dc:title>
 <dc:creator>Ghasemzadeh, Mohammad</dc:creator>
 <dc:creator>Samragh, Mohammad</dc:creator>
 <dc:creator>Koushanfar, Farinaz</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Recent efforts on training light-weight binary neural networks offer
promising execution/memory efficiency. This paper introduces ResBinNet, which
is a composition of two interlinked methodologies aiming to address the slow
convergence speed and limited accuracy of binary convolutional neural networks.
The first method, called residual binarization, learns a multi-level binary
representation for the features within a certain neural network layer. The
second method, called temperature adjustment, gradually binarizes the weights
of a particular layer. The two methods jointly learn a set of soft-binarized
parameters that improve the convergence rate and accuracy of binary neural
networks. We corroborate the applicability and scalability of ResBinNet by
implementing a prototype hardware accelerator. The accelerator is
reconfigurable in terms of the numerical precision of the binarized features,
offering a trade-off between runtime and inference accuracy.
</dc:description>
 <dc:description>Comment: Added the results of large-scale experiments (Imagenet); Extended the
  comparison with prior art</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:date>2017-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01243</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01244</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lifelong Learning by Adjusting Priors</dc:title>
 <dc:creator>Amit, Ron</dc:creator>
 <dc:creator>Meir, Ron</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In representational lifelong learning an agent aims to learn to solve novel
tasks while updating its representation in light of previous tasks. Under the
assumption that future tasks are `related' to previous tasks, representations
should be learned in such a way that they capture the common structure across
learned tasks, while allowing the learner sufficient flexibility to adapt to
novel aspects of a new task. We develop a framework for lifelong learning in
deep neural networks that is based on generalization bounds, developed within
the PAC-Bayes framework. Learning takes place through the construction of a
distribution over networks based on the tasks seen so far, and its utilization
for learning a new task. Thus, prior knowledge is incorporated through setting
a history-dependent prior for novel tasks. We develop a gradient-based
algorithm implementing these ideas, based on minimizing an objective function
motivated by generalization bounds, and demonstrate its effectiveness through
numerical examples.
</dc:description>
 <dc:description>Comment: 16 pages, 1 figure</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01244</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01246</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Artificial Delay Based ARC of a Class of Uncertain EL Systems with Only
  Position Feedback</dc:title>
 <dc:creator>Roy, Spandan</dc:creator>
 <dc:creator>Kar, Indra Narayan</dc:creator>
 <dc:creator>Lee, Jinoh</dc:creator>
 <dc:creator>Tsagarakis, Nikos</dc:creator>
 <dc:creator>Caldwell, Darwin G.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, the tracking control problem of an Euler-Lagrange system is
addressed with regard to parametric uncertainties, and an adaptive-robust
control strategy, christened Time-Delayed Adaptive Robust Control (TARC), is
presented. TARC approximates the unknown dynamics through the time-delayed
estimation, and the adaptive-robust control provides robustness against the
approximation error. The novel adaptation law of TARC, in contrast to the
conventional adaptive-robust control methodologies, requires neither complete
model of the system nor any knowledge of predefined uncertainty bounds to
compute the switching gain, and circumvents the over- and underestimation
problems of the switching gain. Moreover, TARC only utilizes position feedback
and approximates the velocity and acceleration terms from the past position
data. The adopted state-derivatives estimation method in TARC avoids any
explicit requirement of external low pass filters for the removal of
measurement noise. A new stability notion in continuous-time domain is proposed
considering the time delay, adaptive law, and state-derivatives estimation
which in turn provides a selection criterion for gains and sampling interval of
the controller.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01246</dc:identifier>
 <dc:identifier>doi:10.1109/TCST.2017.2772210</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01249</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Unmixing of Hyperspectral Data With Sparsity Constraint</dc:title>
 <dc:creator>Khoshsokhan, Sara</dc:creator>
 <dc:creator>Rajabi, Roozbeh</dc:creator>
 <dc:creator>Zayyani, Hadi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Spectral unmixing (SU) is a data processing problem in hyperspectral remote
sensing. The significant challenge in the SU problem is how to identify
endmembers and their weights, accurately. For estimation of signature and
fractional abundance matrices in a blind problem, nonnegative matrix
factorization (NMF) and its developments are used widely in the SU problem. One
of the constraints which was added to NMF is sparsity constraint that was
regularized by L 1/2 norm. In this paper, a new algorithm based on distributed
optimization has been used for spectral unmixing. In the proposed algorithm, a
network including single-node clusters has been employed. Each pixel in
hyperspectral images considered as a node in this network. The distributed
unmixing with sparsity constraint has been optimized with diffusion LMS
strategy, and then the update equations for fractional abundance and signature
matrices are obtained. Simulation results based on defined performance metrics,
illustrate advantage of the proposed algorithm in spectral unmixing of
hyperspectral data compared with other methods. The results show that the AAD
and SAD of the proposed approach are improved respectively about 6 and 27
percent toward distributed unmixing in SNR=25dB.
</dc:description>
 <dc:description>Comment: 6 pages, conference paper</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01250</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Robustness of LWPP and WPP, with an Application to Graph
  Reconstruction</dc:title>
 <dc:creator>Hemaspaandra, Edith</dc:creator>
 <dc:creator>Hemaspaandra, Lane A.</dc:creator>
 <dc:creator>Spakowski, Holger</dc:creator>
 <dc:creator>Watanabe, Osamu</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We show that the counting class LWPP [FFK94] remains unchanged even if one
allows a polynomial number of gap values rather than one. On the other hand, we
show that it is impossible to improve this from polynomially many gap values to
a superpolynomial number of gap values by relativizable proof techniques.
  The first of these results implies that the Legitimate Deck Problem (from the
study of graph reconstruction) is in LWPP (and thus low for PP, i.e., $\rm
PP^\mbox{Legitimate Deck} = PP$) if the weakened version of the Reconstruction
Conjecture holds in which the number of nonisomorphic preimages is assumed
merely to be polynomially bounded. This strengthens the 1992 result of
K\&quot;{o}bler, Sch\&quot;{o}ning, and Tor\'{a}n [KST92] that the Legitimate Deck
Problem is in LWPP if the Reconstruction Conjecture holds, and provides
strengthened evidence that the Legitimate Deck Problem is not NP-hard.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01250</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01254</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Detection, Exploitation, and Elimination of Double-Fetch Bugs
  using Modern CPU Features</dc:title>
 <dc:creator>Schwarz, Michael</dc:creator>
 <dc:creator>Gruss, Daniel</dc:creator>
 <dc:creator>Lipp, Moritz</dc:creator>
 <dc:creator>Maurice, Cl&#xe9;mentine</dc:creator>
 <dc:creator>Schuster, Thomas</dc:creator>
 <dc:creator>Fogh, Anders</dc:creator>
 <dc:creator>Mangard, Stefan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Double-fetch bugs are a special type of race condition, where an unprivileged
execution thread is able to change a memory location between the time-of-check
and time-of-use of a privileged execution thread. If an unprivileged attacker
changes the value at the right time, the privileged operation becomes
inconsistent, leading to a change in control flow, and thus an escalation of
privileges for the attacker. More severely, such double-fetch bugs can be
introduced by the compiler, entirely invisible on the source-code level.
  We propose novel techniques to efficiently detect, exploit, and eliminate
double-fetch bugs. We demonstrate the first combination of state-of-the-art
cache attacks with kernel-fuzzing techniques to allow fully automated
identification of double fetches. We demonstrate the first fully automated
reliable detection and exploitation of double-fetch bugs, making manual
analysis as in previous work superfluous. We show that cache-based triggers
outperform state-of-the-art exploitation techniques significantly, leading to
an exploitation success rate of up to 97%. Our modified fuzzer automatically
detects double fetches and automatically narrows down this candidate set for
double-fetch bugs to the exploitable ones. We present the first generic
technique based on hardware transactional memory, to eliminate double-fetch
bugs in a fully automated and transparent manner. We extend defensive
programming techniques by retrofitting arbitrary code with automated
double-fetch prevention, both in trusted execution environments as well as in
syscalls, with a performance overhead below 1%.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01254</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01262</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Graph Clustering and Sparsification</dc:title>
 <dc:creator>Sun, He</dc:creator>
 <dc:creator>Zanetti, Luca</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Graph clustering is a fundamental computational problem with a number of
applications in algorithm design, machine learning, data mining, and analysis
of social networks. Over the past decades, researchers have proposed a number
of algorithmic design methods for graph clustering. Most of these methods,
however, are based on complicated spectral techniques or convex optimisation,
and cannot be directly applied for clustering many networks that occur in
practice, whose information is often collected on different sites. Designing a
simple and distributed clustering algorithm is of great interest, and has wide
applications for processing big datasets.
  In this paper we present a simple and distributed algorithm for graph
clustering: for a wide class of graphs that are characterised by a strong
cluster-structure, our algorithm finishes in a poly-logarithmic number of
rounds, and recovers a partition of the graph close to optimal. One of the main
components behind our algorithm is a sampling scheme that, given a dense graph
as input, produces a sparse subgraph that provably preserves the
cluster-structure of the input. Compared with previous sparsification
algorithms that require Laplacian solvers or involve combinatorial
constructions, this component is easy to implement in a distributed way and
runs fast in practice.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01262</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01263</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SparseNN: An Energy-Efficient Neural Network Accelerator Exploiting
  Input and Output Sparsity</dc:title>
 <dc:creator>Zhu, Jingyang</dc:creator>
 <dc:creator>Jiang, Jingbo</dc:creator>
 <dc:creator>Chen, Xizi</dc:creator>
 <dc:creator>Tsui, Chi-Ying</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Contemporary Deep Neural Network (DNN) contains millions of synaptic
connections with tens to hundreds of layers. The large computation and memory
requirements pose a challenge to the hardware design. In this work, we leverage
the intrinsic activation sparsity of DNN to substantially reduce the execution
cycles and the energy consumption. An end-to-end training algorithm is proposed
to develop a lightweight run-time predictor for the output activation sparsity
on the fly. From our experimental results, the computation overhead of the
prediction phase can be reduced to less than 5% of the original feedforward
phase with negligible accuracy loss. Furthermore, an energy-efficient hardware
architecture, SparseNN, is proposed to exploit both the input and output
sparsity. SparseNN is a scalable architecture with distributed memories and
processing elements connected through a dedicated on-chip network. Compared
with the state-of-the-art accelerators which only exploit the input sparsity,
SparseNN can achieve a 10%-70% improvement in throughput and a power reduction
of around 50%.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01263</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01283</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mandolin: A Knowledge Discovery Framework for the Web of Data</dc:title>
 <dc:creator>Soru, Tommaso</dc:creator>
 <dc:creator>Esteves, Diego</dc:creator>
 <dc:creator>Marx, Edgard</dc:creator>
 <dc:creator>Ngomo, Axel-Cyrille Ngonga</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>G.3.8</dc:subject>
 <dc:subject>E.1.3</dc:subject>
 <dc:description>  Markov Logic Networks join probabilistic modeling with first-order logic and
have been shown to integrate well with the Semantic Web foundations. While
several approaches have been devised to tackle the subproblems of rule mining,
grounding, and inference, no comprehensive workflow has been proposed so far.
In this paper, we fill this gap by introducing a framework called Mandolin,
which implements a workflow for knowledge discovery specifically on RDF
datasets. Our framework imports knowledge from referenced graphs, creates
similarity relationships among similar literals, and relies on state-of-the-art
techniques for rule mining, grounding, and inference computation. We show that
our best configuration scales well and achieves at least comparable results
with respect to other statistical-relational-learning algorithms on link
prediction.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01283</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01287</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovering More Precise Process Models from Event Logs by Filtering Out
  Chaotic Activities</dc:title>
 <dc:creator>Tax, Niek</dc:creator>
 <dc:creator>Sidorova, Natalia</dc:creator>
 <dc:creator>van der Aalst, Wil M. P.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Process Discovery is concerned with the automatic generation of a process
model that describes a business process from execution data of that business
process. Real life event logs can contain chaotic activities. These activities
are independent of the state of the process and can, therefore, happen at
rather arbitrary points in time. We show that the presence of such chaotic
activities in an event log heavily impacts the quality of the process models
that can be discovered with process discovery techniques. The current modus
operandi for filtering activities from event logs is to simply filter out
infrequent activities. We show that frequency-based filtering of activities
does not solve the problems that are caused by chaotic activities. Moreover, we
propose a novel technique to filter out chaotic activities from event logs. We
evaluate this technique on a collection of seventeen real-life event logs that
originate from both the business process management domain and the smart home
environment domain. As demonstrated, the developed activity filtering methods
enable the discovery of process models that are more behaviorally specific
compared to process models that are discovered using standard frequency-based
filtering.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01287</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01293</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Localization of Multiple Targets with Identical Radar Signatures in
  Multipath Environments with Correlated Blocking</dc:title>
 <dc:creator>Aditya, Sundar</dc:creator>
 <dc:creator>Molisch, Andreas F.</dc:creator>
 <dc:creator>Rabeah, Naif</dc:creator>
 <dc:creator>Behairy, Hatim</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper addresses the problem of localizing an unknown number of targets,
all having the same radar signature, by a distributed MIMO radar consisting of
single antenna transmitters and receivers that cannot determine directions of
departure and arrival. Furthermore, we consider the presence of multipath
propagation, and the possible (correlated) blocking of the direct paths (going
from the transmitter and reflecting off a target to the receiver). In its most
general form, this problem can be cast as a Bayesian estimation problem where
every multipath component is accounted for. However, when the environment map
is unknown, this problem is ill-posed and hence, a tractable approximation is
derived where only direct paths are accounted for. In particular, we take into
account the correlated blocking by scatterers in the environment which appears
as a prior term in the Bayesian estimation framework. A sub-optimal
polynomial-time algorithm to solve the Bayesian multi-target localization
problem with correlated blocking is proposed and its performance is evaluated
using simulations. We found that when correlated blocking is severe, assuming
the blocking events to be independent and having constant probability (as was
done in previous papers) resulted in poor detection performance, with false
alarms more likely to occur than detections.
</dc:description>
 <dc:description>Comment: To appear in the IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01293</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01295</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Data Acquisition for Statistical Estimation</dc:title>
 <dc:creator>Chen, Yiling</dc:creator>
 <dc:creator>Immorlica, Nicole</dc:creator>
 <dc:creator>Lucier, Brendan</dc:creator>
 <dc:creator>Syrgkanis, Vasilis</dc:creator>
 <dc:creator>Ziani, Juba</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider a data analyst's problem of purchasing data from strategic agents
to compute an unbiased estimate of a statistic of interest. Agents incur
private costs to reveal their data and the costs can be arbitrarily correlated
with their data. Once revealed, data are verifiable. This paper focuses on
linear unbiased estimators. We design an individually rational and incentive
compatible mechanism that optimizes the worst-case mean-squared error of the
estimation, where the worst-case is over the unknown correlation between costs
and data, subject to a budget constraint in expectation. We characterize the
form of the optimal mechanism in closed-form. We further extend our results to
acquiring data for estimating a parameter in regression analysis, where private
costs can correlate with the values of the dependent variable but not with the
values of the independent variables.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01295</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01297</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Implicit Weight Uncertainty in Neural Networks</dc:title>
 <dc:creator>Pawlowski, Nick</dc:creator>
 <dc:creator>Rajchl, Martin</dc:creator>
 <dc:creator>Glocker, Ben</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We interpret HyperNetworks within the framework of variational inference
within implicit distributions. Our method, Bayes by Hypernet, is able to model
a richer variational distribution than previous methods. Experiments show that
it achieves comparable predictive performance on the MNIST classification task
while providing higher predictive uncertainties compared to MC-Dropout and
regular maximum likelihood training.
</dc:description>
 <dc:description>Comment: Submitted to Bayesian Deep Learning Workshop at NIPS 2017</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01297</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01299</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BoostClean: Automated Error Detection and Repair for Machine Learning</dc:title>
 <dc:creator>Krishnan, Sanjay</dc:creator>
 <dc:creator>Franklin, Michael J.</dc:creator>
 <dc:creator>Goldberg, Ken</dc:creator>
 <dc:creator>Wu, Eugene</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Predictive models based on machine learning can be highly sensitive to data
error. Training data are often combined with a variety of different sources,
each susceptible to different types of inconsistencies, and new data streams
during prediction time, the model may encounter previously unseen
inconsistencies. An important class of such inconsistencies is domain value
violations that occur when an attribute value is outside of an allowed domain.
We explore automatically detecting and repairing such violations by leveraging
the often available clean test labels to determine whether a given detection
and repair combination will improve model accuracy. We present BoostClean which
automatically selects an ensemble of error detection and repair combinations
using statistical boosting. BoostClean selects this ensemble from an extensible
library that is pre-populated general detection functions, including a novel
detector based on the Word2Vec deep learning model, which detects errors across
a diverse set of domains. Our evaluation on a collection of 12 datasets from
Kaggle, the UCI repository, real-world data analyses, and production datasets
that show that Boost- Clean can increase absolute prediction accuracy by up to
9% over the best non-ensembled alternatives. Our optimizations including
parallelism, materialization, and indexing techniques show a 22.2x end-to-end
speedup on a 16-core machine.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01299</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01306</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning-Based Dynamic Watermarking for Secure Signal
  Authentication in the Internet of Things</dc:title>
 <dc:creator>Ferdowsi, Aidin</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Securing the Internet of Things (IoT) is a necessary milestone toward
expediting the deployment of its applications and services. In particular, the
functionality of the IoT devices is extremely dependent on the reliability of
their message transmission. Cyber attacks such as data injection,
eavesdropping, and man-in-the-middle threats can lead to security challenges.
Securing IoT devices against such attacks requires accounting for their
stringent computational power and need for low-latency operations. In this
paper, a novel deep learning method is proposed for dynamic watermarking of IoT
signals to detect cyber attacks. The proposed learning framework, based on a
long short-term memory (LSTM) structure, enables the IoT devices to extract a
set of stochastic features from their generated signal and dynamically
watermark these features into the signal. This method enables the IoT's cloud
center, which collects signals from the IoT devices, to effectively
authenticate the reliability of the signals. Furthermore, the proposed method
prevents complicated attack scenarios such as eavesdropping in which the cyber
attacker collects the data from the IoT devices and aims to break the
watermarking algorithm. Simulation results show that, with an attack detection
delay of under 1 second the messages can be transmitted from IoT devices with
an almost 100% reliability.
</dc:description>
 <dc:description>Comment: 6 pages, 9 figures</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01306</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01316</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Stable and Energetically Economical Walking with RAMone</dc:title>
 <dc:creator>Nash, Audrow</dc:creator>
 <dc:creator>Chen, Yu-Ming</dc:creator>
 <dc:creator>Smit-Anseeuw, Nils</dc:creator>
 <dc:creator>Zaytsev, Petr</dc:creator>
 <dc:creator>Remy, C. David</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this paper, we optimize over the control parameter space of our
planar-bipedal robot, RAMone, for stable and energetically economical walking
at various speeds. We formulate this task as an episodic reinforcement learning
problem and use Covariance Matrix Adaptation. The parameters we are interested
in modifying include gains from our Hybrid Zero Dynamics style controller and
from RAMone's low-level motor controllers.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01320</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Rethinking of RF Wireless Power Transfer: How to Re-Green the Future
  Networks?</dc:title>
 <dc:creator>Tran, Ha-Vu</dc:creator>
 <dc:creator>Kaddoum, Georges</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  Green radio communication is an emerging topic since the overall footprint of
information and communication technology (ICT) services is predicted to triple
between 2007 and 2020. Given this research line, energy harvesting (EH) and
wireless power transfer (WPT) networks can be evaluated as promising
approaches. In this paper, an overview of recent trends for future green
networks on the platforms of EH and WPT is provided. By rethinking the
application of radio frequency (RF)-WPT, a new concept, namely green RF-WTP, is
introduced. Accordingly, opening challenges and promising combinations among
current technologies, such as small-cell, millimeter (mm)-wave, and Internet of
Things (IoT) networks, are discussed in details to seek solutions for the
question with how to re-green the future networks?
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01320</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01323</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constant Approximation for $k$-Median and $k$-Means with Outliers via
  Iterative Rounding</dc:title>
 <dc:creator>Krishnaswamy, Ravishankar</dc:creator>
 <dc:creator>Li, Shi</dc:creator>
 <dc:creator>Sandeep, Sai</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper, we present a novel iterative rounding framework for many
clustering problems. This leads to an $(\alpha_1 + \epsilon \approx 7.08 +
\epsilon)$-approximation algorithm for $k$-median with outliers, greatly
improving upon the large implicit constant approximation ratio of Chen [Chen,
SODA 08]. For $k$-means with outliers, we give an $(\alpha_2+\epsilon \approx
53 + \epsilon)$-approximation, which is the first $O(1)$-approximation for this
problem. The iterative algorithm framework is very versatile; we show how it
can be used to give $\alpha_1$- and $(\alpha_1 + \epsilon)$-approximation
algorithms for matroid median and knapsack median problems respectively,
improving upon the previous best approximations ratios of $8$~[Swamy, ACM
Trans.\ Algorithms] and $17.46$ [Byrka et al, ESA 2015].
  The natural LP relaxation for the $k$-median/$k$-means with outliers problem
has an unbounded integrality gap. In spite of this negative result, our
iterative rounding framework shows that we can round an LP solution to an
\emph{almost-integral} solution of small cost, in which we have at most two
fractionally open facilities. Thus, the LP integrality gap arises due to the
gap between almost-integral and fully-integral solutions. Then, using a
pre-processing procedure, we show how to convert an almost-integral solution to
a fully-integral solution losing only a constant-factor in the approximation
ratio. By further using a sparsification technique, the additive factor loss
incurred by the conversion can be reduced to any $\epsilon &gt; 0$.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01323</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01327</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phototactic Supersmarticles</dc:title>
 <dc:creator>Cannon, Sarah</dc:creator>
 <dc:creator>Daymude, Joshua J.</dc:creator>
 <dc:creator>Savoie, William</dc:creator>
 <dc:creator>Warkentin, Ross</dc:creator>
 <dc:creator>Li, Shengkai</dc:creator>
 <dc:creator>Goldman, Daniel I.</dc:creator>
 <dc:creator>Randall, Dana</dc:creator>
 <dc:creator>Richa, Andrea W.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Smarticles, or smart active particles, are small robots equipped with only
basic movement and sensing abilities that are incapable of rotating or
displacing individually. We study the ensemble behavior of smarticles, i.e.,
the behavior a collective of these very simple computational elements can
achieve, and how such behavior can be implemented using minimal programming. We
show that an ensemble of smarticles constrained to remain close to one another
(which we call a supersmarticle), achieves directed locomotion toward or away
from a light source, a phenomenon known as phototaxing. We present experimental
and theoretical models of phototactic supersmarticles that collectively move
with a directed displacement in response to light. The motion of the
supersmarticle is approximately Brownian, and is a result of chaotic
interactions among smarticles. The system can be directed by introducing
asymmetries among the individual smarticle's behavior, in our case by varying
activity levels in response to light, resulting in supersmarticle biased
motion.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01327</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01328</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An homotopy method for $\ell_p$ regression provably beyond
  self-concordance and in input-sparsity time</dc:title>
 <dc:creator>Bubeck, S&#xe9;bastien</dc:creator>
 <dc:creator>Cohen, Michael B.</dc:creator>
 <dc:creator>Lee, Yin Tat</dc:creator>
 <dc:creator>Li, Yuanzhi</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the problem of linear regression where the $\ell_2^n$ norm loss
(i.e., the usual least squares loss) is replaced by the $\ell_p^n$ norm. We
show how to solve such problems up to machine precision in $O^*(n^{|1/2 -
1/p|})$ (dense) matrix-vector products and $O^*(1)$ matrix inversions, or
alternatively in $O^*(n^{|1/2 - 1/p|})$ calls to a (sparse) linear system
solver. This improves the state of the art for any $p\not\in \{1,2,+\infty\}$.
Furthermore we also propose a randomized algorithm solving such problems in
{\em input sparsity time}, i.e., $O^*(Z + \mathrm{poly}(d))$ where $Z$ is the
size of the input and $d$ is the number of variables. Such a result was only
known for $p=2$. Finally we prove that these results lie outside the scope of
the Nesterov-Nemirovski's theory of interior point methods by showing that any
symmetric self-concordant barrier on the $\ell_p^n$ unit ball has
self-concordance parameter $\tilde{\Omega}(n)$.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01328</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01333</identifier>
 <datestamp>2017-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Bid Without Knowing your Value</dc:title>
 <dc:creator>Feng, Zhe</dc:creator>
 <dc:creator>Podimata, Chara</dc:creator>
 <dc:creator>Syrgkanis, Vasilis</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We address online learning in complex auction settings, such as sponsored
search auctions, where the value of the bidder is unknown to her, evolving in
an arbitrary manner and observed only if the bidder wins an allocation. We
leverage the structure of the utility of the bidder to provide algorithms with
regret rates against the best fixed bid in hindsight, that are exponentially
faster in convergence in terms of dependence on the action space, than what
would have been derived by applying a generic bandit algorithm. Our results are
enabled by analyzing a new online learning setting with outcome-based feedback,
which generalizes learning with feedback graphs. We provide an online learning
algorithm for this setting, of independent interest, with regret that grows
only logarithmically with the number of actions and linearly only in the number
of potential outcomes (the latter being very small in most auction settings).
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:date>2017-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01333</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01334</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two Error Bounds of Imperfect Binary Search</dc:title>
 <dc:creator>Wu, Haoze</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Suppose we know that an object is in a sorted table and we want to determine
the index of that object. To achieve this goal we could perform a binary
search. However, suppose it is time-consuming to determine the relative
position of that object to any other objects in the table. In this scenario, we
might want to resort to an incomplete solution: we could device an algorithm
that quickly predicts the result of comparing two objects, and replace the
actual comparison with this algorithm during a binary search. The question then
is how far away are the results yielded by the imperfect binary search from the
correct answers. We present two quick lemmas that answer this question.
</dc:description>
 <dc:description>Comment: 2 pages</dc:description>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01334</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01335</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differentially Private ANOVA Testing</dc:title>
 <dc:creator>Campbell, Zachary</dc:creator>
 <dc:creator>Bray, Andrew</dc:creator>
 <dc:creator>Ritz, Anna</dc:creator>
 <dc:creator>Groce, Adam</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Modern society generates an incredible amount of data about individuals, and
releasing summary statistics about this data in a manner that provably protects
individual privacy would offer a valuable resource for researchers in many
fields. We present the first algorithm for analysis of variance (ANOVA) that
preserves differential privacy, allowing this important statistical test to be
conducted (and the results released) on databases of sensitive information. In
addition to our private algorithm for the F test statistic, we show a rigorous
way to compute p-values that accounts for the added noise needed to preserve
privacy. Finally, we present experimental results quantifying the statistical
power of this differentially private version of the test, finding that a sample
of several thousand observations is frequently enough to detect variation
between groups. The differentially private ANOVA algorithm is a promising
approach for releasing a common test statistic that is valuable in fields in
the sciences and social sciences.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01335</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01336</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Study of Optimizing Heterogeneous Resources for Open IoT</dc:title>
 <dc:creator>Yamato, Yoji</dc:creator>
 <dc:creator>Hoshikawa, Naoto</dc:creator>
 <dc:creator>Noguchi, Hirofumi</dc:creator>
 <dc:creator>Demizu, Tatsyua</dc:creator>
 <dc:creator>Kataoka, Misao</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Recently, IoT technologies have been progressed, and many sensors and
actuators are connected to networks. Previously, IoT services were developed by
vertical integration style. But now Open IoT concept has attracted attentions
which achieves various IoT services by integrating horizontal separated devices
and services. For Open IoT era, we have proposed the Tacit Computing technology
to discover the devices with necessary data for users on demand and use them
dynamically. We also implemented elemental technologies of Tacit Computing. In
this paper, we propose three layers optimizations to reduce operation cost and
improve performance of Tacit computing service, in order to make as a
continuous service of discovered devices by Tacit Computing. In optimization
process, appropriate function allocations are calculated for device, network
and cloud layer before full-scale operation.
</dc:description>
 <dc:description>Comment: 6 pages, in japanese 2 figures</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01336</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01339</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binary Linear Codes with Optimal Scaling and Quasi-Linear Complexity</dc:title>
 <dc:creator>Fazeli, Arman</dc:creator>
 <dc:creator>Hassani, S. Hamed</dc:creator>
 <dc:creator>Mondelli, Marco</dc:creator>
 <dc:creator>Vardy, Alexander</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We present the first family of binary codes that attains optimal scaling and
quasi-linear complexity, at least for the binary erasure channel (BEC). In
other words, for any fixed $\delta &gt; 0$, we provide codes that ensure reliable
communication at rates within $\varepsilon &gt; 0$ of the Shannon capacity with
block length $n=O(1/\varepsilon^{2+\delta})$, construction complexity
$\Theta(n)$, and encoding/decoding complexity $\Theta(n\log n)$. Furthermore,
this scaling between the gap to capacity and the block length is optimal in an
information-theoretic sense.
  Our proof is based on the construction and analysis of binary polar codes
obtained from large kernels. It was recently shown that, for all binary-input
symmetric memoryless channels, conventional polar codes (based on a $2\times 2$
kernel) allow reliable communication at rates within $\varepsilon &gt; 0$ of the
Shannon capacity with block length, construction, encoding and decoding
complexity all bounded by a polynomial in $1/\varepsilon$. In particular, this
means that the block length $n$ scales as $O(1/\varepsilon^{\mu})$, where $\mu$
is referred to as the scaling exponent. It is furthermore known that the
optimal scaling exponent is $\mu=2$, and it is achieved by random linear codes.
However, for general channels, the decoding complexity of random linear codes
is exponential in the block length. As far as conventional polar codes, their
scaling exponent depends on the channel, and for the BEC it is given by
$\mu=3.63$.
  Our main contribution is a rigorous proof of the following result: there
exist $\ell\times\ell$ binary kernels, such that polar codes constructed from
these kernels achieve scaling exponent $\mu(\ell)$ that tends to the optimal
value of $2$ as $\ell$ grows. The resulting binary codes also achieve
construction complexity $\Theta(n)$ and encoding/decoding complexity
$\Theta(n\log n)$.
</dc:description>
 <dc:description>Comment: 27 pages, 1 figure, submitted to STOC'18</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01343</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerating Training of Deep Neural Networks via Sparse Edge Processing</dc:title>
 <dc:creator>Dey, Sourya</dc:creator>
 <dc:creator>Shao, Yinan</dc:creator>
 <dc:creator>Chugg, Keith M.</dc:creator>
 <dc:creator>Beerel, Peter A.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a reconfigurable hardware architecture for deep neural networks
(DNNs) capable of online training and inference, which uses algorithmically
pre-determined, structured sparsity to significantly lower memory and
computational requirements. This novel architecture introduces the notion of
edge-processing to provide flexibility and combines junction pipelining and
operational parallelization to speed up training. The overall effect is to
reduce network complexity by factors up to 30x and training time by up to 35x
relative to GPUs, while maintaining high fidelity of inference results. This
has the potential to enable extensive parameter searches and development of the
largely unexplored theoretical foundation of DNNs. The architecture
automatically adapts itself to different network sizes given available hardware
resources. As proof of concept, we show results obtained for different bit
widths.
</dc:description>
 <dc:description>Comment: Presented at the 26th International Conference on Artificial Neural
  Networks (ICANN) 2017 in Alghero, Italy</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01343</dc:identifier>
 <dc:identifier>Proceedings Part 1 of ICANN 2017, pp 273-280. Lecture Notes in
  Computer Science, vol 10613. Springer, Cham</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-68600-4_32</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01345</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computationally efficient cardiac views projection using 3D
  Convolutional Neural Networks</dc:title>
 <dc:creator>Le, Matthieu</dc:creator>
 <dc:creator>Lieman-Sifry, Jesse</dc:creator>
 <dc:creator>Lau, Felix</dc:creator>
 <dc:creator>Sall, Sean</dc:creator>
 <dc:creator>Hsiao, Albert</dc:creator>
 <dc:creator>Golden, Daniel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  4D Flow is an MRI sequence which allows acquisition of 3D images of the
heart. The data is typically acquired volumetrically, so it must be reformatted
to generate cardiac long axis and short axis views for diagnostic
interpretation. These views may be generated by placing 6 landmarks: the left
and right ventricle apex, and the aortic, mitral, pulmonary, and tricuspid
valves. In this paper, we propose an automatic method to localize landmarks in
order to compute the cardiac views. Our approach consists of first calculating
a bounding box that tightly crops the heart, followed by a landmark
localization step within this bounded region. Both steps are based on a 3D
extension of the recently introduced ENet. We demonstrate that the long and
short axis projections computed with our automated method are of equivalent
quality to projections created with landmarks placed by an experienced cardiac
radiologist, based on a blinded test administered to a different cardiac
radiologist.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01348</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Differentiation for Tensor Algebras</dc:title>
 <dc:creator>Urban, Sebastian</dc:creator>
 <dc:creator>van der Smagt, Patrick</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Kjolstad et. al. proposed a tensor algebra compiler. It takes expressions
that define a tensor element-wise, such as $f_{ij}(a,b,c,d) =
\exp\left[-\sum_{k=0}^4 \left((a_{ik}+b_{jk})^2\, c_{ii} + d_{i+k}^3 \right)
\right]$, and generates the corresponding compute kernel code.
  For machine learning, especially deep learning, it is often necessary to
compute the gradient of a loss function $l(a,b,c,d)=l(f(a,b,c,d))$ with respect
to parameters $a,b,c,d$. If tensor compilers are to be applied in this field,
it is necessary to derive expressions for the derivatives of element-wise
defined tensors, i.e. expressions for $(da)_{ik}=\partial l/\partial a_{ik}$.
  When the mapping between function indices and argument indices is not 1:1,
special attention is required. For the function $f_{ij} (x) = x_i^2$, the
derivative of the loss is $(dx)_i=\partial l/\partial x_i=\sum_j
(df)_{ij}2x_i$; the sum is necessary because index $j$ does not appear in the
indices of $f$. Another example is $f_{i}(x)=x_{ii}^2$, where $x$ is a matrix;
here we have $(dx)_{ij}=\delta_{ij}(df)_i2x_{ii}$; the Kronecker delta is
necessary because the derivative is zero for off-diagonal elements. Another
indexing scheme is used by $f_{ij}(x)=\exp x_{i+j}$; here the correct
derivative is $(dx)_{k}=\sum_i (df)_{i,k-i} \exp x_{k}$, where the range of the
sum must be chosen appropriately.
  In this publication we present an algorithm that can handle any case in which
the indices of an argument are an arbitrary linear combination of the indices
of the function, thus all the above examples can be handled. Sums (and their
ranges) and Kronecker deltas are automatically inserted into the derivatives as
necessary. Additionally, the indices are transformed, if required (as in the
last example). The algorithm outputs a symbolic expression that can be
subsequently fed into a tensor algebra compiler.
  Source code is provided.
</dc:description>
 <dc:description>Comment: Technical Report</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01348</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01349</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Wire Alternatives to Capacity Expansion</dc:title>
 <dc:creator>Contreras-Oca&#xf1;a, Jesus E.</dc:creator>
 <dc:creator>Siddiqi, Uzma</dc:creator>
 <dc:creator>Zhang, Baosen</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Distributed energy resources (DERs) can serve as non-wire alternatives to
capacity expansion by managing peak load to avoid or defer traditional
expansion projects. In this paper, we study a planning problem that
co-optimizes DERs investment and operation (e.g., energy efficiency, energy
storage, demand response, solar photovoltaic) and the timing of capacity
expansion. We show that this problem can be written as a convex program.
However, the problem potentially includes millions of variables because we
model the operation of DERs over decades. We use the Dantzig-Wolfe
Decomposition to solve this high-dimensional, non-linear problem. Finally, we
present a real planning problem at the University of Washington Seattle Campus.
</dc:description>
 <dc:description>Comment: This document is an online supplement for a paper submitted to the
  2018 Power and Energy Society General Meeting</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01351</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uplink Performance Analysis of a Drone Cell in a Random Field of Ground
  Interferers</dc:title>
 <dc:creator>Azari, M. M.</dc:creator>
 <dc:creator>Rosas, F.</dc:creator>
 <dc:creator>Chiumento, A.</dc:creator>
 <dc:creator>Ligata, A.</dc:creator>
 <dc:creator>Pollin, S.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Aerial base stations are a promising technology to increase the capabilities
of the existing communication networks. However, the existing analytical
frameworks do not sufficiently characterize the impact of ground interferers on
the aerial base stations. In order to address this issue, we model the effect
of interference coming from the coexisting ground networks on the aerial link,
which could be the uplink of an aerial cell served by a drone base station. By
considering a Poisson field of ground interferers, we characterize the
aggregate interference experienced by the drone. This result includes the
effect of the drone antenna pattern, the height-dependent shadowing, and
various types of environment. We show that the benefits that a drone obtains
from a better line-of-sight (LoS) at high altitudes is counteracted by a high
vulnerability to the interference coming from the ground. However, by deriving
the link coverage probability and transmission rate we show that a drone base
station is still a promising technology if the overall system is properly
dimensioned according to the given density and transmission power of the
interferers. Particularly, our results illustrate how the benefits of such
network is maximized by defining the optimal drone altitude and signal-to-
interference (SIR) requirement.
</dc:description>
 <dc:description>Comment: Related Works: 1- arXiv:1710.11404, 2- arXiv:1710.03103, 3-
  arXiv:1708.06598, 4- arXiv:1705.02877</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01351</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01353</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decentralised firewall for malware detection</dc:title>
 <dc:creator>Raje, Saurabh</dc:creator>
 <dc:creator>Vaderia, Shyamal</dc:creator>
 <dc:creator>Wilson, Neil</dc:creator>
 <dc:creator>Panigrahi, Rudrakh</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper describes the design and development of a decentralized firewall
system powered by a novel malware detection engine. The firewall is built using
blockchain technology. The detection engine aims to classify Portable
Executable (PE) files as malicious or benign. File classification is carried
out using a deep belief neural network (DBN) as the detection engine. Our
approach is to model the files as grayscale images and use the DBN to classify
those images into the aforementioned two classes. An extensive data set of
10,000 files is used to train the DBN. Validation is carried out using 4,000
files previously unexposed to the network. The final result of whether to allow
or block a file is obtained by arriving at a proof of work based consensus in
the blockchain network.
</dc:description>
 <dc:description>Comment: To be published in &quot;2017 International Conference on Advances in
  Computing, Communication and Control (ICAC3)&quot;</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01353</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01355</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Counting Roots of Polynomials Over Prime Power Rings</dc:title>
 <dc:creator>Cheng, Qi</dc:creator>
 <dc:creator>Gao, Shuhong</dc:creator>
 <dc:creator>Rojas, J. Maurice</dc:creator>
 <dc:creator>Wan, Daqing</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  Suppose $p$ is a prime, $t$ is a positive integer, and
$f\!\in\!\mathbb{Z}[x]$ is a univariate polynomial of degree $d$ with
coefficients of absolute value $&lt;\!p^t$. We show that for any fixed $t$, we can
compute the number of roots in $\mathbb{Z}/(p^t)$ of $f$ in deterministic time
$(d+\log p)^{O(1)}$. This fixed parameter tractability appears to be new for
$t\!\geq\!3$. A consequence for arithmetic geometry is that we can efficiently
compute Igusa zeta functions $Z$, for univariate polynomials, assuming the
degree of $Z$ is fixed.
</dc:description>
 <dc:description>Comment: title page, plus 11 pages, no illustrations, submitted to a
  conference</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01355</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01357</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reconstructing Video from Interferometric Measurements of Time-Varying
  Sources</dc:title>
 <dc:creator>Bouman, Katherine L.</dc:creator>
 <dc:creator>Johnson, Michael D.</dc:creator>
 <dc:creator>Dalca, Adrian V.</dc:creator>
 <dc:creator>Chael, Andrew A.</dc:creator>
 <dc:creator>Roelofs, Freek</dc:creator>
 <dc:creator>Doeleman, Sheperd S.</dc:creator>
 <dc:creator>Freeman, William T.</dc:creator>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Very long baseline interferometry (VLBI) makes it possible to recover images
of astronomical sources with extremely high angular resolution. Most recently,
the Event Horizon Telescope (EHT) has extended VLBI to short mm wavelengths
with a goal of achieving angular resolution sufficient for imaging the event
horizons of supermassive black holes. VLBI provides measurements related to the
underlying source image through a sparse set spatial frequencies. An image can
then be recovered from these measurements by making assumptions about the
underlying image. One of the most important assumptions made by conventional
imaging methods is that over the course of a night's observation the image is
static. However, for quickly evolving sources, such as the galactic center's
supermassive black hole (SgrA*) targeted by the EHT, this assumption is
violated and these conventional imaging approaches fail. In this work we
propose a new way to model VLBI measurements that allows us to recover both the
appearance and dynamics of an evolving source by reconstructing a video rather
than a static image. By modeling VLBI measurements using a Gaussian Markov
Model, we are able to propagate information across observations in time to
reconstruct a video, while simultaneously learning about the dynamics of the
source's emission region. We demonstrate our proposed Expectation-Maximization
(EM) algorithm, StarWarps, on realistic, synthetic observations of black holes,
and show how it substantially improves results compared to conventional imaging
algorithms.
</dc:description>
 <dc:description>Comment: Submitted to Transactions on Computational Imaging</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01358</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strengthening Convex Relaxations of 0/1-Sets Using Boolean Formulas</dc:title>
 <dc:creator>Fiorini, Samuel</dc:creator>
 <dc:creator>Huynh, Tony</dc:creator>
 <dc:creator>Weltge, Stefan</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>90C25, 90C27,</dc:subject>
 <dc:description>  In convex integer programming, various procedures have been developed to
strengthen convex relaxations of sets of integer points. On the one hand, there
exist several general-purpose methods that strengthen relaxations without
specific knowledge of the set $ S $, such as popular linear programming or
semi-definite programming hierarchies. On the other hand, various methods have
been designed for obtaining strengthened relaxations for very specific sets
that arise in combinatorial optimization. We propose a new efficient method
that interpolates between these two approaches.
  Our procedure strengthens any convex set $ Q \subseteq \mathbb{R}^n $
containing a set $ S \subseteq \{0,1\}^n $ by exploiting certain additional
information about $ S $. Namely, the required extra information will be in the
form of a Boolean formula $ \phi $ defining the target set $ S $.
  The aim of this work is to analyze various aspects regarding the strength of
our procedure. As one result, interpreting an iterated application of our
procedure as a hierarchy, our findings simplify, improve, and extend previous
results by Bienstock and Zuckerberg on covering problems.
</dc:description>
 <dc:description>Comment: 11 pages, 0 figures</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:date>2017-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01358</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01361</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Optimal Distributed $(\Delta+1)$-Coloring Algorithm?</dc:title>
 <dc:creator>Chang, Yi-Jun</dc:creator>
 <dc:creator>Li, Wenzheng</dc:creator>
 <dc:creator>Pettie, Seth</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Vertex coloring is one of the classic symmetry breaking problems studied in
distributed computing. In this paper we present a new algorithm for
$(\Delta+1)$-list coloring in the randomized $\textsf{LOCAL}$ model running in
$O(\log^\ast n + \textsf{Det}_d(\text{poly} \log n))$ time, where
$\textsf{Det}_d(n')$ is the deterministic complexity of $(\text{deg}+1)$-list
coloring ($v$'s palette has size $\text{deg}(v)+1$) on $n'$-vertex graphs. This
improves upon a previous randomized algorithm of Harris, Schneider, and Su
(STOC 2016). with complexity $O(\sqrt{\log \Delta} + \log\log n +
\textsf{Det}_d(\text{poly} \log n))$, and is dramatically faster than the best
known deterministic algorithm of Fraigniaud, Heinrich, and Kosowski (FOCS
2016), with complexity $O(\sqrt{\Delta}\log^{2.5}\Delta + \log^* n)$.
  Our algorithm appears to be optimal. It matches the $\Omega(\log^\ast n)$
randomized lower bound, due to Naor (SIDMA 1991) and sort of matches the
$\Omega(\textsf{Det}(\text{poly} \log n))$ randomized lower bound due to Chang,
Kopelowitz, and Pettie (FOCS 2016), where $\textsf{Det}$ is the deterministic
complexity of $(\Delta+1)$-list coloring. The best known upper bounds on
$\textsf{Det}_d(n')$ and $\textsf{Det}(n')$ are both $2^{O(\sqrt{\log n'})}$ by
Panconesi and Srinivasan (Journal of Algorithms 1996), and it is quite
plausible that the complexities of both problems are the same, asymptotically.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01361</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01362</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>&quot;Attention&quot; for Detecting Unreliable News in the Information Age</dc:title>
 <dc:creator>Duppada, Venkatesh</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  An Unreliable news is any piece of information which is false or misleading,
deliberately spread to promote political, ideological and financial agendas.
Recently the problem of unreliable news has got a lot of attention as the
number instances of using news and social media outlets for propaganda have
increased rapidly. This poses a serious threat to society, which calls for
technology to automatically and reliably identify unreliable news sources. This
paper is an effort made in this direction to build systems for detecting
unreliable news articles. In this paper, various NLP algorithms were built and
evaluated on Unreliable News Data 2017 dataset. Variants of hierarchical
attention networks (HAN) are presented for encoding and classifying news
articles which achieve the best results of 0.944 ROC-AUC. Finally, Attention
layer weights are visualized to understand and give insight into the decisions
made by HANs. The results obtained are very promising and encouraging to deploy
and use these systems in the real world to mitigate the problem of unreliable
news.
</dc:description>
 <dc:description>Comment: AICS 2018, AAAI-18 Conference</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01362</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01364</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Faster Distributed Single-Source Shortest Paths Algorithm</dc:title>
 <dc:creator>Krinninger, Sebastian</dc:creator>
 <dc:creator>Nanongkai, Danupon</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We devise new algorithms for the single-source shortest paths problem in the
CONGEST model of distributed computing. While close-to-optimal solutions, in
terms of the number of rounds spent by the algorithm, have recently been
developed for computing single-source shortest paths approximately, the fastest
known exact algorithms are still far away from matching the lower bound of $
\tilde \Omega (\sqrt{n} + D) $ rounds by Peleg and Rubinovich [SICOMP'00],
where $ n $~is the number of nodes in the network and $ D $ is its diameter.
The state of the art is Elkin's randomized algorithm [STOC'17] that performs $
\tilde O(n^{2/3} D^{1/3} + n^{5/6}) $ rounds. We significantly improve upon
this upper bound with our two new randomized algorithms, the first performing $
\tilde O (\sqrt{n D}) $ rounds and the second performing $ \tilde O (\sqrt{n}
D^{1/4} + n^{3/5} + D) $ rounds.
</dc:description>
 <dc:description>Comment: Work in progress</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01364</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01365</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A generalized MBO diffusion generated motion for orthogonal
  matrix-valued fields</dc:title>
 <dc:creator>Osting, Braxton</dc:creator>
 <dc:creator>Wang, Dong</dc:creator>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>35K93, 35K05, 65M12</dc:subject>
 <dc:description>  We consider the problem of finding stationary points of the Dirichlet energy
for orthogonal matrix-valued fields. Following the Ginzburg-Landau approach,
this energy is relaxed by penalizing the matrix-valued field when it does not
take orthogonal matrix values. A generalization of the MBO diffusion generated
motion is introduced that effectively finds local minimizers of this energy by
iterating two steps until convergence. In the first step, as in the original
method, the current matrix-valued field is evolved by the diffusion equation.
In the second step, the field is pointwise reassigned to the closest orthogonal
matrix, which can be computed via the singular value decomposition. We extend
the Lyapunov function of Esedoglu and Otto to show that the method is
non-increasing on iterates and hence, unconditionally stable. We also prove
that spatially discretized iterates converge to a stationary solution in a
finite number of iterations. The algorithm is implemented using the closest
point method and non-uniform fast Fourier transform. We conclude with several
numerical experiments on flat tori and closed surfaces, which, unsurprisingly,
exhibit classical behavior from the Allen-Cahn and complex Ginzburg Landau
equations, but also new phenomena.
</dc:description>
 <dc:description>Comment: 32 pages, 10 figures</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01365</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01369</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge Transfer from Weakly Labeled Audio using Convolutional Neural
  Network for Sound Events and Scenes</dc:title>
 <dc:creator>Kumar, Anurag</dc:creator>
 <dc:creator>Khadkevich, Maksim</dc:creator>
 <dc:creator>Fugen, Christian</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  In this work we propose approaches to effectively transfer knowledge from
weakly labeled web audio data. We first describe a convolutional neural network
(CNN) based framework for sound event detection and classification using weakly
labeled audio data. Our model trains efficiently from audios of variable
lengths which; hence, it is well suited for transfer learning. We then propose
methods to learn representations using this model which can be effectively used
for solving the target task. We study both transductive and inductive transfer
learning tasks, showing the effectiveness of our methods for both domain and
task adaptation. We show that even off-the-shelf representations using the
proposed CNN model generalizes well enough to reach human level accuracy on
ESC-50 sound events dataset. We further use them for acoustic scene
classification task and once again show that our proposed approaches suits well
for this task as well. Moreover, we show that our methods are helpful in
capturing semantic meanings and relations as well.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01369</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01370</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On constant multi-commodity flow-cut gaps for directed minor-free graphs</dc:title>
 <dc:creator>Salmasi, Ario</dc:creator>
 <dc:creator>Sidiropoulos, Anastasios</dc:creator>
 <dc:creator>Sridhar, Vijay</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The multi-commodity flow-cut gap is a fundamental parameter that affects the
performance of several divide \&amp; conquer algorithms, and has been extensively
studied for various classes of undirected graphs. It has been shown by Linial,
London and Rabinovich \cite{linial1994geometry} and by Aumann and Rabani
\cite{aumann1998log} that for general $n$-vertex graphs it is bounded by
$O(\log n)$ and the Gupta-Newman-Rabinovich-Sinclair conjecture
\cite{gupta2004cuts} asserts that it is $O(1)$ for any family of graphs that
excludes some fixed minor.
  The flow-cut gap is poorly understood for the case of directed graphs. We
show that for uniform demands it is $O(1)$ on directed series-parallel graphs,
and on directed graphs of bounded pathwidth. These are the first constant upper
bounds of this type for some non-trivial family of directed graphs. We also
obtain $O(1)$ upper bounds for the general multi-commodity flow-cut gap on
directed trees and cycles. These bounds are obtained via new embeddings and
Lipschitz quasipartitions for quasimetric spaces, which generalize analogous
results form the metric case, and could be of independent interest. Finally, we
discuss limitations of methods that were developed for undirected graphs, such
as random partitions, and random embeddings.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01370</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01371</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Iterative Co-Saliency Framework for RGBD Images</dc:title>
 <dc:creator>Cong, Runmin</dc:creator>
 <dc:creator>Lei, Jianjun</dc:creator>
 <dc:creator>Fu, Huazhu</dc:creator>
 <dc:creator>Lin, Weisi</dc:creator>
 <dc:creator>Huang, Qingming</dc:creator>
 <dc:creator>Cao, Xiaochun</dc:creator>
 <dc:creator>Hou, Chunping</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  As a newly emerging and significant topic in computer vision community,
co-saliency detection aims at discovering the common salient objects in
multiple related images. The existing methods often generate the co-saliency
map through a direct forward pipeline which is based on the designed cues or
initialization, but lack the refinement-cycle scheme. Moreover, they mainly
focus on RGB image and ignore the depth information for RGBD images. In this
paper, we propose an iterative RGBD co-saliency framework, which utilizes the
existing single saliency maps as the initialization, and generates the final
RGBD cosaliency map by using a refinement-cycle model. Three schemes are
employed in the proposed RGBD co-saliency framework, which include the addition
scheme, deletion scheme, and iteration scheme. The addition scheme is used to
highlight the salient regions based on intra-image depth propagation and
saliency propagation, while the deletion scheme filters the saliency regions
and removes the non-common salient regions based on interimage constraint. The
iteration scheme is proposed to obtain more homogeneous and consistent
co-saliency map. Furthermore, a novel descriptor, named depth shape prior, is
proposed in the addition scheme to introduce the depth information to enhance
identification of co-salient objects. The proposed method can effectively
exploit any existing 2D saliency model to work well in RGBD co-saliency
scenarios. The experiments on two RGBD cosaliency datasets demonstrate the
effectiveness of our proposed framework.
</dc:description>
 <dc:description>Comment: 13 pages, 13 figures, Accepted by IEEE Transactions on Cybernetics
  2017. Project URL: https://rmcong.github.io/proj_RGBD_cosal_tcyb.html</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01371</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01377</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Ensemble-based Approach to Click-Through Rate Prediction for Promoted
  Listings at Etsy</dc:title>
 <dc:creator>Aryafar, Kamelia</dc:creator>
 <dc:creator>Guillory, Devin</dc:creator>
 <dc:creator>Hong, Liangjie</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Etsy is a global marketplace where people across the world connect to make,
buy and sell unique goods. Sellers at Etsy can promote their product listings
via advertising campaigns similar to traditional sponsored search ads.
Click-Through Rate (CTR) prediction is an integral part of online search
advertising systems where it is utilized as an input to auctions which
determine the final ranking of promoted listings to a particular user for each
query. In this paper, we provide a holistic view of Etsy's promoted listings'
CTR prediction system and propose an ensemble learning approach which is based
on historical or behavioral signals for older listings as well as content-based
features for new listings. We obtain representations from texts and images by
utilizing state-of-the-art deep learning techniques and employ multimodal
learning to combine these different signals. We compare the system to
non-trivial baselines on a large-scale real world dataset from Etsy,
demonstrating the effectiveness of the model and strong correlations between
offline experiments and online performance. The paper is also the first
technical overview to this kind of product in e-commerce context.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:date>2017-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01377</dc:identifier>
 <dc:identifier>doi:10.1145/3124749.3124758</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01380</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Power Allocation and Beamforming for Non-Orthogonal Multiple
  Access (NOMA) in 5G Millimeter-Wave Communications</dc:title>
 <dc:creator>Xiao, Zhenyu</dc:creator>
 <dc:creator>Zhu, Lipeng</dc:creator>
 <dc:creator>Choi, Jinho</dc:creator>
 <dc:creator>Xia, Pengfei</dc:creator>
 <dc:creator>Xia, Xiang-Gen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we explore non-orthogonal multiple access (NOMA) in
millimeter-wave (mmWave) communications (mmWave-NOMA). In particular, we
consider a typical problem, i.e., maximization of the sum rate of a 2-user
mmWave-NOMA system. In this problem, we need to find the beamforming vector to
steer towards the two users simultaneously subject to an analog beamforming
structure, while allocating appropriate power to them. As the problem is
non-convex and may not be converted to a convex problem with simple
manipulations, we propose a suboptimal solution to this problem. The basic idea
is to decompose the original joint beamforming and power allocation problem
into two sub-problems which are relatively easy to solve: one is a power and
beam gain allocation problem, and the other is a beamforming problem under a
constant-modulus constraint. Extension of the proposed solution from 2-user
mmWave-NOMA to more-user mmWave-NOMA is also discussed. Extensive performance
evaluations are conducted to verify the rational of the proposed solution, and
the results also show that the proposed sub-optimal solution achieve
close-to-bound sum-rate performance, which is significantly better than that of
time-division multiple access (TDMA).
</dc:description>
 <dc:description>Comment: 14pages, Submitted to TWC</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01380</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01381</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding branch-decompositions of matroids, hypergraphs, and more</dc:title>
 <dc:creator>Jeong, Jisu</dc:creator>
 <dc:creator>Kim, Eun Jung</dc:creator>
 <dc:creator>Oum, Sang-il</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05C85, 05C78, 68R05, 05B35</dc:subject>
 <dc:description>  Given $n$ subspaces of a finite-dimensional vector space over a fixed finite
field $\mathcal F$, we wish to find a &quot;branch-decomposition&quot; of these subspaces
of width at most $k$, that is a subcubic tree $T$ with $n$ leaves mapped
bijectively to the subspaces such that for every edge $e$ of $T$, the sum of
subspaces associated with leaves in one component of $T-e$ and the sum of
subspaces associated with leaves in the other component have the intersection
of dimension at most $k$. This problem includes the problems of computing
branch-width of $\mathcal F$-represented matroids, rank-width of graphs,
branch-width of hypergraphs, and carving-width of graphs.
  We present a fixed-parameter algorithm to construct such a
branch-decomposition of width at most $k$, if it exists, for input subspaces of
a finite-dimensional vector space over $\mathcal F$. Our algorithm is analogous
to the algorithm of Bodlaender and Kloks (1996) on tree-width of graphs. To
extend their framework to branch-decompositions of vector spaces, we developed
highly generic tools for branch-decompositions on vector spaces. The only known
previous fixed-parameter algorithm for branch-width of $\mathcal F$-represented
matroids was due to Hlin\v{e}n\'y and Oum (2008) that runs in time $O(n^3)$
where $n$ is the number of elements of the input $\mathcal F$-represented
matroid. But their method is highly indirect. Their algorithm uses the
non-trivial fact by Geelen et al. (2003) that the number of forbidden minors is
finite and uses the algorithm of Hlin\v{e}n\'y (2005) on checking monadic
second-order formulas on $\mathcal F$-represented matroids of small
branch-width. Our result does not depend on such a fact and is completely
self-contained, and yet matches their asymptotic running time for each fixed
$k$.
</dc:description>
 <dc:description>Comment: 73 pages, 10 figures</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01386</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Discharge Medications at Admission Time Based on Deep
  Learning</dc:title>
 <dc:creator>Yang, Yuan</dc:creator>
 <dc:creator>Xie, Pengtao</dc:creator>
 <dc:creator>Gao, Xin</dc:creator>
 <dc:creator>Cheng, Carol</dc:creator>
 <dc:creator>Li, Christy</dc:creator>
 <dc:creator>Zhang, Hongbao</dc:creator>
 <dc:creator>Xing, Eric</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Predicting discharge medications right after a patient being admitted is an
important clinical decision, which provides physicians with guidance on what
type of medication regimen to plan for and what possible changes on initial
medication may occur during an inpatient stay. It also facilitates medication
reconciliation process with easy detection of medication discrepancy at
discharge time to improve patient safety. However, since the information
available upon admission is limited and patients' condition may evolve during
an inpatient stay, these predictions could be a difficult decision for
physicians to make. In this work, we investigate how to leverage deep learning
technologies to assist physicians in predicting discharge medications based on
information documented in the admission note. We build a convolutional neural
network which takes an admission note as input and predicts the medications
placed on the patient at discharge time. Our method is able to distill semantic
patterns from unstructured and noisy texts, and is capable of capturing the
pharmacological correlations among medications. We evaluate our method on 25K
patient visits and compare with 4 strong baselines. Our methods demonstrate a
20% increase in macro-averaged F1 score than the best baseline.
</dc:description>
 <dc:date>2017-11-03</dc:date>
 <dc:date>2017-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01391</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Guiding the search in continuous state-action spaces by learning an
  action sampling distribution from off-target samples</dc:title>
 <dc:creator>Kim, Beomjoon</dc:creator>
 <dc:creator>Kaelbling, Leslie Pack</dc:creator>
 <dc:creator>Lozano-Perez, Tomas</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In robotics, it is essential to be able to plan efficiently in
high-dimensional continuous state-action spaces for long horizons. For such
complex planning problems, unguided uniform sampling of actions until a path to
a goal is found is hopelessly inefficient, and gradient-based approaches often
fall short when the optimization manifold of a given problem is not smooth. In
this paper we present an approach that guides the search of a state-space
planner, such as A*, by learning an action-sampling distribution that can
generalize across different instances of a planning problem. The motivation is
that, unlike typical learning approaches for planning for continuous action
space that estimate a policy, an estimated action sampler is more robust to
error since it has a planner to fall back on. We use a Generative Adversarial
Network (GAN), and address an important issue: search experience consists of a
relatively large number of actions that are not on a solution path and a
relatively small number of actions that actually are on a solution path. We
introduce a new technique, based on an importance-ratio estimation method, for
using samples from a non-target distribution to make GAN learning more
data-efficient. We provide theoretical guarantees and empirical evaluation in
three challenging continuous robot planning problems to illustrate the
effectiveness of our algorithm.
</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01391</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01396</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Separation-Free Super-Resolution from Compressed Measurements is
  Possible: an Orthonormal Atomic Norm Minimization Approach</dc:title>
 <dc:creator>Xu, Weiyu</dc:creator>
 <dc:creator>Yi, Jirong</dc:creator>
 <dc:creator>Dasgupta, Soura</dc:creator>
 <dc:creator>Cai, Jian-Feng</dc:creator>
 <dc:creator>Jacob, Mathews</dc:creator>
 <dc:creator>Cho, Myung</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We consider the problem of recovering the superposition of $R$ distinct
complex exponential functions from compressed non-uniform time-domain samples.
Total Variation (TV) minimization or atomic norm minimization was proposed in
the literature to recover the $R$ frequencies or the missing data. However, it
is known that in order for TV minimization and atomic norm minimization to
recover the missing data or the frequencies, the underlying $R$ frequencies are
required to be well-separated, even when the measurements are noiseless. This
paper shows that the Hankel matrix recovery approach can super-resolve the $R$
complex exponentials and their frequencies from compressed non-uniform
measurements, regardless of how close their frequencies are to each other. We
propose a new concept of orthonormal atomic norm minimization (OANM), and
demonstrate that the success of Hankel matrix recovery in separation-free
super-resolution comes from the fact that the nuclear norm of a Hankel matrix
is an orthonormal atomic norm. More specifically, we show that, in traditional
atomic norm minimization, the underlying parameter values $\textbf{must}$ be
well separated to achieve successful signal recovery, if the atoms are changing
continuously with respect to the continuously-valued parameter. In contrast,
for the OANM, it is possible the OANM is successful even though the original
atoms can be arbitrarily close.
  As a byproduct of this research, we provide one matrix-theoretic inequality
of nuclear norm, and give its proof from the theory of compressed sensing.
</dc:description>
 <dc:description>Comment: 39 pages</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01396</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01399</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RSSI-Based Self-Localization with Perturbed Anchor Positions</dc:title>
 <dc:creator>Kumar, Vikram</dc:creator>
 <dc:creator>Arablouei, Reza</dc:creator>
 <dc:creator>Jurdak, Raja</dc:creator>
 <dc:creator>Kusy, Branislav</dc:creator>
 <dc:creator>Bergmann, Neil W.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the problem of self-localization by a resource-constrained mobile
node given perturbed anchor position information and distance estimates from
the anchor nodes. We consider normally-distributed noise in anchor position
information. The distance estimates are based on the log-normal shadowing
path-loss model for the RSSI measurements. The available solutions to this
problem are based on complex and iterative optimization techniques such as
semidefinite programming or second-order cone programming, which are not
suitable for resource-constrained environments. In this paper, we propose a
closed-form weighted least-squares solution. We calculate the weights by taking
into account the statistical properties of the perturbations in both RSSI and
anchor position information. We also estimate the bias of the proposed solution
and subtract it from the proposed solution. We evaluate the performance of the
proposed algorithm considering a set of arbitrary network topologies in
comparison to an existing algorithm that is based on a similar approach but
only accounts for perturbations in the RSSI measurements. We also compare the
results with the corresponding Cramer-Rao lower bound. Our experimental
evaluation shows that the proposed algorithm can substantially improve the
localization performance in terms of both root mean square error and bias.
</dc:description>
 <dc:description>Comment: Accepted for publication in 28th Annual IEEE International Symposium
  on Personal, Indoor and Mobile Radio Communications (IEEE PIMRC 2017)</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01399</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01401</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tighter Einstein-Podolsky-Rosen steering inequality based on the sum
  uncertainty relation</dc:title>
 <dc:creator>Maity, Ananda G.</dc:creator>
 <dc:creator>Datta, Shounak</dc:creator>
 <dc:creator>Majumdar, A. S.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the uncertainty bound on the sum of variances of two incompatible
observables in order to derive a corresponding steering inequality. Our
steering criterion when applied to discrete variables yields the optimum
steering range for two qubit Werner states in the two measurement and two
outcome scenario. We further employ the derived steering relation for several
classes of continuous variable systems. We show that non-Gaussian entangled
states such as the photon subtracted squeezed vacuum state and the
two-dimensional harmonic oscillator state furnish greater violation of the sum
steering relation compared to the Reid criterion as well as the entropic
steering criterion. The sum steering inequality provides a tighter steering
condition to reveal the steerability of continuous variable states.
</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01401</dc:identifier>
 <dc:identifier>Physical Review A 96, 052326 (2017)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevA.96.052326</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01404</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring cooperative game mechanisms of scientific coauthorship
  networks</dc:title>
 <dc:creator>Xie, Zheng</dc:creator>
 <dc:creator>Li, Jianping</dc:creator>
 <dc:creator>Li, Miao</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Scientific coauthorship, generated by collaborations and competitions among
researchers, reflects effective organizations of human resources. Researchers,
their expected benefits through collaborations, and their cooperative costs
constitute the elements of a game. Hence we propose a cooperative game model to
explore the evolution mechanisms of scientific coauthorship networks. The model
generates geometric hypergraphs, where the costs are modelled by space
distances, and the benefits are expressed by node reputations, i. e. geometric
zones that depend on node position in space and time. Modelled cooperative
strategies conditioned on positive benefit-minus-cost reflect the spatial
reciprocity principle in collaborations, and generate high clustering and
degree assortativity, two typical features of coauthorship networks. Modelled
reputations generate the generalized Poisson parts and fat tails appeared in
specific distributions of empirical data, e. g. paper team size distribution.
The combined effect of modelled costs and reputations reproduces the
transitions emerged in degree distribution, in the correlation between degree
and local clustering coefficient, etc. The model provides an example of how
individual strategies induce network complexity, as well as an application of
game theory to social affiliation networks.
</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01404</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01406</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Merging error analysis of name disambiguation based on author similarity</dc:title>
 <dc:creator>Xie, Zheng</dc:creator>
 <dc:creator>Li, Jianping</dc:creator>
 <dc:creator>Li, Miao</dc:creator>
 <dc:creator>Yi, Dongyun</dc:creator>
 <dc:creator>Feng, Yanqin</dc:creator>
 <dc:creator>Xie, Zonglin</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Falsely identifying different authors as one is called merging error in the
name disambiguation of coauthorship networks. Research on the measurement and
distribution of merging errors helps to collect high quality coauthorship
networks. In the aspect of measurement, we provide a Bayesian model to measure
the errors through author similarity. We illustratively use the model and
coauthor similarity to measure the errors caused by initial-based name
disambiguation methods. The empirical result on large-scale coauthorship
networks shows that using coauthor similarity cannot increase the accuracy of
disambiguation through surname and the initial of the first given name. In the
aspect of distribution, expressing coauthorship data as hypergraphs and
supposing the merging error rate is proper to hyperdegree with an exponent, we
find that hypergraphs with a range of network properties highly similar to
those of low merging error hypergraphs can be constructed from high merging
error hypergraphs. It implies that focusing on the error correction of high
hyperdegree nodes is a labor- and time-saving approach of improving the data
quality for coauthorship network analysis.
</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01406</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01407</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Timing Aware Dummy Metal Fill Methodology</dc:title>
 <dc:creator>Charre, Luis</dc:creator>
 <dc:creator>Gravano, Bruno</dc:creator>
 <dc:creator>P&#xf4;ssas, R&#xe9;mi</dc:creator>
 <dc:creator>Zheng, Chen</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  In this paper, we analyzed parasitic coupling capacitance coming from dummy
metal fill and its impact on timing. Based on the modeling, we proposed two
approaches to minimize the timing impact from dummy metal fill. The first
approach applies more spacing between critical nets and metal fill, while the
second approach leverages the shielding effects of reference nets. Experimental
results show consistent improvement compared to traditional metal fill method.
</dc:description>
 <dc:description>Comment: 3 pages, 2 figures, 2 tables</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01407</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01410</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SPUX: Scalable Particle Markov Chain Monte Carlo for uncertainty
  quantification in stochastic ecological models</dc:title>
 <dc:creator>&#x160;ukys, Jonas</dc:creator>
 <dc:creator>Kattwinkel, Mira</dc:creator>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Calibration of individual based models (IBMs), successful in modeling complex
ecological dynamical systems, is often performed only ad-hoc. Bayesian
inference can be used for both parameter estimation and uncertainty
quantification, but its successful application to realistic scenarios has been
hindered by the complex stochastic nature of IBMs. Computationally expensive
techniques such as Particle Filter (PF) provide marginal likelihood estimates,
where multiple model simulations (particles) are required to get a sample from
the state distribution conditional on the observed data. Particle ensembles are
re-sampled at each data observation time, requiring particle destruction and
replication, which lead to an increase in algorithmic complexity. We present
SPUX, a Python implementation of parallel Particle Markov Chain Monte Carlo
(PMCMC) algorithm, which mitigates high computational costs by distributing
particles over multiple computational units. Adaptive load re-balancing
techniques are used to mitigate computational work imbalances introduced by
re-sampling. Framework performance is investigated and significant speed-ups
are observed for a simple predator-prey IBM model.
</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01410</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01416</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Language as a matrix product state</dc:title>
 <dc:creator>Pestun, Vasily</dc:creator>
 <dc:creator>Terilla, John</dc:creator>
 <dc:creator>Vlassopoulos, Yiannis</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a statistical model for natural language that begins by
considering language as a monoid, then representing it in complex matrices with
a compatible translation invariant probability measure. We interpret the
probability measure as arising via the Born rule from a translation invariant
matrix product state.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01416</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01419</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conditional Task and Motion Planning through an Effort-based Approach</dc:title>
 <dc:creator>Castaman, Nicola</dc:creator>
 <dc:creator>Tosello, Elisa</dc:creator>
 <dc:creator>Pagello, Enrico</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper proposes a Conditional Task and Motion Planning algorithm able to
find a plan that minimizes robot efforts while solving assigned tasks. Unlike
most of existing approaches that replan a path only when it becomes unfeasible,
the proposed algorithm takes into consideration a replanning every time an
effort saving is possible. The effort is here considered as the execution time
but it is extensible to the energy consumption. The computed plan is both
conditional and dynamically adaptable to the unexpected environment changes.
Authors prove the completeness and scalability of their proposal.
</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01419</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01427</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Stacking Networks for Low-Resource Chinese Word Segmentation with
  Transfer Learning</dc:title>
 <dc:creator>Xu, Jingjing</dc:creator>
 <dc:creator>Sun, Xu</dc:creator>
 <dc:creator>Li, Sujian</dc:creator>
 <dc:creator>Cai, Xiaoyan</dc:creator>
 <dc:creator>Wei, Bingzhen</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In recent years, neural networks have proven to be effective in Chinese word
segmentation. However, this promising performance relies on large-scale
training data. Neural networks with conventional architectures cannot achieve
the desired results in low-resource datasets due to the lack of labelled
training data. In this paper, we propose a deep stacking framework to improve
the performance on word segmentation tasks with insufficient data by
integrating datasets from diverse domains. Our framework consists of two parts,
domain-based models and deep stacking networks. The domain-based models are
used to learn knowledge from different datasets. The deep stacking networks are
designed to integrate domain-based models. To reduce model conflicts, we
innovatively add communication paths among models and design various structures
of deep stacking networks, including Gaussian-based Stacking Networks,
Concatenate-based Stacking Networks, Sequence-based Stacking Networks and
Tree-based Stacking Networks. We conduct experiments on six low-resource
datasets from various domains. Our proposed framework shows significant
performance improvements on all datasets compared with several strong
baselines.
</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01427</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01431</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Case for Meta-Cognitive Machine Learning: On Model Entropy and
  Concept Formation in Deep Learning</dc:title>
 <dc:creator>Loeckx, Johan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Machine learning is usually defined in behaviourist terms, where external
validation is the primary mechanism of learning. In this paper, I argue for a
more holistic interpretation in which finding more probable, efficient and
abstract representations is as central to learning as performance. In other
words, machine learning should be extended with strategies to reason over its
own learning process, leading to so-called meta-cognitive machine learning. As
such, the de facto definition of machine learning should be reformulated in
these intrinsically multi-objective terms, taking into account not only the
task performance but also internal learning objectives. To this end, we suggest
a &quot;model entropy function&quot; to be defined that quantifies the efficiency of the
internal learning processes. It is conjured that the minimization of this model
entropy leads to concept formation. Besides philosophical aspects, some initial
illustrations are included to support the claims.
</dc:description>
 <dc:description>Comment: 5 pages, 5 figures</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01431</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01432</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Noise-induced synchronization of self-organized systems:
  Hegselmann-Krause dynamics in infinite space</dc:title>
 <dc:creator>Su, Wei</dc:creator>
 <dc:creator>Guo, Jin</dc:creator>
 <dc:creator>Chen, Xianzhong</dc:creator>
 <dc:creator>Chen, Ge</dc:creator>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Nonlinear Sciences - Cellular Automata and Lattice Gases</dc:subject>
 <dc:description>  It has been well established the theoretical analysis for the noise-induced
consensus of the local-rule based Hegselmann-Krause (HK) dynamics in finite
space. However, when system states are allowed in the infinite space, severe
mathematical difficulties arise, and the problem remains open. In this paper,
we completely resolved the case when system states are allowed in the infinite
space, and also the critical noise strength is given.
</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01432</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01434</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transaction Fraud Detection Using GRU-centered Sandwich-structured Model</dc:title>
 <dc:creator>Li, Xurui</dc:creator>
 <dc:creator>Yu, Wei</dc:creator>
 <dc:creator>Luwang, Tianyu</dc:creator>
 <dc:creator>Zheng, Jianbin</dc:creator>
 <dc:creator>Zhao, Jintao</dc:creator>
 <dc:creator>Xia, Lei</dc:creator>
 <dc:creator>Li, Yujiao</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Rapid growth of modern technologies such as internet and mobile computing are
bringing dramatically increased e-commerce payments, as well as the explosion
in transaction fraud. Meanwhile, fraudsters are continually refining their
tricks, making rule-based fraud detection systems difficult to handle the
ever-changing fraud patterns. Many data mining and artificial intelligence
methods have been proposed for identifying small anomalies in large transaction
data sets, increasing detecting efficiency to some extent. Nevertheless, there
is always a contradiction that most methods are irrelevant to transaction
sequence, yet sequence-related methods usually cannot learn information at
single-transaction level well. In this paper, a new &quot;within-&gt;between-&gt;within&quot;
sandwich-structured sequence learning architecture has been proposed by
stacking an ensemble method, a deep sequential learning method and another
top-layer ensemble classifier in proper order. Moreover, attention mechanism
has also been introduced in to further improve performance. Models in this
structure have been manifested to be very efficient in scenarios like fraud
detection, where the information sequence is made up of vectors with complex
interconnected features.
</dc:description>
 <dc:description>Comment: submitted to cscwd2018</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01434</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01436</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Searching for Biophysically Realistic Parameters for Dynamic Neuron
  Models by Genetic Algorithms from Calcium Imaging Recording</dc:title>
 <dc:creator>Fuchs, Magdalena</dc:creator>
 <dc:creator>Zimmer, Manuel</dc:creator>
 <dc:creator>Grosu, Radu</dc:creator>
 <dc:creator>Hasani, Ramin M.</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Individual Neurons in the nervous systems exploit various dynamics. To
capture these dynamics for single neurons, we tune the parameters of an
electrophysiological model of nerve cells, to fit experimental data obtained by
calcium imaging. A search for the biophysical parameters of this model is
performed by means of a genetic algorithm, where the model neuron is exposed to
a predefined input current representing overall inputs from other parts of the
nervous system. The algorithm is then constrained for keeping the ion-channel
currents within reasonable ranges, while producing the best fit to a calcium
imaging time series of the AVA interneuron, from the brain of the soil-worm, C.
elegans. Our settings enable us to project a set of biophysical parameters to
the the neuron kinetics observed in neuronal imaging.
</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01437</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monaural Singing Voice Separation with Skip-Filtering Connections and
  Recurrent Inference of Time-Frequency Mask</dc:title>
 <dc:creator>Mimilakis, Stylianos Ioannis</dc:creator>
 <dc:creator>Drossos, Konstantinos</dc:creator>
 <dc:creator>Santos, Jo&#xe3;o F.</dc:creator>
 <dc:creator>Schuller, Gerald</dc:creator>
 <dc:creator>Virtanen, Tuomas</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Singing voice separation based on deep learning relies on the usage of
time-frequency masking. In many cases the masking process is not a learnable
function or is not encapsulated into the deep learning optimization.
Consequently, most of the existing methods rely on a post processing step using
the generalized Wiener filtering. This work proposes a method that learns and
optimizes (during training) a source-dependent mask and does not need the
aforementioned post processing step. We introduce a recurrent inference
algorithm, a sparse transformation step to improve the mask generation process,
and a learned denoising filter. Obtained results show an increase of 0.49 dB
for the signal to distortion ratio and 0.30 dB for the signal to interference
ratio, compared to previous state-of-the-art approaches for monaural singing
voice separation.
</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01437</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01439</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Communications using Nonlinear Silicon Photonic Keys</dc:title>
 <dc:creator>Grubel, Brian C.</dc:creator>
 <dc:creator>Bosworth, Bryan T.</dc:creator>
 <dc:creator>Kossey, Michael R.</dc:creator>
 <dc:creator>Cooper, A. Brinton</dc:creator>
 <dc:creator>Foster, Mark A.</dc:creator>
 <dc:creator>Foster, Amy C.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:description>  We present a secure communication system constructed using pairs of nonlinear
photonic physical unclonable functions (PUFs) that harness physical chaos in
integrated silicon micro-cavities. Compared to a large, electronically stored
one-time pad, our method provisions large amounts of information within the
intrinsically complex nanostructure of the micro-cavities. By probing a
micro-cavity with a rapid sequence of spectrally-encoded ultrafast optical
pulses and measuring the lightwave responses, we experimentally demonstrate the
ability to extract 2.4 Gb of key material from a single micro-cavity device.
Subsequently, in a secure communications experiment with pairs of devices, we
achieve bit error rates below $10^{-5}$ at code rates of up to 0.1. The PUFs'
responses are never transmitted over the channel or stored in digital memory,
thus enhancing security of the system. Additionally, the micro-cavity PUFs are
extremely small, inexpensive, robust, and fully compatible with
telecommunications infrastructure, components, and electronic fabrication. This
approach can serve one-time pad or public key exchange applications where high
security is required
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01439</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01443</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Method for Phase Space Transport with Applications to Lobe
  Dynamics and Rate of Escape</dc:title>
 <dc:creator>Naik, Shibabrat</dc:creator>
 <dc:creator>Lekien, Francois</dc:creator>
 <dc:creator>Ross, Shane D.</dc:creator>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:subject>37J35, 37M99, 65D20, 65D30, 65P99</dc:subject>
 <dc:description>  Lobe dynamics and escape from a potential well are general frameworks
introduced to study phase space transport in chaotic dynamical systems. While
the former approach studies how regions of phase space are transported by
reducing the flow to a two-dimensional map, the latter approach studies the
phase space structures that lead to critical events by crossing periodic orbit
around saddles. Both of these frameworks require computation with curves
represented by millions of points-computing intersection points between these
curves and area bounded by the segments of these curves-for quantifying the
transport and escape rate. We present a theory for computing these intersection
points and the area bounded between the segments of these curves based on a
classification of the intersection points using equivalence class. We also
present an alternate theory for curves with nontransverse intersections and a
method to increase the density of points on the curves for locating the
intersection points accurately.The numerical implementation of the theory
presented herein is available as an open source software called Lober. We used
this package to demonstrate the application of the theory to lobe dynamics that
arises in fluid mechanics, and rate of escape from a potential well that arises
in ship dynamics.
</dc:description>
 <dc:description>Comment: 33 pages, 17 figures</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01443</dc:identifier>
 <dc:identifier>Regular and Chaotic Dynamics, 22(3): 272-297, 2017</dc:identifier>
 <dc:identifier>doi:10.1134/S1560354717030078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01447</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Game theoretic path selection to support security in device-to-device
  communications</dc:title>
 <dc:creator>Panaousis, Emmanouil</dc:creator>
 <dc:creator>Karapistoli, Eirini</dc:creator>
 <dc:creator>Elsemary, Hadeer</dc:creator>
 <dc:creator>Alpcan, Tansu</dc:creator>
 <dc:creator>Khuzani, MHR</dc:creator>
 <dc:creator>Economides, Anastasios A.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>K.6.5, C.2.2</dc:subject>
 <dc:description>  Device-to-Device (D2D) communication is expected to be a key feature
supported by 5G networks, especially due to the proliferation of Mobile Edge
Computing (MEC), which has a prominent role in reducing network stress by
shifting computational tasks from the Internet to the mobile edge. Apart from
being part of MEC, D2D can extend cellular coverage allowing users to
communicate directly when telecommunication infrastructure is highly congested
or absent. This significant departure from the typical cellular paradigm
imposes the need for decentralised network routing protocols. Moreover,
enhanced capabilities of mobile devices and D2D networking will likely result
in proliferation of new malware types and epidemics. Although the literature is
rich in terms of D2D routing protocols that enhance quality-of-service and
energy consumption, they provide only basic security support, e.g., in the form
of encryption. Routing decisions can, however, contribute to collaborative
detection of mobile malware by leveraging different kinds of anti-malware
software installed on mobile devices. Benefiting from the cooperative nature of
D2D communications, devices can rely on each other's contributions to detect
malware. The impact of our work is geared towards having more malware-free D2D
networks. To achieve this, we designed and implemented a novel routing protocol
for D2D communications that optimises routing decisions for explicitly
improving malware detection. The protocol identifies optimal network paths, in
terms of malware mitigation and energy spent for malware detection, based on a
game theoretic model. Diverse capabilities of network devices running different
types of anti-malware software and their potential for inspecting messages
relayed towards an intended destination device are leveraged using game
theoretic tools. An optimality analysis of both Nash and Stackelberg security
games is undertaken, including both zero and non-zero sum variants, and the
Defender's equilibrium strategies. By undertaking network simulations,
theoretical results obtained are illustrated through randomly generated network
scenarios showing how our protocol outperforms conventional routing protocols,
in terms of expected payoff, which consists of: security damage in inflicted by
malware and malware detection cost.
</dc:description>
 <dc:description>Comment: 35 pages, 7 figures</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01447</dc:identifier>
 <dc:identifier>Ad Hoc Networks (2017), 28-42</dc:identifier>
 <dc:identifier>doi:10.1016/j.adhoc.2016.11.008.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01454</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Checkpointing for Secure Intermittently-Powered IoT Devices</dc:title>
 <dc:creator>Ghodsi, Zahra</dc:creator>
 <dc:creator>Garg, Siddharth</dc:creator>
 <dc:creator>Karri, Ramesh</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Energy harvesting is a promising solution to power Internet of Things (IoT)
devices. Due to the intermittent nature of these energy sources, one cannot
guarantee forward progress of program execution. Prior work has advocated for
checkpointing the intermediate state to off-chip non-volatile memory (NVM).
Encrypting checkpoints addresses the security concern, but significantly
increases the checkpointing overheads. In this paper, we propose a new online
checkpointing policy that judiciously determines when to checkpoint so as to
minimize application time to completion while guaranteeing security. Compared
to state-of-the-art checkpointing schemes that do not account for the overheads
of encrypted checkpoints we improve execution time up to 1.4x.
</dc:description>
 <dc:description>Comment: ICCAD 2017</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01454</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01458</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DDD17: End-To-End DAVIS Driving Dataset</dc:title>
 <dc:creator>Binas, Jonathan</dc:creator>
 <dc:creator>Neil, Daniel</dc:creator>
 <dc:creator>Liu, Shih-Chii</dc:creator>
 <dc:creator>Delbruck, Tobi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Event cameras, such as dynamic vision sensors (DVS), and dynamic and
active-pixel vision sensors (DAVIS) can supplement other autonomous driving
sensors by providing a concurrent stream of standard active pixel sensor (APS)
images and DVS temporal contrast events. The APS stream is a sequence of
standard grayscale global-shutter image sensor frames. The DVS events represent
brightness changes occurring at a particular moment, with a jitter of about a
millisecond under most lighting conditions. They have a dynamic range of &gt;120
dB and effective frame rates &gt;1 kHz at data rates comparable to 30 fps
(frames/second) image sensors. To overcome some of the limitations of current
image acquisition technology, we investigate in this work the use of the
combined DVS and APS streams in end-to-end driving applications. The dataset
DDD17 accompanying this paper is the first open dataset of annotated DAVIS
driving recordings. DDD17 has over 12 h of a 346x260 pixel DAVIS sensor
recording highway and city driving in daytime, evening, night, dry and wet
weather conditions, along with vehicle speed, GPS position, driver steering,
throttle, and brake captured from the car's on-board diagnostics interface. As
an example application, we performed a preliminary end-to-end learning study of
using a convolutional neural network that is trained to predict the
instantaneous steering angle from DVS and APS visual data.
</dc:description>
 <dc:description>Comment: Presented at the ICML 2017 Workshop on Machine Learning for
  Autonomous Vehicles</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01458</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01464</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gaussian Kernel in Quantum Paradigm</dc:title>
 <dc:creator>Bishwas, Arit Kumar</dc:creator>
 <dc:creator>Mani, Ashish</dc:creator>
 <dc:creator>Palade, Vasile</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Gaussian kernel is a very popular kernel function used in many machine
learning algorithms, especially in support vector machines (SVM). For nonlinear
training instances in machine learning, it often outperforms polynomial kernels
in model accuracy. The Gaussian kernel is heavily used in formulating nonlinear
classical SVM. A very elegant quantum version of least square support vector
machine which is exponentially faster than the classical counterparts was
discussed in literature with quantum polynomial kernel. In this paper, we have
demonstrated a quantum version of the Gaussian kernel and analyzed its
complexity, which is O(\epsilon^(-1)logN) with N-dimensional instances and an
accuracy \epsilon. The Gaussian kernel is not only more efficient than
polynomial kernel but also has broader application range than polynomial
kernel.
</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01464</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01467</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attentional Pooling for Action Recognition</dc:title>
 <dc:creator>Girdhar, Rohit</dc:creator>
 <dc:creator>Ramanan, Deva</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce a simple yet surprisingly powerful model to incorporate
attention in action recognition and human object interaction tasks. Our
proposed attention module can be trained with or without extra supervision, and
gives a sizable boost in accuracy while keeping the network size and
computational cost nearly the same. It leads to significant improvements over
state of the art base architecture on three standard action recognition
benchmarks across still images and videos, and establishes new state of the art
on MPII dataset with 12.5% relative improvement. We also perform an extensive
analysis of our attention module both empirically and analytically. In terms of
the latter, we introduce a novel derivation of bottom-up and top-down attention
as low-rank approximations of bilinear pooling methods (typically used for
fine-grained classification). From this perspective, our attention formulation
suggests a novel characterization of action recognition as a fine-grained
recognition problem.
</dc:description>
 <dc:description>Comment: In NIPS 2017. Project page:
  https://rohitgirdhar.github.io/AttentionalPoolingAction/</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01467</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01468</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ensembles of Multiple Models and Architectures for Robust Brain Tumour
  Segmentation</dc:title>
 <dc:creator>Kamnitsas, Konstantinos</dc:creator>
 <dc:creator>Bai, Wenjia</dc:creator>
 <dc:creator>Ferrante, Enzo</dc:creator>
 <dc:creator>McDonagh, Steven</dc:creator>
 <dc:creator>Sinclair, Matthew</dc:creator>
 <dc:creator>Pawlowski, Nick</dc:creator>
 <dc:creator>Rajchl, Martin</dc:creator>
 <dc:creator>Lee, Matthew</dc:creator>
 <dc:creator>Kainz, Bernhard</dc:creator>
 <dc:creator>Rueckert, Daniel</dc:creator>
 <dc:creator>Glocker, Ben</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep learning approaches such as convolutional neural nets have consistently
outperformed previous methods on challenging tasks such as dense, semantic
segmentation. However, the various proposed networks perform differently, with
behaviour largely influenced by architectural choices and training settings.
This paper explores Ensembles of Multiple Models and Architectures (EMMA) for
robust performance through aggregation of predictions from a wide range of
methods. The approach reduces the influence of the meta-parameters of
individual models and the risk of overfitting the configuration to a particular
database. EMMA can be seen as an unbiased, generic deep learning model which is
shown to yield excellent performance, winning the first position in the BRATS
2017 competition among 50+ participating teams.
</dc:description>
 <dc:description>Comment: The method won the 1st-place in the Brain Tumour Segmentation (BRATS)
  2017 competition (segmentation task)</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01468</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01470</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Object-Centric Photometric Bundle Adjustment with Deep Shape Prior</dc:title>
 <dc:creator>Zhu, Rui</dc:creator>
 <dc:creator>Wang, Chaoyang</dc:creator>
 <dc:creator>Lin, Chen-Hsuan</dc:creator>
 <dc:creator>Wang, Ziyan</dc:creator>
 <dc:creator>Lucey, Simon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Reconstructing 3D shapes from a sequence of images has long been a problem of
interest in computer vision. Classical Structure from Motion (SfM) methods have
attempted to solve this problem through projected point displacement \&amp; bundle
adjustment. More recently, deep methods have attempted to solve this problem by
directly learning a relationship between geometry and appearance. There is,
however, a significant gap between these two strategies. SfM tackles the
problem from purely a geometric perspective, taking no account of the object
shape prior. Modern deep methods more often throw away geometric constraints
altogether, rendering the results unreliable. In this paper we make an effort
to bring these two seemingly disparate strategies together. We introduce
learned shape prior in the form of deep shape generators into Photometric
Bundle Adjustment (PBA) and propose to accommodate full 3D shape generated by
the shape prior within the optimization-based inference framework,
demonstrating impressive results.
</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01470</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01471</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Convergence of Power Flow using Tx Stepping Method with
  Equivalent Circuit Formulation</dc:title>
 <dc:creator>Pandey, Amritanshu</dc:creator>
 <dc:creator>Jereminov, Marko</dc:creator>
 <dc:creator>Wagner, Martin R.</dc:creator>
 <dc:creator>Hug, Gabriela</dc:creator>
 <dc:creator>Pileggi, Larry</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Robust solving of critical large power flow cases (with 50k or greater buses)
forms the backbone of planning and operation of any large connected power grid.
At present, reliable convergence with applications of existing power flow tools
to large power systems is contingent upon a good initial guess for the system
state. To enable robust convergence for large scale systems starting with an
arbitrary initial guess, we extend our equivalent circuit formulation for power
flow analysis to include a novel continuation method based on transmission line
(Tx) stepping. While various continuation methods have been proposed for use
with the traditional PQV power flow formulation, these methods have either
failed to completely solve the problem or have resulted in convergence to a low
voltage solution. The proposed Tx Stepping method in this paper demonstrates
robust convergence to the high voltage solution from an arbitrary initial
guess. Example systems, including 75k+ bus test cases representing different
loading and operating conditions for Eastern Interconnection of the U.S. power
grid, are solved from arbitrary initial guesses.Interconnection of the U.S.
power grid, are solved from arbitrary initial guesses.
</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01471</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01478</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>OCDN: Oblivious Content Distribution Networks</dc:title>
 <dc:creator>Edmundson, Anne</dc:creator>
 <dc:creator>Schmitt, Paul</dc:creator>
 <dc:creator>Feamster, Nick</dc:creator>
 <dc:creator>Rexford, Jennifer</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  As publishers increasingly use Content Distribution Networks (CDNs) to
distribute content across geographically diverse networks, CDNs themselves are
becoming unwitting targets of requests for both access to user data and content
takedown. From copyright infringement to moderation of online speech, CDNs have
found themselves at the forefront of many recent legal quandaries. At the heart
of the tension, however, is the fact that CDNs have rich information both about
the content they are serving and the users who are requesting that content.
This paper offers a technical contribution that is relevant to this ongoing
tension with the design of an Oblivious CDN (OCDN); the system is both
compatible with the existing Web ecosystem of publishers and clients and hides
from the CDN both the content it is serving and the users who are requesting
that content. OCDN is compatible with the way that publishers currently host
content on CDNs. Using OCDN, publishers can use multiple CDNs to publish
content; clients retrieve content through a peer-to-peer anonymizing network of
proxies. Our prototype implementation and evaluation of OCDN show that the
system can obfuscate both content and clients from the CDN operator while still
delivering content with good performance.
</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01478</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01479</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling Duct Flow for Molecular Communication</dc:title>
 <dc:creator>Wicke, Wayan</dc:creator>
 <dc:creator>Schwering, Tobias</dc:creator>
 <dc:creator>Ahmadzadeh, Arman</dc:creator>
 <dc:creator>Jamali, Vahid</dc:creator>
 <dc:creator>Noel, Adam</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Active transport is sought in molecular communication to extend coverage,
improve reliability, and mitigate interference. One such active mechanism
inherent to many liquid environments is fluid flow. Flow models are often
over-simplified, e.g., assuming one-dimensional diffusion with constant drift.
However, diffusion and flow are usually encountered in three-dimensional
bounded environments where the flow is highly non-uniform such as in blood
vessels or microfluidic channels. For a qualitative understanding of the
relevant physical effects inherent to these channels a systematic framework is
provided based on the Peclet number and the ratio of transmitter-receiver
distance to duct radius. We review the relevant laws of physics and highlight
when simplified models of uniform flow and advection-only transport are
applicable. For several molecular communication setups, we highlight the effect
of different flow scenarios on the channel impulse response.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures, submitted to IEEE International Conference on
  Communications 2018 (IEEE ICC 2018)</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01479</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01481</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building a Location-Based Set of Social Media Users</dc:title>
 <dc:creator>Marks, Christopher</dc:creator>
 <dc:creator>Zaman, Tauhid</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In many instances one may want to gain situational awareness in an
environment by monitoring the content of local social media users. Often the
challenge is how to build a set of users from a target location. Here we
introduce a method for building such a set of users by using an
\emph{expand-classify} approach which begins with a small set of seed users
from the target location and then iteratively collects their neighbors and then
classifies their locations. We perform this classification using maximum
likelihood estimation on a factor graph model which incorporates features of
the user profile and also social network connections. We show that maximum
likelihood estimation reduces to solving a minimum cut problem on an
appropriately defined graph. We are able to obtain several thousand users
within a few hours for many diverse locations using our approach. Using
geo-located data, we find that our approach typically achieves good accuracy
for population centers with less than 500,000 inhabitants, while for larger
cities performance degrades somewhat. We also find that our approach is able to
collect many more users with higher accuracy than existing search methods.
Finally, we show that by studying the content of location specific users
obtained with our approach, we can identify the onset of significant social
unrest in locations such as the Philippines.
</dc:description>
 <dc:description>Comment: 13 figures</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01490</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Model that Predicts the Material Recognition Performance of Thermal
  Tactile Sensing</dc:title>
 <dc:creator>Bhattacharjee, Tapomayukh</dc:creator>
 <dc:creator>Bai, Haoping</dc:creator>
 <dc:creator>Chen, Haofeng</dc:creator>
 <dc:creator>Kemp, Charles C.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Tactile sensing can enable a robot to infer properties of its surroundings,
such as the material of an object. Heat transfer based sensing can be used for
material recognition due to differences in the thermal properties of materials.
While data-driven methods have shown promise for this recognition problem, many
factors can influence performance, including sensor noise, the initial
temperatures of the sensor and the object, the thermal effusivities of the
materials, and the duration of contact. We present a physics-based mathematical
model that predicts material recognition performance given these factors. Our
model uses semi-infinite solids and a statistical method to calculate an F1
score for the binary material recognition. We evaluated our method using
simulated contact with 69 materials and data collected by a real robot with 12
materials. Our model predicted the material recognition performance of support
vector machine (SVM) with 96% accuracy for the simulated data, with 92%
accuracy for real-world data with constant initial sensor temperatures, and
with 91% accuracy for real-world data with varied initial sensor temperatures.
Using our model, we also provide insight into the roles of various factors on
recognition performance, such as the temperature difference between the sensor
and the object. Overall, our results suggest that our model could be used to
help design better thermal sensors for robots and enable robots to use them
more effectively.
</dc:description>
 <dc:description>Comment: This article is currently under review for possible publication</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01490</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01501</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate Supermodularity Bounds for Experimental Design</dc:title>
 <dc:creator>Chamon, Luiz F. O.</dc:creator>
 <dc:creator>Ribeiro, Alejandro</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  This work provides performance guarantees for the greedy solution of
experimental design problems. In particular, it focuses on A- and E-optimal
designs, for which typical guarantees do not apply since the mean-square error
and the maximum eigenvalue of the estimation error covariance matrix are not
supermodular. To do so, it leverages the concept of approximate supermodularity
to derive non-asymptotic worst-case suboptimality bounds for these greedy
solutions. These bounds reveal that as the SNR of the experiments decreases,
these cost functions behave increasingly as supermodular functions. As such,
greedy A- and E-optimal designs approach (1-1/e)-optimality. These results
reconcile the empirical success of greedy experimental design with the
non-supermodularity of the A- and E-optimality criteria.
</dc:description>
 <dc:description>Comment: 15 pages, NIPS 2017</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01503</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Composing Meta-Policies for Autonomous Driving Using Hierarchical Deep
  Reinforcement Learning</dc:title>
 <dc:creator>Liaw, Richard</dc:creator>
 <dc:creator>Krishnan, Sanjay</dc:creator>
 <dc:creator>Garg, Animesh</dc:creator>
 <dc:creator>Crankshaw, Daniel</dc:creator>
 <dc:creator>Gonzalez, Joseph E.</dc:creator>
 <dc:creator>Goldberg, Ken</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Rather than learning new control policies for each new task, it is possible,
when tasks share some structure, to compose a &quot;meta-policy&quot; from previously
learned policies. This paper reports results from experiments using Deep
Reinforcement Learning on a continuous-state, discrete-action autonomous
driving simulator. We explore how Deep Neural Networks can represent
meta-policies that switch among a set of previously learned policies,
specifically in settings where the dynamics of a new scenario are composed of a
mixture of previously learned dynamics and where the state observation is
possibly corrupted by sensing noise. We also report the results of experiments
varying dynamics mixes, distractor policies, magnitudes/distributions of
sensing noise, and obstacles. In a fully observed experiment, the meta-policy
learning algorithm achieves 2.6x the reward achieved by the next best policy
composition technique with 80% less exploration. In a partially observed
experiment, the meta-policy learning algorithm converges after 50 iterations
while a direct application of RL fails to converge even after 200 iterations.
</dc:description>
 <dc:description>Comment: 8 pages, 11 figures</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01503</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01505</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Linguistically Generalizable NLP Systems: A Workshop and Shared
  Task</dc:title>
 <dc:creator>Ettinger, Allyson</dc:creator>
 <dc:creator>Rao, Sudha</dc:creator>
 <dc:creator>Daum&#xe9; III, Hal</dc:creator>
 <dc:creator>Bender, Emily M.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper presents a summary of the first Workshop on Building
Linguistically Generalizable Natural Language Processing Systems, and the
associated Build It Break It, The Language Edition shared task. The goal of
this workshop was to bring together researchers in NLP and linguistics with a
shared task aimed at testing the generalizability of NLP systems beyond the
distributions of their training data. We describe the motivation, setup, and
participation of the shared task, provide discussion of some highlighted
results, and discuss lessons learned.
</dc:description>
 <dc:description>Comment: Updated version of the EMNLP Workshop and Shared Task description
  paper, Proceedings of the First Workshop on Building Linguistically
  Generalizable NLP Systems. 2017</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01505</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01506</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Focal FCN: Towards Biomedical Small Object Segmentation with Limited
  Training Data</dc:title>
 <dc:creator>Zhou, Xiao-Yun</dc:creator>
 <dc:creator>Shen, Mali</dc:creator>
 <dc:creator>Riga, Celia</dc:creator>
 <dc:creator>Yang, Guang-Zhong</dc:creator>
 <dc:creator>Lee, Su-Lin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Small object segmentation is a common task in medical image analysis.
Traditional feature-based methods require human intervention while methods
based on deep learning train the neural network automatically. However, it is
still error prone when applying deep learning methods for small objects. In
this paper, Focal FCN was proposed for small object segmentation with limited
training data. Firstly, Fully-weighted FCN was proposed to apply an
initialization for Focal FCN by adding weights to the background and foreground
loss. Secondly, focal loss was applied to make the training focus on
wrongly-classified pixels and hence achieve good performance on small object
segmentation. Comparisons between FCN, Weighted FCN, Fully-weighted FCN and
Focal FCN were tested on customized stent graft marker segmentation.
</dc:description>
 <dc:description>Comment: 14 pages, 4 figure, 1 table</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01506</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01514</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distribution-Preserving k-Anonymity</dc:title>
 <dc:creator>Wei, Dennis</dc:creator>
 <dc:creator>Ramamurthy, Karthikeyan Natesan</dc:creator>
 <dc:creator>Varshney, Kush R.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Preserving the privacy of individuals by protecting their sensitive
attributes is an important consideration during microdata release. However, it
is equally important to preserve the quality or utility of the data for at
least some targeted workloads. We propose a novel framework for privacy
preservation based on the k-anonymity model that is ideally suited for
workloads that require preserving the probability distribution of the
quasi-identifier variables in the data. Our framework combines the principles
of distribution-preserving quantization and k-member clustering, and we
specialize it to two variants that respectively use intra-cluster and Gaussian
dithering of cluster centers to achieve distribution preservation. We perform
theoretical analysis of the proposed schemes in terms of distribution
preservation, and describe their utility in workloads such as covariate shift
and transfer learning where such a property is necessary. Using extensive
experiments on real-world Medical Expenditure Panel Survey data, we demonstrate
the merits of our algorithms over standard k-anonymization for a hallmark
health care application where an insurance company wishes to understand the
risk in entering a new market. Furthermore, by empirically quantifying the
reidentification risk, we also show that the proposed approaches indeed
maintain k-anonymity.
</dc:description>
 <dc:description>Comment: Portions of this work were first presented at the 2015 SIAM
  International Conference on Data Mining</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01514</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01515</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Word Embeddings from Speech</dc:title>
 <dc:creator>Chung, Yu-An</dc:creator>
 <dc:creator>Glass, James</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we propose a novel deep neural network architecture,
Sequence-to-Sequence Audio2Vec, for unsupervised learning of fixed-length
vector representations of audio segments excised from a speech corpus, where
the vectors contain semantic information pertaining to the segments, and are
close to other vectors in the embedding space if their corresponding segments
are semantically similar. The design of the proposed model is based on the RNN
Encoder-Decoder framework, and borrows the methodology of continuous skip-grams
for training. The learned vector representations are evaluated on 13 widely
used word similarity benchmarks, and achieved competitive results to that of
GloVe. The biggest advantage of the proposed model is its capability of
extracting semantic information of audio segments taken directly from raw
speech, without relying on any other modalities such as text or images, which
are challenging and expensive to collect and annotate.
</dc:description>
 <dc:description>Comment: Accepted by Machine Learning for Audio Signal Processing (ML4Audio),
  31st Conference on Neural Information Processing Systems (NIPS 2017)</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01515</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01518</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Web Today: From Oil Rigs to Panama Papers</dc:title>
 <dc:creator>Perera, Rivindu</dc:creator>
 <dc:creator>Nand, Parma</dc:creator>
 <dc:creator>Bacic, Boris</dc:creator>
 <dc:creator>Yang, Wen-Hsin</dc:creator>
 <dc:creator>Seki, Kazuhiro</dc:creator>
 <dc:creator>Burget, Radek</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The next leap on the internet has already started as Semantic Web. At its
core, Semantic Web transforms the document oriented web to a data oriented web
enriched with semantics embedded as metadata. This change in perspective
towards the web offers numerous benefits for vast amount of data intensive
industries that are bound to the web and its related applications. The
industries are diverse as they range from Oil &amp; Gas exploration to the
investigative journalism, and everything in between. This paper discusses eight
different industries which currently reap the benefits of Semantic Web. The
paper also offers a future outlook into Semantic Web applications and discusses
the areas in which Semantic Web would play a key role in the future.
</dc:description>
 <dc:description>Comment: 21 pages</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01518</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01519</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HPX Smart Executors</dc:title>
 <dc:creator>Khatami, Zahra</dc:creator>
 <dc:creator>Troska, Lukas</dc:creator>
 <dc:creator>Kaiser, Hartmut</dc:creator>
 <dc:creator>Ramanujam, J.</dc:creator>
 <dc:creator>Serio, Adrian</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The performance of many parallel applications depends on loop-level
parallelism. However, manually parallelizing all loops may result in degrading
parallel performance, as some of them cannot scale desirably to a large number
of threads. In addition, the overheads of manually tuning loop parameters might
prevent an application from reaching its maximum parallel performance. We
illustrate how machine learning techniques can be applied to address these
challenges. In this research, we develop a framework that is able to
automatically capture the static and dynamic information of a loop. Moreover,
we advocate a novel method by introducing HPX smart executors for determining
the execution policy, chunk size, and prefetching distance of an HPX loop to
achieve higher possible performance by feeding static information captured
during compilation and runtime-based dynamic information to our learning model.
Our evaluated execution results show that using these smart executors can speed
up the HPX execution process by around 12%-35% for the Matrix Multiplication,
Stream and $2D$ Stencil benchmarks compared to setting their HPX loop's
execution policy/parameters manually or using HPX auto-parallelization
techniques.
</dc:description>
 <dc:description>Comment: In Proceedings of ESPM2'17: Third International Workshop on Extreme
  Scale Programming Models and Middleware, Denver, CO, USA, November
  12-17,,2017 (ESPM2'17), 8 pages</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01519</dc:identifier>
 <dc:identifier>doi:10.1145/3152041.3152084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01520</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical Data-Dependent Metric Compression with Provable Guarantees</dc:title>
 <dc:creator>Indyk, Piotr</dc:creator>
 <dc:creator>Razenshteyn, Ilya</dc:creator>
 <dc:creator>Wagner, Tal</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We introduce a new distance-preserving compact representation of
multi-dimensional point-sets. Given $n$ points in a $d$-dimensional space where
each coordinate is represented using $B$ bits (i.e., $dB$ bits per point), it
produces a representation of size $O( d \log(d B/\epsilon) + \log n)$ bits per
point from which one can approximate the distances up to a factor of $1 \pm
\epsilon$. Our algorithm almost matches the recent bound
of~\cite{indyk2017near} while being much simpler. We compare our algorithm to
Product Quantization (PQ)~\cite{jegou2011product}, a state of the art heuristic
metric compression method. We evaluate both algorithms on several data sets:
SIFT (used in \cite{jegou2011product}), MNIST~\cite{lecun1998mnist}, New York
City taxi time series~\cite{guha2016robust} and a synthetic one-dimensional
data set embedded in a high-dimensional space. With appropriately tuned
parameters, our algorithm produces representations that are comparable to or
better than those produced by PQ, while having provable guarantees on its
performance.
</dc:description>
 <dc:description>Comment: NIPS 2017</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01521</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Greedy Algorithms For Multiple Measurement Vectors</dc:title>
 <dc:creator>Qin, Jing</dc:creator>
 <dc:creator>Li, Shuang</dc:creator>
 <dc:creator>Needell, Deanna</dc:creator>
 <dc:creator>Ma, Anna</dc:creator>
 <dc:creator>Grotheer, Rachel</dc:creator>
 <dc:creator>Huang, Chenxi</dc:creator>
 <dc:creator>Durgin, Natalie</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  Sparse representation of a single measurement vector (SMV) has been explored
in a variety of compressive sensing applications. Recently, SMV models have
been extended to solve multiple measurement vectors (MMV) problems, where the
underlying signal is assumed to have joint sparse structures. To circumvent the
NP-hardness of the $\ell_0$ minimization problem, many deterministic MMV
algorithms solve the convex relaxed models with limited efficiency. In this
paper, we develop stochastic greedy algorithms for solving the joint sparse MMV
reconstruction problem. In particular, we propose the MMV Stochastic Iterative
Hard Thresholding (MStoIHT) and MMV Stochastic Gradient Matching Pursuit
(MStoGradMP) algorithms, and we also utilize the mini-batching technique to
further improve their performance. Convergence analysis indicates that the
proposed algorithms are able to converge faster than their SMV counterparts,
i.e., concatenated StoIHT and StoGradMP, under certain conditions. Numerical
experiments have illustrated the superior effectiveness of the proposed
algorithms over their SMV counterparts.
</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01521</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01526</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Identification of Distribution Grids</dc:title>
 <dc:creator>Ardakanian, Omid</dc:creator>
 <dc:creator>Wong, Vincent W. S.</dc:creator>
 <dc:creator>Dobbe, Roel</dc:creator>
 <dc:creator>Low, Steven H.</dc:creator>
 <dc:creator>von Meier, Alexandra</dc:creator>
 <dc:creator>Tomlin, Claire</dc:creator>
 <dc:creator>Yuan, Ye</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Large-scale integration of distributed energy resources into residential
distribution feeders necessitates careful control of their operation through
power flow analysis. While the knowledge of the distribution system model is
crucial for this type of analysis, it is often unavailable or outdated. The
recent introduction of synchrophasor technology in low-voltage distribution
grids has created an unprecedented opportunity to learn this model from
high-precision, time-synchronized measurements of voltage and current phasors
at various locations. This paper focuses on joint estimation of model
parameters (admittance values) and operational structure of a poly-phase
distribution network from the available telemetry data via the lasso, a method
for regression shrinkage and selection. We propose tractable convex programs
capable of tackling the low rank structure of the distribution system and
develop an online algorithm for early detection and localization of critical
events that induce a change in the admittance matrix. The efficacy of these
techniques is corroborated through power flow studies on four three-phase
radial distribution systems serving real household demands.
</dc:description>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01526</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01530</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fisher-Rao Metric, Geometry, and Complexity of Neural Networks</dc:title>
 <dc:creator>Liang, Tengyuan</dc:creator>
 <dc:creator>Poggio, Tomaso</dc:creator>
 <dc:creator>Rakhlin, Alexander</dc:creator>
 <dc:creator>Stokes, James</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the relationship between geometry and capacity measures for deep
neural networks from an invariance viewpoint. We introduce a new notion of
capacity --- the Fisher-Rao norm --- that possesses desirable invariance
properties and is motivated by Information Geometry. We discover an analytical
characterization of the new capacity measure, through which we establish
norm-comparison inequalities and further show that the new measure serves as an
umbrella for several existing norm-based complexity measures. We discuss upper
bounds on the generalization error induced by the proposed measure. Extensive
numerical experiments on CIFAR-10 support our theoretical findings. Our
theoretical analysis rests on a key structural lemma about partial derivatives
of multi-layer rectifier networks.
</dc:description>
 <dc:description>Comment: 31 pages, 7 figures</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01530</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01537</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating Infection Sources in Networks Using Partial Timestamps</dc:title>
 <dc:creator>Tang, Wenchang</dc:creator>
 <dc:creator>Ji, Feng</dc:creator>
 <dc:creator>Tay, Wee Peng</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  We study the problem of identifying infection sources in a network based on
the network topology, and a subset of infection timestamps. In the case of a
single infection source in a tree network, we derive the maximum likelihood
estimator of the source and the unknown diffusion parameters. We then introduce
a new heuristic involving an optimization over a parametrized family of Gromov
matrices to develop a single source estimation algorithm for general graphs.
Compared with the breadth-first search tree heuristic commonly adopted in the
literature, simulations demonstrate that our approach achieves better
estimation accuracy than several other benchmark algorithms, even though these
require more information like the diffusion parameters. We next develop a
multiple sources estimation algorithm for general graphs, which first
partitions the graph into source candidate clusters, and then applies our
single source estimation algorithm to each cluster. We show that if the graph
is a tree, then each source candidate cluster contains at least one source.
Simulations using synthetic and real networks, and experiments using real-world
data suggest that our proposed algorithms are able to estimate the true
infection source(s) to within a small number of hops with a small portion of
the infection timestamps being observed.
</dc:description>
 <dc:description>Comment: 13 pages, 33 figures, submitted to IEEE Transactions on Information
  Forensics and Security</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01537</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01543</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Registration and Fusion of Multi-Spectral Images Using a Novel Edge
  Descriptor</dc:title>
 <dc:creator>Ofir, Nati</dc:creator>
 <dc:creator>Silberstein, Shai</dc:creator>
 <dc:creator>Rozenbaum, Dani</dc:creator>
 <dc:creator>Bar, Sharon Duvdevani</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we introduce a fully end-to-end approach for multi-spectral
image registration and fusion. Our method for fusion combines images from
different spectral channels into a single fused image by different approaches
for low and high frequency signals. A prerequisite of fusion is a stage of
geometric alignment between the spectral bands, commonly referred to as
registration. Unfortunately, common methods for image registration of a single
spectral channel do not yield reasonable results on images from different
modalities. For that end, we introduce a new algorithm for multi-spectral image
registration, based on a novel edge descriptor of feature points. Our method
achieves an accurate alignment of a level that allows us to further fuse the
images. As our experiments show, we produce a high quality of multi-spectral
image registration and fusion under many challenging scenarios.
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01543</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01558</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wasserstein Auto-Encoders</dc:title>
 <dc:creator>Tolstikhin, Ilya</dc:creator>
 <dc:creator>Bousquet, Olivier</dc:creator>
 <dc:creator>Gelly, Sylvain</dc:creator>
 <dc:creator>Schoelkopf, Bernhard</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose the Wasserstein Auto-Encoder (WAE)---a new algorithm for building
a generative model of the data distribution. WAE minimizes a penalized form of
the Wasserstein distance between the model distribution and the target
distribution, which leads to a different regularizer than the one used by the
Variational Auto-Encoder (VAE). This regularizer encourages the encoded
training distribution to match the prior. We compare our algorithm with several
other techniques and show that it is a generalization of adversarial
auto-encoders (AAE). Our experiments show that WAE shares many of the
properties of VAEs (stable training, encoder-decoder architecture, nice latent
manifold structure) while generating samples of better quality, as measured by
the FID score.
</dc:description>
 <dc:description>Comment: Fixed a typo in Algorithm 2</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01559</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine Learning Approach to RF Transmitter Identification</dc:title>
 <dc:creator>Youssef, K.</dc:creator>
 <dc:creator>Bouchard, Louis-S.</dc:creator>
 <dc:creator>Haigh, K. Z.</dc:creator>
 <dc:creator>Krovi, H.</dc:creator>
 <dc:creator>Silovsky, J.</dc:creator>
 <dc:creator>Valk, C. P. Vander</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  With the development and widespread use of wireless devices in recent years
(mobile phones, Internet of Things, Wi-Fi), the electromagnetic spectrum has
become extremely crowded. In order to counter security threats posed by rogue
or unknown transmitters, it is important to identify RF transmitters not by the
data content of the transmissions but based on the intrinsic physical
characteristics of the transmitters. RF waveforms represent a particular
challenge because of the extremely high data rates involved and the potentially
large number of transmitters present in a given location. These factors outline
the need for rapid fingerprinting and identification methods that go beyond the
traditional hand-engineered approaches. In this study, we investigate the use
of machine learning (ML) strategies to the classification and identification
problems, and the use of wavelets to reduce the amount of data required. Four
different ML strategies are evaluated: deep neural nets (DNN), convolutional
neural nets (CNN), support vector machines (SVM), and multi-stage training
(MST) using accelerated Levenberg-Marquardt (A-LM) updates. The A-LM MST method
preconditioned by wavelets was by far the most accurate, achieving 100%
classification accuracy of transmitters, as tested using data originating from
12 different transmitters. We discuss strategies for extension of MST to a much
larger number of transmitters.
</dc:description>
 <dc:description>Comment: 14 pages, 14 figures</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01559</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01560</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diffusion Operator and Spectral Analysis for Directed Hypergraph
  Laplacian</dc:title>
 <dc:creator>Chan, T-H. Hubert</dc:creator>
 <dc:creator>Tang, Zhihao Gavin</dc:creator>
 <dc:creator>Wu, Xiaowei</dc:creator>
 <dc:creator>Zhang, Chenzi</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  In spectral graph theory, the Cheeger's inequality gives upper and lower
bounds of edge expansion in normal graphs in terms of the second eigenvalue of
the graph's Laplacian operator. Recently this inequality has been extended to
undirected hypergraphs and directed normal graphs via a non-linear operator
associated with a diffusion process in the underlying graph.
  In this work, we develop a unifying framework for defining a diffusion
operator on a directed hypergraph with stationary vertices, which is general
enough for the following two applications.
  1. Cheeger's inequality for directed hyperedge expansion.
  2. Quadratic optimization with stationary vertices in the context of
semi-supervised learning.
  Despite the crucial role of the diffusion process in spectral analysis,
previous works have not formally established the existence of the corresponding
diffusion processes. In this work, we give a proof framework that can indeed
show that such diffusion processes are well-defined. In the first application,
we use the spectral properties of the diffusion operator to achieve the
Cheeger's inequality for directed hyperedge expansion. In the second
application, the diffusion operator can be interpreted as giving a continuous
analog to the subgradient method, which moves the feasible solution in discrete
steps towards an optimal solution.
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01560</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01563</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-label Dataless Text Classification with Topic Modeling</dc:title>
 <dc:creator>Zha, Daochen</dc:creator>
 <dc:creator>Li, Chenliang</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Manually labeling documents is tedious and expensive, but it is essential for
training a traditional text classifier. In recent years, a few dataless text
classification techniques have been proposed to address this problem. However,
existing works mainly center on single-label classification problems, that is,
each document is restricted to belonging to a single category. In this paper,
we propose a novel Seed-guided Multi-label Topic Model, named SMTM. With a few
seed words relevant to each category, SMTM conducts multi-label classification
for a collection of documents without any labeled document. In SMTM, each
category is associated with a single category-topic which covers the meaning of
the category. To accommodate with multi-labeled documents, we explicitly model
the category sparsity in SMTM by using spike and slab prior and weak smoothing
prior. That is, without using any threshold tuning, SMTM automatically selects
the relevant categories for each document. To incorporate the supervision of
the seed words, we propose a seed-guided biased GPU (i.e., generalized Polya
urn) sampling procedure to guide the topic inference of SMTM. Experiments on
two public datasets show that SMTM achieves better classification accuracy than
state-of-the-art alternatives and even outperforms supervised solutions in some
scenarios.
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01563</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01566</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Submodular Maximization: The Case of Coverage Functions</dc:title>
 <dc:creator>Karimi, Mohammad Reza</dc:creator>
 <dc:creator>Lucic, Mario</dc:creator>
 <dc:creator>Hassani, Hamed</dc:creator>
 <dc:creator>Krause, Andreas</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Stochastic optimization of continuous objectives is at the heart of modern
machine learning. However, many important problems are of discrete nature and
often involve submodular objectives. We seek to unleash the power of stochastic
continuous optimization, namely stochastic gradient descent and its variants,
to such discrete problems. We first introduce the problem of stochastic
submodular optimization, where one needs to optimize a submodular objective
which is given as an expectation. Our model captures situations where the
discrete objective arises as an empirical risk (e.g., in the case of
exemplar-based clustering), or is given as an explicit stochastic model (e.g.,
in the case of influence maximization in social networks). By exploiting that
common extensions act linearly on the class of submodular functions, we employ
projected stochastic gradient ascent and its variants in the continuous domain,
and perform rounding to obtain discrete solutions. We focus on the rich and
widely used family of weighted coverage functions. We show that our approach
yields solutions that are guaranteed to match the optimal approximation
guarantees, while reducing the computational cost by several orders of
magnitude, as we demonstrate empirically.
</dc:description>
 <dc:description>Comment: 31st Conference on Neural Information Processing Systems (NIPS 2017)</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01566</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01567</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Speech Recognition Using Generative Adversarial Networks</dc:title>
 <dc:creator>Sriram, Anuroop</dc:creator>
 <dc:creator>Jun, Heewoo</dc:creator>
 <dc:creator>Gaur, Yashesh</dc:creator>
 <dc:creator>Satheesh, Sanjeev</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper describes a general, scalable, end-to-end framework that uses the
generative adversarial network (GAN) objective to enable robust speech
recognition. Encoders trained with the proposed approach enjoy improved
invariance by learning to map noisy audio to the same embedding space as that
of clean audio. Unlike previous methods, the new framework does not rely on
domain expertise or simplifying assumptions as are often needed in signal
processing, and directly encourages robustness in a data-driven way. We show
the new approach improves simulated far-field speech recognition of vanilla
sequence-to-sequence models without specialized front-ends or preprocessing.
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01567</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01569</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Double Q($\sigma$) and Q($\sigma, \lambda$): Unifying Reinforcement
  Learning Control Algorithms</dc:title>
 <dc:creator>Dumke, Markus</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Temporal-difference (TD) learning is an important field in reinforcement
learning. Sarsa and Q-Learning are among the most used TD algorithms. The
Q($\sigma$) algorithm (Sutton and Barto (2017)) unifies both. This paper
extends the Q($\sigma$) algorithm to an online multi-step algorithm Q($\sigma,
\lambda$) using eligibility traces and introduces Double Q($\sigma$) as the
extension of Q($\sigma$) to double learning. Experiments suggest that the new
Q($\sigma, \lambda$) algorithm can outperform the classical TD control methods
Sarsa($\lambda$), Q($\lambda$) and Q($\sigma$).
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01569</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01573</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Local Dimension of Deep Manifold</dc:title>
 <dc:creator>Zhang, Mengxiao</dc:creator>
 <dc:creator>Wu, Wangquan</dc:creator>
 <dc:creator>Zhang, Yanren</dc:creator>
 <dc:creator>He, Kun</dc:creator>
 <dc:creator>Yu, Tao</dc:creator>
 <dc:creator>Long, Huan</dc:creator>
 <dc:creator>Hopcroft, John E.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Based on our observation that there exists a dramatic drop for the singular
values of the fully connected layers or a single feature map of the
convolutional layer, and that the dimension of the concatenated feature vector
almost equals the summation of the dimension on each feature map, we propose a
singular value decomposition (SVD) based approach to estimate the dimension of
the deep manifolds for a typical convolutional neural network VGG19. We choose
three categories from the ImageNet, namely Persian Cat, Container Ship and
Volcano, and determine the local dimension of the deep manifolds of the deep
layers through the tangent space of a target image. Through several
augmentation methods, we found that the Gaussian noise method is closer to the
intrinsic dimension, as by adding random noise to an image we are moving in an
arbitrary dimension, and when the rank of the feature matrix of the augmented
images does not increase we are very close to the local dimension of the
manifold. We also estimate the dimension of the deep manifold based on the
tangent space for each of the maxpooling layers. Our results show that the
dimensions of different categories are close to each other and decline quickly
along the convolutional layers and fully connected layers. Furthermore, we show
that the dimensions decline quickly inside the Conv5 layer. Our work provides
new insights for the intrinsic structure of deep neural networks and helps
unveiling the inner organization of the black box of deep neural networks.
</dc:description>
 <dc:description>Comment: 11 pages, 11 figures</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01573</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01575</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Dropout Regularization</dc:title>
 <dc:creator>Saito, Kuniaki</dc:creator>
 <dc:creator>Ushiku, Yoshitaka</dc:creator>
 <dc:creator>Harada, Tatsuya</dc:creator>
 <dc:creator>Saenko, Kate</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a method for transferring neural representations from label-rich
source domains to unlabeled target domains. Recent adversarial methods proposed
for this task learn to align features across domains by fooling a special
domain critic network. However, a drawback of this approach is that the critic
simply labels the generated features as in-domain or not, without considering
the boundaries between classes. This can lead to ambiguous features being
generated near class boundaries, reducing target classification accuracy. We
propose a novel approach, Adversarial Dropout Regularization (ADR), to
encourage the generator to output more discriminative features for the target
domain. Our key idea is to replace the critic with one that detects
non-discriminative features, using dropout on the classifier network. The
generator then learns to avoid these areas of the feature space and thus
creates better features. We apply our ADR approach to the problem of
unsupervised domain adaptation for image classification and semantic
segmentation tasks, and demonstrate significant improvement over the state of
the art. We also show that our approach can be used to train Generative
Adversarial Networks for semi-supervised learning.
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01575</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01577</identifier>
 <datestamp>2017-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wider and Deeper, Cheaper and Faster: Tensorized LSTMs for Sequence
  Learning</dc:title>
 <dc:creator>He, Zhen</dc:creator>
 <dc:creator>Gao, Shaobing</dc:creator>
 <dc:creator>Xiao, Liang</dc:creator>
 <dc:creator>Liu, Daxue</dc:creator>
 <dc:creator>He, Hangen</dc:creator>
 <dc:creator>Barber, David</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Long Short-Term Memory (LSTM) is a popular approach to boosting the ability
of Recurrent Neural Networks to store longer term temporal information. The
capacity of an LSTM network can be increased by widening and adding layers.
However, usually the former introduces additional parameters, while the latter
increases the runtime. As an alternative we propose the Tensorized LSTM in
which the hidden states are represented by tensors and updated via a
cross-layer convolution. By increasing the tensor size, the network can be
widened efficiently without additional parameters since the parameters are
shared across different locations in the tensor; by delaying the output, the
network can be deepened implicitly with little additional runtime since deep
computations for each timestep are merged into temporal computations of the
sequence. Experiments conducted on five challenging sequence learning tasks
show the potential of the proposed model.
</dc:description>
 <dc:description>Comment: Accepted by NIPS 2017</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:date>2017-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01577</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01587</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inference-Based Similarity Search in Randomized Montgomery Domains for
  Privacy-Preserving Biometric Identification</dc:title>
 <dc:creator>Wang, Yi</dc:creator>
 <dc:creator>Wan, Jianwu</dc:creator>
 <dc:creator>Guo, Jun</dc:creator>
 <dc:creator>Cheung, Yiu-Ming</dc:creator>
 <dc:creator>Yuen, Pong C</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Similarity search is essential to many important applications and often
involves searching at scale on high-dimensional data based on their similarity
to a query. In biometric applications, recent vulnerability studies have shown
that adversarial machine learning can compromise biometric recognition systems
by exploiting the biometric similarity information. Existing methods for
biometric privacy protection are in general based on pairwise matching of
secured biometric templates and have inherent limitations in search efficiency
and scalability. In this paper, we propose an inference-based framework for
privacy-preserving similarity search in Hamming space. Our approach builds on
an obfuscated distance measure that can conceal Hamming distance in a dynamic
interval. Such a mechanism enables us to systematically design statistically
reliable methods for retrieving most likely candidates without knowing the
exact distance values. We further propose to apply Montgomery multiplication
for generating search indexes that can withstand adversarial similarity
analysis, and show that information leakage in randomized Montgomery domains
can be made negligibly small. Our experiments on public biometric datasets
demonstrate that the inference-based approach can achieve a search accuracy
close to the best performance possible with secure computation methods, but the
associated cost is reduced by orders of magnitude compared to cryptographic
primitives.
</dc:description>
 <dc:description>Comment: 14 pages, 10 figures, 2 tables, regular paper</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01587</dc:identifier>
 <dc:identifier>doi:10.1109/TPAMI.2017.2727048</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01589</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simultaneous Joint and Object Trajectory Templates for Human Activity
  Recognition from 3-D Data</dc:title>
 <dc:creator>Ghodsi, Saeed</dc:creator>
 <dc:creator>Mohammadzade, Hoda</dc:creator>
 <dc:creator>Korki, Erfan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The availability of low-cost range sensors and the development of relatively
robust algorithms for the extraction of skeleton joint locations have inspired
many researchers to develop human activity recognition methods using the 3-D
data. In this paper, an effective method for the recognition of human
activities from the normalized joint trajectories is proposed. We represent the
actions as multidimensional signals and introduce a novel method for generating
action templates by averaging the samples in a &quot;dynamic time&quot; sense. Then in
order to deal with the variations in the speed and style of performing actions,
we warp the samples to the action templates by an efficient algorithm and
employ wavelet filters to extract meaningful spatiotemporal features. The
proposed method is also capable of modeling the human-object interactions, by
performing the template generation and temporal warping procedure via the joint
and object trajectories simultaneously. The experimental evaluation on several
challenging datasets demonstrates the effectiveness of our method compared to
the state-of-the-arts.
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01589</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01596</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Is Input Sparsity Time Possible for Kernel Low-Rank Approximation?</dc:title>
 <dc:creator>Musco, Cameron</dc:creator>
 <dc:creator>Woodruff, David P.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Low-rank approximation is a common tool used to accelerate kernel methods:
the $n \times n$ kernel matrix $K$ is approximated via a rank-$k$ matrix
$\tilde K$ which can be stored in much less space and processed more quickly.
In this work we study the limits of computationally efficient low-rank kernel
approximation. We show that for a broad class of kernels, including the popular
Gaussian and polynomial kernels, computing a relative error $k$-rank
approximation to $K$ is at least as difficult as multiplying the input data
matrix $A \in \mathbb{R}^{n \times d}$ by an arbitrary matrix $C \in
\mathbb{R}^{d \times k}$. Barring a breakthrough in fast matrix multiplication,
when $k$ is not too large, this requires $\Omega(nnz(A)k)$ time where $nnz(A)$
is the number of non-zeros in $A$. This lower bound matches, in many parameter
regimes, recent work on subquadratic time algorithms for low-rank approximation
of general kernels [MM16,MW17], demonstrating that these algorithms are
unlikely to be significantly improved, in particular to $O(nnz(A))$ input
sparsity runtimes. At the same time there is hope: we show for the first time
that $O(nnz(A))$ time approximation is possible for general radial basis
function kernels (e.g., the Gaussian kernel) for the closely related problem of
low-rank approximation of the kernelized dataset.
</dc:description>
 <dc:description>Comment: To appear, NIPS 2017</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01596</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01616</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bloom Filters, Adaptivity, and the Dictionary Problem</dc:title>
 <dc:creator>Bender, Michael A.</dc:creator>
 <dc:creator>Farach-Colton, Martin</dc:creator>
 <dc:creator>Goswami, Mayank</dc:creator>
 <dc:creator>Johnson, Rob</dc:creator>
 <dc:creator>McCauley, Samuel</dc:creator>
 <dc:creator>Singh, Shikha</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The Bloom filter---or, more generally, an approximate membership query data
structure (AMQ)---maintains a compact, probabilistic representation of a set S
of keys from a universe U . An AMQ supports lookup, and possibly insert and
delete operations. If x in S, then lookup(x) returns &quot;present.&quot; If x not in S,
then, lookup(x) may return &quot;present&quot; with probability at most epsilon, where
epsilon is a tunable false-positive probability, and such an x is called a
false positive of the AMQ. Otherwise lookup(x) returns &quot;absent.&quot; AMQs have
become widely used to accelerate dictionaries that are stored remotely (e.g.,
on disk or across a network). By using an AMQ, the dictionary needs to access
the remote representation of S only when the AMQ indicates that the queried
item might be present in S.
  Thus, the primary goal of an AMQ is to minimize its false-positive rate, so
that the number of unnecessary accesses to the remote representation of S can
be minimized. However, the false-positive guarantees for AMQs are rather weak.
The false-positive probability of epsilon holds only for distinct or randomly
chosen queries, but does not hold for arbitrary sequences of queries. For
example, an adversary that chooses its queries based on the outcomes of
previous queries can easily create a sequence of queries consisting almost
entirely of false positives. Even simply repeating a randomly chosen query has
an epsilon chance of producing a sequence entirely of false positives. In this
paper, we give adaptive AMQs that do have strong false-positive guarantees. In
particular, for any fixed epsilon, our AMQs guarantee a false-positive rate of
epsilon for every query and for every sequence of previously made queries.
Furthermore, our adaptive AMQ is optimal in terms of space (up to lower order
terms) and complexity (all operations are constant time).
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01616</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01620</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scheduling Wireless Ad Hoc Networks in Polynomial Time Using Claw-free
  Conflict Graphs</dc:title>
 <dc:creator>Kose, Alper</dc:creator>
 <dc:creator>Medard, Muriel</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we address the scheduling problem in wireless ad hoc networks
by exploiting the computational advantage that comes when such scheduling
problems can be represented by claw-free conflict graphs. It is possible to
formulate a scheduling problem of network coded flows as finding maximum
weighted independent set (MWIS) in the conflict graph of the network. We
consider activation of hyperedges in a hypergraph to model a wireless broadcast
medium. We show that the conflict graph of certain wireless ad hoc networks are
claw-free. It is known that finding MWIS of a general graph is NP-hard, but in
a claw-free conflict graph, it is possible to apply Minty's or Faenza et al.'s
algorithms in polynomial time. We discuss our approach on some sample networks.
</dc:description>
 <dc:description>Comment: This paper has been presented by Alper Kose in the IEEE International
  Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC) 2017</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01620</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01623</identifier>
 <datestamp>2017-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fooling Views: A New Lower Bound Technique for Distributed Computations
  under Congestion</dc:title>
 <dc:creator>Abboud, Amir</dc:creator>
 <dc:creator>Censor-Hillel, Keren</dc:creator>
 <dc:creator>Khoury, Seri</dc:creator>
 <dc:creator>Lenzen, Christoph</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We introduce a novel lower bound technique for distributed graph algorithms
under bandwidth limitations.
  We define the notion of \emph{fooling views} and exemplify its strength by
proving two new lower bounds for triangle membership in the CONGEST(B) model:
  (i) Any $1$-round algorithm requires $B\geq c\Delta \log n$ for a constant
$c&gt;0$.
  (ii) If $B=1$, even in constant-degree graphs any algorithm must take
$\Omega(\log^* n)$ rounds.
  The implication of the former is the first proven separation between the
LOCAL and the CONGEST models for deterministic triangle membership.
  The latter result is the first non-trivial lower bound on the number of
rounds required, even for \emph{triangle detection}, under limited bandwidth.
  All previous known techniques are provably incapable of giving these bounds.
  We hope that our approach may pave the way for proving lower bounds for
additional problems in various settings of distributed computing for which
previous techniques do not suffice.
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:date>2017-12-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01623</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01624</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Power Flow Robustness via Circuit Simulation Methods</dc:title>
 <dc:creator>Pandey, Amritanshu</dc:creator>
 <dc:creator>Jereminov, Marko</dc:creator>
 <dc:creator>Hug, Gabriela</dc:creator>
 <dc:creator>Pileggi, Larry</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Recent advances in power system simulation have included the use of complex
rectangular current and voltage (I-V) variables for solving the power flow and
three-phase power flow problems. This formulation has demonstrated superior
convergence properties over conventional polar coordinate based formulations
for three-phase power flow, but has failed to replicate the same advantages for
power flow in general due to convergence issues with systems containing PV
buses. In this paper, we demonstrate how circuit simulation techniques can
provide robust convergence for any complex I-V formulation that is derived from
our split equivalent circuit representation. Application to power grid test
systems with up to 10000 buses demonstrates consistent global convergence to
the correct physical solution from arbitrary initial conditions.
</dc:description>
 <dc:description>Comment: Presented at IEEE PES General Meeting, July 2017, Chicago</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01624</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01625</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trustware: A Device-based Protocol for Verifying Client Legitimacy</dc:title>
 <dc:creator>Doyle, Ben</dc:creator>
 <dc:creator>Korth, Patrick</dc:creator>
 <dc:creator>Nekritz, Kyle</dc:creator>
 <dc:creator>Salem, Zane</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Online services commonly attempt to verify the legitimacy of users with
CAPTCHAs. However, CAPTCHAs are annoying for users, often difficult for users
to solve, and can be defeated using cheap labor or, increasingly, with improved
algorithms. We propose a new protocol for clients to prove their legitimacy,
allowing the client's devices to vouch for the client. The client's devices,
and those in close proximity, provide a one-time passcode that is verified by
the device manufacturer. This verification proves that the client has physical
access to expensive and trusted devices, vouching for the client's legitimacy.
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01625</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01628</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Effect of Communication on Noncooperative Multiplayer Multi-Armed
  Bandit Problems</dc:title>
 <dc:creator>Evirgen, Noyan</dc:creator>
 <dc:creator>Kose, Alper</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider decentralized stochastic multi-armed bandit problem with multiple
players in the case of different communication probabilities between players.
Each player makes a decision of pulling an arm without cooperation while aiming
to maximize his or her reward but informs his or her neighbors in the end of
every turn about the arm he or she pulled and the reward he or she got.
Neighbors of players are determined according to an Erdos-Renyi graph with
which is reproduced in the beginning of every turn. We consider i.i.d. rewards
generated by a Bernoulli distribution and assume that players are unaware about
the arms' probability distributions and their mean values. In case of a
collision, we assume that only one of the players who is randomly chosen gets
the reward where the others get zero reward. We study the effects of
connectivity, the degree of communication between players, on the cumulative
regret using well-known algorithms UCB1, epsilon-Greedy and Thompson Sampling.
</dc:description>
 <dc:description>Comment: This work has been accepted to the 2017 IEEE ICMLA</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01628</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01629</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mutual Information in Frequency and its Application to Measure
  Cross-Frequency Coupling in Epilepsy</dc:title>
 <dc:creator>Malladi, Rakesh</dc:creator>
 <dc:creator>Johnson, Don H</dc:creator>
 <dc:creator>Kalamangalam, Giridhar P</dc:creator>
 <dc:creator>Tandon, Nitin</dc:creator>
 <dc:creator>Aazhang, Behnaam</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  We define a novel metric, mutual information in frequency (MI-in-frequency),
to detect and quantify the statistical dependence between different frequency
components in the data and apply it to electrophysiological recordings from the
brain to infer cross-frequency coupling. The current metrics used to quantify
the cross-frequency coupling in neuroscience cannot detect statistical
independence in frequency between nonlinear recordings. Our MI-in-frequency
metric, based on Shannon's mutual information between the Cram\'{e}r's
representation of stochastic processes, overcomes this shortcoming. We describe
two data-driven estimators of MI-in-frequency: one based on kernel density
estimation and the other based on the nearest neighbor algorithm and validate
their performance on linear and nonlinear models. We then use MI-in-frequency
to estimate mutual information between two data streams that are dependent
across time, without making parametric model assumptions. Finally, we use the
MI-in-frequency metric to investigate the cross-frequency coupling in seizure
onset zone from electrocorticographic recordings during seizures. The inferred
cross-frequency coupling characteristics are essential to optimize the spatial
and spectral parameters of electrical stimulation based treatments of epilepsy.
</dc:description>
 <dc:description>Comment: This paper is under review for publication in IEEE Transactions on
  Signal Processing and contains 28 pages, 8 figures and 1 table</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01629</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01630</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capacity upper bounds for deletion-type channels</dc:title>
 <dc:creator>Cheraghchi, Mahdi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We develop a systematic approach, based on convex programming and real
analysis, for obtaining upper bounds on the capacity of the binary deletion
channel and, more generally, channels with i.i.d. insertions and deletions.
Other than the classical deletion channel, we give a special attention to the
Poisson-repeat channel introduced by Mitzenmacher and Drinea (IEEE Transactions
on Information Theory, 2006). Our framework can be applied to obtain capacity
upper bounds for any repetition distribution (the deletion and Poisson-repeat
channels corresponding to the special cases of Bernoulli and Poisson
distributions). Our techniques essentially reduce the task of proving capacity
upper bounds to maximizing a univariate, real-valued, and often concave
function over a bounded interval. We show the following:
  1. The capacity of the binary deletion channel with deletion probability $d$
is at most $(1-d)\log\varphi$ for $d\geq 1/2$, and, assuming the capacity
function is convex, is at most $1-d\log(4/\varphi)$ for $d&lt;1/2$, where
$\varphi=(1+\sqrt{5})/2$ is the golden ratio. This is the first nontrivial
capacity upper bound for any value of $d$ outside the limiting case $d\to 0$
that is fully explicit and proved without computer assistance.
  2. We derive the first set of capacity upper bounds for the Poisson-repeat
channel.
  3. We derive several novel upper bounds on the capacity of the deletion
channel. All upper bounds are maximums of efficiently computable, and concave,
univariate real functions over a bounded domain. In turn, we upper bound these
functions in terms of explicit elementary and standard special functions, whose
maximums can be found even more efficiently (and sometimes, analytically, for
example for $d=1/2$).
  Along the way, we develop several new techniques of potentially independent
interest in information theory, probability, and mathematical analysis.
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01630</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01631</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Space Time MUSIC: Consistent Signal Subspace Estimation for Wide-band
  Sensor Arrays</dc:title>
 <dc:creator>Di Claudio, Elio D.</dc:creator>
 <dc:creator>Parisi, Raffaele</dc:creator>
 <dc:creator>Jacovitti, Giovanni</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Wide-band Direction of Arrival (DOA) estimation with sensor arrays is an
essential task in sonar, radar, acoustics, biomedical and multimedia
applications. Many state of the art wide-band DOA estimators coherently process
frequency binned array outputs by approximate Maximum Likelihood, Weighted
Subspace Fitting or focusing techniques. This paper shows that bin signals
obtained by filter-bank approaches do not obey the finite rank narrow-band
array model, because spectral leakage and the change of the array response with
frequency within the bin create \emph{ghost sources} dependent on the
particular realization of the source process. Therefore, existing DOA
estimators based on binning cannot claim consistency even with the perfect
knowledge of the array response. In this work, a more realistic array model
with a finite length of the sensor impulse responses is assumed, which still
has finite rank under a space-time formulation. It is shown that signal
subspaces at arbitrary frequencies can be consistently recovered under mild
conditions by applying MUSIC-type (ST-MUSIC) estimators to the dominant
eigenvectors of the wide-band space-time sensor cross-correlation matrix. A
novel Maximum Likelihood based ST-MUSIC subspace estimate is developed in order
to recover consistency. The number of sources active at each frequency are
estimated by Information Theoretic Criteria. The sample ST-MUSIC subspaces can
be fed to any subspace fitting DOA estimator at single or multiple frequencies.
Simulations confirm that the new technique clearly outperforms binning
approaches at sufficiently high signal to noise ratio, when model mismatches
exceed the noise floor.
</dc:description>
 <dc:description>Comment: 15 pages, 10 figures. Submitted to the IEEE Trans. on Signal
  Processing</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01631</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01634</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strategies for Conceptual Change in Convolutional Neural Networks</dc:title>
 <dc:creator>Grachten, Maarten</dc:creator>
 <dc:creator>Chac&#xf3;n, Carlos Eduardo Cancino</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  A remarkable feature of human beings is their capacity for creative
behaviour, referring to their ability to react to problems in ways that are
novel, surprising, and useful. Transformational creativity is a form of
creativity where the creative behaviour is induced by a transformation of the
actor's conceptual space, that is, the representational system with which the
actor interprets its environment. In this report, we focus on ways of adapting
systems of learned representations as they switch from performing one task to
performing another. We describe an experimental comparison of multiple
strategies for adaptation of learned features, and evaluate how effectively
each of these strategies realizes the adaptation, in terms of the amount of
training, and in terms of their ability to cope with restricted availability of
training data. We show, among other things, that across handwritten digits,
natural images, and classical music, adaptive strategies are systematically
more effective than a baseline method that starts learning from scratch.
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01634</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01636</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Kneser graphs are Hamiltonian</dc:title>
 <dc:creator>M&#xfc;tze, Torsten</dc:creator>
 <dc:creator>Nummenpalo, Jerri</dc:creator>
 <dc:creator>Walczak, Bartosz</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  For integers $k\geq 1$ and $n\geq 2k+1$, the Kneser graph $K(n,k)$ is the
graph whose vertices are the $k$-element subsets of $\{1,\ldots,n\}$ and whose
edges connect pairs of subsets that are disjoint. The Kneser graphs of the form
$K(2k+1,k)$ are also known as the odd graphs. We settle an old problem due to
Meredith, Lloyd, and Biggs from the 1970s, proving that for every $k\geq 3$,
the odd graph $K(2k+1,k)$ has a Hamilton cycle. This and a known conditional
result due to Johnson imply that all Kneser graphs of the form $K(2k+2^a,k)$
with $k\geq 3$ and $a\geq 0$ have a Hamilton cycle. We also prove that
$K(2k+1,k)$ has at least $2^{2^{k-6}}$ distinct Hamilton cycles for $k\geq 6$.
Our proofs are based on a reduction of the Hamiltonicity problem in the odd
graph to the problem of finding a spanning tree in a suitably defined
hypergraph on Dyck words.
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01636</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01637</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimized State Space Grids for Abstractions</dc:title>
 <dc:creator>Weber, Alexander</dc:creator>
 <dc:creator>Rungger, Matthias</dc:creator>
 <dc:creator>Reissig, Gunther</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Primary, 93B51, Secondary, 93B52, 93C10, 93C30, 93C55, 93C57, 93C65</dc:subject>
 <dc:description>  The practical impact of abstraction-based controller synthesis methods is
currently limited by the immense computational effort for obtaining
abstractions. In this note we focus on a recently proposed method to compute
abstractions whose state space is a cover of the state space of the plant by
congruent hyper-intervals. The problem of how to choose the size of the
hyper-intervals so as to obtain computable and useful abstractions is unsolved.
This note provides a twofold contribution towards a solution. Firstly, we
present a functional to predict the computational effort for the abstraction to
be computed. Secondly, we propose a method for choosing the aspect ratio of the
hyper-intervals when their volume is fixed. More precisely, we propose to
choose the aspect ratio so as to minimize a predicted number of transitions of
the abstraction to be computed, in order to reduce the computational effort. To
this end, we derive a functional to predict the number of transitions in
dependence of the aspect ratio. The functional is to be minimized subject to
suitable constraints. We characterize the unique solvability of the respective
optimization problem and prove that it transforms, under appropriate
assumptions, into an equivalent convex problem with strictly convex objective.
The latter problem can then be globally solved using standard numerical
methods. We demonstrate our approach on an example.
</dc:description>
 <dc:description>Comment: This is the accepted version of a paper published in IEEE Trans.
  Automat. Control</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01637</dc:identifier>
 <dc:identifier>IEEE Trans. Automat. Control, vol. 62, no. 11, pp. 5816-5821, 2017</dc:identifier>
 <dc:identifier>doi:10.1109/TAC.2016.2642794</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01647</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Comparison of Algorithms for Movie Rating Estimation</dc:title>
 <dc:creator>Kose, Alper</dc:creator>
 <dc:creator>Kanbak, Can</dc:creator>
 <dc:creator>Evirgen, Noyan</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, our goal is to compare performances of three different
algorithms to predict the ratings that will be given to movies by potential
users where we are given a user-movie rating matrix based on the past
observations. To this end, we evaluate User-Based Collaborative Filtering,
Iterative Matrix Factorization and Yehuda Koren's Integrated model using
neighborhood and factorization where we use root mean square error (RMSE) as
the performance evaluation metric. In short, we do not observe significant
differences between performances, especially when the complexity increase is
considered. We can conclude that Iterative Matrix Factorization performs fairly
well despite its simplicity.
</dc:description>
 <dc:description>Comment: This work has been accepted to the 2017 IEEE ICMLA</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01647</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01649</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Investigations of a Robotic Testbed with Viscoelastic Liquid Cooled
  Actuators</dc:title>
 <dc:creator>Kim, Donghyun</dc:creator>
 <dc:creator>Ahn, Junhyeok</dc:creator>
 <dc:creator>Campbell, Orion</dc:creator>
 <dc:creator>Paine, Nicholas</dc:creator>
 <dc:creator>Sentis, Luis</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We design, build, and empirically test a robotic leg prototype using a new
type of high performance device dubbed a viscoelastic liquid cooled actuator
(VLCA). VLCAs excel in the following five critical axes of performance, which
are essential for dynamic locomotion of legged systems: energy efficiency,
torque density, mechanical robustness, position and force controllability. We
first study the design objectives and choices of the VLCA to enhance the
performance on the needed criteria. We follow by an investigation on
viscoelastic materials in terms of their damping, viscous and hysteresis
properties as well as parameters related to the long-term performance. As part
of the actuator design, we configure a disturbance observer to provide
high-fidelity force control to enable a wide range of impedance control
capabilities. After designing the VLCA, we proceed to design a robotic system
capable to lift payloads of 32.5 kg, which is three times larger than its own
weight. In addition, we experiment with Cartesian trajectory control up to 2 Hz
with a vertical range of motion of 32 cm while carrying a payload of 10 kg.
Finally, we perform experiments on impedance control by studying the response
of the leg testbed to hammering impacts and external force interactions.
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01649</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01654</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond Profiling: Scaling Profiling Data Usage to Multiple Applications</dc:title>
 <dc:creator>Quackenbush, Chris</dc:creator>
 <dc:creator>Zahran, Mohamed</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Profiling techniques are used extensively at different parts of the computing
stack to achieve many goals. One major goal is to make a piece of software
execute more efficiently on a specific hardware platform, where efficiency
spans criteria such as power, performance, resource requirements, etc.
Researchers, both in academia and industry, have introduced many techniques to
gather, and make use of, profiling data. However, one thing remains unchanged:
making application A run more efficiently on machine 1. In this paper, we
extend this criteria by asking: can profiling information of application A on
machine 1 be used to make application B run more efficiently on machine 1? If
so, then this means as machine 1 continues to execute more applications, it
becomes better and more efficient. We present a generalized method for using
profiling information gathered from the execution of programs from a limited
corpus of applications to improve the performance of software from outside our
corpus. As a proof of concept, we apply our technique to the specific problem
of selecting the most efficient last-level-cache with which to execute an
application. We were able to turn off an average of 19% of last-level-cache
blocks for selected programs from PARSEC benchmark suite and only saw an
average 2.8% increase in the rate of last-level cache misses.
</dc:description>
 <dc:description>Comment: 18 pages, 13 figures</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01654</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01655</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximating Partition Functions in Constant Time</dc:title>
 <dc:creator>Jain, Vishesh</dc:creator>
 <dc:creator>Koehler, Frederic</dc:creator>
 <dc:creator>Mossel, Elchanan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study approximations of the partition function of dense graphical models.
Partition functions of graphical models play a fundamental role is statistical
physics, in statistics and in machine learning. Two of the main methods for
approximating the partition function are Markov Chain Monte Carlo and
Variational Methods. An impressive body of work in mathematics, physics and
theoretical computer science provides conditions under which Markov Chain Monte
Carlo methods converge in polynomial time. These methods often lead to
polynomial time approximation algorithms for the partition function in cases
where the underlying model exhibits correlation decay. There are very few
theoretical guarantees for the performance of variational methods. One
exception is recent results by Risteski (2016) who considered dense graphical
models and showed that using variational methods, it is possible to find an
$O(\epsilon n)$ additive approximation to the log partition function in time
$n^{O(1/\epsilon^2)}$ even in a regime where correlation decay does not hold.
  We show that under essentially the same conditions, an $O(\epsilon n)$
additive approximation of the log partition function can be found in constant
time, independent of $n$. In particular, our results cover dense Ising and
Potts models as well as dense graphical models with $k$-wise interaction. They
also apply for low threshold rank models.
  To the best of our knowledge, our results are the first to give a constant
time approximation to log partition functions and the first to use the
algorithmic regularity lemma for estimating partition functions. As an
application of our results we derive a constant time algorithm for
approximating the magnetization of Ising and Potts model on dense graphs.
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01655</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01656</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial Pyramid Context-Aware Moving Object Detection and Tracking for
  Full Motion Video and Wide Aerial Motion Imagery</dc:title>
 <dc:creator>Poostchi, Mahdieh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A robust and fast automatic moving object detection and tracking system is
essential to characterize target object and extract spatial and temporal
information for different functionalities including video surveillance systems,
urban traffic monitoring and navigation, robotic. In this dissertation, I
present a collaborative Spatial Pyramid Context-aware moving object detection
and Tracking system. The proposed visual tracker is composed of one master
tracker that usually relies on visual object features and two auxiliary
trackers based on object temporal motion information that will be called
dynamically to assist master tracker. SPCT utilizes image spatial context at
different level to make the video tracking system resistant to occlusion,
background noise and improve target localization accuracy and robustness. We
chose a pre-selected seven-channel complementary features including RGB color,
intensity and spatial pyramid of HoG to encode object color, shape and spatial
layout information. We exploit integral histogram as building block to meet the
demands of real-time performance. A novel fast algorithm is presented to
accurately evaluate spatially weighted local histograms in constant time
complexity using an extension of the integral histogram method. Different
techniques are explored to efficiently compute integral histogram on GPU
architecture and applied for fast spatio-temporal median computations and 3D
face reconstruction texturing. We proposed a multi-component framework based on
semantic fusion of motion information with projected building footprint map to
significantly reduce the false alarm rate in urban scenes with many tall
structures. The experiments on extensive VOTC2016 benchmark dataset and aerial
video confirm that combining complementary tracking cues in an intelligent
fusion framework enables persistent tracking for Full Motion Video and Wide
Aerial Motion Imagery.
</dc:description>
 <dc:description>Comment: PhD Dissertation (162 pages)</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01656</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01660</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conditional Gradient Method for Stochastic Submodular Maximization:
  Closing the Gap</dc:title>
 <dc:creator>Mokhtari, Aryan</dc:creator>
 <dc:creator>Hassani, Hamed</dc:creator>
 <dc:creator>Karbasi, Amin</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we study the problem of \textit{constrained} and
\textit{stochastic} continuous submodular maximization. Even though the
objective function is not concave (nor convex) and is defined in terms of an
expectation, we develop a variant of the conditional gradient method, called
\alg, which achieves a \textit{tight} approximation guarantee. More precisely,
for a monotone and continuous DR-submodular function and subject to a
\textit{general} convex body constraint, we prove that \alg achieves a
$[(1-1/e)\text{OPT} -\eps]$ guarantee (in expectation) with
$\mathcal{O}{(1/\eps^3)}$ stochastic gradient computations. This guarantee
matches the known hardness results and closes the gap between deterministic and
stochastic continuous submodular maximization. By using stochastic continuous
optimization as an interface, we also provide the first $(1-1/e)$ tight
approximation guarantee for maximizing a \textit{monotone but stochastic}
submodular \textit{set} function subject to a general matroid constraint.
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01661</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Provenance and Pseudo-Provenance for Seeded Learning-Based Automated
  Test Generation</dc:title>
 <dc:creator>Groce, Alex</dc:creator>
 <dc:creator>Holmes, Josie</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Many methods for automated software test generation, including some that
explicitly use machine learning (and some that use ML more broadly conceived)
derive new tests from existing tests (often referred to as seeds). Often, the
seed tests from which new tests are derived are manually constructed, or at
least simpler than the tests that are produced as the final outputs of such
test generators. We propose annotation of generated tests with a provenance
(trail) showing how individual generated tests of interest (especially failing
tests) derive from seed tests, and how the population of generated tests
relates to the original seed tests. In some cases, post-processing of generated
tests can invalidate provenance information, in which case we also propose a
method for attempting to construct &quot;pseudo-provenance&quot; describing how the tests
could have been (partly) generated from seeds.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2017 Symposium on Interpretable Machine Learning</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01661</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01666</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Label-driven weakly-supervised learning for multimodal deformable image
  registration</dc:title>
 <dc:creator>Hu, Yipeng</dc:creator>
 <dc:creator>Modat, Marc</dc:creator>
 <dc:creator>Gibson, Eli</dc:creator>
 <dc:creator>Ghavami, Nooshin</dc:creator>
 <dc:creator>Bonmati, Ester</dc:creator>
 <dc:creator>Moore, Caroline M.</dc:creator>
 <dc:creator>Emberton, Mark</dc:creator>
 <dc:creator>Noble, J. Alison</dc:creator>
 <dc:creator>Barratt, Dean C.</dc:creator>
 <dc:creator>Vercauteren, Tom</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Spatially aligning medical images from different modalities remains a
challenging task, especially for intraoperative applications that require fast
and robust algorithms. We propose a weakly-supervised, label-driven formulation
for learning 3D voxel correspondence from higher-level label correspondence,
thereby bypassing classical intensity-based image similarity measures. During
training, a convolutional neural network is optimised by outputting a dense
displacement field (DDF) that warps a set of available anatomical labels from
the moving image to match their corresponding counterparts in the fixed image.
These label pairs, including solid organs, ducts, vessels, point landmarks and
other ad hoc structures, are only required at training time and can be
spatially aligned by minimising a cross-entropy function of the warped moving
label and the fixed label. During inference, the trained network takes a new
image pair to predict an optimal DDF, resulting in a fully-automatic,
label-free, real-time and deformable registration. For interventional
applications where large global transformation prevails, we also propose a
neural network architecture to jointly optimise the global- and local
displacements. Experiment results are presented based on cross-validating
registrations of 111 pairs of T2-weighted magnetic resonance images and 3D
transrectal ultrasound images from prostate cancer patients with a total of
over 4000 anatomical labels, yielding a median target registration error of 4.2
mm on landmark centroids and a median Dice of 0.88 on prostate glands.
</dc:description>
 <dc:description>Comment: Accepted to ISBI 2018</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01666</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01679</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SIR-Hawkes: on the Relationship Between Epidemic Models and Hawkes Point
  Processes</dc:title>
 <dc:creator>Rizoiu, Marian-Andrei</dc:creator>
 <dc:creator>Mishra, Swapnil</dc:creator>
 <dc:creator>Kong, Quyu</dc:creator>
 <dc:creator>Carman, Mark</dc:creator>
 <dc:creator>Xie, Lexing</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Two of the main frameworks used for modeling information diffusions in the
online are epidemic models and Hawkes point processes. The former consider
information as a viral contagion which spreads into a population of online
users, and employ tools initially developed in the field of epidemiology. The
latter view individual broadcasts of information as events in a point process
and they modulate the event rate according to observed (or assumed) social
principles; they have been broadly used in fields such as finance and
geophysics. Here, we study for the first time the connection between these two
mature frameworks, and we find them to be equivalent. More precisely, the rate
of events in the Hawkes model is identical to the rate of new infections in the
Susceptible-Infected-Recovered (SIR) model when taking the expectation over
recovery events -- which are unobserved in a Hawkes process. This paves the way
to apply tools developed for one framework across the gap, to the other
framework.
  We make three further contributions in this work. First, we propose HawkesN,
an extension of the basic Hawkes model, in which we introduce the notion of
finite maximum number of events that can occur. Second, we show HawkesN to
explain real retweet cascades better than the current state-of-the-art Hawkes
modeling. The size of the population can be learned while observing the
cascade, at the expense of requiring larger amounts of training data. Third, we
employ an SIR method based on Markov chains for computing the final size
distribution for a partially observed cascade fitted with HawkesN. We propose
an explanation to the generally perceived randomness of online popularity: the
final size distribution for real diffusion cascades tends to have two maxima,
one corresponding to large cascade sizes and another one around zero.
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:date>2017-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01679</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01683</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ENGINE:Cost Effective Offloading in Mobile Edge Computing with Fog-Cloud
  Cooperation</dc:title>
 <dc:creator>Chen, Long</dc:creator>
 <dc:creator>Wu, Jigang</dc:creator>
 <dc:creator>Long, Xin</dc:creator>
 <dc:creator>Zhang, Zikai</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Mobile Edge Computing (MEC) as an emerging paradigm utilizing cloudlet or fog
nodes to extend remote cloud computing to the edge of the network, is foreseen
as a key technology towards next generation wireless networks. By offloading
computation intensive tasks from resource constrained mobile devices to fog
nodes or the remote cloud, the energy of mobile devices can be saved and the
computation capability can be enhanced. For fog nodes, they can rent the
resource rich remote cloud to help them process incoming tasks from mobile
devices. In this architecture, the benefit of short computation and computation
delay of mobile devices can be fully exploited. However, existing studies
mostly assume fog nodes possess unlimited computing capacity, which is not
practical, especially when fog nodes are also energy constrained mobile
devices. To provide incentive of fog nodes and reduce the computation cost of
mobile devices, we provide a cost effective offloading scheme in mobile edge
computing with the cooperation between fog nodes and the remote cloud with task
dependency constraint. The mobile devices have limited budget and have to
determine which task should be computed locally or sent to the fog. To address
this issue, we first formulate the offloading problem as a task finish time
inimization problem with given budgets of mobile devices, which is NP-hard. We
then devise two more algorithms to study the network performance. Simulation
results show that the proposed greedy algorithm can achieve the near optimal
performance. On average, the Brute Force method and the greedy algorithm
outperform the simulated annealing algorithm by about 28.13% on the application
finish time.
</dc:description>
 <dc:description>Comment: 10 pages, 9 figures, Working Paper, Submitted to IEEE International
  Parallel &amp; Distributed Processing Symposium (IPDPS 2018) for possible
  inclusion</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01683</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01684</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Authorship Analysis of Xenophon's Cyropaedia</dc:title>
 <dc:creator>Field, Anjalie</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In the past several decades, many authorship attribution studies have used
computational methods to determine the authors of disputed texts. Disputed
authorship is a common problem in Classics, since little information about
ancient documents has survived the centuries. Many scholars have questioned the
authenticity of the final chapter of Xenophon's Cyropaedia, a 4th century B.C.
historical text. In this study, we use N-grams frequency vectors with a cosine
similarity function and word frequency vectors with Naive Bayes Classifiers
(NBC) and Support Vector Machines (SVM) to analyze the authorship of the
Cyropaedia. Although the N-gram analysis shows that the epilogue of the
Cyropaedia differs slightly from the rest of the work, comparing the analysis
of Xenophon with analyses of Aristotle and Plato suggests that this difference
is not significant. Both NBC and SVM analyses of word frequencies show that the
final chapter of the Cyropaedia is closely related to the other chapters of the
Cyropaedia. Therefore, this analysis suggests that the disputed chapter was
written by Xenophon. This information can help scholars better understand the
Cyropaedia and also demonstrates the usefulness of applying modern authorship
analysis techniques to classical literature.
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01684</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01691</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Elastic LiDAR Fusion: Dense Map-Centric Continuous-Time SLAM</dc:title>
 <dc:creator>Park, Chanoh</dc:creator>
 <dc:creator>Moghadam, Peyman</dc:creator>
 <dc:creator>Kim, Soohwan</dc:creator>
 <dc:creator>Elfes, Alberto</dc:creator>
 <dc:creator>Fookes, Clinton</dc:creator>
 <dc:creator>Sridharan, Sridha</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The concept of continuous-time trajectory representation has brought
increased accuracy and efficiency to multi-modal sensor fusion in modern SLAM.
However, regardless of these advantages, its offline property caused by the
requirement of a global batch optimization is critically hindering its
relevance for real-time and life-long applications. In this paper, we present a
dense map-centric SLAM method based on a continuous-time trajectory to cope
with this problem. The proposed system locally functions in a similar fashion
to conventional Continuous-Time SLAM (CT-SLAM). However, it removes global
trajectory optimization by introducing map deformation. The computational
complexity of the proposed approach for loop closure does not depend on the
operation time, but only on the size of the space it explored before the loop
closure. It is therefore more suitable for long term operation compared to
conventional CT-SLAM. Furthermore, the proposed method reduces uncertainty in
the reconstructed dense map by using probabilistic surface element (surfel)
fusion. We demonstrate that the proposed method produces globally consistent
maps without a global batch trajectory optimization, and effectively reduces
LiDAR noise by fusion in dense surfel mapping.
</dc:description>
 <dc:description>Comment: 8 pages, submitted to ICRA 2018 Demo video link:
  https://www.youtube.com/watch?v=QNNLncT9XmQ</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:date>2017-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01691</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01692</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Routing Symmetric Demands in Directed Minor-Free Graphs with Constant
  Congestion</dc:title>
 <dc:creator>Carpenter, Timothy</dc:creator>
 <dc:creator>Salmasi, Ario</dc:creator>
 <dc:creator>Sidiropoulos, Anastasios</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The problem of routing in graphs using node-disjoint paths has received a lot
of attention and a polylogarithmic approximation algorithm with constant
congestion is known for undirected graphs [Chuzhoy and Li 2016] and [Chekuri
and Ene 2013]. However, the problem is hard to approximate within polynomial
factors on directed graphs, for any constant congestion [Chuzhoy, Kim and Li
2016].
  Recently, [Chekuri, Ene and Pilipczuk 2016] have obtained a polylogarithmic
approximation with constant congestion on directed planar graphs, for the
special case of symmetric demands. We extend their result by obtaining a
polylogarithmic approximation with constant congestion on arbitrary directed
minor-free graphs, for the case of symmetric demands.
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01692</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01694</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multilingual Speech Recognition With A Single End-To-End Model</dc:title>
 <dc:creator>Toshniwal, Shubham</dc:creator>
 <dc:creator>Sainath, Tara N.</dc:creator>
 <dc:creator>Weiss, Ron J.</dc:creator>
 <dc:creator>Li, Bo</dc:creator>
 <dc:creator>Moreno, Pedro</dc:creator>
 <dc:creator>Weinstein, Eugene</dc:creator>
 <dc:creator>Rao, Kanishka</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Training a conventional automatic speech recognition (ASR) system to support
multiple languages is challenging because the sub-word unit, lexicon and word
inventories are typically language specific. In contrast, sequence-to-sequence
models are well suited for multilingual ASR because they encapsulate an
acoustic, pronunciation and language model jointly in a single network. In this
work we present a single sequence-to-sequence ASR model trained on 9 different
Indian languages, which have very little overlap in their scripts.
Specifically, we take a union of language-specific grapheme sets and train a
grapheme-based sequence-to-sequence model jointly on data from all languages.
We find that this model, which is not explicitly given any information about
language identity, improves recognition performance by 21% relative compared to
analogous sequence-to-sequence models trained on each language individually. By
modifying the model to accept a language identifier as an additional input
feature, we further improve performance by an additional 7% relative and
eliminate confusion between different languages.
</dc:description>
 <dc:description>Comment: Submitted to ICASSP 2018</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01694</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01696</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bilinear Controllability of a Class of Advection-Diffusion-Reaction
  Systems</dc:title>
 <dc:creator>Elamvazhuthi, Karthik</dc:creator>
 <dc:creator>Kuiper, Hendrik</dc:creator>
 <dc:creator>Kawski, Matthias</dc:creator>
 <dc:creator>Berman, Spring</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper, we investigate the exact controllability properties of an
advection-diffusion equation on a bounded domain, using time- and
space-dependent velocity fields as the control parameters. This partial
differential equation (PDE) is the Kolmogorov forward equation for a reflected
diffusion process that models the spatiotemporal evolution of a swarm of
agents. We prove that if a target probability density has bounded first-order
weak derivatives and is uniformly bounded from below by a positive constant,
then it can be reached in finite time using control inputs that are bounded in
space and time. We then extend this controllability result to a class of
advection-diffusion-reaction PDEs that corresponds to a hybrid-switching
diffusion process (HSDP), in which case the reaction parameters are
additionally incorporated as the control inputs. Our proof for controllability
of the advection-diffusion equation is constructive and is based on linear
operator semigroup theoretic arguments and spectral properties of the
multiplicatively perturbed Neumann Laplacian. For the HSDP, we first
constructively prove controllability of the associated continuous-time Markov
chain (CTMC) system, in which the state space is finite. Then we show that our
controllability results for the advection-diffusion equation and the CTMC can
be combined to establish controllability of the forward equation of the HSDP.
Lastly, we provide constructive solutions to the problem of asymptotically
stabilizing an HSDP to a target non-negative stationary distribution using
time-independent state feedback laws, which correspond to spatially-dependent
coefficients of the associated system of PDEs.
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01696</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01700</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nearly Work-Efficient Parallel Algorithm for Digraph Reachability</dc:title>
 <dc:creator>Fineman, Jeremy T.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  One of the simplest problems on directed graphs is that of identifying the
set of vertices reachable from a designated source vertex. This problem can be
solved easily sequentially by performing a graph search, but efficient parallel
algorithms have eluded researchers for decades. For sparse high-diameter graphs
in particular, there is no known work-efficient parallel algorithm with
nontrivial parallelism. This amounts to one of the most fundamental open
questions in parallel graph algorithms: Is there a parallel algorithm for
digraph reachability with nearly linear work? This paper shows that the answer
is yes.
  This paper presents a randomized parallel algorithm for digraph reachability
and related problems with expected work $\tilde{O}(m)$ and span
$\tilde{O}(n^{2/3})$, and hence parallelism $\tilde{\Omega}(n^{1/3})$, on any
graph with $n$ vertices and $m$ arcs. This is the first parallel algorithm
having both nearly linear work and strongly sublinear span. The algorithm can
be extended to produce a directed spanning tree, determine whether the graph is
acyclic, topologically sort the strongly connected components of the graph, or
produce a directed ear decomposition of a strongly connected graph, all with
similar work and span.
  The main technical contribution is an \emph{efficient} Monte Carlo algorithm
that, through the addition of $\tilde{O}(n)$ shortcuts, reduces the diameter of
the graph to $\tilde{O}(n^{2/3})$ with high probability. While both sequential
and parallel algorithms are known with those combinatorial properties, even the
sequential algorithms are not efficient. This paper presents a surprisingly
simple sequential algorithm that achieves the stated diameter reduction and
runs in $\tilde{O}(m)$ time. Parallelizing that algorithm yields the main
result, but doing so involves overcoming several other challenges.
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01700</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01701</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Representation for Traditional Chinese Medicine Herb via
  Deep Learning Models</dc:title>
 <dc:creator>Li, Wei</dc:creator>
 <dc:creator>Yang, Zheng</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Traditional Chinese Medicine (TCM) has accumulated a big amount of precious
resource in the long history of development. TCM prescriptions that consist of
TCM herbs are an important form of TCM treatment, which are similar to natural
language documents, but in a weakly ordered fashion. Directly adapting language
modeling style methods to learn the embeddings of the herbs can be problematic
as the herbs are not strictly in order, the herbs in the front of the
prescription can be connected to the very last ones. In this paper, we propose
to represent TCM herbs with distributed representations via Prescription Level
Language Modeling (PLLM). In one of our experiments, the correlation between
our calculated similarity between medicines and the judgment of professionals
achieves a Spearman score of 55.35 indicating a strong correlation, which
surpasses human beginners (TCM related field bachelor student) by a big margin
(over 10%).
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01701</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01702</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impact of Communication Delay on Asynchronous Distributed Optimal Power
  Flow Using ADMM</dc:title>
 <dc:creator>Guo, Junyao</dc:creator>
 <dc:creator>Hug, Gabriela</dc:creator>
 <dc:creator>Tonguz, Ozan</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Distributed optimization has attracted lots of attention in the operation of
power systems in recent years, where a large area is decomposed into smaller
control regions each solving a local optimization problem with periodic
information exchange with neighboring regions. However, most distributed
optimization methods are iterative and require synchronization of all regions
at each iteration, which is hard to achieve without a centralized coordinator
and might lead to under-utilization of computation resources due to the
heterogeneity of the regions. To address such limitations of synchronous
schemes, this paper investigates the applicability of asynchronous distributed
optimization methods to power system optimization. Particularly, we focus on
solving the AC Optimal Power Flow problem and propose an algorithmic framework
based on the Alternating Direction Method of Multipliers (ADMM) method that
allows the regions to perform local updates with information received from a
subset of but not all neighbors. Through experimental studies, we demonstrate
that the convergence performance of the proposed asynchronous scheme is
dependent on the communication delay of passing messages among the regions.
Under mild communication delays, the proposed scheme can achieve comparable or
even faster convergence compared with its synchronous counterpart, which can be
used as a good alternative to centralized or synchronous distributed
optimization approaches.
</dc:description>
 <dc:description>Comment: SmartGridComm 2017</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01702</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01703</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RoboCupSimData: A RoboCup soccer research dataset</dc:title>
 <dc:creator>Michael, Olivia</dc:creator>
 <dc:creator>Obst, Oliver</dc:creator>
 <dc:creator>Schmidsberger, Falk</dc:creator>
 <dc:creator>Stolzenburg, Frieder</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  RoboCup is an international scientific robot competition in which teams of
multiple robots compete against each other. Its different leagues provide many
sources of robotics data, that can be used for further analysis and application
of machine learning. This paper describes a large dataset from games of some of
the top teams (from 2016 and 2017) in RoboCup Soccer Simulation League (2D),
where teams of 11 robots (agents) compete against each other. Overall, we used
10 different teams to play each other, resulting in 45 unique pairings. For
each pairing, we ran 25 matches (of 10mins), leading to 1125 matches or more
than 180 hours of game play. The generated CSV files are 17GB of data (zipped),
or 229GB (unzipped). The dataset is unique in the sense that it contains both
the ground truth data (global, complete, noise-free information of all objects
on the field), as well as the noisy, local and incomplete percepts of each
robot. These data are made available as CSV files, as well as in the original
soccer simulator formats.
</dc:description>
 <dc:description>Comment: 6 pages; https://bitbucket.org/oliverobst/robocupsimdata</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01711</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coding-theorem Like Behaviour and Emergence of the Universal
  Distribution from Resource-bounded Algorithmic Probability</dc:title>
 <dc:creator>Zenil, Hector</dc:creator>
 <dc:creator>Badillo, Liliana</dc:creator>
 <dc:creator>Hern&#xe1;ndez-Orozco, Santiago</dc:creator>
 <dc:creator>Hern&#xe1;ndez-Quiroz, Francisco</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Previously referred to as 'miraculous' because of its surprisingly powerful
properties and its application as the optimal theoretical solution to
induction/inference, (approximations to) Algorithmic Probability (AP) and the
Universal Distribution are of the greatest importance in computer science and
science in general. Here we investigate the emergence, the rates of emergence
and convergence, and the Coding-theorem like behaviour of AP in subuniversal
models of computation. We investigate empirical distributions of computer
programs of weaker computational power according to the Chomsky hierarchy. We
introduce measures of algorithmic probability and algorithmic complexity based
upon resource-bounded computation, in contrast to previously thoroughly
investigated distributions produced from the output distribution of Turing
machines. This approach allows for numerical approximations to algorithmic
(Kolmogorov-Chaitin) complexity-based estimations at each of the levels of a
computational hierarchy. We demonstrate that all these estimations are
correlated in rank and that they converge both in rank and values as a function
of computational power, despite the fundamental differences of each
computational model. In the context of natural processes that may operate below
the Turing universal level due to the constraint of resources and physical
degradation, the investigation of natural biases coming from algorithmic laws
is highly relevant. We show that the simplicity/complexity bias in
distributions produced even by the weakest of the computational models can be
accounted up to 60% by Algorithmic Probability in its approximation to the
Universal Distribution.
</dc:description>
 <dc:description>Comment: 28 pages main text. 40 pages including Supplementary Material.
  Tweaked conclusions</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01711</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01714</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-End Video Classification with Knowledge Graphs</dc:title>
 <dc:creator>Yuan, Fang</dc:creator>
 <dc:creator>Wang, Zhe</dc:creator>
 <dc:creator>Lin, Jie</dc:creator>
 <dc:creator>D'Haro, Luis Fernando</dc:creator>
 <dc:creator>Jae, Kim Jung</dc:creator>
 <dc:creator>Zeng, Zeng</dc:creator>
 <dc:creator>Chandrasekhar, Vijay</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Video understanding has attracted much research attention especially since
the recent availability of large-scale video benchmarks. In this paper, we
address the problem of multi-label video classification. We first observe that
there exists a significant knowledge gap between how machines and humans learn.
That is, while current machine learning approaches including deep neural
networks largely focus on the representations of the given data, humans often
look beyond the data at hand and leverage external knowledge to make better
decisions. Towards narrowing the gap, we propose to incorporate external
knowledge graphs into video classification. In particular, we unify traditional
&quot;knowledgeless&quot; machine learning models and knowledge graphs in a novel
end-to-end framework. The framework is flexible to work with most existing
video classification algorithms including state-of-the-art deep models.
Finally, we conduct extensive experiments on the largest public video dataset
YouTube-8M. The results are promising across the board, improving mean average
precision by up to 2.9%.
</dc:description>
 <dc:description>Comment: 9 pages, 5 figures</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01714</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01725</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joining Local Knowledge to Communicate Reliably (Extended Abstract)</dc:title>
 <dc:creator>Pagourtzis, Aris</dc:creator>
 <dc:creator>Panagiotakos, Giorgos</dc:creator>
 <dc:creator>Sakavalas, Dimitris</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  A fundamental primitive in distributed computing is Reliable Message
Transmission (RMT), which refers to the task of correctly sending a message
from a party (or player) to another, in a network where some intermediate
relays might be controlled by an adversary. We address the problem under the
realistic assumption that the topological knowledge of players is restricted to
a certain subgraph and specifically study the role of local information
exchange in the feasibility of RMT. We employ the General Adversary model of
Hirt and Maurer and the recently introduced Partial Knowledge Model which
subsume all known models for the adversary and local knowledge respectively.
Tight feasibility conditions, naturally involving the network topology, the
adversary and the local knowledge of players, are presented.
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01725</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01728</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PowerModels.jl: An Open-Source Framework for Exploring Power Flow
  Formulations</dc:title>
 <dc:creator>Coffrin, Carleton</dc:creator>
 <dc:creator>Bent, Russell</dc:creator>
 <dc:creator>Sundar, Kaarthik</dc:creator>
 <dc:creator>Ng, Yeesian</dc:creator>
 <dc:creator>Lubin, Miles</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  In recent years, the power system research community has seen an explosion of
novel methods for formulating and solving various power network optimization
problems. These emerging methods range from new power flow approximations,
which go beyond the traditional DC Power Flow by capturing reactive power, to
convex relaxations, which provide solution quality and run time performance
guarantees. Unfortunately, the complexity of these emerging methods often
presents a significant barrier to evaluating these methods on power system
optimization problems. To address this issue, this work proposes PowerModels,
an open-source platform for comparing power flow formulations. From its
inception, PowerModels was designed to streamline the process of evaluating
different power flow formulations on shared optimization problem
specifications. This work provides a brief introduction to the design of
PowerModels and demonstrates its effectiveness with a proof-of-concept study
analyzing five different formulations of the Optimal Power Flow problem.
</dc:description>
 <dc:date>2017-11-05</dc:date>
 <dc:date>2017-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01728</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01731</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Dialogue Systems: Recent Advances and New Frontiers</dc:title>
 <dc:creator>Chen, Hongshen</dc:creator>
 <dc:creator>Liu, Xiaorui</dc:creator>
 <dc:creator>Yin, Dawei</dc:creator>
 <dc:creator>Tang, Jiliang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Dialogue systems have attracted more and more attention. Recent advances on
dialogue systems are overwhelmingly contributed by deep learning techniques,
which have been employed to enhance a wide range of big data applications such
as computer vision, natural language processing, and recommender systems. For
dialogue systems, deep learning can leverage a massive amount of data to learn
meaningful feature representations and response generation strategies, while
requiring a minimum amount of hand-crafting. In this article, we give an
overview to these recent advances on dialogue systems from various perspectives
and discuss some possible research directions. In particular, we generally
divide existing dialogue systems into task-oriented and non-task-oriented
models, then detail how deep learning techniques help them with representative
algorithms and finally discuss some appealing research directions that can
bring the dialogue system research into a new frontier.
</dc:description>
 <dc:description>Comment: 13 pages. arXiv admin note: text overlap with arXiv:1703.01008 by
  other authors</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2018-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01731</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01732</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Learning for Visual Question Answering: An Empirical Study</dc:title>
 <dc:creator>Lin, Xiao</dc:creator>
 <dc:creator>Parikh, Devi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present an empirical study of active learning for Visual Question
Answering, where a deep VQA model selects informative question-image pairs from
a pool and queries an oracle for answers to maximally improve its performance
under a limited query budget. Drawing analogies from human learning, we explore
cramming (entropy), curiosity-driven (expected model change), and goal-driven
(expected error reduction) active learning approaches, and propose a fast and
effective goal-driven active learning scoring function to pick question-image
pairs for deep VQA models under the Bayesian Neural Network framework. We find
that deep VQA models need large amounts of training data before they can start
asking informative questions. But once they do, all three approaches outperform
the random selection baseline and achieve significant query savings. For the
scenario where the model is allowed to ask generic questions about images but
is evaluated only on specific questions (e.g., questions whose answer is either
yes or no), our proposed goal-driven scoring function performs the best.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01732</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01735</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Flows in Arithmetic</dc:title>
 <dc:creator>Tabatabai, Amirhossein Akbar</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  A computational flow is a pair consisting of a sequence of computational
problems of a certain sort and a sequence of computational reductions among
them. In this paper we will develop a theory for these computational flows and
we will use it to make a sound and complete interpretation for bounded theories
of arithmetic. This property helps us to decompose a first order arithmetical
proof to a sequence of computational reductions by which we can extract the
computational content of low complexity statements in some bounded theories of
arithmetic such as $I\Delta_0$, $T^k_n$, $I\Delta_0+EXP$ and $PRA$. In the last
section, by generalizing term-length flows to ordinal-length flows, we will
extend our investigation from bounded theories to strong unbounded ones such as
$I\Sigma_n$ and $PA+TI(\alpha)$ and we will capture their total $NP$ search
problems as a consequence.
</dc:description>
 <dc:description>Comment: 40 pages</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01735</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01742</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Memory-efficient Kernel PCA via Partial Matrix Sampling and Nonconvex
  Optimization: a Model-free Analysis of Local Minima</dc:title>
 <dc:creator>Chen, Ji</dc:creator>
 <dc:creator>Li, Xiaodong</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Kernel PCA is a widely used nonlinear dimension reduction technique in
machine learning, but storing the kernel matrix is notoriously challenging when
the sample size is large. Inspired by Yi et al. [2016], where the idea of
partial matrix sampling followed by nonconvex optimization is proposed for
matrix completion and robust PCA, we apply a similar approach to
memory-efficient Kernel PCA. In theory, with no assumptions on the kernel
matrix in terms of eigenvalues or eigenvectors, we established a model-free
theory for the low-rank approximation based on any local minimum of the
proposed objective function. As interesting byproducts, when the underlying
positive semidefinite matrix is assumed to be low-rank and highly structured,
corollaries of our main theorem improve the state-of-the-art results of Ge et
al. [2016, 2017] for nonconvex matrix completion with no spurious local minima.
Numerical experiments also show that our approach is competitive in terms of
approximation accuracy compared to the well-known Nystr\&quot;{o}m algorithm for
Kernel PCA.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01742</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01744</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>KGAN: How to Break The Minimax Game in GAN</dc:title>
 <dc:creator>Le, Trung</dc:creator>
 <dc:creator>Nguyen, Tu Dinh</dc:creator>
 <dc:creator>Phung, Dinh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Generative Adversarial Networks (GANs) were intuitively and attractively
explained under the perspective of game theory, wherein two involving parties
are a discriminator and a generator. In this game, the task of the
discriminator is to discriminate the real and generated (i.e., fake) data,
whilst the task of the generator is to generate the fake data that maximally
confuses the discriminator. In this paper, we propose a new viewpoint for GANs,
which is termed as the minimizing general loss viewpoint. This viewpoint shows
a connection between the general loss of a classification problem regarding a
convex loss function and a f-divergence between the true and fake data
distributions. Mathematically, we proposed a setting for the classification
problem of the true and fake data, wherein we can prove that the general loss
of this classification problem is exactly the negative f-divergence for a
certain convex function f. This allows us to interpret the problem of learning
the generator for dismissing the f-divergence between the true and fake data
distributions as that of maximizing the general loss which is equivalent to the
min-max problem in GAN if the Logistic loss is used in the classification
problem. However, this viewpoint strengthens GANs in two ways. First, it allows
us to employ any convex loss function for the discriminator. Second, it
suggests that rather than limiting ourselves in NN-based discriminators, we can
alternatively utilize other powerful families. Bearing this viewpoint, we then
propose using the kernel-based family for discriminators. This family has two
appealing features: i) a powerful capacity in classifying non-linear nature
data and ii) being convex in the feature space. Using the convexity of this
family, we can further develop Fenchel duality to equivalently transform the
max-min problem to the max-max dual problem.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01744</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01754</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Solving Procedure for Artificial Neural Network</dc:title>
 <dc:creator>Lee, Ju-Hong</dc:creator>
 <dc:creator>Kang, Moon-Ju</dc:creator>
 <dc:creator>Choi, Bumghi</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  It is expected that progress toward true artificial intelligence will be
achieved through the emergence of a system that integrates representation
learning and complex reasoning (LeCun et al. 2015). In response to this
prediction, research has been conducted on implementing the symbolic reasoning
of a von Neumann computer in an artificial neural network (Graves et al. 2016;
Graves et al. 2014; Reed et al. 2015). However, these studies have many
limitations in realizing neural-symbolic integration (Jaeger. 2016). Here, we
present a new learning paradigm: a learning solving procedure (LSP) that learns
the procedure for solving complex problems. This is not accomplished merely by
learning input-output data, but by learning algorithms through a solving
procedure that obtains the output as a sequence of tasks for a given input
problem. The LSP neural network system not only learns simple problems of
addition and multiplication, but also the algorithms of complicated problems,
such as complex arithmetic expression, sorting, and Hanoi Tower. To realize
this, the LSP neural network structure consists of a deep neural network and
long short-term memory, which are recursively combined. Through
experimentation, we demonstrate the efficiency and scalability of LSP and its
validity as a mechanism of complex reasoning.
</dc:description>
 <dc:description>Comment: 10 pages, 10 figures</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01754</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01758</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enabling rootless Linux Containers in multi-user environments: the
  udocker tool</dc:title>
 <dc:creator>Gomes, Jorge</dc:creator>
 <dc:creator>Campos, Isabel</dc:creator>
 <dc:creator>Bagnaschi, Emanuele</dc:creator>
 <dc:creator>David, Mario</dc:creator>
 <dc:creator>Alves, Luis</dc:creator>
 <dc:creator>Martins, Joao</dc:creator>
 <dc:creator>Pina, Joao</dc:creator>
 <dc:creator>Lopez-Garcia, Alvaro</dc:creator>
 <dc:creator>Orviz, Pablo</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>High Energy Physics - Lattice</dc:subject>
 <dc:subject>High Energy Physics - Phenomenology</dc:subject>
 <dc:description>  Containers are increasingly used as means to distribute and run Linux
services and applications. In this paper we describe the architectural design
and implementation of udocker a tool to execute Linux containers in user mode
and we describe a few practical applications for a range of scientific codes
meeting different requirements: from single core execution to MPI parallel
execution and execution on GPGPUs.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01758</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01761</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AdaBatch: Efficient Gradient Aggregation Rules for Sequential and
  Parallel Stochastic Gradient Methods</dc:title>
 <dc:creator>D&#xe9;fossez, Alexandre</dc:creator>
 <dc:creator>Bach, Francis</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study a new aggregation operator for gradients coming from a mini-batch
for stochastic gradient (SG) methods that allows a significant speed-up in the
case of sparse optimization problems. We call this method AdaBatch and it only
requires a few lines of code change compared to regular mini-batch SGD
algorithms. We provide a theoretical insight to understand how this new class
of algorithms is performing and show that it is equivalent to an implicit
per-coordinate rescaling of the gradients, similarly to what Adagrad methods
can do. In theory and in practice, this new aggregation allows to keep the same
sample efficiency of SG methods while increasing the batch size.
Experimentally, we also show that in the case of smooth convex optimization,
our procedure can even obtain a better loss when increasing the batch size for
a fixed number of samples. We then apply this new algorithm to obtain a
parallelizable stochastic gradient method that is synchronous but allows
speed-up on par with Hogwild! methods as convergence does not deteriorate with
the increase of the batch size. The same approach can be used to make
mini-batch provably efficient for variance-reduced SG methods such as SVRG.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01761</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01763</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Game Theoretic Approaches to Massive Data Processing in Wireless
  Networks</dc:title>
 <dc:creator>Zheng, Zijie</dc:creator>
 <dc:creator>Song, Lingyang</dc:creator>
 <dc:creator>Han, Zhu</dc:creator>
 <dc:creator>Li, Geoffrey Ye</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Wireless communication networks are becoming highly virtualized with
two-layer hierarchies, in which controllers at the upper layer with tasks to
achieve can ask a large number of agents at the lower layer to help realize
computation, storage, and transmission functions. Through offloading data
processing to the agents, the controllers can accomplish otherwise prohibitive
big data processing. Incentive mechanisms are needed for the agents to perform
the controllers' tasks in order to satisfy the corresponding objectives of
controllers and agents. In this article, a hierarchical game framework with
fast convergence and scalability is proposed to meet the demand for real-time
processing for such situations. Possible future research directions in this
emerging area are also discussed.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01763</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01768</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Whitening Black-Box Neural Networks</dc:title>
 <dc:creator>Oh, Seong Joon</dc:creator>
 <dc:creator>Augustin, Max</dc:creator>
 <dc:creator>Schiele, Bernt</dc:creator>
 <dc:creator>Fritz, Mario</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Many deployed learned models are black boxes: given input, returns output.
Internal information about the model, such as the architecture, optimisation
procedure, or training data, is not disclosed explicitly as it might contain
proprietary information or make the system more vulnerable. This work shows
that such attributes of neural networks can be exposed from a sequence of
queries. This has multiple implications. On the one hand, our work exposes the
vulnerability of black-box neural networks to different types of attacks -- we
show that the revealed internal information helps generate more effective
adversarial examples against the black box model. On the other hand, this
technique can be used for better protection of private content from automatic
recognition models using adversarial examples. Our paper suggests that it is
actually hard to draw a line between white box and black box models.
</dc:description>
 <dc:description>Comment: 12 pages, 7 figures</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01768</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01775</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multimodal Signal Processing and Learning Aspects of Human-Robot
  Interaction for an Assistive Bathing Robot</dc:title>
 <dc:creator>Zlatintsi, A.</dc:creator>
 <dc:creator>Rodomagoulakis, I.</dc:creator>
 <dc:creator>Koutras, P.</dc:creator>
 <dc:creator>Dometios, A. C.</dc:creator>
 <dc:creator>Pitsikalis, V.</dc:creator>
 <dc:creator>Tzafestas, C. S.</dc:creator>
 <dc:creator>Maragos, P.</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We explore new aspects of assistive living on smart human-robot interaction
(HRI) that involve automatic recognition and online validation of speech and
gestures in a natural interface, providing social features for HRI. We
introduce a whole framework and resources of a real-life scenario for elderly
subjects supported by an assistive bathing robot, addressing health and hygiene
care issues. We contribute a new dataset and a suite of tools used for data
acquisition and a state-of-the-art pipeline for multimodal learning within the
framework of the I-Support bathing robot, with emphasis on audio and RGB-D
visual streams. We consider privacy issues by evaluating the depth visual
stream along with the RGB, using Kinect sensors. The audio-gestural recognition
task on this new dataset yields up to 84.5%, while the online validation of the
I-Support system on elderly users accomplishes up to 84% when the two
modalities are fused together. The results are promising enough to support
further research in the area of multimodal recognition for assistive social
HRI, considering the difficulties of the specific task. Upon acceptance of the
paper part of the data will be publicly available.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01775</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01782</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Outage Probability Conjecture for MIMO Channels</dc:title>
 <dc:creator>Li, Gen</dc:creator>
 <dc:creator>Yan, Jingkai</dc:creator>
 <dc:creator>Gu, Yuantao</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Multiple-Input-Multiple-Output (MIMO) communication systems have seen wide
application due to its performance benefits such as multiplexing gain. For MIMO
systems with non-ergodic Gaussian channel, a conjecture regarding its outage
probability has been proposed by Telatar in [1]. This conjecture has been
proved for the special single-output case, and is in general assumed to be
true. In this work, we analyze the special Two-Input-Multiple-Output (TIMO)
case theoretically, and provide a counter-example to the conjecture. The
counter-example is verified both theoretically and by numerical experiments. We
also present a theoretical analysis for general MIMO case, including a method
for calculation. This result rejects the decades-long conjecture and provides
interesting insight into the symmetry of MIMO systems.
</dc:description>
 <dc:description>Comment: 18 pages, 2 figures</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2017-12-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01782</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01788</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Analysis of Trial and Error Algorithms</dc:title>
 <dc:creator>Gaveau, J&#xe9;r&#xf4;me</dc:creator>
 <dc:creator>Martret, Christophe J. Le</dc:creator>
 <dc:creator>Assaad, Mohamad</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Model-free decentralized optimizations and learning are receiving increasing
attention from theoretical and practical perspectives. In particular, two fully
decentralized learning algorithms, namely Trial and Error (TEL) and Optimal
Dynamical Learning (ODL), are very appealing for a broad class of games. In
fact, ODL has the property to spend a high proportion of time in an optimum
state that maximizes the sum of utility of all players. And the TEL has the
property to spend a high proportion of time in an optimum state that maximizes
the sum of utility of all players if there is a Pure Nash Equilibrium (PNE),
otherwise, it spends a high proportion of time in an optimum state that
maximizes a tradeoff between the sum of utility of all players and a predefined
stability function. On the other hand, estimating the mean fraction of time
spent in the optimum state (as well as the mean time duration to reach it) is
challenging due to the high complexity and dimension of the inherent Markov
Chains. In this paper, under some specific system model, an evaluation of the
above performance metrics is provided by proposing an approximation of the
considered Markov chains, which allows overcoming the problem of high
dimensionality. A comparison between the two algorithms is then performed which
allows a better understanding of their performances.
</dc:description>
 <dc:description>Comment: 38 pages, 12 figures, journal</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01788</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01789</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fusible HSTs and the randomized k-server conjecture</dc:title>
 <dc:creator>Lee, James R.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We show that a potential-based algorithm for the fractional $k$-server
problem on hierarchically separated trees (HSTs) with competitive ratio $f(k)$
can be used to obtain a randomized algorithm for any metric space with
competitive ratio $f(k)^2 O((\log k)^2)$. Employing the $O((\log
k)^2)$-competitive algorithm for HSTs from our joint work with Bubeck, Cohen,
Lee, and M\k{a}dry (2017), this yields an $O((\log k)^6)$-competitive algorithm
for the $k$-server problem on general metric spaces.
  The best previous result independent of the geometry of the underlying metric
space is the $2k-1$ competitive ratio established for the deterministic work
function algorithm by Koutsoupias and Papadimitriou (1995). Even for the
special case when the underlying metric space is the real line, the best known
competitive ratio was $k$. Since deterministic algorithms can do no better than
$k$ on any metric space with at least $k+1$ points, this establishes that for
every metric space on which the problem is non-trivial, randomized algorithms
give an exponential improvement over deterministic algorithms.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01789</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01790</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simultaneous Block-Sparse Signal Recovery Using Pattern-Coupled Sparse
  Bayesian Learning</dc:title>
 <dc:creator>Xiao, Hang</dc:creator>
 <dc:creator>Xing, Zhengli</dc:creator>
 <dc:creator>Yang, Linxiao</dc:creator>
 <dc:creator>Fang, Jun</dc:creator>
 <dc:creator>Wu, Yanlun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we consider the block-sparse signals recovery problem in the
context of multiple measurement vectors (MMV) with common row sparsity
patterns. We develop a new method for recovery of common row sparsity MMV
signals, where a pattern-coupled hierarchical Gaussian prior model is
introduced to characterize both the block-sparsity of the coefficients and the
statistical dependency between neighboring coefficients of the common row
sparsity MMV signals. Unlike many other methods, the proposed method is able to
automatically capture the block sparse structure of the unknown signal. Our
method is developed using an expectation-maximization (EM) framework.
Simulation results show that our proposed method offers competitive performance
in recovering block-sparse common row sparsity pattern MMV signals.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01790</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01791</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HyperNetworks with statistical filtering for defending adversarial
  examples</dc:title>
 <dc:creator>Sun, Zhun</dc:creator>
 <dc:creator>Ozay, Mete</dc:creator>
 <dc:creator>Okatani, Takayuki</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep learning algorithms have been known to be vulnerable to adversarial
perturbations in various tasks such as image classification. This problem was
addressed by employing several defense methods for detection and rejection of
particular types of attacks. However, training and manipulating networks
according to particular defense schemes increases computational complexity of
the learning algorithms. In this work, we propose a simple yet effective method
to improve robustness of convolutional neural networks (CNNs) to adversarial
attacks by using data dependent adaptive convolution kernels. To this end, we
propose a new type of HyperNetwork in order to employ statistical properties of
input data and features for computation of statistical adaptive maps. Then, we
filter convolution weights of CNNs with the learned statistical maps to compute
dynamic kernels. Thereby, weights and kernels are collectively optimized for
learning of image classification models robust to adversarial attacks without
employment of additional target detection and rejection algorithms. We
empirically demonstrate that the proposed method enables CNNs to spontaneously
defend against different types of attacks, e.g. attacks generated by Gaussian
noise, fast gradient sign methods (Goodfellow et al., 2014) and a black-box
attack(Narodytska &amp; Kasiviswanathan, 2016).
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01791</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01799</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Language properties and Grammar of Parallel and Series Parallel
  Languages</dc:title>
 <dc:creator>Mohana, N.</dc:creator>
 <dc:creator>Desikan, Kalyani</dc:creator>
 <dc:creator>Dare, V. Rajkumar</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  In this paper we have defined the language theoretical properties of Parallel
languages and series parallel languages. Parallel languages and Series parallel
languages play vital roles in parallel processing and many applications in
computer programming. We have defined regular expressions and context free
grammar for parallel and series parallel languages based on sequential
languages [2]. We have also discussed the recognizability of parallel and
series parallel languages using regular expression and regular grammar.
</dc:description>
 <dc:description>Comment: 9 Pages, 2 figures</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01799</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01800</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Beam-Frequency Allocation Algorithm with Position Uncertainty
  for Millimeter-Wave MIMO Systems</dc:title>
 <dc:creator>Ismayilov, Rafail</dc:creator>
 <dc:creator>Kaneko, Megumi</dc:creator>
 <dc:creator>Hiraguri, Takefumi</dc:creator>
 <dc:creator>Nishimori, Kentaro</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Envisioned for fifth generation (5G) systems, millimeter-wave (mmWave)
communications are under very active research worldwide. Although pencil beams
with accurate beamtracking may boost the throughput of mmWave systems, this
poses great challenges in the design of radio resource allocation for highly
mobile users. In this paper, we propose a joint adaptive beam-frequency
allocation algorithm that takes into account the position uncertainty inherent
to high mobility and/or unstable users as, e.g., Unmanned Aerial Vehicles
(UAV), for whom this is a major problem. Our proposed method provides an
optimized beamwidth selection under quality of service (QoS) requirements for
maximizing system proportional fairness, under user position uncertainty. The
rationale of our scheme is to adapt the beamwidth such that the best trade-off
among system performance (narrower beam) and robustness to uncertainty (wider
beam) is achieved. Simulation results show that the proposed method largely
enhances the system performance compared to reference algorithms, by an
appropriate adaptation of the mmWave beamwidths, even under severe
uncertainties and imperfect channel state information (CSIs).
</dc:description>
 <dc:description>Comment: 5 pages, 6 figures, 1 table, 1 algorithm</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01803</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Codes over $\mathbb{Z}_{p^2}$ and its Covering Radius</dc:title>
 <dc:creator>Annamalai, N.</dc:creator>
 <dc:creator>Durairajan, C.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper gives lower and upper bounds on the covering radius of codes over
$\mathbb{Z}_{p^2}$ with respect to Lee distance. We also determine the covering
radius of various Repetition codes over $\mathbb{Z}_{p^2}.$
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01803</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01804</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluation of Croatian Word Embeddings</dc:title>
 <dc:creator>Svoboda, Lukas</dc:creator>
 <dc:creator>Beliga, Slobodan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Croatian is poorly resourced and highly inflected language from Slavic
language family. Nowadays, research is focusing mostly on English. We created a
new word analogy corpus based on the original English Word2vec word analogy
corpus and added some of the specific linguistic aspects from Croatian
language. Next, we created Croatian WordSim353 and RG65 corpora for a basic
evaluation of word similarities. We compared created corpora on two popular
word representation models, based on Word2Vec tool and fastText tool. Models
has been trained on 1.37B tokens training data corpus and tested on a new
robust Croatian word analogy corpus. Results show that models are able to
create meaningful word representation. This research has shown that free word
order and the higher morphological complexity of Croatian language influences
the quality of resulting word embeddings.
</dc:description>
 <dc:description>Comment: In review process on LREC 2018 conference</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01804</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01806</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Directed Graph Embeddings</dc:title>
 <dc:creator>Meir, Reshef</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Definitions of graph embeddings and graph minors for directed graphs are
introduced. For the class of 2-terminal directed acyclic graphs (TDAGs) the
definitions coincide, and the class is closed under both operations. The
usefulness of the directed embedding operation is demonstrated be
characterizing all TDAGs with parallel-width at most $k$, which generalizes
earlier characterizations of series-parallel graphs.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01806</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01811</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Complexity Aspects of Point Visibility Graphs</dc:title>
 <dc:creator>Himmel, Anne-Sophie</dc:creator>
 <dc:creator>Hoffmann, Clemens</dc:creator>
 <dc:creator>Kunz, Pascal</dc:creator>
 <dc:creator>Froese, Vincent</dc:creator>
 <dc:creator>Sorge, Manuel</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>68R10, 05C62, 05C45, 05C69</dc:subject>
 <dc:description>  A point visibility graph is a graph induced by a set of points in the plane
where the vertices of the graph represent the points in the point set and two
vertices are adjacent if and only if no other point from the point set lies on
the line segment between the two corresponding points. The set of all point
visibility graphs form a graph class which is examined from a computational
complexity perspective in this paper. We show NP-hardness for several classic
graph problems on point visibility graphs such as Feedback Vertex Set, Longest
Induced Path, Bisection and $\mathcal{F}$-free Vertex Deletion (for certain
sets $\mathcal{F}$). Furthermore, we consider the complexity of the Dominating
Set problem on point visibility graphs of points on a grid.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2017-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01811</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01813</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Analysis of NOMA in Training Based Multiuser MIMO Systems</dc:title>
 <dc:creator>Cheng, Hei Victor</dc:creator>
 <dc:creator>Bj&#xf6;rnson, Emil</dc:creator>
 <dc:creator>Larsson, Erik G.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  This paper considers the use of NOMA in multiuser MIMO systems in practical
scenarios where CSI is acquired through pilot signaling. A new NOMA scheme that
uses shared pilots is proposed. Achievable rate analysis is carried out for
different pilot signaling schemes including both uplink and downlink pilots.
The achievable rate performance of the proposed NOMA scheme with shared pilot
within each group is compared with the traditional orthogonal access scheme
with orthogonal pilots. Our proposed scheme is a generalization of the
orthogonal scheme, and can be reduced to the orthogonal scheme when appropriate
power allocation parameters are chosen. Numerical results show that when
downlink CSI is available at the users, our proposed NOMA scheme outperforms
orthogonal schemes. However with more groups of users present in the cell, it
is preferable to use multi-user beamforming in stead of NOMA.
</dc:description>
 <dc:description>Comment: 13 pages, accepted in IEEE Transaction on Wireless Communications</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01813</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01815</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Profile Matching Across Unstructured Online Social Networks: Threats and
  Countermeasures</dc:title>
 <dc:creator>Halimi, Anisa</dc:creator>
 <dc:creator>Ayday, Erman</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this work, we propose a profile matching (or deanonymization) attack for
unstructured online social networks (OSNs) in which similarity in graphical
structure cannot be used for profile matching. We consider different attributes
that are publicly shared by users. Such attributes include both obvious
identifiers such as the user name and non-obvious identifiers such as interest
similarity or sentiment variation between different posts of a user in
different platforms. We study the effect of using different combinations of
these attributes to the profile matching in order to show the privacy threat in
an extensive way. Our proposed framework mainly relies on machine learning
techniques and optimization algorithms. We evaluate the proposed framework on
two real-life datasets that are constructed by us. Our results indicate that
profiles of the users in different OSNs can be matched with high probability by
only using publicly shared attributes and without using the underlying
graphical structure of the OSNs. We also propose possible countermeasures to
mitigate this threat in the expense of reduction in the accuracy (or utility)
of the attributes shared by the users. We formulate the tradeoff between the
privacy and profile utility of the users as an optimization problem and show
how slight changes in the profiles of the users would reduce the success of the
attack. We believe that this work will be a valuable step to build a
privacy-preserving tool for users against profile matching attacks between
OSNs.
</dc:description>
 <dc:description>Comment: 17 pages, 15 figures</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01815</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01816</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Z2Z4[\xi]-Skew Cyclic Codes</dc:title>
 <dc:creator>Aydogdu, Ismail</dc:creator>
 <dc:creator>Gursoy, Fatmanur</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Z2Z4-additive codes have been defined as a subgroup of Z2^{r} x Z4^{s} in [5]
where Z2, Z4 are the rings of integers modulo 2 and 4 respectively and r and s
positive integers. In this study, we define a new family of codes over the set
Z2^{r}[\bar{\xi}] x Z4^{s}[\xi] where \xi is the root of a monic basic
primitive polynomial in Z4[x]. We give the standard form of the generator and
parity-check matrices of codes over Z2^{r}[\bar{\xi}] x Z4^{s}[\xi] and also we
introduce skew cyclic codes and their spanning sets over this set.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01816</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01820</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resource Allocation for D2D Communications with Partial Channel State
  Information</dc:title>
 <dc:creator>Neogi, Anushree</dc:creator>
 <dc:creator>Chaporkar, Prasanna</dc:creator>
 <dc:creator>Karandikar, Abhay</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Enhancement of system capacity is one of the objectives of the fifth
generation (5G) networks in which device-to-device (D2D) communications is
anticipated to play a crucial role. This can be achieved by devising efficient
resource allocation strategies for the D2D users. While most of the works in
resource allocation assume full knowledge of the channel states, transmitting
it in every time slot reduces the system throughput due to extra control
overhead and leads to wastage of power. In this paper, we address the problem
of D2D resource allocation with partial channel state information (CSI) at the
base station (BS) and ensure that the interference from the D2D users do not
jeopardize the communications of cellular users (CUs). With partial CSI,
existing algorithms determine the Nash equilibrium in a distributed manner,
whose inefficiency in maximizing the social utility is well known as the
players try to maximize their own utilities. This is the first work in the D2D
resource allocation field in which within a game theoretic framework, an
optimal D2D resource allocation algorithm is proposed which maximizes the
social utility of the D2D players such that a social optimum is attained. Each
D2D player with the help of the BS learns to select the optimal action. We
consider the channel to exhibit path loss. Next, we consider both a slow and
fast fading with CU mobility and propose two heuristic algorithms. We validate
the performance of our proposed algorithms through simulation results.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01820</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01823</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DCSYNTH: Guided Reactive Synthesis with Soft Requirements for Robust
  Controller and Shield Synthesis</dc:title>
 <dc:creator>Wakankar, Amol</dc:creator>
 <dc:creator>Pandya, Paritosh K.</dc:creator>
 <dc:creator>Matteplackel, Raj Mohan</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>68N30</dc:subject>
 <dc:description>  DCSYNTH is a tool for the synthesis of controllers from safety and bounded
liveness requirements given in interval temporal logic QDDC. It investigates
the role of soft requirements (with priorities) in obtaining high quality
controllers. A QDDC formula specifies past time properties. In DCSYNTH
synthesis, hard requirements must be invariantly satisfied whereas soft
requirements may be satisfied &quot;as much as possible&quot; in a best effort manner by
the controller. Soft requirements provide an invaluable ability to guide the
controller synthesis. In the paper, using DCSYNTH, we show the application of
soft requirements in obtaining robust controllers with various specifiable
notions of robustness. We also show the use of soft requirements to specify and
synthesize efficient runtime enforcement shields which can correct burst
errors. Finally, we discuss the use of soft requirements in improving the
latency of controlled system.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01823</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01828</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Isogeometric Analysis Simulation of TESLA Cavities Under Uncertainty</dc:title>
 <dc:creator>Corno, Jacopo</dc:creator>
 <dc:creator>de Falco, Carlo</dc:creator>
 <dc:creator>De Gersem, Herbert</dc:creator>
 <dc:creator>Sch&#xf6;ps, Sebastian</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  In the design of electromagnetic devices the accurate representation of the
geometry plays a crucial role in determining the device performance. For
accelerator cavities, in particular, controlling the frequencies of the
eigenmodes is important in order to guarantee the synchronization between the
electromagnetic field and the accelerated particles. The main interest of this
work is in the evaluation of eigenmode sensitivities with respect to
geometrical changes using Monte Carlo simulations and stochastic collocation.
The choice of an IGA approach for the spatial discretization allows for an
exact handling of the domains and their deformations, guaranteeing, at the same
time, accurate and highly regular solutions.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01828</dc:identifier>
 <dc:identifier>Proceedings of the International Conference on Electromagnetics in
  Advanced Applications (ICEAA) 2015. IEEE, Sept. 2015, pp. 1508-1511</dc:identifier>
 <dc:identifier>doi:10.1109/ICEAA.2015.7297375</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01834</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prophet Secretary: Surpassing the $1-1/e$ Barrier</dc:title>
 <dc:creator>Azar, Yossi</dc:creator>
 <dc:creator>Chiplunkar, Ashish</dc:creator>
 <dc:creator>Kaplan, Haim</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In the Prophet Secretary problem, samples from a known set of probability
distributions arrive one by one in a uniformly random order, and an algorithm
must irrevocably pick one of the samples as soon as it arrives. The goal is to
maximize the expected value of the sample picked relative to the expected
maximum of the distributions. This is one of the most simple and fundamental
problems in online decision making that models the process selling one item to
a sequence of costumers. For a closely related problem called the Prophet
Inequality where the order of the random variables is adversarial, it is known
that one can achieve in expectation $1/2$ of the expected maximum, and no
better ratio is possible. For the Prophet Secretary problem, that is, when the
variables arrive in a random order, Esfandiari et al.\ (ESA 2015) showed that
one can actually get $1-1/e$ of the maximum. The $1-1/e$ bound was recently
extended to more general settings (Ehsani et al., 2017). Given these results,
one might be tempted to believe that $1-1/e$ is the correct bound. We show that
this is not the case by providing an algorithm for the Prophet Secretary
problem that beats the $1-1/e$ bound and achieves $1-1/e+1/400$ of the optimum
value. We also prove a hardness result on the performance of algorithms under a
natural restriction which we call deterministic distribution-insensitivity.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01834</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01843</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Tool Condition Monitoring Based on Parsimonious Ensemble+</dc:title>
 <dc:creator>Pratama, Mahardhika</dc:creator>
 <dc:creator>Dimla, Eric</dc:creator>
 <dc:creator>Lughofer, Edwin</dc:creator>
 <dc:creator>Pedrycz, Witold</dc:creator>
 <dc:creator>Tjahjowidowo, Tegoeh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Accurate diagnosis of tool wear in metal turning process remains an open
challenge for both scientists and industrial practitioners because of
inhomogeneities in workpiece material, nonstationary machining settings to suit
production requirements, and nonlinear relations between measured variables and
tool wear. Common methodologies for tool condition monitoring still rely on
batch approaches which cannot cope with a fast sampling rate of metal cutting
process. Furthermore they require a retraining process to be completed from
scratch when dealing with a new set of machining parameters. This paper
presents an online tool condition monitoring approach based on Parsimonious
Ensemble+, pENsemble+. The unique feature of pENsemble+ lies in its highly
flexible principle where both ensemble structure and base-classifier structure
can automatically grow and shrink on the fly based on the characteristics of
data streams. Moreover, the online feature selection scenario is integrated to
actively sample relevant input attributes. The paper presents advancement of a
newly developed ensemble learning algorithm, pENsemble+, where online active
learning scenario is incorporated to reduce operator labelling effort. The
ensemble merging scenario is proposed which allows reduction of ensemble
complexity while retaining its diversity. Experimental studies utilising
real-world manufacturing data streams and comparisons with well known
algorithms were carried out. Furthermore, the efficacy of pENsemble was
examined using benchmark concept drift data streams. It has been found that
pENsemble+ incurs low structural complexity and results in a significant
reduction of operator labelling effort.
</dc:description>
 <dc:description>Comment: this paper is currently under review by IEEE</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01843</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01845</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparison of Parallelisation Approaches, Languages, and Compilers for
  Unstructured Mesh Algorithms on GPUs</dc:title>
 <dc:creator>Balogh, G. D.</dc:creator>
 <dc:creator>Reguly, I. Z.</dc:creator>
 <dc:creator>Mudalige, G. R.</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Efficiently exploiting GPUs is increasingly essential in scientific
computing, as many current and upcoming supercomputers are built using them. To
facilitate this, there are a number of programming approaches, such as CUDA,
OpenACC and OpenMP 4, supporting different programming languages (mainly C/C++
and Fortran). There are also several compiler suites (clang, nvcc, PGI, XL)
each supporting different combinations of languages. In this study, we take a
detailed look at some of the currently available options, and carry out a
comprehensive analysis and comparison using computational loops and
applications from the domain of unstructured mesh computations. Beyond runtimes
and performance metrics (GB/s), we explore factors that influence performance
such as register counts, occupancy, usage of different memory types,
instruction counts, and algorithmic differences. Results of this work show how
clang's CUDA compiler frequently outperform NVIDIA's nvcc, performance issues
with directive-based approaches on complex kernels, and OpenMP 4 support
maturing in clang and XL; currently around 10% slower than CUDA.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01845</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01846</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast amortized inference of neural activity from calcium imaging data
  with variational autoencoders</dc:title>
 <dc:creator>Speiser, Artur</dc:creator>
 <dc:creator>Yan, Jinyao</dc:creator>
 <dc:creator>Archer, Evan</dc:creator>
 <dc:creator>Buesing, Lars</dc:creator>
 <dc:creator>Turaga, Srinivas C.</dc:creator>
 <dc:creator>Macke, Jakob H.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Calcium imaging permits optical measurement of neural activity. Since
intracellular calcium concentration is an indirect measurement of neural
activity, computational tools are necessary to infer the true underlying
spiking activity from fluorescence measurements. Bayesian model inversion can
be used to solve this problem, but typically requires either computationally
expensive MCMC sampling, or faster but approximate maximum-a-posteriori
optimization. Here, we introduce a flexible algorithmic framework for fast,
efficient and accurate extraction of neural spikes from imaging data. Using the
framework of variational autoencoders, we propose to amortize inference by
training a deep neural network to perform model inversion efficiently. The
recognition network is trained to produce samples from the posterior
distribution over spike trains. Once trained, performing inference amounts to a
fast single forward pass through the network, without the need for iterative
optimization or sampling. We show that amortization can be applied flexibly to
a wide range of nonlinear generative models and significantly improves upon the
state of the art in computation time, while achieving competitive accuracy. Our
framework is also able to represent posterior distributions over spike-trains.
We demonstrate the generality of our method by proposing the first
probabilistic approach for separating backpropagating action potentials from
putative synaptic inputs in calcium imaging of dendritic spines.
</dc:description>
 <dc:description>Comment: NIPS 2017</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01846</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01853</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lisco: A Continuous Approach in LiDAR Point-cloud Clustering</dc:title>
 <dc:creator>Najdataei, Hannaneh</dc:creator>
 <dc:creator>Nikolakopoulos, Yiannis</dc:creator>
 <dc:creator>Gulisano, Vincenzo</dc:creator>
 <dc:creator>Papatriantafilou, Marina</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The light detection and ranging (LiDAR) technology allows to sense
surrounding objects with fine-grained resolution in a large areas. Their data
(aka point clouds), generated continuously at very high rates, can provide
information to support automated functionality in cyberphysical systems.
Clustering of point clouds is a key problem to extract this type of
information. Methods for solving the problem in a continuous fashion can
facilitate improved processing in e.g. fog architectures, allowing continuous,
streaming processing of data close to the sources. We propose Lisco, a
single-pass continuous Euclidean-distance-based clustering of LiDAR point
clouds, that maximizes the granularity of the data processing pipeline. Besides
its algorithmic analysis, we provide a thorough experimental evaluation and
highlight its up to 3x improvements and its scalability benefits compared to
the baseline, using both real-world datasets as well as synthetic ones to fully
explore the worst-cases.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01853</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01858</identifier>
 <datestamp>2017-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cryptanalyzing an image encryption algorithm based on autoblocking and
  electrocardiography</dc:title>
 <dc:creator>Li, Chengqing</dc:creator>
 <dc:creator>Lin, Dongdong</dc:creator>
 <dc:creator>L&#xfc;, Jinhu</dc:creator>
 <dc:creator>Hao, Feng</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>94A60</dc:subject>
 <dc:description>  This paper analyzes the security of an image encryption algorithm proposed by
Ye and Huang [\textit{IEEE MultiMedia}, vol. 23, pp. 64-71, 2016]. The Ye-Huang
algorithm uses electrocardiography (ECG) signals to generate the initial key
for a chaotic system and applies an autoblocking method to divide a plain image
into blocks of certain sizes suitable for subsequent encryption. The designers
claim that the proposed algorithm is &quot;strong and flexible enough for practical
applications&quot;. In this paper, we perform a thorough analysis of their algorithm
from the view point of modern cryptography. We find it is vulnerable to the
known plaintext attack: based on one pair of a known plain-image and its
corresponding cipher-image, an adversary is able to derive a mask image, which
can be used as an equivalent secret key to successfully decrypt other
cipher-images encrypted under the same key with a non-negligible probability of
1/256. Using this as a typical counterexample, we summarize security defects in
the design of the Ye-Huang algorithm. The lessons are generally applicable to
many other image encryption schemes.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:date>2017-12-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01858</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01863</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Model Checking for Continuous Time Markov Chains via
  Sequential Bayesian Inference</dc:title>
 <dc:creator>Milios, Dimitrios</dc:creator>
 <dc:creator>Sanguinetti, Guido</dc:creator>
 <dc:creator>Schnoerr, David</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Probabilistic model checking for systems with large or unbounded state space
is a challenging computational problem in formal modelling and its
applications. Numerical algorithms require an explicit representation of the
state space, while statistical approaches require a large number of samples to
estimate the desired properties with high confidence. Here, we show how model
checking of time-bounded path properties % in a wide class of logics can be
recast exactly as a Bayesian inference problem. In this novel formulation the
problem can be efficiently approximated using techniques from machine learning.
Our approach is inspired by a recent result in statistical physics which
derived closed form differential equations for the first-passage time
distribution of stochastic processes. We show on a number of non-trivial case
studies that our method achieves both high accuracy and significant
computational gains compared to statistical model checking.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01863</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01866</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combined shared/dedicated resource allocation for Device-to-Device
  Communication</dc:title>
 <dc:creator>Mach, Pavel</dc:creator>
 <dc:creator>Becvar, Zdenek</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Device-to-device (D2D) communication is an effective technology enhancing
spectral efficiency and network throughput of contemporary cellular networks.
Typically, the users exploiting D2D reuse the same radio resources as common
cellular users (CUEs) that communicate through a base station. This mode is
known as shared mode. Another option is to dedicate specific amount of
resources exclusively for the D2D users in so-called a dedicated mode. In this
paper, we propose novel combined share/dedicated resource allocation scheme
enabling the D2D users to utilize the radio resources in both modes
simultaneously. To that end, we propose a graph theory-based framework for
efficient resource allocation. Within this framework, neighborhood relations
between the cellular users and the D2D users and between the individual D2D
users are derived to form graphs. Then, the graphs are decomposed into
subgraphs to identify resources, which can be reused by other users so that
capacity of the D2D users is maximized. The results show that the sum D2D
capacity is increased from 1.67 and 2.5 times (depending on a density of D2D
users) when compared to schemes selecting only between shared or dedicated
modes.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01866</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01867</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of group evolution prediction in complex networks</dc:title>
 <dc:creator>Saganowski, Stanis&#x142;aw</dc:creator>
 <dc:creator>Br&#xf3;dka, Piotr</dc:creator>
 <dc:creator>Koziarski, Micha&#x142;</dc:creator>
 <dc:creator>Kazienko, Przemys&#x142;aw</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  In a world, in which the acceptance and the social community membership is
highly desired, the ability to predict social group evolution appears to be a
fascinating research task, yet very complex. Therefore, the problem
decomposition has been performed, and a new, adaptable and generic method for
group evolution prediction in social networks (called GEP) is proposed in this
paper. The work also contains extensive evaluation of the GEP method for many
real-world social networks, including (1) analysis of numerous parameters (time
window type and size, community detection method, evolution chain length,
classifier used, etc.), (2) comparative analysis against other existing
methods, (3) adaptation of the transfer learning concept to group evolution
prediction, (4) enhancing the classification model with a more appropriate
training set, and (5) prediction of more distant and multiple following future
events. Additionally, many new predictive features reflecting the community
state at a given time are proposed as well as rankings of the features most
valuable for the classification process are provided. Moreover, the work
identified a number of problems of existing methods for evolution prediction.
The most severe are methodological issues, a narrow application area,
insufficient validation, superficial descriptions of the methods and conducted
experiments, as well as lack or unreliable comparisons with other methods.
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01867</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01870</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpretable Feature Recommendation for Signal Analytics</dc:title>
 <dc:creator>Banerjee, Snehasis</dc:creator>
 <dc:creator>Chattopadhyay, Tanushyam</dc:creator>
 <dc:creator>Mukherjee, Ayan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper presents an automated approach for interpretable feature
recommendation for solving signal data analytics problems. The method has been
tested by performing experiments on datasets in the domain of prognostics where
interpretation of features is considered very important. The proposed approach
is based on Wide Learning architecture and provides means for interpretation of
the recommended features. It is to be noted that such an interpretation is not
available with feature learning approaches like Deep Learning (such as
Convolutional Neural Network) or feature transformation approaches like
Principal Component Analysis. Results show that the feature recommendation and
interpretation techniques are quite effective for the problems at hand in terms
of performance and drastic reduction in time to develop a solution. It is
further shown by an example, how this human-in-loop interpretation system can
be used as a prescriptive system.
</dc:description>
 <dc:description>Comment: 4 pages, Interpretable Data Mining Workshop, CIKM 2017</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01870</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01871</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Classes of Distributed Time Complexity</dc:title>
 <dc:creator>Balliu, Alkida</dc:creator>
 <dc:creator>Hirvonen, Juho</dc:creator>
 <dc:creator>Korhonen, Janne H.</dc:creator>
 <dc:creator>Lempi&#xe4;inen, Tuomo</dc:creator>
 <dc:creator>Olivetti, Dennis</dc:creator>
 <dc:creator>Suomela, Jukka</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  A number of recent papers -- e.g. Brandt et al. (STOC 2016), Chang et al.
(FOCS 2016), Ghaffari &amp; Su (SODA 2017), Brandt et al. (PODC 2017), and Chang &amp;
Pettie (FOCS 2017) -- have advanced our understanding of one of the most
fundamental questions in theory of distributed computing: what are the possible
time complexity classes of LCL problems in the LOCAL model? In essence, we have
a graph problem $\Pi$ in which a solution can be verified by checking all
radius-$O(1)$ neighbourhoods, and the question is what is the smallest $T$ such
that a solution can be computed so that each node chooses its own output based
on its radius-$T$ neighbourhood. Here $T$ is the distributed time complexity of
$\Pi$.
  The time complexity classes for deterministic algorithms in bounded-degree
graphs that are known to exist by prior work are $\Theta(1)$, $\Theta(\log^*
n)$, $\Theta(\log n)$, $\Theta(n^{1/k})$, and $\Theta(n)$. It is also known
that there are two gaps: one between $\omega(1)$ and $o(\log \log^* n)$, and
another between $\omega(\log^* n)$ and $o(\log n)$. It has been conjectured
that many more gaps would exist, and that the overall time hierarchy would be
relatively simple -- indeed, this is known to be the case in restricted graph
families such as cycles and grids.
  We show that the picture is much more diverse than previously expected. We
present a general technique for engineering LCL problems with numerous
different deterministic time complexities, including $\Theta( \log^{p/q} n )$,
$2^{\Theta( \log^{q/p} n )}$, and $\Theta(n^{pq/(p+q)^2})$ in the high end and
$\Theta( \log^{p/q} \log^* n )$, $\smash{2^{\Theta( \log^{q/p} \log^* n )}}$,
and $\Theta((\log^* n)^{q/p})$ in the low end of the complexity spectrum ($p
\ge q$).
</dc:description>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1711.01871</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<resumptionToken cursor="138000" completeListSize="155308">2369777|139001</resumptionToken>
</ListRecords>
</OAI-PMH>
